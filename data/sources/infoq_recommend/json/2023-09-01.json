[
  {
    "title": "ChatGPT和OpenAI都在用的Redis，是如何从传统数据库升级为向量数据库的？",
    "url": "https://www.infoq.cn/article/TXWfVNYFWQPfPS1WKIbb",
    "summary": "<p>各行业的公司越来越认识到，制定数据驱动的决策是现在、未来 5 年、未来 20 年甚至更长时间内竞争的必要条件。数据增长（尤其是非结构化数据增长）达到了前所未有的水平，数据泛滥和人工智能时代已经来临。</p><p>&nbsp;</p><p>这一现实隐含的是，人工智能可以对海量数据进行有意义的分类和处理——不仅对 Alphabet、Meta 和微软等拥有庞大研发业务和定制人工智能工具的科技巨头是这样，对普通企业甚至中小型企业而言也是如此。</p><p>&nbsp;</p><p>精心设计的基于人工智能的应用程序可以极快地筛选极其庞大的数据集，以产生新的见解并最终推动新的收入来源，从而为企业创造真正的价值。但是，如果没有新出现的新事物——向量数据库，任何数据增长都无法真正实现可操作性和民主化。</p><p>&nbsp;</p><p>随着大语言模型的爆火，向量数据库也成为了热门话题。只需几行简单的 Python 代码，向量数据库就可以充当大语言模型廉价但高效的“外部大脑”。但我们真的需要一个专门的向量数据库吗？向量数据库究竟是炒作还是刚需？</p><p>&nbsp;</p><p>近期，在北京QCon大会之际，InfoQ有幸采访到了Redis 高级架构师史磊，听他聊一聊Redis向量数据库技术实践。</p><p>&nbsp;</p><p>在9月3-5日即将召开的QCon 北京 2023上，Redis 高级架构师史磊将带来以<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5477\">《搜索、探索、求索：Redis 向量数据库》</a>\"为主题的演讲分享。会前，InfoQ对史磊老师进行了专访，听他聊一聊Redis向量数据库技术实践。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p>&nbsp;</p><p>InfoQ：史磊老师您好，能先做下自我介绍吗？</p><p>&nbsp;</p><p>史磊：我目前在 Redis 工作，担任高级产品架构师，负责管理 Redis 在亚太区的技术事务。我的主要职责是协助 Redis 客户优化他们的 Redis 实例，指导他们在使用 Redis 的新功能时能够得到最佳体验；以及帮助Redis在中国的服务商取得成功。</p><p>&nbsp;</p><p>作为 Redis 原厂，我们维护着开源社区版，并且提供了企业版（Redis Enterprise）的软件。在亚太区，越来越多的客户开始了解 Redis 企业版的价值。然而，目前大多数人对 Redis 的理解还停留在开源版本或者一些经过修改的第三方版本上，对于 Redis 的核心功能和应用场景可能了解有限。因此，我主要的使命是帮助客户更好地利用 Redis 提供的工具，解决实际问题，满足业务需求。</p><p>&nbsp;</p><p>我在去年加入 Redis，之前我在新加坡从事科研工作，后来在一家金融科技创业公司负责开发 AI 产品。在那个公司，我已经使用 Redis 大约七八年时间，但主要限于开源版。加入 Redis 原厂后，我更深入地了解了 Redis 企业版，掌握了更多强大的功能。我希望借助自己的经验，帮助客户充分发挥 Redis 的潜力。</p><p>&nbsp;</p><p>InfoQ：您是什么时候开始关注向量数据库这个领域的？</p><p>&nbsp;</p><p>史磊：在加入 Redis 之前，我主要从事 AI 和大数据方面的产品开发。我涉猎过特征生成、存取方式以及实时 AI 处理等领域，并使用了许多工具。然而，直到我加入 Redis 原厂，我才真正了解到 Redis 也在向量数据库方向提供支持。Redis 的这种布局实际上已经有一段时间了。</p><p>&nbsp;</p><p>我们最初是通过一个搜索模块来支持搜索功能，这个模块从大约 2018 年开始就存在了。Redis 2.0 的搜索功能将其提升到了一个新的水平，使其更加容易和方便。从 Redis 2.4 开始，也就是去年 3 月份开始，我们正式支持向量搜索。在大型语言模型引起轰动之前，Redis 就已经开始在向量数据库领域布局。由于 Redis 在各行业广泛应用，一经推出向量搜索功能，全球范围内的许多客户就开始使用了。</p><p>&nbsp;</p><p>随着大型语言模型的兴起，向量数据库的应用进入了新的阶段。起初，人们可能只是用向量查询来处理简单的图片、视频、音频或文档等内容，提取和搜索一些基本的向量特征。但随着大型模型的普及，人们开始探索如何更好地使用向量数据库，将其应用到更高的维度、更广泛的范围以及更快的请求速度上。对于一个向量数据库而言，以前大家的认识更多是小众、性能要求不高，而现在这些观念正在被快速转变。在这个过程中，Redis 经历了很多考验。作为一个向量数据库，随着大型模型的兴起，许多核心企业应用，比如像 ChatGPT、OpenAI 这样的应用，开始在后台使用 Redis。这使得 Redis 在满足客户需求方面有了更多的合作机会。</p><p>&nbsp;</p><p>同时，Redis 的搜索模块也在不断发展壮大。我们通过收集来自客户的第一手资料，产品团队将客户在实际应用中遇到的需求以及在 AI 和大数据环境下的新需求，迅速转化为产品，更好地为客户提供服务。</p><p></p><h2>Redis向量数据库技术实践</h2><p></p><p>&nbsp;</p><p>InfoQ：我注意到您提到了 ChatGPT 和 OpenAI，他们已经在使用 Redis。那他们是否将 Redis 作为唯一的向量数据库使用？这方面有哪些信息可以分享吗？</p><p>&nbsp;</p><p>史磊：根据我了解，ChatGPT 和 OpenAI 并不仅仅使用 Redis 作为唯一的向量数据库，他们也在与其他向量数据库合作。因为技术的更新和迭代非常迅速，Redis 已经成立了专门的团队来负责向量数据库的研究和开发，并与多个不同的企业合作。</p><p>&nbsp;</p><p>在 Redis 的官网上，我们已经展示了与许多 AI 大模型领域的合作案例，包括与 ChatGPT 等的合作。然而，具体细节和哪些实际用例正在使用 Redis，以及它们的具体情况，因为这些领域变化迅速，所以我目前没有最新的相关信息。</p><p>&nbsp;</p><p>InfoQ：您之前提到的是在 2018 年，Redis引入了向量搜索的模块。当时具体是什么情况？我们是基于客户需求开发这个功能的吗？还是我们自己看到了这个大的趋势？</p><p>&nbsp;</p><p>史磊：从 2018 年开始，Redis引入了一个搜索模块。当时，这个搜索模块主要支持标量搜索，而不是向量搜索。在那时，Redis使用中的一个痛点是，尽管它是一个内存中的键值存储系统，查询时如果不逐个扫描每个键，就没有很好的方法来根据查询条件检索数据。</p><p>&nbsp;</p><p>因此，2018 年的版本主要是为了解决搜索这一痛点。它允许用户在 Redis 中存储大量的键，而且这些键的检索速度非常快。但是，如何在这些键中快速找到满足特定条件的数据呢？通过内部迭代和升级，从 1.0 版本到 2.0 版本，我们收集了许多客户的需求。这些需求主要集中在如何快速创建索引、如何快速执行查询，以及如何让应用程序自动完成这些操作。2020 年我们推出的 2.0 版本中就着重于这些方面。随后，在 2.4 版本中（从去年3月开始，在ChatGPT等大模型流行之前），我们正式引入了向量搜索功能。在这个过程中，我们收到了许多客户的请求，他们问是否可以将 Redis 的快速标量搜索扩展到向量化数据的搜索。我们的产品团队听取了这些客户的需求，在初期支持了基本的向量相似性搜索功能。</p><p>&nbsp;</p><p>随着时间的推移，我们不断地加入各种主流搜索模式和算法，逐步完善这个功能，使其变得更加成熟。现在，Redis 在 7.2 版本中进行了重大更新，带来了许多新功能。值得注意的是，我们不再将搜索作为一个模块进行推广，而是将其视为 Redis 提供的主要功能之一。这意味着 Redis 不仅可以用作缓存和主数据库，还可以用作向量数据库。</p><p>&nbsp;</p><p>InfoQ：随着功能的增加，Redis的定位也发生了一些变化？</p><p>&nbsp;</p><p>史磊：是的。最初，Redis的产品定位确实是作为一种内存数据库，专注于提供内存存储，并通过模块来扩展其功能。然而，随着时间的推移，我们对Redis进行了重新定位。现在，我们提供了Redis企业版软件，将所有功能集成在其中。只要使用Redis企业版，就能够获得全部功能，无需额外购买或部署特定组件，即可直接使用。</p><p>&nbsp;</p><p>对于客户而言，如果他们已经在使用Redis作为缓存，他们现在只需将向量存储到Redis中，便可以直接进行向量搜索。这对客户来说非常直观且易用，同时也不会增加额外的系统复杂性，无需引入其他产品或功能。</p><p>&nbsp;</p><p>InfoQ：我想了解一下关于这个模组研发历程的情况，以及它在研发过程中所经历的一些迭代。此外，当它与 Redis 数据库结合时，是否遇到了什么问题？如果有技术上的难题，您是如何解决的？能介绍一下相关的技术实践过程吗。</p><p>&nbsp;</p><p>史磊：Redis在不同领域的广泛应用促使我们从各个领域收集了对Redis搜索的需求。起初，有客户提出了希望在内存中进行向量搜索的需求。我们认真倾听了这些客户的意见，并着手实现这个功能。</p><p>&nbsp;</p><p>在实现过程中，从初始的POC（Proof of Concept）项目开始，我们将这个功能作为一个附加组件添加到Redis中。随着时间的推移，我们将它演变成了Redis的主推功能。在这个过程中，Redis的主产品与我们的模组功能相互协同进化。举个例子来说，Redis企业版在解决日常应用中的痛点方面拥有许多特性，比如内建的强大代理（proxy）。这个代理能够自动将请求导向相应的分片，不管是单一分片还是集群模式，从而保证了Redis的存储和吞吐量能够自动调整，无需额外干预。对客户而言，借助内建的代理，可以简化业务逻辑，无需关心是单一模式还是集群模式。这同时也解决了搜索的难题，因为Redis每个分片是单线程模式，如果请求集中在一个分片上，性能会受到影响。但如果使用集群模式，客户端需要维护连接并了解每个分片上的数据，这会使得业务逻辑变得复杂。</p><p>&nbsp;</p><p>企业版解决了这些困难，同时也使得搜索更加容易。在Redis集群版中，由于已经内置了代理，搜索请求能够自动分配到各个分片上执行，并以最低的成本整合结果。这确保了Redis在搜索中不再受制于单一分片的性能，同时提供更大量、更快速的搜索。这种搜索的扩展性和速度得益于Redis企业版内置的代理。</p><p>&nbsp;</p><p>在开发Redis搜索过程中，由于需要维护额外的数据结构，如索引，我们的产品团队进行了优化，确保快速的分配和查询这些结构，使得Redis企业版性能比开源版有了显著提升。</p><p>&nbsp;</p><p>此外，我们正在推出的企业版本中，包括最新的7.2版本，已经引入了预览版的功能。在搜索方面，我们解决了每个分片上搜索仍然受限于单线程限制的问题。通过多线程方式，我们实现了同时搜索，这在测试中已经实现了超过10倍甚至16倍的性能提升。这也说明了搜索有许多方法可以进一步优化性能，这是一个不断进化和不断完善的过程。</p><p>&nbsp;</p><p>InfoQ：把上述功能融入到 Redis ，赋能 Redis数据库，时间上花了多久呢？</p><p>&nbsp;</p><p>史磊：这项技术的演进过程从最初的讨论到研究，再到研发，以及现在的预览版功能，经历了相当长的时间。根据我了解，这个功能的实际测试时间至少超过一年，从最初的讨论到实际测试的过程确实需要一段时间。而在规划和实施这些功能之前，所花费的时间绝对不止一年。</p><p>&nbsp;</p><p>Redis的产品团队投入了大量的时间和精力，甚至设立了一个专门的团队，负责确定Redis作为向量数据库需要实现的功能。这个团队需要思考有哪些核心组件可以完成这些功能，还需要与其他团队合作。整个过程需要跨足多个团队的合作，因此这是一个长期发展的过程。</p><p>&nbsp;</p><p>InfoQ：鉴于大模型如此受欢迎，以及数据库的重要性，您是否认为在这个人工智能与大数据的时代，数据库变得尤为重要？是否必须要研发新的数据库，以满足不断增长的需求？</p><p>&nbsp;</p><p>史磊：我认为现在的向量数据库已经成为刚需，因为它解决了传统数据库无法解决的几个核心问题。传统数据库主要基于关键词进行精确搜索，即存在或不存在的模式。而向量数据库提供的是近似搜索，当我提供一张图片、一段文字或者一个语音时，它能够找到相似的匹配项，而不仅仅是0和1的结果。它通过打分机制给出近似值，这是传统数据库无法实现的。</p><p>&nbsp;</p><p>同时，传统的关系型数据库的索引方法也无法直接适用于现在的向量数据库。因为在底层，包括计算、数据存储以及应用层面，向量数据库与传统数据库完全不同。起初，向量数据库可能只是作为关系数据库的一个补充。然而，随着大数据、大模型和人工智能的发展，对于向量的存储和查询以及快速性能都提出了更高的要求，只有向量数据库才能够满足这些要求。</p><p></p><h2>向量数据库的需求会持续上升吗</h2><p></p><p>&nbsp;</p><p>InfoQ：未来向量数据库的需求会持续上升吗？</p><p>&nbsp;</p><p>史磊：我认为这是一个持续上升的过程。随着大模型的兴起，对向量数据库的需求不断增加。许多传统的向量数据库也在不断进行迭代和更新，一些以前不支持向量数据库的产品也在声称自己支持，不断地添加这一功能。因此，这种需求将持续存在，这是一个不断洗牌、淘汰不足的过程。</p><p>&nbsp;</p><p>InfoQ：目前有一些人认为未来的每个数据库都会自然而然地、本地支持向量嵌入和向量搜索。您对这种观点有何看法？如果这种趋势确实出现，它会对向量数据库行业产生什么影响，可能会有哪些积极的方面，或者可能会带来哪些挑战？</p><p>&nbsp;</p><p>史磊：从技术角度来看，几乎任何存储系统或查询系统都可以通过添加功能来支持向量搜索、查询或存储。从这个角度来说，技术上并没有问题。然而，在实际应用中，我们可能会逐渐趋向于一种或两种常用的类型，其他的方式可能会逐渐淘汰。尽管它们都是数据存储或数据库系统，但它们通过不同的方法来满足索引和查询的需求。传统的数据库很难直接支持向量查询，因为在底层设计上缺乏对向量查询的有效支持。尽管可以通过添加功能来实现，但这可能变得笨拙且不够便捷。</p><p>&nbsp;</p><p>新兴的向量数据库可能更适应当前的需求，但它们可能会引入系统的复杂性。例如，客户可能需要同时使用传统数据库、关系数据库和向量数据库，这会增加维护、成本和开销。因此，我们需要找到一个良好的平衡点，一个系统既能满足向量数据库的要求，同时也能满足传统查询功能的需求。找到这样的组合是关键。作为客户，如果能够使用一个系统来高效地完成不同类型的功能，而不是选择传统系统再另外添加功能，维护成本和各种成本都会降低。</p><p>&nbsp;</p><p>在这种情况下，我认为 Redis 可以很好地实现这种平衡。Redis不仅是广泛使用的应用，作为企业版，它还提供了完整的企业级应用生态系统，可以帮助客户满足各种需求。无论是向量搜索还是标量搜索，在 Redis 中都是以 key-value 的方式存储在内存中，查询效率都很高。此外，Redis还具有强大的混合查询功能，允许同时查询向量和其他类型的数据，如文本、数值或GPS信息。这种原生的混合查询功能使得 Redis 在向量数据库领域具有显著优势，同时保持高性能。</p><p></p><h2>AIGC浪潮下，开发者该如何“武装”自己？</h2><p></p><p>&nbsp;</p><p>InfoQ：作为一个在数据库领域有多年经验的老师，您认为现在程序员如果希望在AI和向量数据库领域发展，需要掌握哪些关键技能呢？</p><p>&nbsp;</p><p>史磊：当前技术的迭代速度极快，去年使用的产品和经验可能在今年已经变得过时，或者新的技术已经涌现。在这种情况下，我认为首先我们需要更深入地了解现有系统。以 Redis 为例，大多数人可能知道它在缓存方面表现出色，但除此之外，Redis在其他领域的应用可能并不为人所知。作为技术从业者，了解主流产品的底层架构和功能，以及它们能够实现的功能非常重要。</p><p>&nbsp;</p><p>我们需要不断地更新知识，尤其是在向量数据库和大模型等新兴技术兴起之后。作为技术人员，要积极拥抱新技术，深入了解它们的工作原理和应用场景。不是从已有技术跳跃到崭新的技术，而是要利用自身积累的经验，将新技术应用于现有的工作中。虽然这种技术转换是存在成本的，但我们需要找到最有效的方法来将转换成本降至最低，让技术为我们服务，而不是成为技术的奴隶。这需要经验、技术洞察力和不断的探索精神来实现。</p><p></p><h2>未来向量数据库市场会正向地“卷”</h2><p></p><p>&nbsp;</p><p>InfoQ：老师的话确实给了我们很有价值的启示。最后，我们可以探讨一个广泛受关注的话题，即向量数据库未来的发展。当前，向量数据库已经进入了热门阶段，许多相关技术也变得非常成熟，包括向量索引和传统数据库技术。然而，人们普遍关心的是，未来的发展将会走向何方，以及我们应该关注哪些趋势？</p><p>&nbsp;</p><p>史磊：根据我的个人观点，结合我多年来在 AI 和大数据领域的经验，以及对传统数据库的了解，我要说，几年前我无法预料到数据库领域能够如此迅速地发展至今的程度。</p><p>&nbsp;</p><p>在向量数据库方面，我认为它的出现受到了强烈的驱动力，这种驱动力能够快速淘汰那些不合适的技术，同时也会促使新技术的不断涌现，这是一个逐步筛选的过程。从长远来看，我坚信向量数据库将不断成熟，同时也会为不同的应用场景提供更加精准的向量搜索结果。</p><p>&nbsp;</p><p>以一个简单的例子来说明，我们可能需要实时、快速的搜索，也可能需要大规模特征搜索。在未来，这些需求可能会逐渐演变成不同的维度。我相信会有一些特定领域的向量数据库逐渐崭露头角，可能会涌现出一两个或者更多的适应特定场景的数据库类型。每个类型可能会在特定的领域得到优化，这将是一个整合与优化的过程。</p><p>&nbsp;</p><p>InfoQ：未来向量数据库会不像传统数据库那样，在国内涌现200多家出来？</p><p>&nbsp;</p><p>史磊：我认为数据库市场的持续扩张是不可避免的，这主要是因为技术的迭代速度非常快，同时技术门槛也在逐渐降低。当前存在着大量的需求，这将吸引越来越多的数据库甚至向量数据库加入竞争。然而，从业界角度看，这种市场扩张是有利的。它可以促使更多的技术和业务参与，尽管市场在一定范围内会有限制，但这将在一场竞争中筛选出更优秀的技术和解决方案，以更好地满足需求。</p><p>&nbsp;</p><p>我希望看到更多竞争者涌现在这个领域，同时也期待看到哪些技术能够经受住应用的考验，证明自己在实践中的可行性。对我而言，这种市场扩张应当是良性的。我们不希望看到恶性竞争，也不应该是通过贬低其他应用来凸显自身的优越性。我认为这对于行业的生态是不利的。相反，我期待一种良性竞争，让人们有更多优质的选择，从而推动整个领域的进步。</p><p>&nbsp;</p><p>嘉宾简介：</p><p>&nbsp;</p><p>史磊，现担任 Redis 高级架构师 (Senior Solution Architect)，致力于使用 Redis 企业版为客户提供产品架构方案咨询及设计、性能优化、Redis 技术的应用及推广等服务。他拥有超过十年的软件架构设计开发、大数据系统调度及优化、计算机视觉、金融科技人工智能等方面的产品及技术研发经验，拥有八年多的 Redis 开发、运维及使用经验。在加入 Redis 之前，他曾任新加坡某金融科技创新公司的人工智能架构负责人（Head, AI Architect）、新加坡国立大学数据科学研究所 (Institute of Data Science, NUS) 首席架构师等职位。</p><p>&nbsp;</p><p></p><h4>活动推荐：</h4><p></p><p>&nbsp;</p><p>以「启航·AIGC 软件工程变革」为主题的 <a href=\"https://qcon.infoq.cn/202309/beijing/schedule?utm_source=infoqweb&amp;utm_medium=wenzhang&amp;utm_campaign=10\">QCon 全球软件开发大会·北京站</a>\"将于 9 月 3-5 日在北京•富力万丽酒店举办，此次大会策划了向量数据库、大前端新场景探索、大前端融合提效、大模型应用落地、面向 AI 的存储、AIGC 浪潮下的研发效能提升、LLMOps、异构计算、微服务架构治理、业务安全技术、构建未来软件的编程语言、FinOps 等近 30 个精彩专题。</p><p>&nbsp;</p><p>会上，史磊老师将做以<a href=\"https://qcon.infoq.cn/202309/beijing/presentation/5477\">《搜索、探索、求索：Redis 向量数据库》</a>\"为主题的分享，探寻Redis数据库如何从传统数据库升级为向量数据库背后的技术实践，点击下方图片中的【二维码】了解详情~</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/4e/4e9f1ee9456d9e354efc7b53f9c02376.png\" /></p><p></p><p>大会报名仅剩最后 2 天，咨询购票优惠信息可联系票务经理 18514549229（微信同手机号）。</p>",
    "publish_time": "2023-09-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "谷歌发布Hive-BigQuery开源连接器，加强跨平台数据集成能力",
    "url": "https://www.infoq.cn/article/ew2TK8PeMsF5qfHt3jEX",
    "summary": "<p>最近，谷歌宣布<a href=\"https://cloud.google.com/blog/products/data-analytics/the-hive-bigquery-connector-is-ga\">正式发布Hive-BigQuery Connector</a>\"，简化Apache Hive和Google BigQuery之间的集成和迁移。这个开源连接器是一个Hive存储处理程序，它使Hive能够与BigQuery的存储层进行交互。</p><p>&nbsp;</p><p>这个新增选项支持在Hive中使用类SQI查询语言<a href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual\">HiveQL</a>\"对BigQuery进行读写。这样，数据工程师就可以在不移动数据的情况下访问和查询BigQuery数据集，而BigQuery的用户则可以利用Hive的工具、库和框架进行数据处理和分析。谷歌云解决方案架构师<a href=\"https://www.linkedin.com/in/julienphalip/\">Julien Phalip</a>\"写道：</p><p>&nbsp;</p><p></p><blockquote>Hive-BigQuery连接器实现了Hive StorageHandler API，使Hive工作负载可以与BigQuery和BigLake表集成。所有的计算操作（如聚合和连接）仍然由Hive的执行引擎处理，连接器则管理所有与BigQuery数据层的交互，而不管底层数据是存储在BigQuery本地存储中，还是通过BigLake连接存储在云存储桶中。</blockquote><p></p><p>&nbsp;</p><p><a href=\"https://hive.apache.org/\">Apache Hive</a>\"是一个构建在Hadoop之上的流行的分布式数据仓库选项，它允许用户在大型数据集上执行查询。<a href=\"https://cloud.google.com/bigquery/\">BigQuery</a>\"是谷歌云提供的无服务器数据仓库，支持对海量数据集进行可扩展的查询。为了确保数据的一致性和可靠性，<a href=\"https://github.com/GoogleCloudDataproc/hive-bigquery-connector\">这次发布的开源连接器</a>\"使用Hive的元数据来表示BigQuery中存储的表。</p><p>&nbsp;</p><p>该连接器支持使用MapReduce和Tez执行引擎进行查询，在Hive中创建和删除BigQuery表，以及将BigQuery和BigLake表与Hive表进行连接。它还支持使用Storage Read API流和Apache Arrow格式从BigQuery表中快速读取数据。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/8216fb07c296ce7bfb3060ec6d6b5295.png\" /></p><p></p><p>图片来源：谷歌数据分析博客</p><p>&nbsp;</p><p>根据谷歌云的说法，Hive-BigQuery连接器可以在以下场景中为企业提供帮助：确保迁移过程中操作的连续性，将BigQuery用于需要数据仓库子集的需求，或者保有一个完整的开源软件技术栈。</p><p>&nbsp;</p><p>借助<a href=\"https://cloud.google.com/bigquery/docs/migration-intro\">BigQuery Migration Service</a>\"，谷歌提供了<a href=\"https://cloud.google.com/bigquery/docs/batch-sql-translator\">BigQuery批处理SQL转换器</a>\"和<a href=\"https://cloud.google.com/bigquery/docs/interactive-sql-translator\">交互式SQL转换器</a>\"支持，可以将Hive查询转换为BigQuery特有的兼容ANSI的SQL语法。Phalip解释说：</p><p>&nbsp;</p><p></p><blockquote>这个新的Hive-BigQuery连接器提供了一个额外的选项：你可以保留原来的HiveQL方言的查询，并继续在集群上使用Hive执行引擎运行这些查询，但让它们访问已迁移到BigQuery和BigLake表的数据。</blockquote><p></p><p>&nbsp;</p><p>这不是谷歌为分析不同的数据集并减少数据转换而发布的第一个开源连接器：<a href=\"https://github.com/GoogleCloudDataproc/hadoop-connectors/tree/master/gcs\">Cloud Storage Connector</a>\"实现了Hadoop Compatible File System（HCFS） API，用于读写Cloud Storage中的数据文件，而<a href=\"https://github.com/GoogleCloudDataproc/spark-bigquery-connector\">Apache Spark SQL connector for BigQuery</a>\"则实现了Spark SQL Data Source API，将BigQuery表读取到Spark的数据帧中，并将数据帧写回BigQuery。</p><p>&nbsp;</p><p>Hive-BigQuery连接器支持Dataproc 2.0和2.1。谷歌还大概介绍了有关分区的一些限制。由于Hive和BigQuery的分区方式不同，所以该连接器不支持Hive PARTITIONED BY子句。但是，开发人员仍然可以使用BigQuery支持的时间单位列分区选项和摄入时间分区选项。</p><p>&nbsp;</p><p>感兴趣的读者，可以从<a href=\"https://github.com/GoogleCloudDataproc/hive-bigquery-connector\">GitHub</a>\"上获取该连接器。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/07/google-hive-bigquery-connector/\">https://www.infoq.com/news/2023/07/google-hive-bigquery-connector/</a>\"</p>",
    "publish_time": "2023-09-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从Kinesis到Timestream：探讨基于AWS的无服务器分析架构",
    "url": "https://www.infoq.cn/article/0dy0IW732TOp01GwiUNW",
    "summary": "<p>在基于事件驱动架构构建SaaS应用程序时，分析能力已经成为核心功能，因为它可以更容易地监控使用模式并以可视化的方式呈现数据。因此，这一功能很快成为SaaS平台用户的需求也就不足为奇了。</p><p>&nbsp;</p><p>这让我们灵光乍现，我们意识到，在为客户构建这个新功能的同时，我们也可以通过内部分析仪表盘更好地了解客户如何使用我们的系统。</p><p>&nbsp;</p><p><a href=\"https://jit.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">Jit</a>\"是一家安全创业公司，旨在帮助开发团队快速识别并轻松解决应用程序中的安全问题。我们的产品已经达到了一定的成熟度，在这个阶段，让用户能够直观地了解他们在他们的安全旅途中所处的位置是至关重要的。同时，我们也希望了解哪些产品功能对我们的客户和用户最有价值。</p><p>&nbsp;</p><p>我们开始思考如何最有效地构建一个分析解决方案，它从同一个源获取数据，并将数据呈现到几个不同的目标。</p><p>&nbsp;</p><p>第一个目标是客户指标湖，其本质上是一个随时间变化、租户分离的解决方案。其他目标则是第三方可视化和研究工具，利用相同的数据摄取架构进行更好的产品分析。</p><p>&nbsp;</p><p>在撰写本文时，我们的产品团队有在使用这类工具，如Mixpanel和HubSpot。团队使用这些工具收集关于单个租户使用情况和产品总体使用趋势的宝贵数据。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/7e/7e6c112e7210183be7d14b9a6b5e8d67.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d8/d8bac381c1122e6417f2af54d5a5a545.png\" /></p><p></p><p>如果你曾遇到过类似的工程挑战，那么阅读本文就对了，我们很乐意深入探讨如何使用无服务器架构从头开始构建这样一个系统。</p><p>&nbsp;</p><p>作为一个基于无服务器的应用程序，我们的主要数据存储是DynamoDB。然而，我们很快就明白，它并没有我们聚合和呈现分析数据所需的时间序列能力。使用我们现有的工具来实现这些将需要更长的时间，并且对于我们希望监控、度量并呈现给客户的每一个新指标，都需要大量的投入。因此，我们决定使用AWS构建块从头开始快速构建一个能够为我们提供我们需要的双重功能的东西。</p><p>&nbsp;</p><p>我们意识到，为了能够为每个客户创建个性化的图表，我们必须以时间序列的方式处理数据。此外，我们还要保持强大的租户隔离，确保每个客户只能访问他们独有的数据，从而防止任何潜在的数据泄露，这是这个架构的一个关键设计原则。这让我们开始寻找最经济、管理成本最低的工具。在本文中，我们将介绍我们为内部和外部用户构建新的分析仪表盘所需的技术考量和实现。</p><p>&nbsp;</p><p></p><h1>分析功能架构设计</h1><p></p><p>&nbsp;</p><p>架构设计从数据来源开始——即Jit的微服务写入的事件。这些事件代表了整个系统中发生的所有小事件，例如新发现的安全问题、已修复的安全问题，等等。我们的目标是监听所有这些事件，最终能够以时间序列的方式查询它们，并基于它们向用户呈现图表。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c4f753ae228d2bdf17bba96840fb072.png\" /></p><p></p><p></p><h1>AWS EventBridge</h1><p></p><p>&nbsp;</p><p>然后这些事件被喂给<a href=\"https://aws.amazon.com/eventbridge/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">AWS EventBridge</a>\"，它会根据预定义的标准处理和转换事件将它们转换为由数据、元数据和指标名称组成的统一格式。这可以通过使用<a href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-rules.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">EventBridge Rule</a>\"来实现。由于我们的架构已经是事件驱动的，而且所有这些事件已经被写入到不同的事件桥中，所以我们只需要在希望将“KPI相关”数据喂给分析源的地方通过编程的方式添加EventBridge Rule即可，这很容易做到。</p><p>&nbsp;</p><p>一旦数据和相关事件被转换成EventBridge Rule的一部分，它们就会被发送到Amazon Kinesis Firehose。这可以通过EventBridge Rule的Target功能来实现，它可以将转换后的事件发送给各种目标。</p><p>&nbsp;</p><p>被转换为统一Schema的事件必须包含以下参数才不会被过滤掉：</p><p>&nbsp;</p><p>metric_name字段，它映射到被度量的指标。元数据字典——包含有关事件的所有元数据，每个表（租户隔离）最终都是根据tenant_id参数创建的。数据字典——必须包含event_time，它告诉我们事件到达的实际时间（因为分析和指标总是需要在一段时间内进行度量和可视化的）。</p><p>&nbsp;</p><p>Schema结构：</p><p><code lang=\"null\">{\n \"metric_name\": \"relevant_metric_name\",\n \"metadata\": {\n   \"tenant_id\": \"relevant_tenant_id\",\n   \"other_metadata_fields\": \"metadata_fields\",\n   ...\n },\n \"data\": {\n   \"event_time\": ,\n   \"other_data_fields\": ,\n   ...\n }\n}</code></p><p>&nbsp;</p><p></p><h1>AWS Kinesis Firehose</h1><p></p><p>&nbsp;</p><p><a href=\"https://aws.amazon.com/kinesis/data-firehose/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">AWS Kinesis Data Firehose</a>\"（简称Firehose）是为分析引擎聚合多个事件并将其发送到目标S3存储桶的服务。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3b/3b4c9c912e89f8274e7e95eb1c05d30c.png\" /></p><p></p><p>&nbsp;</p><p>一旦事件数超过阈值（可以是大小或时间段），它们就以批次的形式发送给S3存储桶，等待被写入时间序列数据库和其他事件订阅者，例如需要获取所有租户事件的系统。</p><p>&nbsp;</p><p>Firehose在架构中发挥着重要作用。因为它会等待数据达到阈值，然后按照批次发送事件，所以当我们的代码启动并开始处理事件时，我们将从处理大小可预测的小批次事件开始，避免发生内存错误和其他意外问题。</p><p>&nbsp;</p><p>一旦达到其中一个阈值，Kinesis对要发送的数据执行最后的验证，验证数据严格是否符合所需的Schema格式，并丢弃任何不符合的数据。</p><p>&nbsp;</p><p>我们可以调用Firehose中的lambda来丢弃不符合要求的事件，并进行额外的转换和填充，如添加租户名称。这涉及到查询外部系统并使用环境运行信息来填充数据。这些属性对于下一阶段在时间序列数据库中为每一个租户创建表来说至关重要。</p><p>&nbsp;</p><p>在下面的代码部分中，我们可以看到：</p><p>&nbsp;</p><p>定义了批次窗口，在例子中是60秒或5MB（只要满足其中一个即可）；验证和转换所有到达事件的数据转换lambda，确保事件可靠、统一且有效。</p><p>&nbsp;</p><p>处理数据转换的lambda叫作enrich-lambda。请注意，<a href=\"https://github.com/serverless/serverless?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">Serverless Framework</a>\"会将其名称转换为叫作EnrichDashdataLambdaFunction的lambda资源，所以如果你也在使用Serverless Framework，请注意这个问题。</p><p>&nbsp;</p><p><code lang=\"null\">MetricsDLQ:\n Type: AWS::SQS::Queue\n Properties:\n   QueueName: MetricsDLQ\nKinesisFirehouseDeliveryStream:\n Type: AWS::KinesisFirehose::DeliveryStream\n Properties:\n   DeliveryStreamName: metrics-firehose\n   DeliveryStreamType: DirectPut\n   ExtendedS3DestinationConfiguration:\n     Prefix: \"Data/\" # This prefix is the actual one that later lambdas listen upon new file events\n     ErrorOutputPrefix: \"Error/\"\n     BucketARN: !GetAtt MetricsBucket.Arn # Bucket to save the data\n     BufferingHints:\n       IntervalInSeconds: 60\n       SizeInMBs: 5\n     CompressionFormat: ZIP\n     RoleARN: !GetAtt FirehoseRole.Arn\n     ProcessingConfiguration:\n       Enabled: true\n       Processors:\n         - Parameters:\n             - ParameterName: LambdaArn\n               ParameterValue: !GetAtt EnrichDashdataLambdaFunction.Arn\n           Type: Lambda # Enrichment lambda\nEventBusRoleForFirehosePut:\n Type: AWS::IAM::Role\n Properties:\n   AssumeRolePolicyDocument:\n     Version: '2012-10-17'\n     Statement:\n       - Effect: Allow\n         Principal:\n           Service:\n             - events.amazonaws.com\n         Action:\n           - sts:AssumeRole\n   Policies:\n     - PolicyName: FirehosePut\n       PolicyDocument:\n         Statement:\n           - Effect: Allow\n             Action:\n               - firehose:PutRecord\n               - firehose:PutRecordBatch\n             Resource:\n               - !GetAtt KinesisFirehouseDeliveryStream.Arn\n     - PolicyName: DLQSendMessage\n       PolicyDocument:\n         Statement:\n           - Effect: Allow\n             Action:\n               - sqs:SendMessage\n             Resource:\n               - !GetAtt MetricsDLQ.Arn</code></p><p>&nbsp;</p><p>下面是将Jit系统中的事件映射到统一结构的代码。这个EventBridge将数据发送到Firehose（以下是serverless.yaml的代码片段）。</p><p>&nbsp;</p><p>我们事件映射的代码示例。</p><p>&nbsp;</p><p><code lang=\"null\">FindingsUploadedRule:\n Type: AWS::Events::Rule\n Properties:\n   Description: \"When we finished uploading findings we send this notification.\"\n   State: \"ENABLED\"\n   EventBusName: findings-service-bus\n   EventPattern:\n     source:\n       - \"findings\"\n     detail-type:\n       - \"findings-uploaded\"\n   Targets:\n     - Arn: !GetAtt KinesisFirehouseDeliveryStream.Arn\n       Id: findings-complete-id\n       RoleArn: !GetAtt EventBusRoleForFirehosePut.Arn\n       DeadLetterConfig:\n         Arn: !GetAtt MetricsDLQ.Arn\n       InputTransformer:\n         InputPathsMap:\n           tenant_id: \"$.detail.tenant_id\"\n           event_id: \"$.detail.event_id\"\n           new_findings_count: \"$.detail.new_findings_count\"\n           existing_findings_count: \"$.detail.existing_findings_count\"\n           time: \"$.detail.created_at\"\n         InputTemplate: &gt;\n           {\n             \"metric_name\": \"findings_upload_completed\",\n             \"metadata\": {\n               \"tenant_id\": ,\n               \"event_id\": ,\n             },\n             \"data\": {\n               \"new_findings_count\": ,\n               \"existing_findings_count\": ,\n               \"event_time\": <time>,\n             }\n           }</time></code></p><p>&nbsp;</p><p>我们将在系统中已经存在的一个叫作“findings-uploaded”的事件（被其他服务监听）转换为即将被指标服务摄取的事件。</p><p>&nbsp;</p><p></p><h1>Timestream——时间序列数据库</h1><p></p><p>&nbsp;</p><p>作为一种实践，如果可能的话，你应该先使用你已经在使用的内部技术，然后在必要的情况下采用其他技术（以减少复杂性）。但对于Jit来说，DynamoDB已经不适用了。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/77/77b92f10e644067ff310aa3e46d17788.png\" /></p><p></p><p>&nbsp;</p><p>为了在AWS上处理时间序列数据（并执行各种查询）的同时保持服务合理的总拥有成本（TCO），我们需要探索新的选项。这些数据将在每个客户的自定义仪表盘（需要时间序列功能中呈现，并严格遵循上述的格式。在比较了可能的解决方案后，我们决定将Timestream作为架构的核心，它是一种全托管、低成本的数据库，具有SQL风格的查询功能。</p><p>&nbsp;</p><p>这是在实际当中查询这个数据库的示例代码片段。</p><p>&nbsp;</p><p><code lang=\"null\">SELECT * FROM \"Metrics\".\"b271c41c-0e62-48d2-940e-d8c80b1fe242\" \nWHERE time BETWEEN ago(1d) and now()</code></p><p>&nbsp;</p><p>虽然我们还调研了其他技术，比如Elasticsearch，但我们意识到，将其作为时间序列数据库要么难以管理和实现（例如，索引和执行租户隔离会更困难），要么成本会更高。而使用Timestream，每个租户一个表，这很简单，而且它更加经济，因为仅按使用收费，包括写入、查询和存储。乍一看收费的地方似乎很多，但我们的比较显示，根据我们可预测的使用情况和使用它提供的“心智上的轻松”（鉴于它是一个几乎零管理开销的无服务器亚马逊服务），它是更具经济可行性的解决方案。</p><p>&nbsp;</p><p>Timestream中的数据有三个核心属性可用于优化（你可以在<a href=\"https://docs.aws.amazon.com/timestream/latest/developerguide/concepts.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">文档</a>\"中了解更多相关信息）。</p><p>&nbsp;</p><p>维度（Dimensions）；度量（Measures）；时间（Time）。</p><p>&nbsp;</p><p>维度本质上是描述数据的字段，在我们的例子中就是每个客户的唯一标识符（取自用户元数据）和环境。我们利用这些数据从事件中提取出tenant_id，并将其作为Timestream的表名，从而实现了租户隔离。剩余的数据可根据这些字段进行分区，这使以后查询数据变得非常方便。我们使用的维度越多，查询时需要扫描的数据就越少。这是因为数据是根据这些维度进行分区的，从而有效地创建了索引。这反过来提高了查询性能并为我们带来了更大的规模经济效益。</p><p>&nbsp;</p><p>度量本质上是你要递增或枚举的值（如温度或重量）。在我们的例子中，这些是我们在不同事件中测量的值，非常适合聚合数据。</p><p>&nbsp;</p><p>时间很简单直观，它是事件的时间戳（写入数据库时），这在分析中也是一个关键功能，因为大多数查询和测量都基于特定的时间段或窗口来评估成功或改进。</p><p>&nbsp;</p><p></p><h1>使用Mixpanel和Segment可视化数据</h1><p></p><p>&nbsp;</p><p>在有了摄取、转换、批量写入和查询技术之后，构建仪表盘就很容易了。我们研究了使用Grafana和Kibana等流行的开源工具，它们与Timestream集成得很完美，但我们想在客户的UI中为客户提供最大化的定制能力，所以我们决定使用内部开发的可嵌入式图表。</p><p>&nbsp;</p><p>在Firehose按照预期格式将数据写入S3后，有一个专门的Lambda可以读取数据，然后将其转换为Timestream记录并写入（如上所述，每个租户一个表，在元数据字段中包含tenant_id）。然后另一个lambda将这些预格式化的数据发送到Segment和Mixpanel，为内部摄取和外部用户使用提供整个租户数据的俯瞰视图。</p><p>&nbsp;</p><p>我们利用Mixpanel和Segment的数据和公开查询Timestream的API（通过IAM权限实现租户隔离）为客户构建UI，让每个客户只能可视化他们自己的数据。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d52e21a1167545092ae4a93b6c38c7c.png\" /></p><p></p><p>这使得我们能够利用Mixpanel和Segment作为分析的支撑，为客户提供像乐高积木那样的图表构建块。</p><p>&nbsp;</p><p>通过利用Mixpanel和Segment等工具，我们可以对图表进行跨租户和跨客户洞察，并以此来优化我们为用户提供的功能和产品。</p><p>&nbsp;</p><p></p><h1>重要的注意事项</h1><p></p><p>&nbsp;</p><p>当说到Timestream和决定完全无服务器化，确实需要考虑成本和规模限制问题。我们上面讨论了Timestream的属性，每一个属性都有一个不能超过的阈值，知晓这一点很重要。例如，每个表的维度限制为128，度量的最大值为1024，因此你必须确保系统架构不超过这些阈值。</p><p>&nbsp;</p><p>在内存方面，主要有两种配置：内存和磁性存储（即长期存储。注意，这里的“磁性”是指AWS Timestream的长期经济型高效存储，而不是磁带）。相比之下，内存存储价格更高，但查询速度更快，时间窗口有限（在我们的例子中是2周）。理论上，你可以在磁性存储上存储多达200年的数据，但这一切都有成本问题（我们选择了一年，因为我们觉得这已经足够了，并且可以根据需要动态升级）。 AWS服务的好处在于大量繁重的工作是自动完成的，例如数据分层会自动从磁性存储迁移到磁盘。</p><p>&nbsp;</p><p>其他限制包括每个账户的表数量（阈值为50K），查询也需要至少10MB数据量（查询时间为1秒——可能不如其他引擎快，但成本优势足以让我们在查询速度上做出妥协）。因此，你应该了解总拥有成本，并优化查询，让它们始终高于10MB的限制，在可能的情况下甚至更高，同时还要减少客户端的延迟。解决这些问题的一个好办法是缓存数据，不要进行实时的完整查询，你可以通过联合查询将多个查询合并为单个查询。</p><p>&nbsp;</p><p></p><h1>无服务器乐高积木，永远的王</h1><p></p><p>&nbsp;</p><p>通过利用现有的AWS服务，我们能够快速提升分析能力，管理和维护开销很小，采用低成本的按用计费模式让我们获得了成本效益。这个可伸缩、灵活的系统的最大好处在于，随着客户需求的增加，它也可以轻松地添加新的指标。</p><p>&nbsp;</p><p>由于所有事件已经存在于系统中，并通过事件桥进行了解析，要找到新的相关指标并加入到现有框架中就变得很容易。你可以创建相关的转换，然后立即在系统中拥有一个可以查询的新指标。</p><p>&nbsp;</p><p>通过这个框架，我们可以在未来很容易地基于相同的聚合数据添加“消费者”。通过利用类似乐高的无服务器构建块，我们能够开发出一个可扩展的解决方案，不仅支持大量指标的并行增长，而且可以让架构适应业务和技术的不断演化。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/jit-analytics-architecture/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTI1OTU4NjMsImZpbGVHVUlEIjoienUwZXdmek5udElBMGdxSiIsImlhdCI6MTY5MjU5NTU2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.LtCig9TctTpJUbCostCcJ30OjGyB0xhIlKNW2Cvv8JM\">https://www.infoq.com/articles/jit-analytics-architecture/</a>\"</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/1ec9c642934b678e33feb4ab0\">什么是无服务器架构技术</a>\"</p><p><a href=\"https://xie.infoq.cn/article/9f25ab64f0c1e577b774df664\">引领下一代云计算技术的变革：无服务器架构</a>\"</p><p><a href=\"https://www.infoq.cn/article/dO8a2awAXclEWTUovyYb\">基于无服务器的架构落地与实践</a>\"</p><p><a href=\"https://www.infoq.cn/article/PfajEYJ1miEJyst7F5a8\">论无服务器架构的特征</a>\"</p>",
    "publish_time": "2023-09-01 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "智谱AI上线首款生成式AI助手智谱清言：基于中英双语对话模型ChatGLM2，支持100余种编程语言",
    "url": "https://www.infoq.cn/article/Keo5MOT4MavSIyyxTmII",
    "summary": "<p>8 月 31 日，<a href=\"https://www.infoq.cn/article/s4UU34IIB2IuFiJeeJ3L\">智谱AI</a>\"正式上线首款生成式AI助手“智谱清言”。目前，用户可通过苹果商店App Store、安卓主流应用市场（华为、OPPO、vivo、应用宝及小米）下载或在微信小程序搜索“智谱清言”进行体验。</p><p>&nbsp;</p><p>智谱清言基于智谱 AI 自主研发的中英双语对话模型 ChatGLM2，通过万亿字符的文本与代码预训练，结合有监督微调技术，以通用对话的产品形态成为更懂用户的智能助手，在工作、学习和日常生活中赋能用户，解答用户各类问题，满足用户问询需求。此外，智谱清言的代码生成能力让其化身为程序员们的编程助手，支持100 余种编程语言，代码生成更快更精确，问答更智能。</p><p>&nbsp;</p><p>作为生成式 AI 助手，创作和写作场景是用户最为广泛的需求之一，智谱清言对此进行了针对性打磨，在预训练、微调和强化学习的各个阶段进行了优化。ChatGLM2强大的语言理解能力让智谱清言可以更深入理解文本信息之间的逻辑关系，从非结构化的文本信息中抽取所需的结构化信息，源源不断地产生丰富、广泛、新颖的高质量原创内容，一方面让文案内容更专业更精准，一方面让用户拥有更加自由的文案创作空间，进而帮助用户实现“文案创作”场景下的提质增效。</p><p>&nbsp;</p><p>此外，智谱清言产品团队还创新集成了“灵感大全”模块，帮助用户轻松写需求，以便更好地驱动个人 AI 助手。截至目前，智谱清言“灵感大全”已收录300+个场景的需求模版，覆盖文案创作、职场必备、生活创意、虚拟对话、代码指令等垂直领域的常用生产需求，帮助新用户快速认知其作为提效助手的工作能力。同时，用户可通过“编辑后发送”功能在原有模板上修改，满足用户的个性化需求，多场景激发用户使用灵感。</p><p>&nbsp;</p><p>智谱清言还具备Improve功能，降低使用门槛。用户只需要确认自己要完成的任务，例如“爆款标题”“视频脚本”“采访提纲”，产品就可结合用户的输入行为理解用户意图，匹配到最适用的模板，还可以根据提示增加条件描述。</p><p>&nbsp;</p><p>据了解，智谱AI于2020年底开始研发 GLM 预训练架构，并训练了百亿参数模型GLM-10B，2021年利用MoE架构成功训练出万亿稀疏模型，2022年合作研发了双语千亿级超大规模预训练模型GLM-130B，并基于此千亿基座模型打造大模型平台及产品矩阵。</p><p>&nbsp;</p><p>今年6月，智谱AI将千亿模型ChatGLM升级到二代，模型支持的上下文长度扩展到32K，并大幅提高推理速度。基于基座模型能力的增强，智谱清言已具备更强大的性能，在多轮对话当中，作为一个“有知识、有记忆”的AI助手，智谱清言对上下文理解长度已从2K拓展至32K，储备了包括科学、技术、历史、文化、艺术、商业和其他垂直领域的丰富知识，以此保障用户人机对话体验，持续畅聊无压力。目前产品已具备通用问答、多轮对话、创意写作、代码生成以及虚拟对话等丰富能力，未来还将开放多模生成能力。</p>",
    "publish_time": "2023-09-01 11:01:26",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]