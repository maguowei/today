[
  {
    "title": "日均写7行代码，月薪3万程序员因代码量极少且差，试用期不合格被辞退",
    "url": "https://www.infoq.cn/article/e3AlIJAvAGbCbEFlGqhY",
    "summary": "<p></p><p>代码写得少又烂，离职少不了？</p><p></p><h3>程序员每天写7行代码被开除</h3><p></p><p>“代码写得少，离职少不了”。近期，一则有关程序员代码量的案件引起关注。</p><p></p><p>据中国裁判文书网显示，李某某与中科尚易健康科技（北京）有限公司产生了劳动争议。</p><p></p><p>判决书显示，李某某，男，1979年1月9日出生，于2020年11月2日入职中科尚易公司，岗位为机器视觉算法工程师，双方签订了劳动合同，期限为2020年11月2日至2023年11月1日，试用期为三个月，试用期工资为36000元／月。李某某离职前月平均工资为36000元。</p><p></p><p>2021年1月12日，中科尚易公司以李某某与其岗位不匹配、试用期不合格为由，明确告知李某某公司单方解除劳动合同的决定，并向李某某出示了《解除劳动合同通知书》。</p><p></p><p>2021年1月15日，李某某到开发区劳仲委申请劳动仲裁，要求：</p><p></p><p>1．中科尚易公司支付李某某2020年11月2日至2021年1月12日期间5天休息日加班工资16551．72元；</p><p></p><p>2．中科尚易公司支付李某某2021年1月1日至12日期间工资13241．37元；</p><p></p><p>3．中科尚易公司支付李某某违法解除劳动合同赔偿金36000元。</p><p></p><p>庭审中，中科尚易公司提交《新员工评价表》《李某某试用期工作量及工作质量评估》《人事管理制度》予以证明。</p><p></p><p>《新员工评价表》显示：被评价员工为李某某，评价日期为2021年1月11日，评价项目分为五大项目，包括：知识技能（本岗位相关）、职业素养、业绩表现、团队合作、沟通理解，每个大项目下分为3至5个小项，每个小项均分为四个评分等级，公司给李某某的评分极大部分为最低分，得出的综合评价意见为：</p><p></p><p>李某某试用期被证明不符合录用条件，具体体现在：</p><p></p><p>1．编程语言能力不足，两个多月唯一编写的机械臂控制代码质量极差，最后由其他同事代为重写；</p><p></p><p>2．试用期间提交的算法代码量很少，可交接的代码极少；</p><p></p><p>3．模型训练经验不足，对采集样本的影响因素分析不到位，总纠结于“开关灯”等不重要方面；对扩充样本也是过分着力在“裁剪”等不重要的细节上，造成很多反复浪费；</p><p></p><p>4．不服从小组工作安排，讲条件、推责任；</p><p></p><p>5．反复越级投诉，严重影响同事协作氛围；</p><p></p><p>6．个人工作不达标，延迟公司整体项目产品开发计划。</p><p></p><p>双方签订的《劳动合同书》中约定李某某任职研发部机器视觉算法工程师职务，其具体工作内容为：</p><p></p><p>1．参与医疗机器人项目的研发工作；</p><p></p><p>2．负责人体3D点云数据的实时运动跟踪编程及3D点云处理算法研究、选择和优化；</p><p></p><p>3．负责基于深度学习的人体姿态识别相关算法的研发与优化；</p><p></p><p>4．负责多个摄像头联合识别算法的研发；</p><p></p><p>5．负责基于深度学习的样本制作与训练；</p><p></p><p>6．负责将算法相关代码写成规范的软件并文档化；</p><p></p><p>7．参与产品项目的集成、调试、测试、验证等相关工作；</p><p></p><p>8．领导交办的其他工作。</p><p></p><p>《李某某试用期工作量及工作质量评估》显示：基于李某某上述岗位职责的要求，对试用期员工李某某的工作量及工作质量评估如下（综合评估见试用期员工评估表）：</p><p></p><p>一般工程师每天完成的代码量是100-200行，李某某作为公司聘用的富有经验的软件算法工程师，起码应该达到中位水平，即150行／天，2020年11月2日至2021年1月11日期间李某某完成3D点云处理算法0行；深度学习识别算法总计422行（其中包含70行因质量太差废弃不用的代码）；多摄像头联合识别算法0行；样本制作合计参与拍照时间约2天；样本训练参与工作量折合月7天；软件文档0个；集成、调试、测试、验证相关工作约3天。</p><p></p><p>也就是说，李某某在职72天，只完成了422行代码的编写，除去参与样本训练、集成、调试等相关工作占用的9天时间，在剩下的63天里，平均每天只写7行代码。</p><p></p><p>李某某对《新员工评价表》及《李某某试用期工作量及工作质量评估》的真实性均不认可，称其在职期间未见过该表，对评估结果不认可，工作质量评估的内容也未告知过其本人，不认可公司的解除理由。李某某对上述证据的真实性及证明目的不予认可。</p><p></p><p>关于是否违法解除劳动合同的问题，结合相关证据以及庭审笔录，一审法院认定中科尚易公司于2021年1月12日单方与李某某解除劳动合同，且不再为李某某提供办公设备，双方劳动合同于当日解除，解除理由为李某某试用期考核不合格、其与工作岗位不匹配。对于中科尚易公司关于以李某某存在1月13日至17日持续旷工、严重违反公司规定之情形与其解除劳动合同以及双方于2021年1月17日解除劳动合同的主张，无事实依据，一审法院不予支持。</p><p></p><p>因用人单位作出的开除、除名、辞退、解除劳动合同、减少劳动报酬、计算劳动者工作年限等决定而发生的劳动争议，用人单位负举证责任。</p><p></p><p>本案中，结合《劳动合同》，双方并未明确约定李某某试用期具体的考核标准，中科尚易公司在招聘时也未明确向李某某告知过试用期间的工作量及工作完成质量应达到的具体标准，故一审法院认定中科尚易公司对李某某并未设定具体的试用期录用标准。中科尚易公司提供的《新员工评价表》及《李某某试用期工作量及工作质量评估》均为公司单方制作，并未提交相关证据证明评定表、评估打分结果的具体依据，且表中评价意见未经李某某本人确认，属于主观评定，故一审法院对《新员工评价表》及《李某某试用期工作量及工作质量评估》评测内容不予采信。</p><p></p><p>中科尚易公司亦未提交其他证据证明李某某存在其他法定解除事由之情形，中科尚易公司以李某某试用期不符合录用条件为由与其单方解除劳动合同，无事实及法律依据，系违法解除劳动合同。李某某离职前月平均工资为36000元，且其在中科尚易公司工作年限不满六个月，经计算，中科尚易公司需支付李某某违法解除劳动合同赔偿金36000元。关于中科尚易公司主张无需支付李某某违法解除劳动合同赔偿金的主张，一审法院不予支持。</p><p></p><p>2021年2月24日，一审判决：一、中科尚易公司支付李某某违法解除劳动合同赔偿金36000元；二、中科尚易公司支付李某某2021年1月1日至12日期间工资13241．37元；三、驳回李某某其他申请请求。</p><p></p><p>上诉人中科尚易公司不服判决提起上诉，上诉请求：撤销一审判决第一项，改判中科尚易公司无需支付李某某违法解除劳动合同赔偿金36000元。</p><p></p><p>最终，二审判决，中科尚易公司的上诉请求不能成立，应予驳回；一审判决认定事实清楚，适用法律正确，应予维持。最终判决：驳回上诉，维持原判。</p><p></p><h3>程序员一天写多少代码算合格？</h3><p></p><p>在这个案件中，双方劳动争议的焦点在于，用人单位认为李某某在任职期间的工作表现其岗位不匹配、不合格。主要表现在代码量极少、代码质量差，编程能力差等方面，此外李某某本人还存在工作态度、价值观上的问题。李某某的综合表现导致其公司作出了与其解除劳动关系的决定。</p><p></p><p>由该案件也可以看出，对于程序员来说，代码量和代码质量非常重要。在业界也常常有关于</p><p></p><p>“程序员一天写多少代码才算<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651005558&amp;idx=1&amp;sn=843bf88d88a7326eb8904b7dd84b376d&amp;chksm=bdbeda258ac9533310e471cc5239f975346aad1f223a50eb7bde5fe300ac87e60971415f94d6&amp;scene=27#wechat_redirect\">合格</a>\"？”这样的讨论。</p><p></p><p>此前，在Quora上有这样一个问题 —— Google的工程师们每天写多少行代码？对此，Google的AdMob全栈工程师评论称，“我的同事最近和我分享了一组调查研究数据，一名高效的工程师每天能写100-150行代码，我嘲笑了他，表示这项预估值绝对要比实际值低”。</p><p></p><p>Raymond Farias为了证明上述估计值的错误，决定以他在谷歌工作效率最高的一个月为例，并使用了Google的一个内部工具来查看每天的代码增量，包括增删改查的代码行数。最后他将一个月的数据汇总然后平均到工作日得出最后结论是150，随后对他的其他同事进行了检测，最后得出的数据基本一致。</p><p></p><p>有一些数据显示，在国内公司，一些熟练程序员正常的生产率为每天100行代码左右。当然，这也因人而异。</p><p></p><p>事实上，代码量与“合格”、“优秀”这样的关键词没有直接的因果关系。我们不应当用代码量来评价一个程序员的好坏。就好比，一个作家并不能因为写作字数多而获得诺贝尔文学奖。</p><p></p><p>要想让代码量增多很简单，有很多方法可以实现。但这样多出来的代码有多少是真正有效的代码呢？本来 10 行代码可以实现的功能，非得用 100 行去实现，有什么意义呢？真正理想的代码应当是又好、又快、又精简的。</p><p></p><p>对于应届生以及初入职场的程序员来说，要求代码量无可厚非，因为，代码量在一定程度上是编程基础和熟练程度的体现。而对于有一定工作年限的程序员来说，再以代码量作为硬性指标和考核标准则显得有些机械，最核心关注的指标应该是代码质量，而非代码行数。</p><p></p><p>但是，编码是程序员的本职工作，如果代码量极少且质量又差，这显然是不负责任的。一个优秀的程序员不一定每时每刻都在编码，但应当以具备独立、深入思考，高效代码等能力时刻要求自己。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://wenshu.court.gov.cn/website/wenshu/181107ANFZ0BXSK4/index.html?docId=8bfa168edbc74c25aca03a56e3ac29b2\">https://wenshu.court.gov.cn/website/wenshu/181107ANFZ0BXSK4/index.html?docId=8bfa168edbc74c25aca03a56e3ac29b2</a>\"</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651005558&amp;idx=1&amp;sn=843bf88d88a7326eb8904b7dd84b376d&amp;chksm=bdbeda258ac9533310e471cc5239f975346aad1f223a50eb7bde5fe300ac87e60971415f94d6&amp;scene=27#wechat_redirect\">https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651005558&amp;idx=1&amp;sn=843bf88d88a7326eb8904b7dd84b376d&amp;chksm=bdbeda258ac9533310e471cc5239f975346aad1f223a50eb7bde5fe300ac87e60971415f94d6&amp;scene=27#wechat_redirect</a>\"</p><p></p>",
    "publish_time": "2022-09-04 10:16:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我庆幸果断放弃了SwiftUI：它还不够成熟",
    "url": "https://www.infoq.cn/article/V8U4t2ubMVrEBzyzl8ed",
    "summary": "<p></p><p></p><blockquote>SwiftUI很好，但是苹果对它投资不足。</blockquote><p></p><p></p><p>在2019年的 WWDC大会上，苹果推出了一个全新的 SwiftUI 框架，这是一个现代化的 UI 界面编码结构，它是基于 Swift从头开始构建的。新框架使用声明性范例，让开发者用更少的代码编写相同的 UI。</p><p></p><p>SwiftUI 的愿景是降低开发 iOS 门槛，吸引更多开发者、丰富 iOS 的业态。并且SwiftUI 可以“实现一次编码，可适应五端 Apple 产品平台”， 包括watchOS、tvOS、macOS 等，以此统一苹果平台的 UI 框架。</p><p></p><p>苹果传递出来的消息就像是说：“SwiftUI 是一个了不起的用户界面框架，而且 100% 绝对会成为苹果平台上应用开发的未来。”</p><p></p><p>这些年，也有一些用 SwiftUI 重写 UIKit 应用程序的案例，去年奈飞新版 iOS App 的登录界面也完全由 SwiftUI 重构。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/104d6dd708d46479fabd8690af4d1172.png\" /></p><p></p><p>本文的作者chsxf，是一家独立游戏工作室的首席开发，也是15年的苹果用户，他想尝试将SwiftUI放到自己的项目中，但是最终失败了。他发表了一篇博客，总结了尝试并放弃SwiftUI的过程，这篇文章在Hacker News上引发了开发者们的大量讨论：</p><p></p><p>“恕我直言，SwiftUI 是一个很好的机会，但苹果公司对它投资不足。这是一项很好的技术，响应式方法非常适合许多典型的基于视图的需求，但对如何处理边缘情况，文档中非常缺乏相关的说明。”</p><p></p><p>“这是个好主意，但SwiftUI的主要问题是完全不成熟。”“它具有复杂的行为，不适用于需要大容量或复杂UI的App。”</p><p></p><p>“而且SwiftUI改进太慢了。”......</p><p></p><p></p><h2>chsxf的博客原文翻译：</h2><p></p><p></p><p>最近，我手头正好有个“The Untitled Project”（名字还没想好）项目需要完成。考虑到配套创作工具CiderKit在发展成熟的过程中也变得愈发复杂，再加上创建各种窗口和UI元素的实际需求，我决定尝试用用SwiftUI。这是个宝贵的机会，能让我认真体验一把SwiftUI并探索其内部工作原理。</p><p></p><p>起初项目工作良好，我对SwiftUI的表现可以说非常满意，我甚至创建了自己的修改器，以便更轻松地显示警报消息。但美好的甜蜜期很快过去，接下来我就要说道说道SwiftUI的那些“坏毛病”了。</p><p></p><p></p><h3>实时检查器不好用</h3><p></p><p></p><p>接下来，我开始了SwiftUI探索之旅的第二站——为地图编辑器创建实时检查器。跟其他创作工具一样，这款检查器的功能就是选定一个对象，并把可检查的对应属性显示在一个临时的用户界面元素当中。过程当中，Swift协议和它处理泛型的方式也给我带来了不少麻烦，但这里我们就不过多展开了。</p><p></p><p>我还遇到了其他问题，因为SwiftUI高度依赖于View协议的实现结构，但View协议又有关联的类型，所以只能把它当成约束来用。好在配合some关键字和opaque类型等设计，我最终还是为可选对象找到了一种实现方法，让每个对象都能提供自身特定的UI元素。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/7956d6e023d355d63d3ad532266894b8.png\" /></p><p></p><p>之所以下决心选择SwiftUI，就是因为初步测试时效果不错。如上图所示，地图编辑器位于左侧，检查器位于右侧。起初，我测试了一个UI元素，那是个用于开灯和关灯的勾选框。它运行良好，所以我根本想象不到后续会出什么大乱子。</p><p></p><p>但在开始实现更复杂的检查器视图时，特别是涉及带有/不带步进器或颜色选择器的多个文本字段时，整个运行速度开始剧烈下降。SpriteKit视图一般都能以每秒60帧的完美速率呈现（只要用的不是英特尔孱弱的iGPU）。但每当SwiftUI更新检查器视图时（这种更新可能出现在移动过程中，甚至是在输入文本字段的时候），渲染速率都会下降到每秒10到15帧，而且相当不稳定。这显然让人无法容忍。</p><p></p><p>我认真做了一番分析，并发现了几个问题。首先，由可选对象提供的视图在每次重绘时都是在完全重新创建。我虽然通过缓存稍稍提升了性能表现，但实际体验仍然非常糟糕。事实证明，SwiftUI检查器视图就是没法提供合理的重绘速度。我在网上查找了解决方案，最后编写了一个延迟版本的ObservableObject，由它来强制每秒只发布一次更改（参见以下代码）。</p><p></p><p>import Combine</p><p>import Foundation</p><p></p><p>extension ObservableObject {\n    func delayed(_ delay: TimeInterval = 1.0) -&gt; DelayedObservableObject {\n        return .init(object: self, delay: delay)\n    }\n}</p><p></p><p>@dynamicMemberLookup</p><p>class DelayedObservableObject: ObservableObject where Object: ObservableObject {<p></p><p>    private var original: Object</p><p>    private var subscription: AnyCancellable?</p><p></p><p>fileprivate init(object: Object, delay: TimeInterval) {</p><p>        self.original = object</p><p>        subscription = object.objectWillChange</p><p>            .throttle(for: RunLoop.SchedulerTimeType.Stride(delay), scheduler: RunLoop.main, latest: true)</p><p>            .sink { [weak self] _ in self?.objectWillChange.send() }</p><p>    }</p><p></p><p>subscript(dynamicMember keyPath: WritableKeyPath) -&gt; Subject {</p><p>        get { original[keyPath: keyPath] }</p><p>        set { original[keyPath: keyPath] = newValue }</p><p>    }</p><p>}</p><p></p><p>随着重绘频率的降低，终于能比较顺畅地操作地图上的对象了，每秒的帧率浮动一般就只有个位数。但这会导致检查器中的值出现延迟，因此在地图编辑器的交互过程中（比如使用移动工具时）结果不准确，所以效果还是称不上完美。</p><p></p><p>但我觉得这可能只是个独立问题，并不能因此把SwiftUI一棒子打死。所以，我打算继续探索。</p><p></p><p></p><h3>越来越慢</h3><p></p><p></p><p>在实现了第一个检查器之后，我开始研究另一个主题：Sprite资产编辑器。利用这款工具，我可以用多个sprite拼接成复杂的资产，再最终为它们制作动画。它的显示效果就是主窗口中的一张表，出于学习的目的，我当然还是想继续用SwiftUI喽。毕竟初次尝试肯定会有种种问题，应该再给它一次机会。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d3e33ba0a7a6f71d36812e4018377b6a.png\" /></p><p></p><p>如大家所见，这是个复杂的窗口，包含多种不同上下文（上方的「Sprite资产数据库」列表，左侧的特定「Sprite资产数据库」内容，以及其他与选定Sprite资产对应的编辑器元素）。我需要为每个上下文创建一个视图，这些视图同时又是其他视图的「子视图」，然后把需要的数据传递给特定视图。</p><p></p><p>但上图展示的效果其实是在AppKit中完成的，因为我在SwiftUI一直实现不了预期的功能。大家应该注意到了，中间的SpriteKit视图上有三个按钮（分别是+、200%和-）。这些按钮只跟管理SpriteKit视图缩放的@State相关联。尽管几乎不涉及任何其他数据，在界面更新前单击这些按钮，也会产生将近一秒钟的巨大延迟。我刚开始以为是因为地图编辑器的SpriteKit主视图仍在后台渲染。所以我尝试在工作表显示出来后禁用渲染，但结果没有任何改变。</p><p></p><p>变更从一种环境传播至另一环境时，我也遇到了类似的延迟问题。这可以说是压死骆驼的最后一根稻草了，我决定放弃SwiftUI，继续用AppKit。</p><p></p><p></p><h3>总结</h3><p></p><p></p><p>其实没能在项目中用到SwiftUI，会让我感觉有点遗憾。我仍然觉得它是一项很棒的技术，只是可能不适合我的这个特定用例。但我真的不确定是不是自己的用法有问题。我打算在Nihongo no Kana的更新版本中再用用SwiftUI，毕竟那款iOS/iPadOS应用的重绘频率低得多，所以应该不会有太大问题。</p><p></p><p>也许SwiftUI还没做好全面替代AppKit的准备。The Untitled Project的CiderKit创作工具并不是作为Catalyst应用构建的，也不依赖于UIKit。但继续使用AppKit的最大优点，就是没有任何延迟而且一切功能完全符合预期。当然，整个构建过程更繁琐，而且自动布局功能也不怎么好用。但我至少可以更好地控制应用程序的行为，而且根据需求随意调整各种元素。</p><p></p><p>总之，经历了这么一番波折，我还是很庆幸自己果断放弃了SwiftUI。这可能是我在这个项目上做过的最明智的选择。</p><p></p><p>参考链接：</p><p>https://chsxf.dev/2022/08/28/5-tup-why-i-quit-using-swiftui.html</p><p>https://news.ycombinator.com/item?id=32630389</p><p>https://xie.infoq.cn/article/28af907f31baa7e7283a31ed4</p></p>",
    "publish_time": "2022-09-04 12:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Shopee被曝大规模毁约；东软回应成都核酸系统连续崩溃：与软件无关；GitHub 将关闭Trending热榜 | AI一周资讯",
    "url": "https://www.infoq.cn/article/A9S2fgAsLa7js9L6q1gX",
    "summary": "<p></p><p></p><blockquote>字节跳动下调期权授予价至每股155美元，3万员工获期权增发；2568万员工薪酬样本分析：证券业员工1年薪酬顶制造业员工4年；前华为软件副总裁谢炎加入理想汽车，职级仅次于李想；百度2022年二季度营收296亿元，李彦宏：在困难时期也要有理性的信心；两芯片巨头“互掐”：Arm起诉高通，拟瓦解其14亿美元收购案；马斯克正式通知终止收购推特，440亿美元收购案将迎来大结局？</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>突发，GitHub 即将下线 Trending 热榜</h4><p></p><p>9月1日，GitHub突然宣布，将于9月30日关闭Trending（趋势）功能，原因是rending Repositories 和 Trending Developers 的使用率较低。</p><p></p><p>Trending 功能主要是帮助开发者快速、方便地找到一些有潜力的开源项目，可以查看每天、每周、每月活跃且有趣的项目库。该功能自上线以来就受到了不少开发者喜爱。因此，很多开发者对GitHub突然将该功能下线的决定感到非常吃惊，甚至不满。</p><p></p><p>不过也有不少支持的声音。Apache SkyWalking 创始人吴晟在社交平台评论称，“很高兴看到 GitHub 这样做！无论（GitHub Trending）使用率低或高，此页面产生的噪音远大于价值。它只是一个纯粹的低价值营销工具。此举有益于健康和诚实的社区。”</p><p></p><h4>成都核酸系统连续崩溃！东软回应：与软件无关系，网络出现故障</h4><p></p><p>9月1日，成都宣布自9月1日至9月4日在全市范围内开展全员核酸检测。9月2日晚，成都核酸检测系统出现了异常，导致采样排队时间过长，核酸检测进度缓慢。</p><p></p><p>成都市疫情防控指挥部相关负责人在接受媒体采访时表示，9月2日17时30分左右，我市核酸检测系统因对短时超大并发量预估不足，导致系统出现卡顿问题。故障发生后，我们立即组织专业技术团队与承建商一起排查原因，积极抢修，系统在增加多台服务器、优化关键参数设置后逐步恢复，但还存在不确定性，我们正在努力加以解决。下一步，我市将采取错峰核酸检测采样、强化系统运行监控、加强问题响应等措施，努力保障核酸检测平稳顺利进行。</p><p></p><p>9月3日下午，东软集团发布《关于东软核酸系统的声明》，声明表示，成都疫情以来，为应对成都大规模检测并发的系统稳定性问题，东软全场景疫情病原体检测信息系统（以下简称东软核酸检测系统）紧急上线，于9月2日04时，系统首次投入使用。</p><p></p><p>系统上线后，发现有响应延迟、卡顿等现象，东软集团第一时间组织专家组和坚守现场的公司技术人员，与成都市相关部门一起，排查事故原因，强化安全防护，保证系统运行。据技术专家研判，目前出现的系统响应延迟、卡顿等现象与核酸检测系统软件无关。</p><p></p><p>9月3日零点左右，在进行网络调整之后，系统运行平稳顺畅，效率得到极大提升，当日共完成1200万样本采集量。9月3日13时左右，系统再次无法进行访问，经排查，发现是网络出现故障，在恢复网络连接后，系统于14时左右再次恢复运行。具体网络故障的原因，相关部门正在排查。</p><p></p><h4>前华为软件副总裁谢炎加入理想汽车，职级仅次于李想</h4><p></p><p>36氪从多位知情人士处获悉，目前，前华为消费者BG软件部副总裁、终端OS部部长谢炎已入职理想汽车，出任系统研发部负责人，职级位列M11，仅次于理想汽车创始人兼CEO李想的M12。</p><p></p><p>接下来，谢炎将积极推动理想汽车的操作系统和自研芯片落地，消息人士说，“目前谢炎已经快速投入在业务上，和各个研发条线开会，听取需求。”</p><p></p><p>据悉，谢炎负责的系统研发部主要是一些底层的智能化技术研发，包括理想汽车自研的操作系统、算力平台等。消息人士透露，理想汽车的算力平台业务还包括了自研智能驾驶芯片项目，而这个自研芯片项目已经有数十人的团队规模，且有明确的量产时间表。</p><p></p><h4>网传台积电内部决定放弃N3工艺，或因苹果不满意</h4><p></p><p>近日，业内人士“手机晶片达人”爆料，因为客户都不用，台积电内部决定放弃 N3 工艺，转攻 2023 下半年量产成本更优的 N3E 工艺。根据台积电路线图，N3 是公司的第一代 3nm，N3E 则是第二代。据爆料人透露，从苹果员工处了解到，他们对 3nm 第一个项目 Ibiza 效能不满，所以取消了 N3 Ibiza，短期内是看不到 3nm 的 M3 终端产品了。</p><p></p><h4>百度2022年二季度营收296亿元，李彦宏：在困难时期也要有理性的信心</h4><p></p><p>8月30日，百度发布了截至2022年6月30日的第二季度未经审计的财务报告。第二季度，百度实现营收296.47亿元，与上年同期相比下滑5%；归属百度的净利润（非美国通用会计准则）达到55.41亿元，同比增长3%，环比增长43%，超市场预期。财报显示，第二季度“百度核心”（即搜索服务与交易服务的组合）收入232亿元，预估226亿元，同比减少4%。在线营销收入为171亿元，同比下降10%，百度表示，下降的原因是因为新冠疫情在中国的某些城市的卷土重来。</p><p></p><p>百度第二季度财报数据财报发布后，李彦宏发布内部信表示，宏观环境的困难和挑战，相信每个人已经非常深刻地感受到。要充分认知困难，并在每个工作决策中充分考虑这个前提。“但是在困难时期，也要有理性的信心。”李彦宏表示，中国数字化和智能化转型为百度提供了巨大的增长机会，百度在一个有长期红利的赛道上，需要找出真正的变量，分析出百度的技术能够起到关键性作用的因素有多少。</p><p></p><h4>马斯克正式通知终止收购推特，440亿美元收购案将迎来大结局？</h4><p></p><p>8月30日晚间，据彭博社等外媒报道，<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247569173&amp;idx=1&amp;sn=e60510bae4f1e6dba3efdbaa050d68ef&amp;chksm=fbeb76dacc9cffccf207d2c4e73a5e4f52230ba113dfe7054926b3e5a52992a001e45397ca4f&amp;scene=27#wechat_redirect\">马斯克</a>\"提交了一份终止推特收购的通知。美国证券交易委员会的一份文件称，马斯克已经致函推特，强调了终止收购协议的其他原因。</p><p></p><p>这笔440亿美元的收购案或将迎来大结局。</p><p></p><p>马斯克方面称，最新发送的函件强调了终止并购协议的额外理由，一封来自前推特安全主管Peiter Zatko的举报信称成为焦点。马斯克在信函中花费大量篇幅陈述Peiter Zatko对该公司的指控，并将其作为终止收购交易的补充理由。</p><p></p><p>在指控文件中，Peiter Zatko提出，推特存在三大问题，系统和软件过时、无法抵挡外部黑客的攻击；员工权限混乱、能够随意访问用户数据；虚假账号数量检测流程存在漏洞。其中，虚假账号数量正是马斯克推特收购案的争议焦点。</p><p></p><h4>台积电总裁魏哲家：低端芯片短缺正成为供应链瓶颈</h4><p></p><p>近日，台积电总裁魏哲家表示，低端芯片的短缺，正在让整个半导体产业受到影响。他承认即使是台积电这一全球最大的芯片代工商，在加速向全球扩张的进程中也面临着产品交付延迟和其他限制。</p><p></p><p>其中很重要的一点就是，制造芯片的设备中缺少了一些低端芯片，从而阻止了更多芯片的生产。如尖端的极深紫外线光刻机（EUV）每台的成本超过1亿美元，但是如果其中一个价值10美分的芯片组件短缺，整个设备就无法出货。类似的还有，一辆售价5万美元的汽车可能因为没有50美分的无线电芯片而无法交付....</p><p></p><p>魏哲家表示，台积电的现有工厂已经无法满足低端芯片的需求。汽车制造商追求更多的功能，每年芯片的使用量增加了15%，而智能手机需要的电源管理芯片也出现了激增，是五年前的两到三倍。</p><p></p><h4>2022谷歌博士生奖学金名单公布，17位华人博士生入选</h4><p></p><p>近日，谷歌发布了 2022 年博士奖学金（Google PhD Fellowship）的获奖名单。项目公布名单显示，今年共有 61 位博士生分别入选 14 个方向，包括 机器学习方向 12 人，机器感知、语音技术与计算机视觉方向 9 人，自然语言处理方向 6 人，隐私与安全方向5人，人机交互方向7人。值得一提的是，今年有17位华人博士生入选，约占总数的三成。</p><p></p><h4>百度李彦宏：商业应用是人工智能的软肋，但进展最明显的还是自动驾驶</h4><p></p><p>9月1日，在2022世界人工智能大会上，百度创始人李彦宏表示：“人工智能发展多年，商业是其中的<a href=\"https://www.infoq.cn/article/cp6rdKJYBxRqmYzloHWW\">软肋</a>\"，而缺乏好的商业前景会让创业公司增长停滞、亏损，融资上市变得困难。即便对于大公司，也可能会让公司变得越来越不接地气，逐渐变成一个纯的研究部门。但说到商业应用，进展最明显的还是自动驾驶”。</p><p></p><h4>两芯片巨头“互掐”：Arm起诉高通，拟瓦解其14亿美元收购案</h4><p></p><p>9月1日，芯片公司Arm宣布，已向高通及高通最近收购的芯片设计公司Nuvia发起诉讼，指控其违反授权协议和侵犯注册商标。Arm向法院申请禁令，希望迫使高通销毁根据Nuvia与Arm的授权协议开发的设计。Arm认为，必须获得该公司的许可，才能将这些设计转让给高通。</p><p></p><p>据悉，高通去年斥资14亿美元收购Nuvia。高通公司称，Arm无权干涉高通或Nuvia的创新。高通总法律顾问Ann Chaplin说：“Arm的诉讼忽略了一个事实：高通拥有广泛而完善的授权，覆盖其定制的CPU，而且我们相信这些权利将得到确认。”</p><p></p><p>如果Arm的诉讼能成功，相当于瓦解了高通近些年来规模最大的一次战略收购。</p><p></p><h4>阿里云启动全球最大智算中心，总算力达12 EFLOPS</h4><p></p><p>8月30日，阿里云宣布正式启动张北超级智算中心，总建设规模为12 EFLOPS（每秒1200亿亿次浮点运算）AI算力，可为AI大模型训练、自动驾驶、空间地理等人工智能探索应用提供强大的智能算力服务。该智算中心以先进的技术架构，将衡量算力效率的核心指标“千卡并行计算效率”，从传统架构的40%提升至90%，可将算力资源利用率提高3倍以上。</p><p></p><h4>拼多多2022年第二季度营收314亿美元，研发费用同比增长12%</h4><p></p><p>8月29日，拼多多发布了2022年第二季度财报。财报显示，公司二季度实现营收314.4亿元，同比增长36%，市场预期236.45亿元，去年同期230.46亿元。在美国通用会计准则下，营销费用为113.434亿元，占收入的比例降至36%。拼多多进一步加码研发，本季度研发费用同比增长12%。按美国通用会计准则的经营利润为86.972亿元，归属于普通股股东的净利润为88.963亿元。618期间，平台手机、家电、美妆和日化等制造业品牌均实现了翻倍增长。</p><p></p><h2>开源工具</h2><p></p><p></p><h4>字节跳动开源 Volo：国内首个基于 Rust 语言的 RPC 框架</h4><p></p><p>8 月 30 日，字节跳动基础架构的开源项目 <a href=\"https://www.infoq.cn/article/9iXLu4KjAPg3ufHYmM3J\">CloudWeGo</a>\" 正式发布 Rust RPC 开源框架 Volo。Volo 是一个轻量级、高性能、可扩展性强、易用性好的 Rust RPC 框架，使用了 Rust 最新的 GAT 和 TAIT 特性。</p><p></p><p>GitHub 地址：<a href=\"https://github.com/cloudwego\">https://github.com/cloudwego</a>\"</p><p></p><p>官网：<a href=\"https://www.cloudwego.io/\">www.cloudwego.io</a>\"</p><p></p><p>在字节内部，Volo 已经落地多个业务和基础组件，并且取得了超预期的性能收益（与 Go 版本对比，不那么公平）。</p><p></p><p>Volo 与其它 CloudWeGo 开源项目一样，坚持内外维护一套代码，为开源使用提供了强有力的保障。同时，我们观察到 Rust 开源社区在 RPC 框架这块还比较薄弱，Volo 的开源希望能为社区的完善贡献一份力量，同时也能完善 CloudWeGo 生态矩阵，为追求性能、安全性和最新技术的开发者、企业以及 Rustaceans 开发 RPC 微服务、搭建云原生分布式系统提供强有力的支持。</p><p></p><h2>IT界热评新闻</h2><p></p><p></p><h4>字节跳动下调期权授予价至每股155美元，3万员工获期权增发</h4><p></p><p>据《科创板日报》获得的字节跳动内部邮件显示，该公司将下调其期权授予价至每股155美元。同时，该公司将进行一次期权特殊增发，员工如持有授予价高于每股155美元且尚未完全归属的期权，则有机会获得增发。这部分员工人数超过3万人。据了解，字节跳动上一轮期权授予价是每股195美元。业内人士评论认为，调低期权授予价，有助于回购机制的持续，也将利好在职员工和候选人，这意味着员工未来可以以更低价格，获得更多股票。</p><p></p><h4>2568万员工薪酬样本分析：证券业员工1年薪酬顶制造业员工4年。</h4><p></p><p>最近，金融行业的高薪酬引起热议。</p><p></p><p>据Wind数据统计，2018年至2021年，金融业员工年度平均薪酬是制造业的2.35倍、是其他行业的1.69倍。其中，证券业的薪酬又居于金融业的峰顶位置，该行业员工同期年平均薪酬是制造业的3.76倍、其他行业的2.71倍。而证券行业高管的薪酬水平则是“天花板”，在金融业中居首，是金融业高管的1.22倍、其他行业高管的2.62倍、制造业高管的2.83倍。</p><p></p><p>金融行业的高薪酬或将成为过去式。8月4日，财政部出台了《关于进一步加强国有金融企业财务管理的通知》，《通知》要求，金融企业应当严格遵守财经法律法规和制度规定，牢固树立过紧日子思想，以成本管控为中心，严格预算管理、强化内部控制。这则通知被广泛解读为对金融行业的“限薪令”。</p><p></p><h4>Shopee被曝大规模毁约：有准员工刚落地新加坡，被告知offer没了</h4><p></p><p>近日，据界面新闻报道，东南亚电商巨头Shopee被曝大规模取消offer。不少准员工在临近入职期却被毁约，其中主要包括Shopee在新加坡设立的岗位。有准员工刚落地新加坡，被告知offer没了。据多位采访对象确认，Shopee HR当前给出的解决方案是赔偿1个月工资，另外去往新加坡的其他金钱投入例如机票、酒店等，也声称后续会予以报销赔偿。</p><p></p><p>对此，Shopee回应界面新闻称：由于Shopee部分技术团队的招聘方案调整，一些技术相关岗位被关闭。我们正与相关人员持续沟通，会尽最大努力和支持帮助其妥善过渡。</p>",
    "publish_time": "2022-09-04 13:35:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "EMR 实战心得浅谈",
    "url": "https://www.infoq.cn/article/M0olvG4I2Cxe8H8qO6dI",
    "summary": "<p></p><p></p><blockquote>AWS Elastic MapReduce(以下简称 EMR) 是集齐数据接入、存储、计算、交互式查询、机器学习等一系列开源社区组件封装的云上托管大数据平台，用户可以基于 EMR 迅速拉起一套大数据集群，用于大规模数据处理、分析，使用时可根据实际业务所需灵活调配计算资源，一定程度上降低底层基础设施运维成本。AWS 是最早将大数据管理平台上云的云厂商，查询其官网发行版本记录，能检索到的最古老版本 EMR-4.2.0 发布日期为 2015 年 11 月 18 日，当是时大数据领域最火的三家 Hadoop 发行厂商：Cloudera、Hortonwoks、MapR，三分天下，互为犄角，世事难料的是几年后的今天惟 Cloudera 一家尚存。笔者 2015 年开始接触大数据，管理大数据平台方式从早期的 Apache 逐渐过渡到自动化管理 (CDH、HDP)，于 2020 年初入职朴朴后开始使用 AWS EMR，目前我司大数据平台为混合云架构模式：AWS EMR 结合 IDC CDH。朴朴大数据团队在平台构建过程中积累了大量的 EMR 使用实践和运维经验，受篇幅所限，无法一一展开说明，本文旨在提供一些关于如何玩转 EMR 的使用思路，中间夹以部分我司实践案例佐证，权作抛砖引玉之举。</blockquote><p></p><p></p><p></p><h1>朴朴云上数据平台</h1><p></p><p></p><p></p><h2>1. 架构简要</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/64/64d5d9b7dcef59c15afe5c4a694e4bad.png\" /></p><p></p><p>朴朴数据平台基础技术架构简图</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6f/6f26047265c3e91711df1fad9395caf1.png\" /></p><p></p><p>朴朴云上主体业务数据流转简图</p><p></p><p>EMR 在朴朴云上大数据平台担任计算单元角色，数据计算完毕后经由服务通道输出给业务平台 (平台架构图最顶层部分)，核心计算场景有：离线、实时、查询，三者比例约为 7:2:1。至于云上主体业务数据流转链路，我们使用 Apache Hudi 作为数据湖仓支撑基石，目前是以离线 + 实时双线同步链路方式支持数据入湖。湖仓架构是一种灵活的架构设计模式，本文篇幅有限，后续有机会笔者单开一篇进行论述。</p><p></p><h2>2. 离线计算场景</h2><p></p><p></p><p>我司近七成为离线计算，所支撑的业务场景繁杂多样：业务数据入湖仓 ETL、算法、数据报表、数据分析、仓储配送等，这些离线任务我们内部按照对业务影响程度制定了相关故障等级标准，达到核心故障级别的有：</p><p></p><p>业务库数据入湖仓主链路作为所有数据使用的保障基石，重要程度自然不言而喻。我司在算法域应用大体可分为：预测、推荐、规划三大类，部分算法任务的输出已嵌入业务流程中，典型如自动订补货、仓储商品调度配送等。对公司经营业务产生影响的数据报表，如：收益类、营销类、用户类、商品库存平衡等。</p><p></p><h2>3. 实时计算场景</h2><p></p><p></p><p>目前我司实时计算平台，已上线实时计算任务有 200+，场景涵盖：业务数据实时入湖仓 ETL、算法、数据报表、门店大屏等，与离线计算所不同的是实时计算要求响应时效性更高，基本等同于朴朴主体业务 (A/C 端) 响应速度，随着业务场景不断深化，会逐步按需提升实时计算任务。</p><p></p><p></p><h2>4. 查询计算场景</h2><p></p><p></p><p>查询计算平台基于 presto 封装实现，目前在我司应用场景涉及：BI 平台、即席式交互、跨源融合查询，因云上虚拟机自建 Clickhouse，其存储瓶颈较明显且成本又高，因此引入 Presto 实现跨源融合查询以支持 BI 平台查询湖仓 Hudi 明细表，如此一来湖仓中的数据可无需再同步至 Clickhouse，降低明细表数据传输及落地存储至 Clickhouse 过程开销。</p><p></p><p>除此之外，数据平台团队已在规划、开发实现统一查询服务平台，该平台上线后会提供如下功能：</p><p></p><p>支持统一的 HiveSQL 语法 &amp; 虚拟表查询。支持异步查询和任务优先级调度。支持 spark、presto、flink 等查询引擎。支持查询路由及负载均衡。多数据源融合查询。</p><p></p><p></p><h1>入门</h1><p></p><p></p><h2>1. EMR 集群单元构成</h2><p></p><p></p><p>开篇伊始，先简单了解下 EMR 集群单元架构。</p><p></p><p>AWS 官网介绍 EMR 部署模式有：EC2、EKS、Outposts、Serverless 这几种，后两者目前尚未在国内上线，而当前阶段 EMR On EKS 模式有使用场景限制 (仅支持 Spark 应用)，待之后具体调研使用后再作评论，本文着重于 EMR On EC2 模式进行说明。EMR 集群由三个组类构成：MASTER、CORE、TASK，典型的 EMR 集群实例组架构如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/811df5867d36f805da025c9ca1980ee0.png\" /></p><p></p><p></p><h3>MASTER NODE</h3><p></p><p></p><p>在 EMR 集群中 master node 扮演着管理者角色，诸如：</p><p></p><p><code lang=\"sql\">master node\n    | -- zookeeper server\n    | -- hdfs namenode、hdfs journalnode、hdfs zkfc\n    | -- yarn resourcemanager\n    | -- presto coordinator</code></p><p></p><p>等服务进程在此节点运行，因此一个集群中至少有一个 master node，若需要 HA 架构，可在部署时选择 Multi master 模式 (3 实例)，然后静待 EMR 集群初始化完毕即可。</p><p></p><p>以 HDFS 和 YARN 为例，Multi master 架构下 EMR5 集群中两个 namenode 节点以 active/standby 状态工作，resourcemanager 三节点分别以 active/standby/standby 状态工作；而 EMR6 集群中有所不同的是全部 master node 会启动 namenode 进程，并分别以 active/standby/standby 状态工作，间接提高 HDFS 集群可用性。集群中可通过如下命令获取服务进程状态：</p><p></p><p><code lang=\"javascript\">// hdfs namenode服务状态获取\nhdfs haadmin -getServiceState\n\n// yarn resourcemanager服务状态获取\nyarn rmadmin -getAllServiceState</code></p><p></p><p>高可用架构下当出现某个 master node 崩溃时，ZK/HDFS/YARN 等组件服务因具备故障转移机制，整体集群服务不受影响，EMR 后台会将故障 EC2 实例从集群中剔除并新增一个新 EC2 实例，待初始化完毕后 (含高可用配置操作) 重加入集群。</p><p></p><h3>CORE NODE</h3><p></p><p></p><p>core node 为弹性且可选实例组类型，承载着 datanode、nodemanager、worker 等计算存储角色，用户可自定义 HDFS 副本参数，若不设置会依据 EMR 默认值进行设定：</p><p></p><p><code lang=\"properties\">node &lt; 4，     默认设为1\n4 &lt; node &lt; 10，默认设为2\nnode &gt; 10，    默认设为3</code></p><p></p><p></p><h3>TASK NODE</h3><p></p><p></p><p>task node 为计算节点，一般承载着 nodemanager、worker 等计算角色，适用于应对不同计算资源所需的弹性计算场景，对于弹性 scale 频繁的计算场景，通过调整 task node 使用比例，起到消峰填谷作用的同时又能一定程度上控制和节省成本。</p><p></p><p></p><h2>2. 上手管理 EMR 集群</h2><p></p><p></p><p>作为新手玩家，如何上手管理 EMR 集群呢？笔者大致总结后可从以下方面初窥门径：</p><p></p><h3>部署</h3><p></p><p></p><p>EMR 控制台提供两种部署模式：快速、高级，快速选项模式用户可根据提供的模板，简单配置后即可构建集群，高级选项模式则提供给用户更多自主选择，支持从软件、硬件、集群设置、安全性四大方面自定义配置构建集群。一般而言，作为刚接触 EMR 的新手玩家，选择前者会比较方便，有开源大数据集群运维经验的用户，建议使用后者，可以相对灵活方式管理和部署 EMR 集群。</p><p></p><p></p><h3>集群配置</h3><p></p><p></p><p>自定义配置支持集群全局范围和实例组范围，参数项变更操作支持 json 或表格两种格式编辑，这里要注意的是 EMR 控制台页面&lt;集群配置&gt;只允许在集群构建初始化阶段定义，集群上线后即不可被修改，EMR 控制台在 5.21.0 及之后的版本支持实例组级别 (运行中) 服务配置项修改，具体配置项分发支持可检索参考官网发行版&lt;配置分类&gt;说明。</p><p></p><p></p><h3>监控</h3><p></p><p></p><p>EMR 原生提供部分指标并集成至 cloudwatch，用户可在控制台查看或到 cloudwatch 检索，常用指标基本已提供，若指标项不足以满足需求，可基于 Prometheus+Grafana 套件自行实现指标采集与监控告警。</p><p></p><p></p><h3>安全性</h3><p></p><p></p><p>用户在构建 EMR 集群前，建议事先定义创建好 VPC 网络、安全组及 IAM 角色，部署过程中引用这些安全性定义，当集群构建完毕后，所有 EC2 实例的安全访问即可实现受控，避免集群出现访问安全方面隐患。</p><p></p><p>此外，依据笔者亲身经历的经验教训总结，构建 EMR 集群时可参考如下原则：</p><p></p><p>GRAY/TEST 属性 EMR 集群单 Master 架构，PROD 属性 EMR 集群务必使用 Multi Master 架构。</p><p></p><p>原因：防止单 Master 节点崩溃导致重要集群被销毁。</p><p></p><p>Multi Master 集群初始化完毕后切记跟 AWS 团队确认 master/core node 分布情况。</p><p></p><p>原因：若 master 角色所在 EC2 实例节点分布不均，集中在个别底层硬件上，当此硬件出问题时波及的就是整个集群，较新的 EMR 版本因引入 placement group 机制，会在部署时自动分散开，为防万一，建议再核实一遍。</p><p></p><p>MASTER/CORE 实例组不建议使用 AMD CPU 机型。</p><p></p><p>原因：AMD CPU 机型虽然便宜一些，但在 AWS 北京 a、b 可用区域数量占比较少，容易集中在某些底层物理设施单元上 (机柜、服务器等)，且经测试验证系统稳定性相比 Intel CPU 机型也略差一些。</p><p></p><p></p><h1>进阶</h1><p></p><p></p><p>对于 EMR 已有初步认知和管理能力而言，下一步就是如何提高对其掌控力。</p><p></p><p></p><h2>1. 更优雅便捷地构建集群</h2><p></p><p></p><p>入门篇已简单介绍如何在控制台创建 EMR 集群，官网有详细的操作文档给予用户指引，在此介绍其他创建方式。</p><p></p><h3>集群克隆</h3><p></p><p></p><p>当集群出现故障或人为手动终止且该集群上存在许多用户自定义配置项时，在 EMR 控制台页面有个克隆功能，可通过此功能镜像式创建新集群，新集群构建时会自动同步旧集群用户自定义配置项，避免配置项丢失或遗漏。</p><p></p><h3>高级 API</h3><p></p><p></p><p>除 EMR 控制台外，用户还可基于 AWS CLI、AWS SDK、AWS WEB &nbsp;API 三种更高级定义的方式创建集群，先以 JSON 格式定义好集群模板，一键 POST 提交后静待十分钟，一个新鲜出炉的集群即已创建完毕。</p><p></p><h2>2. 集群环境初始化</h2><p></p><p></p><p>一个 EMR 集群要上线，并不止于构建完毕，还需对集群环境做初始化工作，通常初始化操作分两步：操作系统及平台组件环境。</p><p></p><h3>操作系统</h3><p></p><p></p><p>EMR 底层 EC2 实例所引用的系统映像已由后台针对大数据场景做针对性系统参数优化，因此，一般情况下用户无需再做定制化修改，只要初始化系统时区、Prometheus node_exporter 服务、dnsmasq、docker(若有网段定义冲突) 等基础服务设施即可。</p><p></p><h3>平台组件</h3><p></p><p></p><p>泛指 HDFS/YARN/SPARK 之类组件配置项，EMR 初始化生成的组件配置项大多为默认值或者通用化模板配置，部分场景会存在不适用问题，因此建议用户务必按照集群运行环境所需进行修改。</p><p></p><p>例：spark-env.sh 在初始化过程若不去掉 Standalone 配置，提交 SPARK Application 后会因运行架构冲突导致访问时无法正确解析 SPARK MASTER WEB 服务地址。</p><p></p><p><code lang=\"bash\">export STANDALONE_SPARK_MASTER_HOST=ip-xxx-xxx-xxx-xxx\nexport SPARK_MASTER_PORT=7077\nexport SPARK_MASTER_IP=$STANDALONE_SPARK_MASTER_HOST\nexport SPARK_MASTER_WEBUI_PORT=8080\n\nexport SPARK_WORKER_DIR=${SPARK_WORKER_DIR:-/var/run/spark/work}\nexport SPARK_WORKER_PORT=7078\nexport SPARK_WORKER_WEBUI_PORT=8081\nexport SPARK_PUBLIC_DNS=ip-xxx-xxx-xxx-xxx</code></p><p></p><p></p><h2>3. 自定义 AMI</h2><p></p><p></p><p>若用户需在 EMR 集群范围集成较多复杂组件，却又不想花费太多精力在部署运维上，可尝试使用自定义 AMI 映像方案。以我司为例，早期出于提交计算任务便利性和提高资源利用率考量，将调度平台 Airflow 与 EMR 混部，又因我司在 Airflow 使用场景较为复杂，部署运维不便，经调研后引入自定义 AMI 映像解决掉部署运维上带来的麻烦。</p><p></p><p>祸福相依的是此模式在持续稳定运行约一年后的某天突然爆雷：EMR 集群底层 EC2 实例所引用的自定义 AMI 映像被误删，这直接导致当天所有 EMR 集群无法扩容启动新 EC2 实例，基本处于半瘫状态。事发当天重新构建 AMI 映像，优先恢复 PROD 属性 EMR 集群，之后其余 EMR 集群分批铲除重新构建，过程持续近一个月才恢复到此前状态。</p><p></p><p>因此，备份的重要性，不言而喻。建议有在 EMR 集群内使用自定义 AMI 映像的用户，切记一定要保管好它，避免对线上生产环境造成损失。</p><p></p><p></p><h2>4. 监控告警完善</h2><p></p><p></p><p></p><h3>标签定义</h3><p></p><p></p><p>具体是指对 EC2 实例和 EMR 平台服务打标签，便于之后告警项治理。打标签应成为一种习惯，从管理角度其价值不言而喻。</p><p></p><p></p><h3>集群 EC2 实例指标采集</h3><p></p><p></p><p>在我司，EC2 实例上线前会以类 userData 方式自动安装 node_exporter 服务，之后由 Prometheus server 拉取这些系统层指标，指标落地后使用 Grafana 展示，最后结合 Alertmanager 及自研监控平台实现指标项告警。</p><p></p><p></p><h3>集群平台组件指标采集</h3><p></p><p></p><p>EMR 所提供的组件指标不能完全满足我司实际指标监控诉求，作为管理员可自行开发 exporter 服务将组件指标采集后汇聚到监控中心，依托于监控中心实现平台组件服务监控覆盖和告警能力，也可以将这些指标推送至 AWS cloudWatch 服务进行告警实现。</p><p></p><p></p><h2>5. scale 规则使用</h2><p></p><p></p><p>在没有 scale 机制的自建 Hadoop 集群，不可避免地会碰到计算资源问题 (不足或未用满)，一种典型的做法是将计算引擎运行在 K8S 上，与业务平台错峰使用，以提高整体资源利用率。在 EMR 上用户可基于 cluster 或 InstanceGroup 两个层面定义 scaling 规则，规则触发后即进行集群节点扩缩容操作。</p><p></p><p>scale 一般是应用在需动态伸缩的 Core/Task 节点，Core 相对而言伸缩偏稳定保守一些，建议按比例固定。因此 scale 着重应用于 Task 节点并分别按 OnDemand&amp;Spot 机型灵活配比，scale 配置时支持多种指标定义，用户可择其一或多指标组合形成多层次弹性伸缩规则。定义弹性伸缩策略时可参考如下规则：</p><p></p><p>按 CPU 内存最小化计算集群平均占用资源值，将其换算成 OnDemand 机型个数，这部分为常驻节点在上一条基础上，弹性部分引用 Spot 机型，因 Spot 属于竞争资源，存在被外界引用导致资源申请不到现象，生产环境使用应混搭不同机型，或按需申请此部分比例以 YARN 为例，建议按 cpu、内存、container 三个层级定义复合型弹性规则，规避单条规则定义局限性集群中创建多个 InstanceGroup，避免某个 InstanceGroup 资源伸缩受阻影响到集群计算效率</p><p></p><p>客观地说，EMR Scaling 确实是个很棒的功能，激进一点调配使用，集群资源利用基本可达如下效果</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/97/97b806931f3a33a1dba4876f0931477d.png\" /></p><p></p><p></p><h2>6. bootstrap</h2><p></p><p></p><p>一个 EMR 集群从触发创建请求到上线会大致经历这几个阶段：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/88/881db39202a5b99238fbf0c4036f6d3e.png\" /></p><p></p><p>于 EMR 初阶用户而言，上述阶段能感知到只有首尾阶段，其余部分基本像盲盒，对于中间过程执行情况一概不知。事实上这里列举的各个阶段皆有脉络可循：</p><p></p><p>申请 EC2 实例。从 EMR 管理控制台 InstanceGroup 入口可跳转到 EC2 实例控制台，那里可以观测到 EC2 实例运行情况。初始化系统。包含两部分：选择 AMI 系统映像启动 EC2 实例及系统环境初始化，这部分可查看操作系统日志获知执行情况。执行 userData。在 EMR 集群中较少定义，通常是在单独启动 EC2 实例场景应用，在操作系统初始化完毕之后执行用于自动化修改系统运行环境。执行 bootstrap。EMR 集群中对 EC2 实例启动后的初始化操作，与 userData 功效类似，执行结果可在 /emr 挂载点 bootstrap-actions 目录中获悉，以 controller、stderr、stdout 三个文本文件记录执行过程信息。安装集群组件及集群组件配置。在 bootstrap 执行成功后，EMR 内部以 puppet 任务方式执行集群组件安装及配置初始化，甚至于 HDFS HA 构建，详细执行过程信息可在如下路径获取，S3 上传会有一定滞后。</p><p></p><p><code lang=\"xml\">local路径: /var/log/provision-node/apps-phase/\n或\nS3路径: s3:////node//provision-node/apps-phase/\n</code></p><p></p><p>当上述阶段步骤执行全无问题后，即确认为集群节点服务部署正常，最后状态变更上线。</p><p></p><p></p><h2>7. Core NodeLabel</h2><p></p><p></p><p>EMR 集群上线时会设定一些资源调度策略，该策略会最终影响计算任务调度分布。为提高单集群可承载计算任务并行数量，我们对该策略设定做了一些调整：在原有的 Core NodeLabel 设置基础之上，修改为 exclusive=true ， 即分区独占模式。结合 YARN DominantResourceCalculator 调度策略，调整后 Core 队列有多少核 CPU，即可最高支撑多少个计算任务并行运行，在存算分离较彻底的 EMR 集群中使用 m5.8x、m5.12x 等实例机型作为 Core 节点，显著减低集群 Core 使用成本的同时还能提高集群计算并行度。</p><p></p><p>注意：EMR5 集群初始化时默认会将 CORE 节点设定为一个单独的 Node Label，YARN application 启动时 application master 进程只在 CORE 节点上运行，而 EMR6 集群已将此 CORE Node Label 机制默认关闭。</p><p></p><p></p><h2>8. 集群使用 RDS</h2><p></p><p></p><p>我司基于 Hive 构建企业级大数据平台元数据服务，存在多集群复用统一元数据库现象，从元数据库高可用及运维投入产出比方面考虑，选择 RDS 作为 Hive 等组件元数据库无疑是个明智之举，对于 Hive 元数据库这类读写 IO 要求不高的应用场景，甚至可开启多 A-Z 模式以提高其健壮性。</p><p></p><p>优点:</p><p></p><p>开箱即用，基本免运维，原生支持高可用。EMR 后台已对 JDBC 相关兼容性做适配。</p><p></p><p>缺点:</p><p></p><p>版本升级需重启 RDS 服务，诸如安全补丁之类升级会较频繁。需单独监测底层是否发生 A-Z 切换，若有集群需重启相关组件服务，确保连接有效。高版本 RDS 与 EMR 兼容性适配不佳，建议 RDS 不要超过 5.7 版本。</p><p></p><p></p><h2>9. 集群存储使用</h2><p></p><p></p><p>既已使用了 EMR，那么选择 AWS S3 作为主数据存储就是自然而然的选择，一者存算分离是使用趋势，二者 EBS 与 S3 相比存储成本不在一个量级。在 EMR 体系中，Core 节点作为主数据存储节点，承载着分布式文件系统角色，典型应用有：</p><p></p><p><code lang=\"cpp\">application log   //存储YARN运行中、运行完成的application log\ncheckpoint        //流计算作业状态存储\nhdfs&amp;hbase        //KV型分布式数据库</code></p><p></p><p>我们仅将 EMR 用于计算而不涉及主数据存储，基于 S3 存储强一致性前提 (2021 年 12 月上线)，已具备 checkpoint 或 hbase 场景迁移至 S3 可行性，我们将 checkpoint 从 HDFS 迁移至 AWS S3 后，集群 Core 节点只需存储 application log 及 hdfs 部分应用文件，显著降低存储成本。目前实时计算集群已支持近 200 个 Flink job 运行暂未发现明显问题，今后随着 Flink job 大规模使用，需关注 AWS S3 Bucket 吞吐性能，防止 put、get 达到一定上限，如存在此问题，建议与 AWS 团队沟通，或通过分区倒排序、加盐等方式进行处理，以支撑不断高并发、高吞吐场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/26/268b99d14d143de999951a1bf8324bde.png\" /></p><p></p><p>以客观角度而言，AWS EMR 这一产品确实是提供了诸如节省成本、AWS 服务集成、部署、可灵活地扩展、安全性、监控、界面化管理这些功能特性。相较于其他云厂商亦或开源社区集群管理解决方案相比，虽各有千秋，但也存在有一定的改进空间。</p><p></p><p>节省成本：小规模场景使用综合成本节省比较明显，当规模达到 PB 级时，EC2、EMR、S3、网络流量四者成本累计则未必，所以需要进一步进行架构优化，以获取最佳性价比。</p><p></p><p>监控方面：集群缺乏组件服务状态如健康程度、HA 状态等类指标查看，可根据需要利用 exporter 采集。</p><p></p><p>集群部署 &amp; 管理：基于快速构建集群设计思想，导致部署操作集成度较高，若过程出现异常，只能重新执行构建操作，无法断点连续操作，个别场景下集群验证有明显等待时间成本；EMR 组件只提供 initctl/systemd 系统进程管理方式，不支持按组件 / 进程级别进行启 / 停。</p><p></p><p>扩展伸缩：EMR scale 机制不支持以 CPU vCore 指标作为弹性伸缩规则，在混合计算业务场景 scale 伸缩某些时刻会不符合预期。</p><p></p><p>安全性：依托于 VPC 子网、安全组、IAM Role 等多重机制提供安全性保障，若结合 S3 层面数据安全访问管控，详见 AWS EMR 云上数据安全管控实践 一文。</p><p></p><p></p><h1>会通</h1><p></p><p></p><p>该阶段标志着用户对 EMR 这套产品体系架构的理解程度已达入木三分之境地，日常 EMR 相关使用问题随手可解。因此，笔者认为这一阶段的特点应当不拘泥于官方对 EMR 使用定义，而是要结合各自企业应用场景，灵活调配组装以适应和满足业务需求，形成独有的解决方案架构。</p><p></p><p></p><h2>1. EMR 集群单元管理调整优化</h2><p></p><p></p><h3>集群拆分</h3><p></p><p></p><p>早期，数据平台承载业务量不太，离线、实时计算任务集中在单一集群运行倒也问题不大，随着任务量暴涨、任务重要等级制定、任务属性划分的事项推进，我们按如下原则对集群进行拆分：</p><p></p><p>数据平台环境：PROD、GRAY、TEST</p><p></p><p>计算属性：离线、实时</p><p></p><p>拆分后集群单元从 3 个裂变为 4 个 (成本考量，GRAY、TEST 环境集群任务依然为混合模式运行)。</p><p></p><p>同城跨可用区集群切换实现</p><p></p><p>要知道云计算设计之初衷，便是假设一切皆不可靠。实际使用中 EMR 集群发生局部范围崩溃是个常态化现象，更有甚者，集群级别停服也偶有发生，因此早在 2020 下半年我们已开始规划当集群出现大面积崩溃或停服时如何快速恢复的方案，恢复方案历经多个迭代，迄今为止，我们已实现计算集群恢复时长从 2 小时 + 缩短至分钟级，实现思路请看下文。</p><p></p><p></p><h4>a. &nbsp;分离集群单元</h4><p></p><p></p><p>不同计算属性集群切换方案因其集群计算依赖差异性，切换方案自然有所不同，因此在切换操作前务必先按离线、实时计算属性做好分离工作。</p><p></p><p></p><h4>b. &nbsp;离线计算集群切换</h4><p></p><p></p><p>离线集群切换实现前提有四：</p><p></p><p>计算、存储分离。EMR 只负责相对单纯的计算承载体，数据存储方面则由 AWS S3 服务提供，确保集群切换时底层数据存储统一。元数据。元数据不应存储于 EMR 集群内，应外挂于集群之外，我司将其外挂至 RDS，以确保 EMR 集群故障时元数据不丢。收拢离线集群任务提交入口。以我司为例，在最初计算集群服务上线前即已规划限制离线任务提交入口为 Airflow、Livy(Spark Rest 服务化提供载体，之后将以 Kyuubi 替代)，其余任务提交通道拒不提供。另行开发实现 Livy 负载均衡服务并以域名形式对外提供，调度 Airflow 集群则以 Gateway 方式加入计算集群。</p><p></p><p>当需要进行集群切换操作时，只需修改调度 Airflow 集群中环境信息、Livy 或 Kyuubi 服务域名解析指向到新 EMR 集群即可实现切换。</p><p></p><p></p><h4>c. &nbsp;实时计算集群切换</h4><p></p><p></p><p>受限于此前实时计算集群灾备切换尚未实现，未将计算任务按 (CPU/MEM) 属性分流到不同集群，个别任务会因底层计算 container 资源争抢受影响，导致计算延迟。相比于离线计算，实时计算集群切换实现要更加复杂，在计算存储分离、元数据统一的前提下，我们从以下方面实现了实时集群平滑切换：</p><p></p><p>任务提交入口实现。</p><p></p><p>我司当前 Flink 任务主要分为 FlinkSQL、JAR 两种类型，前者占比约九成，为方便用户使用 Flink 实时计算能力，数据平台研发人员基于 Flink+YARN API 另行开发实现一套流计算作业管理平台，既用于流计算作业编码提交，也用于集群作业管理，收拢实时计算任务提交入口。早期流计算作业管理平台与 EMR 集群捆绑式部署，使得仅支持单一集群提交指向，经迭代几个版本之后，目前已具备多集群指向提交能力。</p><p></p><p>checkpoint 机制。</p><p></p><p>checkpoint 机制作为卡死实现实时计算集群切换最重要的一道关卡，这点是毋庸置疑的。我司一开始使用 Spark StructedStreaming 处理实时计算任务，基于开发易用性、流计算处理机制、实时计算趋势等方面考虑于 2021 年上半年全面切换为 Flink。在使用 StructedStreaming 及 Flink 期间每逢有集群切换操作时，checkpoint 迁移与恢复都是令人无比头疼的事，中间分别做了两次 checkpoint on S3 方案调研工作，都受限于 S3 最终一致性问题效果不佳，所幸的是 AWS S3 在 2021 年底实现强一致性支持，简单验证了下基本满足 checkpoint 使用需求，最后基于 checkpoint on s3 可行性前提，我们规划及开发了任务在多集群内切换功能实现。</p><p></p><p>结合 PROD 环境离线、实时集群拆分操作，至此集群单位裂变为 7+(中间为保障实时计算高等级任务运行，再独立出一个集群单元)。</p><p></p><p></p><h2>2. 集群内资源使用调整优化</h2><p></p><p></p><h3>机型使用</h3><p></p><p></p><p>我们在 EMR 集群底层 EC2 实例使用选择上基本围绕着 C、M、R 三种机型，几种机型主要区别在于 vCPU/memory 的比例，C 型适用于 CPU 计算密集型任务 (除非极度需要 CPU 算力，不然成本相近条件下，不妨优先考虑 M 型)，R 型适用于内存需求比较高的计算场景 (需缓存大量数据在内存中计算)。基于实际计算任务运行所需，在较大规模生产集群中我们选择以 m5/m5a.8xlarge 机型为主，m5/m5a.4xlarge 机型为辅，次之规模集群则按业务计算属性灵活搭配。</p><p></p><p>至于 G 型属于 ARM 芯片架构，因 EMR 是个多组件嵌套大型集群平台，且我司有对部分组件做二开，从集群组件底层兼容性适配验证考量，暂未纳入使用，我司目前将 G 型用于 Cassandra 数据库集群，计算效率有比较明显的提升。</p><p></p><p></p><h3>资源组调配优化</h3><p></p><p></p><p>EMR 集群构建时可选择实例组管理方式: 统一实例组、实例队列。</p><p></p><p>我们主要使用统一实例组方式构建集群，结合自定义 scale 规则管理集群计算资源，原因如下：</p><p></p><p>a. EMR-Managed scaling 方式按照节点负载进行弹性伸缩，规则局限性很明显。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/59/59a6feefb00422dac579057ec1e226ed.png\" /></p><p></p><p>b. 至于不使用实例队列 (InstanceFleet) 的原因也是因为规则存在明显局限性，如一旦在集群创建时定义好实例组类型，之后无法进行实例组配置修改，对于需长期运行的生产集群，管理灵活度欠佳。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/ea9391b256027ae0df474978f93c972f.png\" /></p><p></p><p>C. 使用自定义 scale 规则，管理员可以定义多个指标 (如集群存储使用占比、Container Pending 值、内存使用值等) 作为弹性规则供 AWS 后台判断是否需对集群进行扩缩容。</p><p></p><p>因 Spot 类型资源较容易出现紧俏现象，为提高集群计算稳定性，避免节点频繁上下线带来的波动影响，我们基本将其从生产集群使用中剔除，主力使用 OnDemand 类型，结合主动 + 被动伸缩策略管理 OnDemand 机型数量。被动策略跟之前一样，由 EMR 监控集群状态指标被动进行伸缩调整，主动伸缩策略初期规划是根据历史资源占用指标值，将资源所需换算成具体 EC2 实例所需数量，提前主动发起资源申请，在业务计算节点来临之前准备好计算资源，最大程度保证计算效率及利用集群计算资源，主动伸缩效果如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/94/9463d0792cddded61cfeea576de6612c.png\" /></p><p></p><p></p><h3>资源队列调整</h3><p></p><p></p><p>因离线计算集群存在资源争抢问题，有一定几率促使高优先等级任务运行时申请不到资源，为保证该类型任务申请时有足够资源，集群资源管控策略需做调整优化。EMR YARN 默认以 capacity-scheduler 策略管理及调度集群计算资源，资源调配上不如 fair-scheduler 策略灵活。</p><p></p><p>笔者曾尝试 EMR 集群集成 fair-scheduler 可行性调研，结论是 YARN 集群所有 nodemanager 节点上需存在 fair-scheduler.xml，方可执行 fair-scheduler 调度策略，而 emr 控制台不支持 fair-scheduler 配置分发，虽可勉强通过 bootstrap 方式支持，但远没有 capacity-scheduler 兼容性好。退而求其次，转为研究 capacity-scheduler 队列资源隔离划分，目前已验证可行并即将上线至生产集群。</p><p></p><p></p><h2>3. 数据平台基础设施升级</h2><p></p><p></p><p>受历史包袱影响，当前我司数据平台基础组件部分版本有些错综不一，出于提高平台整体服务执行效率和统一数据平台基础组件版本信息考量，长远规划，有必要对数据平台基础设施进行整改升级，主要升级列表如下：</p><p></p><p><code lang=\"css\">EMR: 5  --&gt;  6\nSpark: 2 --&gt;  3\nFlink: 1.12 --&gt; 1.13\nHudi: 0.6  --&gt; 0.11</code></p><p></p><p>数据平台基础设施大范围升级牵扯范围极大且操作复杂，以上述列表中所涉及平台组件为例，稍有差池即为平台级别故障，因篇幅有限，加上我们目前尚在实施过程中，待完成后有机会的话笔者单写一篇介绍。</p><p></p><p></p><h2>4. 多集群运维管理及资源治理</h2><p></p><p></p><p>伴随我司业务快速发展，数据平台底层基础设施也在不断调整以适应这种变化，而繁多的集群环境和庞大组件矩阵也给数据平台使用者、管理者带来极大的不便。例如：数据平台使用者应专注于业务开发本身而无需过多关注平台底层基础设施运转逻辑、环境信息，避免增加学习使用成本。</p><p></p><p>为此，我们针对性规划一个平台，开发实现多集群统一管理、数据平台计算资源治理、离线 / 实时任务管理、数据生命周期等功能，辅助平台使用者更便捷地使用数据平台资产的同时为下一步推动降本增效的开展提供治理依据。</p><p></p><p></p><h1>结语</h1><p></p><p></p><p>自 2020 年开始使用 EMR 至今，我们从多种渠道了解、探索 EMR 相关实践，自身也在不断地深入压榨 EMR 以满足业务计算所需，即便如此，仍有力所不逮之处：</p><p></p><p>离线计算场景。部分高优先等级离线计算任务运行频次不仅细化到分钟粒度，而且业务方还无法容忍重跑带来的整体计算延时，严格意义上此场景已脱离离线计算场景范畴，达到近实时计算效果，这对离线计算平台的整体响应时效性要求到近乎苛刻程度。面对如此棘手的困境，我们一方面从着手升级基础平台计算设施以提升计算服务效率，另一方面结合业务团队深入优化计算平台服务使用技巧，双线并行，尽最大程度满足业务部门需求。实时计算场景。个别任务会因底层计算 container 资源争抢受影响，导致计算延迟的问题，因 YARN 底层运行机制所限暂无解决办法，虽说引入 CGroup 机制可缓解 CPU 资源争抢问题，但相应的也会在集群管理使用带来其他问题，总体而言得不偿失。未来我们应该会在 Flink ON K8S、部分任务迁移 Kinesis Data Analytics 两个方向以寻求突破。</p><p></p><p>文末，感谢在此过程中 AWS EMR 相关团队对我们的支持。</p><p></p><p>作者介绍：</p><p></p><p>吴建阳，朴朴科技大数据运维负责人，主要负责支撑朴朴大数据平台离线 / 实时计算、数据湖、OLAP 等基础设施，具有多年的大数据实战经验。</p><p></p><p>翁建清，AWS 资深解决方案架构师，具有多年 IT 从业经验，涉及移动互联网、企业、金融、政府等行业，曾任职咨询总监、CIO、企业架构师等岗位，具有多年丰富的各类项目经验，尤其在数据仓库、大数据、数据应用场景等方面具有丰富的实战经验，目前专注于企业整体上云的架构规划、设计和实施。</p><p></p>",
    "publish_time": "2022-09-04 17:48:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]