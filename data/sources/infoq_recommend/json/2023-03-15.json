[
  {
    "title": "使用Strimzi提高Kafka集群的安全性",
    "url": "https://www.infoq.cn/article/CpfvECIb5gWdditBBYy7",
    "summary": "<p>在本系列的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"，我们学习了双写问题以及如何使用变更数据捕获模式解决这些问题，特别是使用<a href=\"https://debezium.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg3NTg3NzAsImZpbGVHVUlEIjoiRzNHOWJOVzN3YW82U1lEbCIsImlhdCI6MTY3ODc1ODQ3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.qjOJBovg9TEEKFV_u47LWZ8lfVkqnISLgq7qNqCjVWg\">Debezium</a>\"读取数据库中所做的变更（通过事务日志）并将它们填充到Kafka主题中。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f98928c3fd3e9385d65df0502eaba7b3.webp\" /></p><p></p><p>在本系列的<a href=\"https://www.infoq.cn/article/ElNtSM5ISobpMB8fMC0j\">第4部分</a>\"，我们将示例又向前推进了一步，将应用程序从本地开发环境部署到Kubernetes（生产环境）中。我们使用<a href=\"https://strimzi.io/\">Strimzi</a>\"来部署和配置Kafka和Debezium。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/183604d98c9728dcff64ac409874023c.webp\" /></p><p></p><p>但总的来说，我们忽略了一个重要的东西——当时我们没有把它简化，但它却非常重要——安全性问题。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/281cb84835d07fcba18c2e0947eec2f4.webp\" /></p><p></p><p>如何在不直接将用户名/密码硬编码在部署文件中的情况下保护MySQL实例。如何使用Strimzi在Kafka集群中添加authn。如何配置Debezium，以便对Kafka和MySQL实例进行安全身份验证。在本文中，我们将通过保护在上一篇文章中开发的应用程序（使用Debezium Server方法）来回答所有这些问题。</p><p></p><h2>Kubernetes</h2><p></p><p>我们需要一个安装了Strimzi的Kubernetes集群。我们在本系列的第4部分中对此进行了介绍，如果你要重用它，需要删除应用程序、MySQL数据库、Kafka集群和Debezium实例。</p><p></p><p>重要提示：如果第4部分中使用的集群还在，需要执行下面的步骤。如果集群已经被删除，请从介绍如何删除集群的部分之后继续阅读。</p><p></p><p>在终端窗口执行如下命令来删除它们：</p><p></p><p><code lang=\"plain\">kubectl delete deployment movie-plays-producer-debezium-server -n kafka\nkubectl delete service movie-plays-producer-debezium-server -n kafka\nkubectl delete -f mysql-deployment.yaml -n kafka\nkubectl delete -f debezium-kafka-connector.yaml -n kafka\nkubectl delete -f debezium-kafka-connect.yaml -n kafka\nkubectl delete -f kafka.yaml -n kafka\n</code></p><p></p><p>重要提示：如果你还没有Kuberntes集群，则只需要执行下面的步骤。</p><p></p><p>如果集群已经被销毁，请按照指示创建一个新的集群。在终端窗口中运行以下命令：</p><p></p><p><code lang=\"plain\">minikube start -p strimzi --kubernetes-version='v1.22.12' --vm-driver='virtualbox' --memory=12096 --cpus=3\n\nkubectl create namespace kafka\n\nkubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></p><p></p><p>执行下面的命令验证Operator是否安装正确：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-597d67c7d6-ms987   1/1     Running   0          4m27s\n</code></p><p></p><p>等待Operator运行并准备就绪。</p><p></p><p>此时，我们可以开始使用身份验证和授权（而不是匿名访问）来安装所有组件。</p><p></p><h2>MySQL</h2><p></p><p>在前一篇文章中，我们部署了MySQL实例，将用户名/密码作为环境变量硬编码在部署文件中：</p><p></p><p><code lang=\"plain\">env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: alex\n    - name: MYSQL_DATABASE\n      value: moviesdb\n    - name: MYSQL_USER\n      value: alex\n    - name: MYSQL_PASSWORD\n      value: alex\n</code></p><p></p><p>我们创建一个Kubernetes Secret来存储这些敏感数据。Kubernetes 密钥文件中的数据必须采用base64格式编码。alex的base64编码为YWxleA==。</p><p></p><p>要生成这个值，执行下面的命令：</p><p></p><p><code lang=\"plain\">echo -n 'alex' | base64\nYWxleA==\n</code></p><p></p><p>在mysql-secret.yaml文件中填入编码的密钥：</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Secret\nmetadata:\n name: mysqlsecret\ntype: Opaque\ndata:\n mysqlrootpassword: YWxleA==\n mysqluser: YWxleA==\n mysqlpassword: YWxleA==\n</code></p><p></p><p>将其应用到集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-secret.yaml -n kafka\n</code></p><p></p><p>然后更新MySQL部署文件，使用value中的secretKeyRef字段读取在上一步中创建的密钥：</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Service\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n ports:\n   - port: 3306\n selector:\n   app: mysql\n clusterIP: None\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n selector:\n   matchLabels:\n     app: mysql\n strategy:\n   type: Recreate\n template:\n   metadata:\n     labels:\n       app: mysql\n   spec:\n     containers:\n     - image: mysql:8.0.30\n       name: mysql\n       env:\n       - name: MYSQL_ROOT_PASSWORD\n         valueFrom:\n           secretKeyRef:\n             key: mysqlrootpassword\n             name: mysqlsecret\n       - name: MYSQL_DATABASE\n         value: moviesdb\n       - name: MYSQL_USER\n         valueFrom:\n           secretKeyRef:\n             key: mysqluser\n             name: mysqlsecret\n       - name: MYSQL_PASSWORD\n         valueFrom:\n           secretKeyRef:\n             key: mysqlpassword\n             name: mysqlsecret\n       ports:\n       - containerPort: 3306\n         name: mysql\n</code></p><p></p><p>在secretKeyRef中，我们指定了密钥名称。在本例中，我们在mysql-secret.yaml文件中指定的是mysqlsecret。</p><p></p><p>将MySQL实例部署到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-deployment.yaml -n kafka\n</code></p><p></p><p>我们可以通过导出环境变量来验证注入的密钥是否正确。首先，我们获取Pod的名称：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\nNAME                                        READY   STATUS    RESTARTS   AGE\nmysql-7888f99967-4cj47                      1/1     Running   0          90s\n</code></p><p></p><p>然后在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl exec -n kafka -ti mysql-7888f99967-4cj47 /bin/bash\n\nbash-4.4# export\ndeclare -x GOSU_VERSION=\"1.14\"\ndeclare -x HOME=\"/root\"\ndeclare -x HOSTNAME=\"mysql-7888f99967-4cj47\"\ndeclare -x KUBERNETES_PORT=\"tcp://10.96.0.1:443\"\ndeclare -x KUBERNETES_PORT_443_TCP=\"tcp://10.96.0.1:443\"\ndeclare -x KUBERNETES_PORT_443_TCP_ADDR=\"10.96.0.1\"\ndeclare -x KUBERNETES_PORT_443_TCP_PORT=\"443\"\ndeclare -x KUBERNETES_PORT_443_TCP_PROTO=\"tcp\"\ndeclare -x KUBERNETES_SERVICE_HOST=\"10.96.0.1\"\ndeclare -x KUBERNETES_SERVICE_PORT=\"443\"\ndeclare -x KUBERNETES_SERVICE_PORT_HTTPS=\"443\"\ndeclare -x MYSQL_DATABASE=\"moviesdb\"\ndeclare -x MYSQL_MAJOR=\"8.0\"\ndeclare -x MYSQL_PASSWORD=\"alex\"\ndeclare -x MYSQL_ROOT_PASSWORD=\"alex\"\ndeclare -x MYSQL_SHELL_VERSION=\"8.0.30-1.el8\"\ndeclare -x MYSQL_USER=\"alex\"\ndeclare -x MYSQL_VERSION=\"8.0.30-1.el8\"\ndeclare -x OLDPWD\ndeclare -x PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\ndeclare -x PWD=\"/\"\ndeclare -x SHLVL=\"1\"\ndeclare -x TERM=\"xterm\"\n</code></p><p></p><p>现在可以退出容器：</p><p></p><p><code lang=\"plain\">exit\n</code></p><p></p><p>现在，MySQL数据库的凭证使用的是Kubernetes Secret配置，这比在部署文件中硬编码要好得多。应用程序也需要修改，因为它现在需要从Secret读取凭证，而不是读取配置文件中的静态凭证。</p><p></p><h2>Move Play Producer Debezium</h2><p></p><p>数据库用户名和密码硬编码在application.properties文件中，如果应用程序能够在部署到Kubernetes时自动配置用户名和密码，那就更好了。</p><p></p><p>一种方法是将密钥作为环境变量注入到应用程序Pod中，就像部署MySQL那样。例如，对于密码，部署文件的env部分可能是这样的：</p><p></p><p><code lang=\"plain\">- name: MYSQL_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      key: mysqlpassword\n      name: mysqlsecret\n</code></p><p></p><p>现在更新application.properties文件，从环境变量中获取密码：</p><p></p><p><code lang=\"plain\">%prod.quarkus.datasource.password=${mysql-password}\n</code></p><p></p><p>虽然这样做可以奏效，但将密钥作为环境变量并不是最安全的做法，因为任何一个可以列出环境变量的人都可以很容易地窃取它们。</p><p></p><p>虽然这样做可以奏效，但将密钥作为环境变量并不是最安全的做法，因为任何一个可以列出环境变量的人都可以很容易地窃取它们。</p><p></p><p>Quarkus有一个<a href=\"https://quarkus.io/guides/kubernetes-config\">kubernetes-config</a>\"扩展，应用程序可以用它直接从Kubernetes API服务器读取Kubernetes ConfigMaps和Secrets。通过这种方式，密钥可以安全地从Kubernetes集群传到应用程序中，而不需要任何中间步骤，如将它们作为环境变量传入或作为卷挂载。</p><p></p><h4>Kubernetes配置扩展</h4><p></p><p>首先要做的是注册kubernetes-config扩展。打开pom.xml文件，并添加以下依赖项：</p><p></p><p><code lang=\"plain\">\n  io.quarkus\n  quarkus-kubernetes-config\n\n</code></p><p></p><p>然后，让应用程序直接从Kubernetes API读取Kubernetes Secrets（在我们的例子中，Secret的名字是mysqlsecret）。</p><p></p><p>打开src/main/resources/application.properties，加入下面的内容：</p><p></p><p><code lang=\"plain\">%prod.quarkus.kubernetes-config.secrets.enabled=true                           \nquarkus.kubernetes-config.secrets=mysqlsecret\n</code></p><p></p><p>然后更新quarku.datasource.username和quarku.datasource.password属性，读取mysqlsecret Secret中的mysqluser和mysqlpassword。</p><p></p><p>在application. properties文件中更新这些属性：</p><p></p><p><code lang=\"plain\">%prod.quarkus.datasource.username=${mysqluser}\n%prod.quarkus.datasource.password=${mysqlpassword}\n</code></p><p></p><p>这两个属性分别使用mysqlsecret Secret中的值进行了赋值。</p><p></p><p>由于读取Kubernetes Secrets需要与Kubernetes API Server发生交互，因此，当集群启用了RBAC（基于角色的访问控制）时，用于运行应用程序的ServiceAccount必须具有适当的访问权限。</p><p></p><p>这两个属性分别使用mysqlsecret Secret中的值进行了赋值。</p><p></p><p>由于读取Kubernetes Secrets需要与Kubernetes API Server发生交互，因此，当集群启用了RBAC（基于角色的访问控制）时，用于运行应用程序的ServiceAccount必须具有适当的访问权限。</p><p></p><p>因为我们在前一篇文章中注册了<a href=\"https://quarkus.io/guides/deploying-to-kubernetes\">Kubernetes扩展</a>\"，所以自动生成了所有必要的Kubernetes资源，所以现在不需要做任何事情。</p><p></p><p>现在在终端窗口运行下面的命令部署应用程序：</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.kubernetes.deploy=true\n\n…\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Deploying to kubernetes server: https://192.168.59.104:8443/ in namespace: kafka.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Applied: Service movie-plays-producer-debezium-server.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Applied: Deployment movie-plays-producer-debezium-server.\n[INFO] [io.quarkus.deployment.QuarkusAugmentor] Quarkus augmentation completed in 9537ms\n</code></p><p></p><p>为了验证部署是否正确，我们检查Pod的日志，确保没有出现错误，并且SQL语句执行是正确的：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                                         READY   STATUS      RESTARTS   AGE\nmovie-plays-producer-debezium-server-auth-7cc69fb56c-nc8tx   1/1     Running     0          44s\n\n\n\nkubectl logs movie-plays-producer-debezium-server-auth-7cc69fb56c-nc8tx -n kafka\n\n__  ____  __  _____   ___  __ ____  ______\n --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/\n -/ /_/ / /_/ / __ |/ , _/ ,&lt; / /_/ /\\ \\\n--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/\n2022-08-21 21:00:41,277 INFO  [io.deb.out.qua.int.AdditionalJaxbMappingProducerImpl] (main) Contributed XML mapping for entity: io.debezium.outbox.quarkus.internal.OutboxEvent\n\n…\nHibernate:\n\n    create table Movie (\n       id bigint not null,\n        director varchar(255),\n        genre varchar(255),\n        name varchar(255),\n        primary key (id)\n    ) engine=InnoDB\nHibernate:\n\n    create table OutboxEvent (\n       id binary(255) not null,\n        aggregatetype varchar(255) not null,\n        aggregateid varchar(255) not null,\n        type varchar(255) not null,\n        timestamp datetime(6) not null,\n        payload varchar(8000),\n        tracingspancontext varchar(256),\n        primary key (id)\n    ) engine=InnoDB\n</code></p><p></p><p>在下图中可以看到我们做了安全性保护的部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84dbad7e319fc25fb996eb441fd1ec1b.webp\" /></p><p></p><p>现在，应用程序正在运行中，MySQL凭证也被保护起来了，下面我们继续为Kafka和Debezium提供保护。</p><p></p><h2>Kafka</h2><p></p><p>到目前为止，我们已经部署了一个开放的Kafka集群，没有启用身份验证或授权逻辑。</p><p></p><p>Strimzi支持使用以下<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-securing-kafka-str\">认证机制</a>\"来部署Kafka集群：</p><p></p><p>SASL SCRAM-SHA-512；TLS客户端认证；OAuth 2.0基于令牌的身份验证。由于Strimzi Operator已经安装在Kubernetes集群中了，所以我们可以使用Kafka自定义资源。Kafka资源配置了集群部署，并启用了TLS客户端身份验证。</p><p></p><p>Strimzi可以在listeners中设置监听器，使用mTLS作为通信协议（tls=true）和认证方法类型（authentication字段）。</p><p></p><p>创建一个叫作kafka.yaml的新文件，使用下面的内容来配置一个安全的Kafka：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\n namespace: kafka\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: demo\n       port: 9092\n       type: internal\n       tls: false\n     - name: secure\n       port: 9093\n       type: internal\n       tls: true\n       authentication:\n         type: tls\n   authorization:\n     type: simple\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 1\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>将其应用到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka.yaml -n kafka\n\nkafka.kafka.strimzi.io/my-cluster created\n</code></p><p></p><p>现在我们来验证Kafka集群已启动并在运行当中：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                         READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-d4db5ff58-rt96n   3/3     Running   0          2m26s\nmy-cluster-kafka-0                           1/1     Running   0          2m58s\nmy-cluster-zookeeper-0                       1/1     Running   0          3m31s\n</code></p><p></p><p>由于我们将监听器设置为使用TLS，所以Strimzi已经自动创建了一个Kubernetes Secret，其中包含集群证书、pkcs12信任存储和相关的密码。</p><p></p><p><code lang=\"plain\">kubectl get secrets -n kafka\n\nmy-cluster-clients-ca                        Opaque                                1      9m14s\nmy-cluster-clients-ca-cert                   Opaque                                3      9m14s\nmy-cluster-cluster-ca                        Opaque                                1      9m14s\nmy-cluster-cluster-ca-cert                   Opaque                                3      9m14s\nmy-cluster-cluster-operator-certs            Opaque                                4      9m14s\nmy-cluster-entity-operator-dockercfg-5wwb5   kubernetes.io/dockercfg               1      8m9s\nmy-cluster-entity-operator-token-h9xkq       kubernetes.io/service-account-token   4      8m9s\nmy-cluster-entity-operator-token-npvfc       kubernetes.io/service-account-token   4      8m9s\nmy-cluster-entity-topic-operator-certs       Opaque                                4      8m9s\nmy-cluster-entity-user-operator-certs        Opaque                                4      8m8s\nmy-cluster-kafka-brokers                     Opaque                                4      8m41s\nmy-cluster-kafka-dockercfg-fgpx2             kubernetes.io/dockercfg               1      8m41s\nmy-cluster-kafka-token-2x7s8                 kubernetes.io/service-account-token   4      8m41s\nmy-cluster-kafka-token-6qdgk                 kubernetes.io/service-account-token   4      8m41s\nmy-cluster-zookeeper-dockercfg-p296g         kubernetes.io/dockercfg               1      9m13s\nmy-cluster-zookeeper-nodes                   Opaque                                4      9m13s\nmy-cluster-zookeeper-token-dp9sc             kubernetes.io/service-account-token   4      9m13s\nmy-cluster-zookeeper-token-gbrxg             kubernetes.io/service-account-token   4      9m13s\n</code></p><p></p><p>这里最为重要的是-cluster-ca-cert（在本例中是my-cluster-cluster-ca-cert）这个密钥。</p><p></p><p>在终端窗口中运行下面的命令列出密钥的内容：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -o yaml -n kafka\n\napiVersion: v1\ndata:\n  ca.crt: LS0tLS1CRUdJTiBDRVJU\n  ca.p12: MIIGkwIBAzCCBk==\n  ca.password: azJjY2tIMEs1c091\nkind: Secret\nmetadata:\n  annotations:\n    strimzi.io/ca-cert-generation: \"0\"\n  creationTimestamp: \"2022-08-21T19:32:55Z\"\n  labels:\n    app.kubernetes.io/instance: my-cluster\n    app.kubernetes.io/managed-by: strimzi-cluster-operator\n    app.kubernetes.io/name: strimzi\n    app.kubernetes.io/part-of: strimzi-my-cluster\n    strimzi.io/cluster: my-cluster\n    strimzi.io/kind: Kafka\n    strimzi.io/name: strimzi\n  name: my-cluster-cluster-ca-cert\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: kafka.strimzi.io/v1beta2\n    blockOwnerDeletion: false\n    controller: false\n    kind: Kafka\n    name: my-cluster\n    uid: 23c84dfb-bb33-47ed-bd41-b4e87e0a4c3a\n  resourceVersion: \"49424\"\n  uid: 6c2679a8-216f-421b-880a-de0e6a0879fa\ntype: Opaque\n</code></p><p></p><p>我们来创建一个mTLS授权的用户。</p><p></p><h2>安全和Debezium</h2><p></p><p>Kafka已经被保护起来了，现在我们来创建一个<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-using-the-user-operator-str\">KafkaUser</a>\"资源，将授权角色赋给使用mTLS模式为用户进行身份验证的组和主题。</p><p></p><p>创建一个叫作kafka-user-connect-all-topics.yaml的文件，包含以下内容：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaUser\nmetadata:\n name: my-connect\n namespace: kafka\n labels:\n   # Cluster name set previously\n   strimzi.io/cluster: my-cluster\nspec:\n authentication:\n   type: tls\n authorization:\n   type: simple\n   acls:\n   # Kafka Connects internal topics used to store configuration, offsets or status\n   - resource:\n       type: group\n       name: outbox-viewer\n     operation: Read\n   - resource:\n       type: group\n       name: outbox-viewer\n     operation: Describe\n   - resource:\n       type: group\n       name: mysql-dbhistory\n     operation: Read\n   - resource:\n       type: group\n       name: mysql-dbhistory\n     operation: Describe\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Read\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Create\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Create\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Create\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Read\n   # Debezium topics\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Read\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Describe\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Write\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Create\n</code></p><p></p><p>在终端窗口中应用这个资源：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-user-connect-all-topics.yaml -n kafka\nkafkauser.kafka.strimzi.io/my-connect created\n</code></p><p></p><p>在注册了这个Kafka用户后，Strimzi创建了一个与KafkaUser资源（my-connect）同名的新密钥，并使用pkcs12密钥存储库保存客户端的私钥和访问它的密码。</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o yaml\n\napiVersion: v1\ndata:\n  ca.crt: LS0tLS1CK\n  user.crt: LS0tLS1CRUdJTiB==\n  user.key: LS0tLS1CRUdJTiBQUklWQVRK\n  user.p12: MIILNAIBAzCAA==\n  user.password: UUR4Nk5NemsxUVFF\nkind: Secret\nmetadata:\n  creationTimestamp: \"2022-08-21T20:12:44Z\"\n  labels:\n    app.kubernetes.io/instance: my-connect\n    app.kubernetes.io/managed-by: strimzi-user-operator\n    app.kubernetes.io/name: strimzi-user-operator\n    app.kubernetes.io/part-of: strimzi-my-connect\n    strimzi.io/cluster: my-cluster\n    strimzi.io/kind: KafkaUser\n  name: my-connect\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: kafka.strimzi.io/v1beta2\n    blockOwnerDeletion: false\n    controller: false\n    kind: KafkaUser\n    name: my-connect\n    uid: 882447cc-7759-4884-9d2f-f57f8be92711\n  resourceVersion: \"60439\"\n  uid: 9313676f-3417-42d8-b3fb-a1b1fe1b3a39\ntype: Opaque\n</code></p><p></p><p>现在，我们有了一个新的Kafka用户，拥有访问Kafka主题所需的权限。</p><p></p><p>在部署Debezium Kafka Connector之前，我们需要允许Kafka Connector对象使用Kubernetes API直接从mysqlsecret Secret对象中读取MySQL密钥（就像我们在应用程序中所做的那样），这样Connector就可以通过数据库身份验证并读取事务日志。</p><p></p><p>创建kafka-role-binding.yaml文件，内容如下：</p><p></p><p><code lang=\"plain\">apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n name: connector-configuration-role\n namespace: kafka\nrules:\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n resourceNames: [\"mysqlsecret\", \"my-connect\", \"my-cluster-cluster-ca-cert\"]\n verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: connector-configuration-role-binding\n namespace: kafka\nsubjects:\n- kind: ServiceAccount\n name: debezium-connect-cluster-connect\n namespace: kafka\nroleRef:\n kind: Role\n name: connector-configuration-role\n apiGroup: rbac.authorization.k8s.io\n</code></p><p></p><p>注意，subjects下面的name是运行Debezium Kafka Connect Pod所需的服务帐户。我们还没有部署Pod，不过在部署KafkaConnect组件时，创建的服务帐户需要遵循$KafkaConnectName-connect的格式。由于Debezium Kafka Connect的名称是debezium-connect-cluster-connect，因此创建的服务帐户就是my-connect-connect，并且我们授予这个帐户直接读取Kubernetes Secrets的权限。</p><p></p><p>在部署Debezium Kafka Connect之前应用kafka-role-binding.yaml文件：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-role-binding.yaml -n kafka\n\nrole.rbac.authorization.k8s.io/connector-configuration-role created\nrolebinding.rbac.authorization.k8s.io/connector-configuration-role-binding created\n</code></p><p></p><p>下图总结了目前的安全通信：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed2041090efd0f54664c99a73a9ae5a2.webp\" /></p><p></p><p>为了部署Debezium Kafka Connect，我们需要再次使用Strimzi提供的<a href=\"https://strimzi.io/docs/operators/latest/deploying.html#deploying-kafka-connect-str\">KafkaConnect</a>\"对象，但需要做一些修改，以便通过Kafka集群的身份验证，并允许从Kubernetes Secrets读取配置参数（主要目的是读取MySQL凭证进行身份验证）。</p><p></p><p>配置如下字段：</p><p></p><p>端口现在是9093。设置用于与集群通信的mTLS证书（tls字段）。设置证书和密钥用户（authentication字段），以便进行身份验证。设置config.providers，让MySQL Connector从Kubernetes Secrets读取配置。externalConfiguration用于将信任存储库和密钥存储库物化到文件中。它们被物化在/opt/kafka/external-configuration/目录下。MySQL Connector会访问这些文件。创建kafka-connect.yaml文件，内容如下所示：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnect\nmetadata:\n name: debezium-connect-cluster\n namespace: kafka\n annotations:\n   strimzi.io/use-connector-resources: \"true\"\nspec:\n version: 3.2.0\n image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4\n replicas: 1\n bootstrapServers: my-cluster-kafka-bootstrap:9093\n logging:\n   type: inline\n   loggers:\n     connect.root.logger.level: \"INFO\"\n tls:\n   trustedCertificates:\n     - secretName: my-cluster-cluster-ca-cert\n       certificate: ca.crt\n authentication:\n   type: tls\n   certificateAndKey:\n     secretName: my-connect\n     certificate: user.crt\n     key: user.key\n config:\n   config.providers: secrets\n   config.providers.secrets.class: io.strimzi.kafka.KubernetesSecretConfigProvider\n   group.id: connect-cluster\n   offset.storage.topic: connect-cluster-offsets\n   offset.storage.replication.factor: 1\n   config.storage.topic: connect-cluster-configs\n   config.storage.replication.factor: 1\n   status.storage.topic: connect-cluster-status\n   status.storage.replication.factor: 1\n externalConfiguration:\n   volumes:\n     - name: cluster-ca\n       secret:\n         secretName: my-cluster-cluster-ca-cert\n     - name: my-user\n       secret:\n         secretName: my-connect\n</code></p><p></p><p>trustedCertificates设置为使用Kafka对象部署Kafka集群时创建的密钥。</p><p></p><p>authentication下面的certificateAndKey设置为注册KafkaUser时创建的密钥。</p><p></p><p>部署资源并验证其正确性：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-connect.yaml -n kafka\nkafkaconnect.kafka.strimzi.io/debezium-connect-cluster created\n</code></p><p></p><p>创建一个叫作debezium-kafka-connector.yaml的新文件，用于配置Debezium，允许MySQL Connector访问MySQL实例的事务日志。在本例中，我们在连接器配置中没有使用明文的用户名和密码，而是引用前面用MySQL凭证创建的Secret对象。Secret的访问格式为secrets:/:。此外，在应用了KafkaConnect定义后，它会读取物化的信任存储库和密钥库。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnector\nmetadata:\n name: debezium-connector-mysql\n namespace: kafka\n labels:\n   strimzi.io/cluster: debezium-connect-cluster\nspec:\n class: io.debezium.connector.mysql.MySqlConnector\n tasksMax: 1\n config:\n   group.id: connect-cluster\n   tasks.max: 1\n   database.hostname: mysql\n   database.port: 3306\n   database.user: root\n   database.password: ${secrets:kafka/mysqlsecret:mysqlpassword}\n   database.server.id: 184054\n   database.server.name: mysql\n   database.include.list: moviesdb\n   database.allowPublicKeyRetrieval: true\n   table.include.list: moviesdb.OutboxEvent\n   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9093\n   database.history.kafka.topic: schema-changes.movies\n   database.history.producer.security.protocol: SSL\n   database.history.producer.ssl.keystore.type: PKCS12\n   database.history.producer.ssl.keystore.location: /opt/kafka/external-configuration/my-user/user.p12\n   database.history.producer.ssl.keystore.password: ${secrets:kafka/my-connect:user.password}\n   database.history.producer.ssl.truststore.type: PKCS12\n   database.history.producer.ssl.truststore.location: /opt/kafka/external-configuration/cluster-ca/ca.p12\n   database.history.producer.ssl.truststore.password: ${secrets:kafka/my-cluster-cluster-ca-cert:ca.password}\n\n   database.history.consumer.security.protocol: SSL\n   database.history.consumer.ssl.keystore.type: PKCS12\n   database.history.consumer.ssl.keystore.location: /opt/kafka/external-configuration/my-user/user.p12\n   database.history.consumer.ssl.keystore.password: ${secrets:kafka/my-connect:user.password}\n   database.history.consumer.ssl.truststore.type: PKCS12\n   database.history.consumer.ssl.truststore.location: /opt/kafka/external-configuration/cluster-ca/ca.p12\n   database.history.consumer.ssl.truststore.password: ${secrets:kafka/my-cluster-cluster-ca-cert:ca.password}\n</code></p><p></p><p>在终端窗口中执行下面的命令应用这个文件注册MySQL Connector：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-connector.yaml -n kafka\nkafkaconnector.kafka.strimzi.io/debezium-connector-mysql created\n</code></p><p></p><p>最后，所有的通信通道都被保护起来了。</p><p></p><h2>演示</h2><p></p><p>现在，我们有了一个与上一篇文章中介绍的同样的示例，但现在它更安全了。</p><p></p><p>我们用一个叫作outbox-viewer的Quarkus应用程序来测试它，它将OutboxEvent主题的所有内容打印到控制台。部署下面的YAML文件：</p><p></p><p><code lang=\"plain\">---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\n---\napiVersion: v1\nkind: Service\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\nspec:\n ports:\n   - name: http\n     port: 80\n     targetPort: 8080\n selector:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n type: ClusterIP\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n name: view-secrets\n namespace: kafka\nrules:\n - apiGroups:\n     - \"\"\n   resources:\n     - secrets\n   verbs:\n     - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: outbox-viewer-view\n namespace: kafka\nroleRef:\n kind: ClusterRole\n apiGroup: rbac.authorization.k8s.io\n name: view\nsubjects:\n - kind: ServiceAccount\n   name: outbox-viewer\n   namespace: kafka\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: outbox-viewer-view-secrets\n namespace: kafka\nroleRef:\n kind: Role\n apiGroup: rbac.authorization.k8s.io\n name: view-secrets\nsubjects:\n - kind: ServiceAccount\n   name: outbox-viewer\n   namespace: kafka\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\nspec:\n replicas: 1\n selector:\n   matchLabels:\n     app.kubernetes.io/name: outbox-viewer\n     app.kubernetes.io/version: 1.0.0-SNAPSHOT\n template:\n   metadata:\n     annotations:\n       app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n       app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n     labels:\n       app.kubernetes.io/name: outbox-viewer\n       app.kubernetes.io/version: 1.0.0-SNAPSHOT\n     namespace: kafka\n   spec:\n     containers:\n       - env:\n           - name: KUBERNETES_NAMESPACE\n             valueFrom:\n               fieldRef:\n                 fieldPath: metadata.namespace\n         image: quay.io/lordofthejars/outbox-viewer:1.0.0-SNAPSHOT\n         imagePullPolicy: Always\n         name: outbox-viewer\n         ports:\n           - containerPort: 8080\n             name: http\n             protocol: TCP\n         volumeMounts:\n           - mountPath: /home/jboss/cluster\n             name: cluster-volume\n             readOnly: false\n           - mountPath: /home/jboss/user\n             name: user-volume\n             readOnly: false\n     serviceAccountName: outbox-viewer\n     volumes:\n       - name: cluster-volume\n         secret:\n           optional: false\n           secretName: my-cluster-cluster-ca-cert\n       - name: user-volume\n         secret:\n           optional: false\n           secretName: my-connect\n</code></p><p></p><p>然后在终端窗口中可以看到应用程序Pod的日志。</p><p></p><p><code lang=\"plain\">kubectl logs outbox-viewer-684969f9f6-7snng -f\n</code></p><p></p><p>将Pod名称替换为你的Pod的名称。</p><p></p><p>在终端中运行下面的命令查找Movie Player Producer应用程序的IP和端口：</p><p></p><p><code lang=\"plain\">minikube ip -p strimzi\n\n192.168.59.106\n</code></p><p></p><p>获取movie-plays-producer-debezium暴露的端口（第二个端口）。</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium   LoadBalancer   10.100.117.203        80:32460/TCP                 67m\n</code></p><p></p><p>向Movie Play Producer应用程序发送curl请求：</p><p></p><p><code lang=\"plain\">curl -X 'POST' \\\n  'http://192.168.59.106:32460/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>根据你的示例调整IP和端口。</p><p></p><p>最后，检查outbox-viewer Pod的输出，可以看到数据从数据库传输到Kafka。</p><p></p><p><code lang=\"plain\">{\"schema\":{\"type\":\"struct\",\"fields\":[{\"type\":\"struct\",\"fields\":[{\"type\":\"bytes\",\"optional\":false,\"field”\n…\n,\"aggregatetype\":\"Movie\",\"aggregateid\":\"1\",\"type\":\"MovieCreated\",\"timestamp\":1661339188708005,\"payload\":\"{\\\"id\\\":1,\\\"name\\\":\\\"Minions: The Rise of Gru\\\",\\\"director\\\":\\\"Kyle Balda\\\",\\\"genre\\\":\\\"Animation\\\"}\",\"tracingspancontext\":null},\"source\":{\"version\":\"1.9.4.Final\",\"connector\":\"mysql\",\"name\":\"mysql\",\"ts_ms\":1661339188000,\"snapshot\":\"false\",\"db\":\"moviesdb\",\"sequence\":null,\"table\":\"OutboxEvent\",\"server_id\":1,\"gtid\":null,\"file\":\"binlog.000002\",\"pos\":2967,\"row\":0,\"thread\":15,\"query\":null},\"op\":\"c\",\"ts_ms\":1661339188768,\"transaction\":null}}\n</code></p><p></p><h2>Debezium Embedded</h2><p></p><p>到目前为止，我们已经保护了应用程序和MySQL数据库、Debezium服务器和MySQL、Debezium服务器和Kafka之间的通信。</p><p></p><p>你可能会想，如果使用部署在Quarkus应用程序中的Debezium Embedded而不是Debezium Server该怎么办？我们该如何配置Kafka连接使用mTLS？</p><p></p><p>Quarkus提供了两种连接Kafka的方式——<a href=\"https://quarkus.io/guides/kafka#kafka-bare-clients\">Kafka客户端</a>\"或<a href=\"https://quarkus.io/guides/kafka\">响应式消息客户端</a>\"。我们来看一下在使用这两种方式时通过mTLS认证方法验证Kafka集群所需的属性。</p><p></p><h4>KeyStore和TrustStore</h4><p></p><p>要在客户端配置mTLS，需要四样东西：</p><p></p><p>建立mTLS连接所需的集群TrustStore；TrustStore的密码；用于身份验证的Kafka User KeyStore；KeyStore的密码。前两个元素保存在之前应用Strimzi资源时创建的my-cluster-cluster-ca-cert Kubernetes Secret中。要获取它们，在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -n kafka -o jsonpath='{.data.ca\\.p12}' | base64 -d &gt; mtls-cluster-ca.p12\n</code></p><p></p><p>获取密码：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -n kafka -o jsonpath='{.data.ca\\.password}' | base64 -d\nk2cckH0K5sOu\n</code></p><p></p><p>后面的元素保存在my-connect Kubernetes Secret中。要获取它们，在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o jsonpath='{.data.user\\.p12}' | base64 -d &gt; mtls-user.p12\n</code></p><p></p><p>获取密码：</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o jsonpath='{.data.user\\.password}' | base64 -d\nQDx6NMzk1QQE\n</code></p><p></p><p>现在，设置Quarkus Kafka配置属性，使用前面的凭证进行Kafka集群身份认证：</p><p></p><p><code lang=\"plain\">%prod.kafka.ssl.truststore.location=mtls-cluster-ca.p12\n%prod.kafka.ssl.truststore.password=k2cckH0K5sOu\n%prod.kafka.ssl.truststore.type=PKCS12\n%prod.kafka.ssl.keystore.location=mtls-user.p12\n%prod.kafka.ssl.keystore.password=QDx6NMzk1QQE\n%prod.kafka.ssl.keystore.type=PKCS12\n%prod.kafka.security.protocol=SSL\n\n%prod.mp.messaging.incoming.movies.ssl.truststore.location=mtls-cluster-ca.p12\n%prod.mp.messaging.incoming.movies.ssl.truststore.password=k2cckH0K5sOu\n%prod.mp.messaging.incoming.movies.ssl.truststore.type=PKCS12\n%prod.mp.messaging.incoming.movies.ssl.keystore.location=mtls-user.p12\n%prod.mp.messaging.incoming.movies.ssl.keystore.password=QDx6NMzk1QQE\n%prod.mp.messaging.incoming.movies.ssl.keystore.type=PKCS12\n%prod.mp.messaging.incoming.movies.security.protocol=SSL\n</code></p><p></p><p>我们可以像使用MySQL凭证一样，用Quarkus Kubernetes Config扩展来直接注入凭证，但为了简化起见，我们没有这么做。</p><p></p><p>不过，在安全性方面，仍然有一个重要的缺失点：如何正确地在YAML文件中存储密钥，以及如何在Kubernetes集群中安全地保存密钥？</p><p></p><h2>加密密钥</h2><p></p><p>在本文开始时，我们使用MySQL凭证创建了一个Kubernetes Secret对象，但它是一个包含Base64编码的敏感信息的YAML文件，所以并不安全。这个YAML文件可能最终会保存在Git存储库中，任何有权访问存储库的人都可以使用这些密钥。在下一节中，我们将解决这个问题。</p><p></p><h4>Sealed Secrets</h4><p></p><p><a href=\"https://sealed-secrets.netlify.app/\">Sealed Secrets</a>\"是一个Kubernetes控制器，允许在客户端（本地机器）加密Kubernetes Secrets资源，并在应用后在Kubernetes集群内解密它们。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f173d589e77ab20d38abb683cdd5892.webp\" /></p><p></p><p>Sealed Secrets需要用到两个组件，第一个是用于加密密钥的kubeseal CLI工具。</p><p></p><p>要安装kubeseal，请根据你的操作系统从这个<a href=\"https://github.com/bitnami-labs/sealed-secrets/releases/tag/v0.18.1\">链接</a>\"下载软件包。</p><p></p><p>第二个是kubeseal Kubernetes控制器。在命令行中执行下面的命令来安装它：</p><p></p><p><code lang=\"plain\">kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.18.1/controller.yaml -n kube-system\n\nrole.rbac.authorization.k8s.io/sealed-secrets-service-proxier created\nclusterrole.rbac.authorization.k8s.io/secrets-unsealer created\ndeployment.apps/sealed-secrets-controller created\ncustomresourcedefinition.apiextensions.k8s.io/sealedsecrets.bitnami.com created\nservice/sealed-secrets-controller created\nrole.rbac.authorization.k8s.io/sealed-secrets-key-admin created\nclusterrolebinding.rbac.authorization.k8s.io/sealed-secrets-controller created\nserviceaccount/sealed-secrets-controller created\nrolebinding.rbac.authorization.k8s.io/sealed-secrets-service-proxier created\nrolebinding.rbac.authorization.k8s.io/sealed-secrets-controller created\n</code></p><p></p><p>运行下面的命令检查控制器是否正确部署并运行：</p><p></p><p><code lang=\"plain\">kubectl  get pods -n kube-system\n\nsealed-secrets-controller-554d94cb68-xr6mw                                1/1     Running   0          8m46s\n</code></p><p></p><p>在那之后，我们可以基于mysql-secret.yaml文件使用kubeseal工具自动创建一个新的Kubernetes资源SealedSecret，其中数据字段是加密的。</p><p></p><p><code lang=\"plain\">kubeseal -n kube -o yaml  mysql-secret-encrypted.yaml\n</code></p><p></p><p>生成的新文件叫作mysql-secret-encrypted.yaml，其中每个密钥的值都经过加密：</p><p></p><p><code lang=\"plain\">apiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n creationTimestamp: null\n name: mysqlsecret\n namespace: kube\nspec:\n encryptedData:\n   mysqlpassword: AgBl721mnowwPlC35FfO26zP0\n   mysqlrootpassword: AgAKl1tWV8hahn00yGS4ucs\n   mysqluser: AgCWrWFl1/LcS\ntemplate:\n   data: null\n   metadata:\n     creationTimestamp: null\n     name: mysqlsecret\n     namespace: kafka\n   type: Opaque\n</code></p><p></p><p>现在，你可以安全地删除mysql-secret.yaml文件，因为我们不再需要它了。</p><p></p><p>像应用其他Kubernetes资源文件一样应用加密的资源，Sealed Secrets Kubernetes控制器将解密并将其作为正常的密钥保存在Kubernetes中。</p><p></p><p>你可以通过下面的命令验证Secret：</p><p></p><p><code lang=\"plain\">kubectl  get secret mysqlsecret -n kafka -o yaml\n\napiVersion: v1\ndata:\n  mysqlpassword: YWxleA==\n  mysqlrootpassword: YWxleA==\n  mysqluser: YWxleA==\nkind: Secret\nmetadata:\n  creationTimestamp: \"2022-08-21T19:05:21Z\"\n  name: mysqlsecret\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: bitnami.com/v1alpha1\n    controller: true\n    kind: SealedSecret\n    name: mysqlsecret\n    uid: 2a5ee74b-c2b2-49b3-9a9f-877e7a77b163\n  resourceVersion: \"41514\"\n  uid: 494cbe8b-7480-4ebd-9cc5-6fe396795eaa\ntype: Opaque\n</code></p><p></p><p>需要注意的是，这是一个解密的Kubernetes Secret，引用了负责创建它的SealedSecret。因此，SealedSecret的生命周期也与Secret紧密相关。</p><p></p><p>我们已经解决了正确存储YAML文件而不泄露敏感数据的问题，但是当Secret被应用到Kubernetes集群，它是以Base64编码格式存储的，所以它不是密钥。</p><p></p><h4>静态密钥</h4><p></p><p>默认情况下，Kubernetes不会在etcd数据库中存储加密的密钥。静态加密密钥数据是一个很大的话题，值得专门为其写一篇文章（事实上，“<a href=\"https://www.manning.com/books/kubernetes-secrets-management#:~:text=Kubernetes%20Secrets%20Management%20reveals%20how,to%20strengthen%20applications%20and%20infrastructure.\">Kubernetes Secret Management</a>\"”一书专门讨论了这个话题）。每一种Kubernetes实现都有可能使用不同的方式来启用静态密钥加密，尽管最后都是一个被复制到每个kube-apiserver节点中的配置文件（<a href=\"https://kubernetes.io/docs/reference/config-api/apiserver-encryption.v1/\">EncryptionConfiguration</a>\"）。</p><p></p><p>该文件的格式为：</p><p></p><p><code lang=\"plain\">apiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n - resources:\n     - secrets\n   providers:\n     - identity: {}\n     - aesgcm:\n         keys:\n           - name: key1\n             secret: c2VjcmV0IGlzIHNlY3VyZQ==\n           - name: key2\n             secret: dGhpcyBpcyBwYXNzd29yZA==\n     - aescbc:\n         keys:\n           - name: key1\n             secret: c2VjcmV0IGlzIHNlY3VyZQ==\n           - name: key2\n             secret: dGhpcyBpcyBwYXNzd29yZA==\n     - secretbox:\n         keys:\n           - name: key1\n             secret: YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=\n</code></p><p></p><p>在下图中，我们可以看到在kube-apiserver中注册EncryptionConfiguration文件的流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/939a16eb0a2114d0cd855ba193c983f3.webp\" /></p><p></p><p>现在，我们已经使用SealedSecrets对象来加密YAML文件中的密钥，还使用EncryptionConfiguration文件来保护静态密钥。</p><p></p><h2>结论</h2><p></p><p>保护好所有的基础设施是一件很重要的事情，我们已经在本文中学习了如何使用Kubernetes Secrets来保护对数据库和Kafka的访问。</p><p></p><p>我们不仅可以使用Strimzi定义身份验证，还可以定义授权，提供一些规则，规定谁可以对Kafka主题做什么。</p><p></p><p>访问这些密钥也是一个重要的部分，Quarkus和Debezium允许你以一种高效而安全的方式访问这些密钥，而不需要将密钥持久化在文件系统中（或作为环境变量），而是直接将它们注入内存。</p><p></p><p>安全性是一个重要的话题，当需要在Kafka集群中管理安全性时，Strimzi是一个完美的选择。</p><p></p><p>源代码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/strimzi\">GitHub</a>\"上找到。</p><p></p><p>作者简介：</p><p>Alex Soto是Red Hat的开发者体验总监。他对Java、软件自动化充满了热情，并且深信开源软件模式。Soto是“Testing Java Microservices”（Manning）和“Quarkus Cookbook”（O'Reilly）的合著者，也是几个开源项目的贡献者。自2017年以来，他获得了Java Champion称号，也是萨尔Universidad Ramon Llull大学的国际演讲者和教师。如果你想继续关注Kubernetes和Java的动态，可以在Twitter上关注他（<a href=\"https://twitter.com/alexsotob\">https://twitter.com/alexsotob</a>\"）。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/secure-kafka-cluster-strimzi/\">https://www.infoq.com/articles/secure-kafka-cluster-strimzi/</a>\"</p>",
    "publish_time": "2023-03-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GPT-4重磅发布，吊打ChatGPT！性能炸天：10秒做出一个网站，在考试中击败90% 人类",
    "url": "https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO",
    "summary": "<p></p><p></p><blockquote>王炸来袭，OpenAI 联合创始人 Sam Altman 表示，GPT-4是“迄今为止功能最强大的语言模型”。与上一代相比，GPT-4更强大更可靠，且更有创造性。</blockquote><p></p><p></p><h2>GPT-4来了</h2><p></p><p></p><p>OpenAI 的新“核弹”来了。</p><p></p><p>3月14日晚间，OpenAI宣布发布多模态大模型GPT-4。</p><p></p><p>“我们创建了GPT-4，这是 OpenAI 努力扩展深度学习的最新里程碑。GPT-4 是一个大型多模态模型（接受图像和文本输入，提供文本输出），虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平”，OpenAI表示。</p><p></p><p>OpenAI 联合创始人 Sam Altman 表示，它是“迄今为止功能最强大、最一致的模型”，能够使用图像和文本。</p><p></p><p>在YouTube上的Live Demo中，OpenAI的总裁和联合创始人Greg Brockman展示了GPT-4拥有的强大技能。GPT-4可以总结文章、写代码、报税、写诗……更惊人的是，GPT-4只需10秒就可以做出一个网站。</p><p></p><p>在演示视频中，按如下操作：</p><p></p><p>1、在草稿本上用纸笔画出一个非常粗糙的草图</p><p></p><p>2、拍照告诉 GPT：我要做一个网站长这样，给我生成网站代码</p><p></p><p>3、网站做完，总共历时十秒钟左右</p><p></p><p>不禁令人感叹，又有多少人要失业了。有网友在社交平台表示，“时刻准备下岗吧”。</p><p></p><p>GPT-4 的技术论文：<a href=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</a>\"</p><p></p><p>GPT-4 系统模型卡介绍：<a href=\"https://cdn.openai.com/papers/gpt-4-system-card.pdf\">https://cdn.openai.com/papers/gpt-4-system-card.pdf</a>\"</p><p></p><p>最近这几个月，ChatGPT的爆火，让人们惊叹于人工智能强大的聊天能力。GPT4出来后，可以看到，在聊天之外，人工智能的能力已不断扩展其外延。</p><p></p><p>ChatGPT用的语言模型是 GPT-3.5。在谈到GPT-4比前一个版本强大在哪里时，OpenAI称，虽然这两个版本在随意的谈话中看起来很相似，但“当任务的复杂性达到足够的阈值时，差异就会出现”，GPT-4更可靠、更有创意，并且能够处理更细微的指令。该公司表示，GPT-4响应禁止内容请求的可能性比其前一个版本低82%。OpenAI表示，在内部评估中，GPT-4产生正确回应的可能性要比GPT-3.5高出40%。</p><p></p><p>而且GPT-4是多模态的，同时支持文本和图像输入功能。此外，GPT-4比以前的版本“更大”，这意味着其已经在更多的数据上进行了训练，并且在模型文件中有更多的权重，这也使得它的运行成本更高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/281ebfb0c5e5938242dbe9ef7f9cf3ce.jpeg\" /></p><p></p><p>GPT-4 在一系列基准测试中的表现优于 GPT-3.5</p><p></p><p>OpenAI 称它使用了微软Azure来训练模型，但没有公布有关具体模型大小或用于训练它的硬件的详细信息。</p><p></p><p>据悉，GPT-4参加了多种基准考试测试，包括美国律师资格考试Uniform Bar Exam、法学院入学考试LSAT、“美国高考”SAT数学部分和证据性阅读与写作部分的考试，在这些测试中，它的得分高于88%的应试者。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9a9092769af2d0a036619ce566e8e1b.png\" /></p><p></p><p>GPT-4 从图像生成食谱</p><p></p><p>OpenAI表示，已经与多家公司合作，要将GPT-4结合到他们的产品中，包括Duolingo、Stripe和Khan Academy。</p><p></p><p>GPT-4模型也将以API的形式，提供给付费版ChatGPT Plus的订阅用户，允许开发者付费将AI集成到他们的应用程序中。</p><p></p><p>微软表示，新款的必应（Bing）搜索引擎将运行于GPT-4系统之上。</p><p></p><p>在 OpenAI 宣布开发出 GPT-4 后，马斯克在推特上评论了这一消息，表达了他对人工智能对就业市场的潜在影响的担忧。马斯克在他的推文中写道：“我们人类还能做什么？我们最好继续使用 Neuralink！（马斯克旗下脑机接口公司）！”</p><p></p><h2>GPT-4：可生成更安全、更有用响应的OpenAI至高系统</h2><p></p><p></p><p>据介绍，凭借更广泛的常识和问题解决能力，GPT-4能为用户提供更准确的回答。</p><p></p><p>GPT-4的创造性和协作能力超越以往各个版本。</p><p></p><p>它能够生成、编辑并与用户一道完成创意和技术性创作任务，包括谱写歌曲、编写剧本或者学习用户的写作风格。</p><p></p><p>例如：</p><p></p><p>输入:</p><p></p><p></p><blockquote>用一句话解释《灰姑娘》的剧情，其中每个单词必须以字母表中从A到Z的下一个字母开头，不得重复字母。</blockquote><p></p><p></p><p></p><p>输出</p><p></p><p></p><blockquote>A beautiful Cinderella, dwelling eagerly, finally gains happiness; inspiring jealous kin, love magically nurtures opulent prince; quietly rescues, slipper triumphs, uniting very wondrously, xenial youth zealously.</blockquote><p></p><p></p><h2>GPT-4的高级推理能力已经超越ChatGPT</h2><p></p><p></p><p>ChatGPT：</p><p></p><p>输入</p><p></p><p></p><blockquote>Andrew从上午11点到下午3点有空，Joanne中午到下午2点有空，之后下午3：30到5点有空。Hannah中午有半小时空闲，之后下午4点到6点有空。如果Andrew、Hannah和Joanne要开个半小时的会，可以选择哪些时段？</blockquote><p></p><p></p><p>输出</p><p></p><p></p><blockquote>以下是空闲时段列表：-Andrew：上午11点至下午3点-Joanne：中午至下午2点，以及下午3：30至5点；-Hannah：中午至12：30，以及下午4点至6点。据此计算，三人都空闲的时间窗口只有一个：下午4点至4：30。因此会议可以安排在下午4点。GPT-4：</blockquote><p></p><p></p><p>输入</p><p></p><p></p><blockquote>Andrew从上午11点到下午3点有空，Joanne中午到下午2点有空，之后下午3：30到5点有空。Hannah中午有半小时空闲，之后下午4点到6点有空。如果Andrew、Hannah和Joanne要开个半小时的会，可以选择哪些时段？</blockquote><p></p><p></p><p>输出</p><p></p><p></p><blockquote>Andrew：上午11点到下午3点；Joanne：中午12点至下午2点，下午3：30至5点；Hannah：中午12点至12：30，下午4点至6点。三人均有空的时段：中午12点至12：30。</blockquote><p></p><p></p><h2>GPT-4在测试中也获得了超过ChatGPT的考核成绩（百分比位次）</h2><p></p><p></p><h4>统一律师考试</h4><p></p><p></p><p>ChatGPT :10%</p><p></p><p>GPT-4: 90%</p><p></p><h4>生物奥赛题</h4><p></p><p>ChatGPT :31%</p><p></p><p>GPT-4 (含视觉):99%</p><p></p><h2>比GPT-3.5准确性提高40%</h2><p></p><p></p><p>沿着对GPT、GPT-2和GPT-3的研究路径，OpenAI的深度学习方法利用更多数据和计算建立起愈发复杂且强大的语言模型。</p><p></p><p>OpenAI投入6个月时间，让GPT-4更安全、也更一致。在OpenAI的内部评估中，与GPT-3.5相比，GPT-4响应拒绝内容请求的几率降低了82%，生成可靠响应的几率提高40%。</p><p></p><h2>安全与对齐</h2><p></p><p></p><h4>人工反馈训练</h4><p></p><p>OpenAI引入了更多人工反馈，包括由ChatGPT用户提交的反馈，以改进GPT-4的行为。OpenAI还与50多位专家合作，在AI安全和保障等领域获得了早期反馈。</p><p></p><h4>在实际应用中不断提升</h4><p></p><p>OpenAI将以往模型在现实应用中的经验教训，引入了GPT-4的安全研究和监控系统当中。与ChatGPT一样，随着使用者越来越多，我们也将定期更新并改进GPT-4。</p><p></p><h4>GPT-4辅助的安全研究</h4><p></p><p>GPT-4的高级推理和指令遵循能力加快了特准的安全工作。OpenAI使用GPT-4辅助创建用于模型微调的训练数据，并在训练、评估和监控流程中对分类器进行迭代。</p><p></p><h2>仍存在缺陷</h2><p></p><p>OpenAI公司CEO Sam Altman 在Twitter上称，GPT-4是其模型“最有能力且最符合”人类价值观和意图的模型，尽管“它仍然存在缺陷”。</p><p></p><p>“它仍然存在缺陷，仍然有限，但它有明显的改进”，Sam Altman写道，“它比以前的模型更有创意，它的幻觉明显减少，而且它的偏见也更少。”</p><p></p><p>参考资料：</p><p></p><p><a href=\"https://openai.com/product/gpt-4\">https://openai.com/product/gpt-4</a>\"</p><p></p><p><a href=\"https://www.youtube.com/watch?v=outcGtbnMuQ\">www.youtube.com/watch?v=outcGtbnMuQ</a>\"</p>",
    "publish_time": "2023-03-15 11:08:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文心一言发布在即，百度智能云升级三大配套云服务",
    "url": "https://www.infoq.cn/article/8CSP7FiAcFaMSWHIGOIg",
    "summary": "<p>随着ChatGPT、文心一言等AI应用的爆火，支撑人工智能所需的算力需求也随之暴涨。百度表示，将于3月16日发布生成式AI产品“文心一言”。为支持文心一言的超大规模计算需求，进一步实现文心一言的产业化落地，近期百度智能云也频繁公布文心一言配套设施的准备情况。</p><p></p><p>3月14日，百度智能云方面表示，从去年年底开始，百度智能云已经通过三大动作全面升级云服务能力：去年12月发布国内首个全栈自研的AI基础设施“AI大底座”、今年2月升级AI研发运营一体化（MLOps）能力、3月百度阳泉智算中心完成升级。据透露，“文心一言”背后的算力基础设施均由百度智算中心支持，后续百度多个智算中心也将为“文心一言”面向产业的规模化落地提供底层支撑。</p><p></p><h2>生成式AI产业落地面临三大挑战，云市场规则正在改变</h2><p></p><p></p><p>在生成式 AI 的热潮背后，云计算对于企业的价值发生了根本质变：从提供基础设施转变为提供智能服务，这同时也夯实了生成式AI产品与产业结合的更多可能性。百度创始人、CEO李彦宏表示，“文心一言”是基于百度智能云技术打造出来的大模型，它将根本性地改变云市场的游戏规则。</p><p></p><p>而这种颠覆式变革，也意味着文心一言等生成式AI产品在产业规模化落地上面临多重挑战。具体而言，挑战主要体现在以下三个方面：首先是智能算力，生成式AI产品的数据量巨大，运行需要空前强大的AI算力，这对现有计算机体系结构提出了挑战。其次是AI基础设施，文心一言等人工智能产品的计算场景复杂、计算架构多维，企业进行AI开发需要集芯片、框架、模型及应用为一体的全栈AI基础设施，端到端的智能化闭环AI开发的全流程。最后是AI工程化水平，AI生成式产品落地到产业实践时，需基于具体业务场景进行二次适配开发。而AI模型的开发运营全流程复杂程度高，任何一环操作不规范都将影响AI模型效果。AI工程化水平决定了AI能否突破产业落地的“最后一公里”。</p><p></p><p>面对云市场新的游戏规则，只有为企业解决以上三大挑战的云厂商才有资格拿到入场券。百度集团执行副总裁、百度智能云事业群总裁沈抖表示，云服务已从数字时代跃迁到智能时代，以前企业选择云厂商更多是看算力、存储等基础云服务，以后企业对云的需求会更加聚焦智能服务水平。</p><p></p><h2>文心一言即将发布，百度智能云升级三大配套云服务</h2><p></p><p></p><p>智算时代下，企业面临上述智能算力短缺、AI开发全流程复杂、AI产业落地工程化困难等诸多挑战，百度智能云凭借“云智一体“独特优势给出了答案。百度表示，将为产业提供三大方面的核心能力，助力产业智能化转型走上快车道。</p><p></p><p>其一，为企业提供巨量高性能智能算力，以支持文心一言等生成式AI产品的产业落地。百度目前已在山西阳泉、江苏盐城等地建设智算中心。其中，百度阳泉智算中心是亚洲最大单体智算中心，建设规模为4 EFLOPS（每秒400亿亿次浮点运算）AI算力，可满足各行业超大规模AI计算需求。昆仑芯科技战略负责人宋春晓表示：“人工智能芯片是算力的核心，昆仑芯2代已在百度文心大模型的应用中广泛落地，并为各行各业的智能化升级提供AI算力支持。”</p><p></p><p>据了解，百度智算中心持续创新计算架构，支持智算时代下企业不同业务场景的计算任务，提升企业的业务效率和创新能力。目前，百度智算中心已支持了文心预训练大模型、生物计算、自动驾驶等前沿AI应用。同时，基于自研创新技术可使PUE低至1.08，实现了高效节能的运行，从而降低客户的电费和运维成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0ac43fc7f98876393a8f64f434c2f24c.png\" /></p><p>（百度阳泉智算中心实景图）</p><p></p><p>其二，为企业提供新型AI基础设施，实现AI开发的降本增效。百度智能云通过对算力、框架、模型、AI应用进行封装，推出“百度AI大底座”。从高端芯片昆仑芯，到飞桨深度学习框架，到文心预训练大模型，再到AI应用，实现端到端的智能化闭环，从而把高门槛的AI技术，变成像水电能一样供企业按需取用，大幅降低企业开发成本，提升效率。百度智能云云计算产品解决方案和运营部总经理宋飞表示：“百度AI大底座可基于实际业务数据进行不断调优，使得资源利用率提升至70%，企业开发效率提升100%。”</p><p></p><p>最后，为企业提供AI研发运营一体化（MLOps）能力，加速生成式AI等大模型产品快速产业落地。百度AI中台总监忻舟表示，百度AI大底座将面向企业提供一系列AI研发运维工具。企业在接入文心一言后，可低成本、便捷地完成与业务场景的适配与二次开发，通过AI工程化能力帮助产业突破AI落地的“最后一公里”。</p><p>在低成本多架构的智能算力、“AI大底座”新型AI基础设施、MLOps&nbsp;AI工程化能力的支撑下，文心一言将推动产业智能化加速到来，带来真正的AI普惠。</p>",
    "publish_time": "2023-03-15 11:47:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "信息检索顶会WSDM CUP 2023揭榜，腾讯获两项任务冠军，成果基于混元AI大模型和太极机器学习平台实现",
    "url": "https://www.infoq.cn/article/6XPmgbG2sSW51frlfIZj",
    "summary": "<p>近日，信息检索领域国际顶级学术会议WSDM（Web Search and Data Mining）宣布了WSDM CUP 2023竞赛成绩，来自腾讯的研究团队基于大模型预训练、搜索排序以及集成学习等技术上的突破，在无偏排序学习和互联网搜索预训练模型赛道上的两项任务中获得冠军。</p><p>&nbsp;&nbsp;</p><p>ACM WSDM（Web Search and Data Mining） 会议是信息检索领域顶级会议之一，由SIGIR、SIGKDD、SIGMOD和SIGWEB四个专委会协调筹办，在互联网搜索、数据挖掘领域享有较高学术声誉。第16 届 ACM 国际 WSDM 会议于 2023 年 2 月 27 日至 3 月 3 日在新加坡举行，论文的接收率为17.8%。</p><p>&nbsp;</p><p>WSDM Cup由 WSDM 会议举办，本届 WSDM Cup 共计400余支队伍参加，分别来自中国、美国、新加坡、日本、印度等国家的知名高校和公司，大赛共设置三个赛道：无偏排序学习和互联网搜索预训练模型赛道（Unbiased Learning to Rank and Pre-training for Web Search）、跨语言连续体的多语言信息检索赛道（Multilingual Information Retrieval Across a Continuum of Languages）和视觉问答挑战赛道（Visual Question Answering Challenge）。</p><p>&nbsp;</p><p>此次腾讯「参赛队名：腾讯机器学习平台部搜索团队（TMLPS）」参加了无偏排序学习和互联网搜索预训练模型赛道，并在该赛道的两项子任务中（Pre-training for Web Search和Unbiased Learning to Rank）获得冠军。</p><p>&nbsp;</p><p>目前两项成果代码和论文均已发布到Github上（见：GitHub - lixsh6/Tencent_wsdm_cup2023）</p><p>&nbsp;</p><p>在深度学习领域，数据标注的质量对于模型的效果有着较为显著的影响，但是较高的标注数据成本一直是研究团队的阻碍之一，如何从技术上利用无标注的数据训练模型自然成为了成为学术界和工业界关注的热点。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/46/4619faee409940ca42bd431d14f4907f.png\" /></p><p></p><p>&nbsp;</p><p>论文：Multi-Feature Integration for Perception-Dependent Examination-Bias Estimation</p><p>地址：https://arxiv.org/pdf/2302.13756.pdf</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cef11ea0093d51f0c49a406efc8e1f4.png\" /></p><p></p><p>本次比赛，针对基于搜索的预训练任务（Pre-training for Web Search），腾讯团队通过大模型训练、用户行为特征去噪等方法，在点击日志上进行基于搜索排序的模型预训练，进而使模型有效地应用到下游相关性排序的检索任务。通过预训练、模型微调、集成学习等多方面的优化，在人工标注的相关性排序任务上取得了较大的领先优势。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/19/19a320d0a016fab483e8fedef5b17469.png\" /></p><p></p><p>论文：Pretraining De-Biased Language Model with Large-scale Click Logs for Document Ranking</p><p>地址：https://arxiv.org/pdf/2302.13498.pdf</p><p>&nbsp;</p><p>在本次比赛的另一赛道无偏排序学习任务（Unbiased Learning to Rank）中，团队通过深入挖掘点击日志信息，充分利用包括文档媒体类型、文档展示高度和点击后的滑屏次数等特征对文档相关性进行无偏估计，提出了一种能够集成多种偏置因素的多特征集成模型，有效地提升了搜索引擎中文档排序的效果。</p><p>&nbsp;</p><p>据了解，夺冠团队的成果均基于腾讯混元AI大模型（下文简称“HunYuan”）和太极机器学习平台实现。目前，通过联合微信搜索团队，两项技术已经在微信搜一搜的多个场景落地相关技术，并取得了显著的效果提升。</p><p>&nbsp;</p><p>AI大模型（又称预训练模型）是指预先训练好，具有相对通用性的“一套算法”，具有“巨量数据、巨量算力、巨量模型”等特性。大模型通过学习样本数据的内在规律和表达层次，发展出接近、超越人类水平的“智能”，具备分析推理能力，能够识别文字、图像和声音等。</p><p>&nbsp;</p><p>2022年4月，腾讯首次对外披露HunYuan大模型研发进展。HunYuan集CV（计算机视觉）、NLP（自然语言理解）、多模态理解能力于一体，先后在MSR-VTT、MSVD等五大权威数据集榜单中登顶，实现跨模态领域的大满贯。2022年5月，在国际公认的CLUE（中文语言理解评测集合）三个榜单同时登顶。近日，HunYuan又迎来全新进展，推出国内首个低成本、可落地的NLP万亿大模型，并再次登顶CLUE。</p><p>&nbsp;</p><p>腾讯太极机器学习平台是集模型训练和在线推理于一身的高性能机器学习平台，具备万亿参数模型的训练和推理能力，为AI大模型预训练推理和应用落地提供了完整的端到端工程能力支撑，一站式解决算法工程师在 AI 应用过程中特征处理、模型训练、模型服务等工程问题。</p>",
    "publish_time": "2023-03-15 14:23:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]