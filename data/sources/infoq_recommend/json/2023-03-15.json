[
  {
    "title": "使用Strimzi提高Kafka集群的安全性",
    "url": "https://www.infoq.cn/article/CpfvECIb5gWdditBBYy7",
    "summary": "<p>在本系列的<a href=\"https://www.infoq.cn/article/V4kqPgrQlqqPgWQuMmDP\">第3部分</a>\"，我们学习了双写问题以及如何使用变更数据捕获模式解决这些问题，特别是使用<a href=\"https://debezium.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg3NTg3NzAsImZpbGVHVUlEIjoiRzNHOWJOVzN3YW82U1lEbCIsImlhdCI6MTY3ODc1ODQ3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.qjOJBovg9TEEKFV_u47LWZ8lfVkqnISLgq7qNqCjVWg\">Debezium</a>\"读取数据库中所做的变更（通过事务日志）并将它们填充到Kafka主题中。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f98928c3fd3e9385d65df0502eaba7b3.webp\" /></p><p></p><p>在本系列的<a href=\"https://www.infoq.cn/article/ElNtSM5ISobpMB8fMC0j\">第4部分</a>\"，我们将示例又向前推进了一步，将应用程序从本地开发环境部署到Kubernetes（生产环境）中。我们使用<a href=\"https://strimzi.io/\">Strimzi</a>\"来部署和配置Kafka和Debezium。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/183604d98c9728dcff64ac409874023c.webp\" /></p><p></p><p>但总的来说，我们忽略了一个重要的东西——当时我们没有把它简化，但它却非常重要——安全性问题。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/281cb84835d07fcba18c2e0947eec2f4.webp\" /></p><p></p><p>如何在不直接将用户名/密码硬编码在部署文件中的情况下保护MySQL实例。如何使用Strimzi在Kafka集群中添加authn。如何配置Debezium，以便对Kafka和MySQL实例进行安全身份验证。在本文中，我们将通过保护在上一篇文章中开发的应用程序（使用Debezium Server方法）来回答所有这些问题。</p><p></p><h2>Kubernetes</h2><p></p><p>我们需要一个安装了Strimzi的Kubernetes集群。我们在本系列的第4部分中对此进行了介绍，如果你要重用它，需要删除应用程序、MySQL数据库、Kafka集群和Debezium实例。</p><p></p><p>重要提示：如果第4部分中使用的集群还在，需要执行下面的步骤。如果集群已经被删除，请从介绍如何删除集群的部分之后继续阅读。</p><p></p><p>在终端窗口执行如下命令来删除它们：</p><p></p><p><code lang=\"plain\">kubectl delete deployment movie-plays-producer-debezium-server -n kafka\nkubectl delete service movie-plays-producer-debezium-server -n kafka\nkubectl delete -f mysql-deployment.yaml -n kafka\nkubectl delete -f debezium-kafka-connector.yaml -n kafka\nkubectl delete -f debezium-kafka-connect.yaml -n kafka\nkubectl delete -f kafka.yaml -n kafka\n</code></p><p></p><p>重要提示：如果你还没有Kuberntes集群，则只需要执行下面的步骤。</p><p></p><p>如果集群已经被销毁，请按照指示创建一个新的集群。在终端窗口中运行以下命令：</p><p></p><p><code lang=\"plain\">minikube start -p strimzi --kubernetes-version='v1.22.12' --vm-driver='virtualbox' --memory=12096 --cpus=3\n\nkubectl create namespace kafka\n\nkubectl create -f 'https://strimzi.io/install/latest?namespace=kafka' -n kafka\n</code></p><p></p><p>执行下面的命令验证Operator是否安装正确：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                        READY   STATUS    RESTARTS   AGE\nstrimzi-cluster-operator-597d67c7d6-ms987   1/1     Running   0          4m27s\n</code></p><p></p><p>等待Operator运行并准备就绪。</p><p></p><p>此时，我们可以开始使用身份验证和授权（而不是匿名访问）来安装所有组件。</p><p></p><h2>MySQL</h2><p></p><p>在前一篇文章中，我们部署了MySQL实例，将用户名/密码作为环境变量硬编码在部署文件中：</p><p></p><p><code lang=\"plain\">env:\n    - name: MYSQL_ROOT_PASSWORD\n      value: alex\n    - name: MYSQL_DATABASE\n      value: moviesdb\n    - name: MYSQL_USER\n      value: alex\n    - name: MYSQL_PASSWORD\n      value: alex\n</code></p><p></p><p>我们创建一个Kubernetes Secret来存储这些敏感数据。Kubernetes 密钥文件中的数据必须采用base64格式编码。alex的base64编码为YWxleA==。</p><p></p><p>要生成这个值，执行下面的命令：</p><p></p><p><code lang=\"plain\">echo -n 'alex' | base64\nYWxleA==\n</code></p><p></p><p>在mysql-secret.yaml文件中填入编码的密钥：</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Secret\nmetadata:\n name: mysqlsecret\ntype: Opaque\ndata:\n mysqlrootpassword: YWxleA==\n mysqluser: YWxleA==\n mysqlpassword: YWxleA==\n</code></p><p></p><p>将其应用到集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-secret.yaml -n kafka\n</code></p><p></p><p>然后更新MySQL部署文件，使用value中的secretKeyRef字段读取在上一步中创建的密钥：</p><p></p><p><code lang=\"plain\">apiVersion: v1\nkind: Service\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n ports:\n   - port: 3306\n selector:\n   app: mysql\n clusterIP: None\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n name: mysql\n labels:\n   app: mysql\nspec:\n selector:\n   matchLabels:\n     app: mysql\n strategy:\n   type: Recreate\n template:\n   metadata:\n     labels:\n       app: mysql\n   spec:\n     containers:\n     - image: mysql:8.0.30\n       name: mysql\n       env:\n       - name: MYSQL_ROOT_PASSWORD\n         valueFrom:\n           secretKeyRef:\n             key: mysqlrootpassword\n             name: mysqlsecret\n       - name: MYSQL_DATABASE\n         value: moviesdb\n       - name: MYSQL_USER\n         valueFrom:\n           secretKeyRef:\n             key: mysqluser\n             name: mysqlsecret\n       - name: MYSQL_PASSWORD\n         valueFrom:\n           secretKeyRef:\n             key: mysqlpassword\n             name: mysqlsecret\n       ports:\n       - containerPort: 3306\n         name: mysql\n</code></p><p></p><p>在secretKeyRef中，我们指定了密钥名称。在本例中，我们在mysql-secret.yaml文件中指定的是mysqlsecret。</p><p></p><p>将MySQL实例部署到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f mysql-deployment.yaml -n kafka\n</code></p><p></p><p>我们可以通过导出环境变量来验证注入的密钥是否正确。首先，我们获取Pod的名称：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\nNAME                                        READY   STATUS    RESTARTS   AGE\nmysql-7888f99967-4cj47                      1/1     Running   0          90s\n</code></p><p></p><p>然后在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl exec -n kafka -ti mysql-7888f99967-4cj47 /bin/bash\n\nbash-4.4# export\ndeclare -x GOSU_VERSION=\"1.14\"\ndeclare -x HOME=\"/root\"\ndeclare -x HOSTNAME=\"mysql-7888f99967-4cj47\"\ndeclare -x KUBERNETES_PORT=\"tcp://10.96.0.1:443\"\ndeclare -x KUBERNETES_PORT_443_TCP=\"tcp://10.96.0.1:443\"\ndeclare -x KUBERNETES_PORT_443_TCP_ADDR=\"10.96.0.1\"\ndeclare -x KUBERNETES_PORT_443_TCP_PORT=\"443\"\ndeclare -x KUBERNETES_PORT_443_TCP_PROTO=\"tcp\"\ndeclare -x KUBERNETES_SERVICE_HOST=\"10.96.0.1\"\ndeclare -x KUBERNETES_SERVICE_PORT=\"443\"\ndeclare -x KUBERNETES_SERVICE_PORT_HTTPS=\"443\"\ndeclare -x MYSQL_DATABASE=\"moviesdb\"\ndeclare -x MYSQL_MAJOR=\"8.0\"\ndeclare -x MYSQL_PASSWORD=\"alex\"\ndeclare -x MYSQL_ROOT_PASSWORD=\"alex\"\ndeclare -x MYSQL_SHELL_VERSION=\"8.0.30-1.el8\"\ndeclare -x MYSQL_USER=\"alex\"\ndeclare -x MYSQL_VERSION=\"8.0.30-1.el8\"\ndeclare -x OLDPWD\ndeclare -x PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\ndeclare -x PWD=\"/\"\ndeclare -x SHLVL=\"1\"\ndeclare -x TERM=\"xterm\"\n</code></p><p></p><p>现在可以退出容器：</p><p></p><p><code lang=\"plain\">exit\n</code></p><p></p><p>现在，MySQL数据库的凭证使用的是Kubernetes Secret配置，这比在部署文件中硬编码要好得多。应用程序也需要修改，因为它现在需要从Secret读取凭证，而不是读取配置文件中的静态凭证。</p><p></p><h2>Move Play Producer Debezium</h2><p></p><p>数据库用户名和密码硬编码在application.properties文件中，如果应用程序能够在部署到Kubernetes时自动配置用户名和密码，那就更好了。</p><p></p><p>一种方法是将密钥作为环境变量注入到应用程序Pod中，就像部署MySQL那样。例如，对于密码，部署文件的env部分可能是这样的：</p><p></p><p><code lang=\"plain\">- name: MYSQL_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      key: mysqlpassword\n      name: mysqlsecret\n</code></p><p></p><p>现在更新application.properties文件，从环境变量中获取密码：</p><p></p><p><code lang=\"plain\">%prod.quarkus.datasource.password=${mysql-password}\n</code></p><p></p><p>虽然这样做可以奏效，但将密钥作为环境变量并不是最安全的做法，因为任何一个可以列出环境变量的人都可以很容易地窃取它们。</p><p></p><p>虽然这样做可以奏效，但将密钥作为环境变量并不是最安全的做法，因为任何一个可以列出环境变量的人都可以很容易地窃取它们。</p><p></p><p>Quarkus有一个<a href=\"https://quarkus.io/guides/kubernetes-config\">kubernetes-config</a>\"扩展，应用程序可以用它直接从Kubernetes API服务器读取Kubernetes ConfigMaps和Secrets。通过这种方式，密钥可以安全地从Kubernetes集群传到应用程序中，而不需要任何中间步骤，如将它们作为环境变量传入或作为卷挂载。</p><p></p><h4>Kubernetes配置扩展</h4><p></p><p>首先要做的是注册kubernetes-config扩展。打开pom.xml文件，并添加以下依赖项：</p><p></p><p><code lang=\"plain\">\n  io.quarkus\n  quarkus-kubernetes-config\n\n</code></p><p></p><p>然后，让应用程序直接从Kubernetes API读取Kubernetes Secrets（在我们的例子中，Secret的名字是mysqlsecret）。</p><p></p><p>打开src/main/resources/application.properties，加入下面的内容：</p><p></p><p><code lang=\"plain\">%prod.quarkus.kubernetes-config.secrets.enabled=true                           \nquarkus.kubernetes-config.secrets=mysqlsecret\n</code></p><p></p><p>然后更新quarku.datasource.username和quarku.datasource.password属性，读取mysqlsecret Secret中的mysqluser和mysqlpassword。</p><p></p><p>在application. properties文件中更新这些属性：</p><p></p><p><code lang=\"plain\">%prod.quarkus.datasource.username=${mysqluser}\n%prod.quarkus.datasource.password=${mysqlpassword}\n</code></p><p></p><p>这两个属性分别使用mysqlsecret Secret中的值进行了赋值。</p><p></p><p>由于读取Kubernetes Secrets需要与Kubernetes API Server发生交互，因此，当集群启用了RBAC（基于角色的访问控制）时，用于运行应用程序的ServiceAccount必须具有适当的访问权限。</p><p></p><p>这两个属性分别使用mysqlsecret Secret中的值进行了赋值。</p><p></p><p>由于读取Kubernetes Secrets需要与Kubernetes API Server发生交互，因此，当集群启用了RBAC（基于角色的访问控制）时，用于运行应用程序的ServiceAccount必须具有适当的访问权限。</p><p></p><p>因为我们在前一篇文章中注册了<a href=\"https://quarkus.io/guides/deploying-to-kubernetes\">Kubernetes扩展</a>\"，所以自动生成了所有必要的Kubernetes资源，所以现在不需要做任何事情。</p><p></p><p>现在在终端窗口运行下面的命令部署应用程序：</p><p></p><p><code lang=\"plain\">./mvnw clean package -DskipTests -Dquarkus.kubernetes.deploy=true\n\n…\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Deploying to kubernetes server: https://192.168.59.104:8443/ in namespace: kafka.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Applied: Service movie-plays-producer-debezium-server.\n[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] Applied: Deployment movie-plays-producer-debezium-server.\n[INFO] [io.quarkus.deployment.QuarkusAugmentor] Quarkus augmentation completed in 9537ms\n</code></p><p></p><p>为了验证部署是否正确，我们检查Pod的日志，确保没有出现错误，并且SQL语句执行是正确的：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                                         READY   STATUS      RESTARTS   AGE\nmovie-plays-producer-debezium-server-auth-7cc69fb56c-nc8tx   1/1     Running     0          44s\n\n\n\nkubectl logs movie-plays-producer-debezium-server-auth-7cc69fb56c-nc8tx -n kafka\n\n__  ____  __  _____   ___  __ ____  ______\n --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/\n -/ /_/ / /_/ / __ |/ , _/ ,&lt; / /_/ /\\ \\\n--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/\n2022-08-21 21:00:41,277 INFO  [io.deb.out.qua.int.AdditionalJaxbMappingProducerImpl] (main) Contributed XML mapping for entity: io.debezium.outbox.quarkus.internal.OutboxEvent\n\n…\nHibernate:\n\n    create table Movie (\n       id bigint not null,\n        director varchar(255),\n        genre varchar(255),\n        name varchar(255),\n        primary key (id)\n    ) engine=InnoDB\nHibernate:\n\n    create table OutboxEvent (\n       id binary(255) not null,\n        aggregatetype varchar(255) not null,\n        aggregateid varchar(255) not null,\n        type varchar(255) not null,\n        timestamp datetime(6) not null,\n        payload varchar(8000),\n        tracingspancontext varchar(256),\n        primary key (id)\n    ) engine=InnoDB\n</code></p><p></p><p>在下图中可以看到我们做了安全性保护的部分。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/84/84dbad7e319fc25fb996eb441fd1ec1b.webp\" /></p><p></p><p>现在，应用程序正在运行中，MySQL凭证也被保护起来了，下面我们继续为Kafka和Debezium提供保护。</p><p></p><h2>Kafka</h2><p></p><p>到目前为止，我们已经部署了一个开放的Kafka集群，没有启用身份验证或授权逻辑。</p><p></p><p>Strimzi支持使用以下<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-securing-kafka-str\">认证机制</a>\"来部署Kafka集群：</p><p></p><p>SASL SCRAM-SHA-512；TLS客户端认证；OAuth 2.0基于令牌的身份验证。由于Strimzi Operator已经安装在Kubernetes集群中了，所以我们可以使用Kafka自定义资源。Kafka资源配置了集群部署，并启用了TLS客户端身份验证。</p><p></p><p>Strimzi可以在listeners中设置监听器，使用mTLS作为通信协议（tls=true）和认证方法类型（authentication字段）。</p><p></p><p>创建一个叫作kafka.yaml的新文件，使用下面的内容来配置一个安全的Kafka：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: Kafka\nmetadata:\n name: my-cluster\n namespace: kafka\nspec:\n kafka:\n   version: 3.2.0\n   replicas: 1\n   listeners:\n     - name: demo\n       port: 9092\n       type: internal\n       tls: false\n     - name: secure\n       port: 9093\n       type: internal\n       tls: true\n       authentication:\n         type: tls\n   authorization:\n     type: simple\n   config:\n     offsets.topic.replication.factor: 1\n     transaction.state.log.replication.factor: 1\n     transaction.state.log.min.isr: 1\n     default.replication.factor: 1\n     min.insync.replicas: 1\n     inter.broker.protocol.version: \"3.2\"\n   storage:\n     type: ephemeral\n zookeeper:\n   replicas: 1\n   storage:\n     type: ephemeral\n entityOperator:\n   topicOperator: {}\n   userOperator: {}\n</code></p><p></p><p>将其应用到Kubernetes集群：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka.yaml -n kafka\n\nkafka.kafka.strimzi.io/my-cluster created\n</code></p><p></p><p>现在我们来验证Kafka集群已启动并在运行当中：</p><p></p><p><code lang=\"plain\">kubectl get pods -n kafka\n\nNAME                                         READY   STATUS    RESTARTS   AGE\nmy-cluster-entity-operator-d4db5ff58-rt96n   3/3     Running   0          2m26s\nmy-cluster-kafka-0                           1/1     Running   0          2m58s\nmy-cluster-zookeeper-0                       1/1     Running   0          3m31s\n</code></p><p></p><p>由于我们将监听器设置为使用TLS，所以Strimzi已经自动创建了一个Kubernetes Secret，其中包含集群证书、pkcs12信任存储和相关的密码。</p><p></p><p><code lang=\"plain\">kubectl get secrets -n kafka\n\nmy-cluster-clients-ca                        Opaque                                1      9m14s\nmy-cluster-clients-ca-cert                   Opaque                                3      9m14s\nmy-cluster-cluster-ca                        Opaque                                1      9m14s\nmy-cluster-cluster-ca-cert                   Opaque                                3      9m14s\nmy-cluster-cluster-operator-certs            Opaque                                4      9m14s\nmy-cluster-entity-operator-dockercfg-5wwb5   kubernetes.io/dockercfg               1      8m9s\nmy-cluster-entity-operator-token-h9xkq       kubernetes.io/service-account-token   4      8m9s\nmy-cluster-entity-operator-token-npvfc       kubernetes.io/service-account-token   4      8m9s\nmy-cluster-entity-topic-operator-certs       Opaque                                4      8m9s\nmy-cluster-entity-user-operator-certs        Opaque                                4      8m8s\nmy-cluster-kafka-brokers                     Opaque                                4      8m41s\nmy-cluster-kafka-dockercfg-fgpx2             kubernetes.io/dockercfg               1      8m41s\nmy-cluster-kafka-token-2x7s8                 kubernetes.io/service-account-token   4      8m41s\nmy-cluster-kafka-token-6qdgk                 kubernetes.io/service-account-token   4      8m41s\nmy-cluster-zookeeper-dockercfg-p296g         kubernetes.io/dockercfg               1      9m13s\nmy-cluster-zookeeper-nodes                   Opaque                                4      9m13s\nmy-cluster-zookeeper-token-dp9sc             kubernetes.io/service-account-token   4      9m13s\nmy-cluster-zookeeper-token-gbrxg             kubernetes.io/service-account-token   4      9m13s\n</code></p><p></p><p>这里最为重要的是-cluster-ca-cert（在本例中是my-cluster-cluster-ca-cert）这个密钥。</p><p></p><p>在终端窗口中运行下面的命令列出密钥的内容：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -o yaml -n kafka\n\napiVersion: v1\ndata:\n  ca.crt: LS0tLS1CRUdJTiBDRVJU\n  ca.p12: MIIGkwIBAzCCBk==\n  ca.password: azJjY2tIMEs1c091\nkind: Secret\nmetadata:\n  annotations:\n    strimzi.io/ca-cert-generation: \"0\"\n  creationTimestamp: \"2022-08-21T19:32:55Z\"\n  labels:\n    app.kubernetes.io/instance: my-cluster\n    app.kubernetes.io/managed-by: strimzi-cluster-operator\n    app.kubernetes.io/name: strimzi\n    app.kubernetes.io/part-of: strimzi-my-cluster\n    strimzi.io/cluster: my-cluster\n    strimzi.io/kind: Kafka\n    strimzi.io/name: strimzi\n  name: my-cluster-cluster-ca-cert\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: kafka.strimzi.io/v1beta2\n    blockOwnerDeletion: false\n    controller: false\n    kind: Kafka\n    name: my-cluster\n    uid: 23c84dfb-bb33-47ed-bd41-b4e87e0a4c3a\n  resourceVersion: \"49424\"\n  uid: 6c2679a8-216f-421b-880a-de0e6a0879fa\ntype: Opaque\n</code></p><p></p><p>我们来创建一个mTLS授权的用户。</p><p></p><h2>安全和Debezium</h2><p></p><p>Kafka已经被保护起来了，现在我们来创建一个<a href=\"https://strimzi.io/docs/operators/latest/configuring.html#assembly-using-the-user-operator-str\">KafkaUser</a>\"资源，将授权角色赋给使用mTLS模式为用户进行身份验证的组和主题。</p><p></p><p>创建一个叫作kafka-user-connect-all-topics.yaml的文件，包含以下内容：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaUser\nmetadata:\n name: my-connect\n namespace: kafka\n labels:\n   # Cluster name set previously\n   strimzi.io/cluster: my-cluster\nspec:\n authentication:\n   type: tls\n authorization:\n   type: simple\n   acls:\n   # Kafka Connects internal topics used to store configuration, offsets or status\n   - resource:\n       type: group\n       name: outbox-viewer\n     operation: Read\n   - resource:\n       type: group\n       name: outbox-viewer\n     operation: Describe\n   - resource:\n       type: group\n       name: mysql-dbhistory\n     operation: Read\n   - resource:\n       type: group\n       name: mysql-dbhistory\n     operation: Describe\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Read\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-configs\n     operation: Create\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-status\n     operation: Create\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Read\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Write\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Describe\n   - resource:\n       type: topic\n       name: connect-cluster-offsets\n     operation: Create\n   - resource:\n       type: group\n       name: connect-cluster\n     operation: Read\n   # Debezium topics\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Read\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Describe\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Write\n   - resource:\n       type: topic\n       name: \"*\"\n     operation: Create\n</code></p><p></p><p>在终端窗口中应用这个资源：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-user-connect-all-topics.yaml -n kafka\nkafkauser.kafka.strimzi.io/my-connect created\n</code></p><p></p><p>在注册了这个Kafka用户后，Strimzi创建了一个与KafkaUser资源（my-connect）同名的新密钥，并使用pkcs12密钥存储库保存客户端的私钥和访问它的密码。</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o yaml\n\napiVersion: v1\ndata:\n  ca.crt: LS0tLS1CK\n  user.crt: LS0tLS1CRUdJTiB==\n  user.key: LS0tLS1CRUdJTiBQUklWQVRK\n  user.p12: MIILNAIBAzCAA==\n  user.password: UUR4Nk5NemsxUVFF\nkind: Secret\nmetadata:\n  creationTimestamp: \"2022-08-21T20:12:44Z\"\n  labels:\n    app.kubernetes.io/instance: my-connect\n    app.kubernetes.io/managed-by: strimzi-user-operator\n    app.kubernetes.io/name: strimzi-user-operator\n    app.kubernetes.io/part-of: strimzi-my-connect\n    strimzi.io/cluster: my-cluster\n    strimzi.io/kind: KafkaUser\n  name: my-connect\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: kafka.strimzi.io/v1beta2\n    blockOwnerDeletion: false\n    controller: false\n    kind: KafkaUser\n    name: my-connect\n    uid: 882447cc-7759-4884-9d2f-f57f8be92711\n  resourceVersion: \"60439\"\n  uid: 9313676f-3417-42d8-b3fb-a1b1fe1b3a39\ntype: Opaque\n</code></p><p></p><p>现在，我们有了一个新的Kafka用户，拥有访问Kafka主题所需的权限。</p><p></p><p>在部署Debezium Kafka Connector之前，我们需要允许Kafka Connector对象使用Kubernetes API直接从mysqlsecret Secret对象中读取MySQL密钥（就像我们在应用程序中所做的那样），这样Connector就可以通过数据库身份验证并读取事务日志。</p><p></p><p>创建kafka-role-binding.yaml文件，内容如下：</p><p></p><p><code lang=\"plain\">apiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n name: connector-configuration-role\n namespace: kafka\nrules:\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n resourceNames: [\"mysqlsecret\", \"my-connect\", \"my-cluster-cluster-ca-cert\"]\n verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: connector-configuration-role-binding\n namespace: kafka\nsubjects:\n- kind: ServiceAccount\n name: debezium-connect-cluster-connect\n namespace: kafka\nroleRef:\n kind: Role\n name: connector-configuration-role\n apiGroup: rbac.authorization.k8s.io\n</code></p><p></p><p>注意，subjects下面的name是运行Debezium Kafka Connect Pod所需的服务帐户。我们还没有部署Pod，不过在部署KafkaConnect组件时，创建的服务帐户需要遵循$KafkaConnectName-connect的格式。由于Debezium Kafka Connect的名称是debezium-connect-cluster-connect，因此创建的服务帐户就是my-connect-connect，并且我们授予这个帐户直接读取Kubernetes Secrets的权限。</p><p></p><p>在部署Debezium Kafka Connect之前应用kafka-role-binding.yaml文件：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-role-binding.yaml -n kafka\n\nrole.rbac.authorization.k8s.io/connector-configuration-role created\nrolebinding.rbac.authorization.k8s.io/connector-configuration-role-binding created\n</code></p><p></p><p>下图总结了目前的安全通信：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed2041090efd0f54664c99a73a9ae5a2.webp\" /></p><p></p><p>为了部署Debezium Kafka Connect，我们需要再次使用Strimzi提供的<a href=\"https://strimzi.io/docs/operators/latest/deploying.html#deploying-kafka-connect-str\">KafkaConnect</a>\"对象，但需要做一些修改，以便通过Kafka集群的身份验证，并允许从Kubernetes Secrets读取配置参数（主要目的是读取MySQL凭证进行身份验证）。</p><p></p><p>配置如下字段：</p><p></p><p>端口现在是9093。设置用于与集群通信的mTLS证书（tls字段）。设置证书和密钥用户（authentication字段），以便进行身份验证。设置config.providers，让MySQL Connector从Kubernetes Secrets读取配置。externalConfiguration用于将信任存储库和密钥存储库物化到文件中。它们被物化在/opt/kafka/external-configuration/目录下。MySQL Connector会访问这些文件。创建kafka-connect.yaml文件，内容如下所示：</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnect\nmetadata:\n name: debezium-connect-cluster\n namespace: kafka\n annotations:\n   strimzi.io/use-connector-resources: \"true\"\nspec:\n version: 3.2.0\n image: quay.io/lordofthejars/debezium-connector-mysql:1.9.4\n replicas: 1\n bootstrapServers: my-cluster-kafka-bootstrap:9093\n logging:\n   type: inline\n   loggers:\n     connect.root.logger.level: \"INFO\"\n tls:\n   trustedCertificates:\n     - secretName: my-cluster-cluster-ca-cert\n       certificate: ca.crt\n authentication:\n   type: tls\n   certificateAndKey:\n     secretName: my-connect\n     certificate: user.crt\n     key: user.key\n config:\n   config.providers: secrets\n   config.providers.secrets.class: io.strimzi.kafka.KubernetesSecretConfigProvider\n   group.id: connect-cluster\n   offset.storage.topic: connect-cluster-offsets\n   offset.storage.replication.factor: 1\n   config.storage.topic: connect-cluster-configs\n   config.storage.replication.factor: 1\n   status.storage.topic: connect-cluster-status\n   status.storage.replication.factor: 1\n externalConfiguration:\n   volumes:\n     - name: cluster-ca\n       secret:\n         secretName: my-cluster-cluster-ca-cert\n     - name: my-user\n       secret:\n         secretName: my-connect\n</code></p><p></p><p>trustedCertificates设置为使用Kafka对象部署Kafka集群时创建的密钥。</p><p></p><p>authentication下面的certificateAndKey设置为注册KafkaUser时创建的密钥。</p><p></p><p>部署资源并验证其正确性：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-connect.yaml -n kafka\nkafkaconnect.kafka.strimzi.io/debezium-connect-cluster created\n</code></p><p></p><p>创建一个叫作debezium-kafka-connector.yaml的新文件，用于配置Debezium，允许MySQL Connector访问MySQL实例的事务日志。在本例中，我们在连接器配置中没有使用明文的用户名和密码，而是引用前面用MySQL凭证创建的Secret对象。Secret的访问格式为secrets:/:。此外，在应用了KafkaConnect定义后，它会读取物化的信任存储库和密钥库。</p><p></p><p><code lang=\"plain\">apiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaConnector\nmetadata:\n name: debezium-connector-mysql\n namespace: kafka\n labels:\n   strimzi.io/cluster: debezium-connect-cluster\nspec:\n class: io.debezium.connector.mysql.MySqlConnector\n tasksMax: 1\n config:\n   group.id: connect-cluster\n   tasks.max: 1\n   database.hostname: mysql\n   database.port: 3306\n   database.user: root\n   database.password: ${secrets:kafka/mysqlsecret:mysqlpassword}\n   database.server.id: 184054\n   database.server.name: mysql\n   database.include.list: moviesdb\n   database.allowPublicKeyRetrieval: true\n   table.include.list: moviesdb.OutboxEvent\n   database.history.kafka.bootstrap.servers: my-cluster-kafka-bootstrap:9093\n   database.history.kafka.topic: schema-changes.movies\n   database.history.producer.security.protocol: SSL\n   database.history.producer.ssl.keystore.type: PKCS12\n   database.history.producer.ssl.keystore.location: /opt/kafka/external-configuration/my-user/user.p12\n   database.history.producer.ssl.keystore.password: ${secrets:kafka/my-connect:user.password}\n   database.history.producer.ssl.truststore.type: PKCS12\n   database.history.producer.ssl.truststore.location: /opt/kafka/external-configuration/cluster-ca/ca.p12\n   database.history.producer.ssl.truststore.password: ${secrets:kafka/my-cluster-cluster-ca-cert:ca.password}\n\n   database.history.consumer.security.protocol: SSL\n   database.history.consumer.ssl.keystore.type: PKCS12\n   database.history.consumer.ssl.keystore.location: /opt/kafka/external-configuration/my-user/user.p12\n   database.history.consumer.ssl.keystore.password: ${secrets:kafka/my-connect:user.password}\n   database.history.consumer.ssl.truststore.type: PKCS12\n   database.history.consumer.ssl.truststore.location: /opt/kafka/external-configuration/cluster-ca/ca.p12\n   database.history.consumer.ssl.truststore.password: ${secrets:kafka/my-cluster-cluster-ca-cert:ca.password}\n</code></p><p></p><p>在终端窗口中执行下面的命令应用这个文件注册MySQL Connector：</p><p></p><p><code lang=\"plain\">kubectl apply -f kafka-connector.yaml -n kafka\nkafkaconnector.kafka.strimzi.io/debezium-connector-mysql created\n</code></p><p></p><p>最后，所有的通信通道都被保护起来了。</p><p></p><h2>演示</h2><p></p><p>现在，我们有了一个与上一篇文章中介绍的同样的示例，但现在它更安全了。</p><p></p><p>我们用一个叫作outbox-viewer的Quarkus应用程序来测试它，它将OutboxEvent主题的所有内容打印到控制台。部署下面的YAML文件：</p><p></p><p><code lang=\"plain\">---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\n---\napiVersion: v1\nkind: Service\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\nspec:\n ports:\n   - name: http\n     port: 80\n     targetPort: 8080\n selector:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n type: ClusterIP\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n name: view-secrets\n namespace: kafka\nrules:\n - apiGroups:\n     - \"\"\n   resources:\n     - secrets\n   verbs:\n     - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: outbox-viewer-view\n namespace: kafka\nroleRef:\n kind: ClusterRole\n apiGroup: rbac.authorization.k8s.io\n name: view\nsubjects:\n - kind: ServiceAccount\n   name: outbox-viewer\n   namespace: kafka\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: outbox-viewer-view-secrets\n namespace: kafka\nroleRef:\n kind: Role\n apiGroup: rbac.authorization.k8s.io\n name: view-secrets\nsubjects:\n - kind: ServiceAccount\n   name: outbox-viewer\n   namespace: kafka\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n annotations:\n   app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n   app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n labels:\n   app.kubernetes.io/name: outbox-viewer\n   app.kubernetes.io/version: 1.0.0-SNAPSHOT\n name: outbox-viewer\n namespace: kafka\nspec:\n replicas: 1\n selector:\n   matchLabels:\n     app.kubernetes.io/name: outbox-viewer\n     app.kubernetes.io/version: 1.0.0-SNAPSHOT\n template:\n   metadata:\n     annotations:\n       app.quarkus.io/commit-id: ebe139afdc9f7f956725af5c5a92cf3c03486bca\n       app.quarkus.io/build-timestamp: 2022-08-23 - 11:14:36 +0000\n     labels:\n       app.kubernetes.io/name: outbox-viewer\n       app.kubernetes.io/version: 1.0.0-SNAPSHOT\n     namespace: kafka\n   spec:\n     containers:\n       - env:\n           - name: KUBERNETES_NAMESPACE\n             valueFrom:\n               fieldRef:\n                 fieldPath: metadata.namespace\n         image: quay.io/lordofthejars/outbox-viewer:1.0.0-SNAPSHOT\n         imagePullPolicy: Always\n         name: outbox-viewer\n         ports:\n           - containerPort: 8080\n             name: http\n             protocol: TCP\n         volumeMounts:\n           - mountPath: /home/jboss/cluster\n             name: cluster-volume\n             readOnly: false\n           - mountPath: /home/jboss/user\n             name: user-volume\n             readOnly: false\n     serviceAccountName: outbox-viewer\n     volumes:\n       - name: cluster-volume\n         secret:\n           optional: false\n           secretName: my-cluster-cluster-ca-cert\n       - name: user-volume\n         secret:\n           optional: false\n           secretName: my-connect\n</code></p><p></p><p>然后在终端窗口中可以看到应用程序Pod的日志。</p><p></p><p><code lang=\"plain\">kubectl logs outbox-viewer-684969f9f6-7snng -f\n</code></p><p></p><p>将Pod名称替换为你的Pod的名称。</p><p></p><p>在终端中运行下面的命令查找Movie Player Producer应用程序的IP和端口：</p><p></p><p><code lang=\"plain\">minikube ip -p strimzi\n\n192.168.59.106\n</code></p><p></p><p>获取movie-plays-producer-debezium暴露的端口（第二个端口）。</p><p></p><p><code lang=\"plain\">kubectl get services -n kafka\n\nmovie-plays-producer-debezium   LoadBalancer   10.100.117.203        80:32460/TCP                 67m\n</code></p><p></p><p>向Movie Play Producer应用程序发送curl请求：</p><p></p><p><code lang=\"plain\">curl -X 'POST' \\\n  'http://192.168.59.106:32460/movie' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"name\": \"Minions: The Rise of Gru\",\n  \"director\": \"Kyle Balda\",\n  \"genre\": \"Animation\"\n}'\n</code></p><p></p><p>根据你的示例调整IP和端口。</p><p></p><p>最后，检查outbox-viewer Pod的输出，可以看到数据从数据库传输到Kafka。</p><p></p><p><code lang=\"plain\">{\"schema\":{\"type\":\"struct\",\"fields\":[{\"type\":\"struct\",\"fields\":[{\"type\":\"bytes\",\"optional\":false,\"field”\n…\n,\"aggregatetype\":\"Movie\",\"aggregateid\":\"1\",\"type\":\"MovieCreated\",\"timestamp\":1661339188708005,\"payload\":\"{\\\"id\\\":1,\\\"name\\\":\\\"Minions: The Rise of Gru\\\",\\\"director\\\":\\\"Kyle Balda\\\",\\\"genre\\\":\\\"Animation\\\"}\",\"tracingspancontext\":null},\"source\":{\"version\":\"1.9.4.Final\",\"connector\":\"mysql\",\"name\":\"mysql\",\"ts_ms\":1661339188000,\"snapshot\":\"false\",\"db\":\"moviesdb\",\"sequence\":null,\"table\":\"OutboxEvent\",\"server_id\":1,\"gtid\":null,\"file\":\"binlog.000002\",\"pos\":2967,\"row\":0,\"thread\":15,\"query\":null},\"op\":\"c\",\"ts_ms\":1661339188768,\"transaction\":null}}\n</code></p><p></p><h2>Debezium Embedded</h2><p></p><p>到目前为止，我们已经保护了应用程序和MySQL数据库、Debezium服务器和MySQL、Debezium服务器和Kafka之间的通信。</p><p></p><p>你可能会想，如果使用部署在Quarkus应用程序中的Debezium Embedded而不是Debezium Server该怎么办？我们该如何配置Kafka连接使用mTLS？</p><p></p><p>Quarkus提供了两种连接Kafka的方式——<a href=\"https://quarkus.io/guides/kafka#kafka-bare-clients\">Kafka客户端</a>\"或<a href=\"https://quarkus.io/guides/kafka\">响应式消息客户端</a>\"。我们来看一下在使用这两种方式时通过mTLS认证方法验证Kafka集群所需的属性。</p><p></p><h4>KeyStore和TrustStore</h4><p></p><p>要在客户端配置mTLS，需要四样东西：</p><p></p><p>建立mTLS连接所需的集群TrustStore；TrustStore的密码；用于身份验证的Kafka User KeyStore；KeyStore的密码。前两个元素保存在之前应用Strimzi资源时创建的my-cluster-cluster-ca-cert Kubernetes Secret中。要获取它们，在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -n kafka -o jsonpath='{.data.ca\\.p12}' | base64 -d &gt; mtls-cluster-ca.p12\n</code></p><p></p><p>获取密码：</p><p></p><p><code lang=\"plain\">kubectl get secret my-cluster-cluster-ca-cert -n kafka -o jsonpath='{.data.ca\\.password}' | base64 -d\nk2cckH0K5sOu\n</code></p><p></p><p>后面的元素保存在my-connect Kubernetes Secret中。要获取它们，在终端窗口中运行下面的命令：</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o jsonpath='{.data.user\\.p12}' | base64 -d &gt; mtls-user.p12\n</code></p><p></p><p>获取密码：</p><p></p><p><code lang=\"plain\">kubectl get secret my-connect -n kafka -o jsonpath='{.data.user\\.password}' | base64 -d\nQDx6NMzk1QQE\n</code></p><p></p><p>现在，设置Quarkus Kafka配置属性，使用前面的凭证进行Kafka集群身份认证：</p><p></p><p><code lang=\"plain\">%prod.kafka.ssl.truststore.location=mtls-cluster-ca.p12\n%prod.kafka.ssl.truststore.password=k2cckH0K5sOu\n%prod.kafka.ssl.truststore.type=PKCS12\n%prod.kafka.ssl.keystore.location=mtls-user.p12\n%prod.kafka.ssl.keystore.password=QDx6NMzk1QQE\n%prod.kafka.ssl.keystore.type=PKCS12\n%prod.kafka.security.protocol=SSL\n\n%prod.mp.messaging.incoming.movies.ssl.truststore.location=mtls-cluster-ca.p12\n%prod.mp.messaging.incoming.movies.ssl.truststore.password=k2cckH0K5sOu\n%prod.mp.messaging.incoming.movies.ssl.truststore.type=PKCS12\n%prod.mp.messaging.incoming.movies.ssl.keystore.location=mtls-user.p12\n%prod.mp.messaging.incoming.movies.ssl.keystore.password=QDx6NMzk1QQE\n%prod.mp.messaging.incoming.movies.ssl.keystore.type=PKCS12\n%prod.mp.messaging.incoming.movies.security.protocol=SSL\n</code></p><p></p><p>我们可以像使用MySQL凭证一样，用Quarkus Kubernetes Config扩展来直接注入凭证，但为了简化起见，我们没有这么做。</p><p></p><p>不过，在安全性方面，仍然有一个重要的缺失点：如何正确地在YAML文件中存储密钥，以及如何在Kubernetes集群中安全地保存密钥？</p><p></p><h2>加密密钥</h2><p></p><p>在本文开始时，我们使用MySQL凭证创建了一个Kubernetes Secret对象，但它是一个包含Base64编码的敏感信息的YAML文件，所以并不安全。这个YAML文件可能最终会保存在Git存储库中，任何有权访问存储库的人都可以使用这些密钥。在下一节中，我们将解决这个问题。</p><p></p><h4>Sealed Secrets</h4><p></p><p><a href=\"https://sealed-secrets.netlify.app/\">Sealed Secrets</a>\"是一个Kubernetes控制器，允许在客户端（本地机器）加密Kubernetes Secrets资源，并在应用后在Kubernetes集群内解密它们。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0f/0f173d589e77ab20d38abb683cdd5892.webp\" /></p><p></p><p>Sealed Secrets需要用到两个组件，第一个是用于加密密钥的kubeseal CLI工具。</p><p></p><p>要安装kubeseal，请根据你的操作系统从这个<a href=\"https://github.com/bitnami-labs/sealed-secrets/releases/tag/v0.18.1\">链接</a>\"下载软件包。</p><p></p><p>第二个是kubeseal Kubernetes控制器。在命令行中执行下面的命令来安装它：</p><p></p><p><code lang=\"plain\">kubectl apply -f https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.18.1/controller.yaml -n kube-system\n\nrole.rbac.authorization.k8s.io/sealed-secrets-service-proxier created\nclusterrole.rbac.authorization.k8s.io/secrets-unsealer created\ndeployment.apps/sealed-secrets-controller created\ncustomresourcedefinition.apiextensions.k8s.io/sealedsecrets.bitnami.com created\nservice/sealed-secrets-controller created\nrole.rbac.authorization.k8s.io/sealed-secrets-key-admin created\nclusterrolebinding.rbac.authorization.k8s.io/sealed-secrets-controller created\nserviceaccount/sealed-secrets-controller created\nrolebinding.rbac.authorization.k8s.io/sealed-secrets-service-proxier created\nrolebinding.rbac.authorization.k8s.io/sealed-secrets-controller created\n</code></p><p></p><p>运行下面的命令检查控制器是否正确部署并运行：</p><p></p><p><code lang=\"plain\">kubectl  get pods -n kube-system\n\nsealed-secrets-controller-554d94cb68-xr6mw                                1/1     Running   0          8m46s\n</code></p><p></p><p>在那之后，我们可以基于mysql-secret.yaml文件使用kubeseal工具自动创建一个新的Kubernetes资源SealedSecret，其中数据字段是加密的。</p><p></p><p><code lang=\"plain\">kubeseal -n kube -o yaml  mysql-secret-encrypted.yaml\n</code></p><p></p><p>生成的新文件叫作mysql-secret-encrypted.yaml，其中每个密钥的值都经过加密：</p><p></p><p><code lang=\"plain\">apiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n creationTimestamp: null\n name: mysqlsecret\n namespace: kube\nspec:\n encryptedData:\n   mysqlpassword: AgBl721mnowwPlC35FfO26zP0\n   mysqlrootpassword: AgAKl1tWV8hahn00yGS4ucs\n   mysqluser: AgCWrWFl1/LcS\ntemplate:\n   data: null\n   metadata:\n     creationTimestamp: null\n     name: mysqlsecret\n     namespace: kafka\n   type: Opaque\n</code></p><p></p><p>现在，你可以安全地删除mysql-secret.yaml文件，因为我们不再需要它了。</p><p></p><p>像应用其他Kubernetes资源文件一样应用加密的资源，Sealed Secrets Kubernetes控制器将解密并将其作为正常的密钥保存在Kubernetes中。</p><p></p><p>你可以通过下面的命令验证Secret：</p><p></p><p><code lang=\"plain\">kubectl  get secret mysqlsecret -n kafka -o yaml\n\napiVersion: v1\ndata:\n  mysqlpassword: YWxleA==\n  mysqlrootpassword: YWxleA==\n  mysqluser: YWxleA==\nkind: Secret\nmetadata:\n  creationTimestamp: \"2022-08-21T19:05:21Z\"\n  name: mysqlsecret\n  namespace: kafka\n  ownerReferences:\n  - apiVersion: bitnami.com/v1alpha1\n    controller: true\n    kind: SealedSecret\n    name: mysqlsecret\n    uid: 2a5ee74b-c2b2-49b3-9a9f-877e7a77b163\n  resourceVersion: \"41514\"\n  uid: 494cbe8b-7480-4ebd-9cc5-6fe396795eaa\ntype: Opaque\n</code></p><p></p><p>需要注意的是，这是一个解密的Kubernetes Secret，引用了负责创建它的SealedSecret。因此，SealedSecret的生命周期也与Secret紧密相关。</p><p></p><p>我们已经解决了正确存储YAML文件而不泄露敏感数据的问题，但是当Secret被应用到Kubernetes集群，它是以Base64编码格式存储的，所以它不是密钥。</p><p></p><h4>静态密钥</h4><p></p><p>默认情况下，Kubernetes不会在etcd数据库中存储加密的密钥。静态加密密钥数据是一个很大的话题，值得专门为其写一篇文章（事实上，“<a href=\"https://www.manning.com/books/kubernetes-secrets-management#:~:text=Kubernetes%20Secrets%20Management%20reveals%20how,to%20strengthen%20applications%20and%20infrastructure.\">Kubernetes Secret Management</a>\"”一书专门讨论了这个话题）。每一种Kubernetes实现都有可能使用不同的方式来启用静态密钥加密，尽管最后都是一个被复制到每个kube-apiserver节点中的配置文件（<a href=\"https://kubernetes.io/docs/reference/config-api/apiserver-encryption.v1/\">EncryptionConfiguration</a>\"）。</p><p></p><p>该文件的格式为：</p><p></p><p><code lang=\"plain\">apiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n - resources:\n     - secrets\n   providers:\n     - identity: {}\n     - aesgcm:\n         keys:\n           - name: key1\n             secret: c2VjcmV0IGlzIHNlY3VyZQ==\n           - name: key2\n             secret: dGhpcyBpcyBwYXNzd29yZA==\n     - aescbc:\n         keys:\n           - name: key1\n             secret: c2VjcmV0IGlzIHNlY3VyZQ==\n           - name: key2\n             secret: dGhpcyBpcyBwYXNzd29yZA==\n     - secretbox:\n         keys:\n           - name: key1\n             secret: YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=\n</code></p><p></p><p>在下图中，我们可以看到在kube-apiserver中注册EncryptionConfiguration文件的流程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/939a16eb0a2114d0cd855ba193c983f3.webp\" /></p><p></p><p>现在，我们已经使用SealedSecrets对象来加密YAML文件中的密钥，还使用EncryptionConfiguration文件来保护静态密钥。</p><p></p><h2>结论</h2><p></p><p>保护好所有的基础设施是一件很重要的事情，我们已经在本文中学习了如何使用Kubernetes Secrets来保护对数据库和Kafka的访问。</p><p></p><p>我们不仅可以使用Strimzi定义身份验证，还可以定义授权，提供一些规则，规定谁可以对Kafka主题做什么。</p><p></p><p>访问这些密钥也是一个重要的部分，Quarkus和Debezium允许你以一种高效而安全的方式访问这些密钥，而不需要将密钥持久化在文件系统中（或作为环境变量），而是直接将它们注入内存。</p><p></p><p>安全性是一个重要的话题，当需要在Kafka集群中管理安全性时，Strimzi是一个完美的选择。</p><p></p><p>源代码可以在<a href=\"https://github.com/lordofthejars/movie-plays-kafka/tree/main/strimzi\">GitHub</a>\"上找到。</p><p></p><p>作者简介：</p><p>Alex Soto是Red Hat的开发者体验总监。他对Java、软件自动化充满了热情，并且深信开源软件模式。Soto是“Testing Java Microservices”（Manning）和“Quarkus Cookbook”（O'Reilly）的合著者，也是几个开源项目的贡献者。自2017年以来，他获得了Java Champion称号，也是萨尔Universidad Ramon Llull大学的国际演讲者和教师。如果你想继续关注Kubernetes和Java的动态，可以在Twitter上关注他（<a href=\"https://twitter.com/alexsotob\">https://twitter.com/alexsotob</a>\"）。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/secure-kafka-cluster-strimzi/\">https://www.infoq.com/articles/secure-kafka-cluster-strimzi/</a>\"</p>",
    "publish_time": "2023-03-15 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GPT-4重磅发布，吊打ChatGPT！性能炸天：10秒做出一个网站，在考试中击败90% 人类",
    "url": "https://www.infoq.cn/article/HFSPasQ7SXZ9QzdFXhGO",
    "summary": "<p></p><p></p><blockquote>王炸来袭，OpenAI 联合创始人 Sam Altman 表示，GPT-4是“迄今为止功能最强大的语言模型”。与上一代相比，GPT-4更强大更可靠，且更有创造性。</blockquote><p></p><p></p><h2>GPT-4来了</h2><p></p><p></p><p>OpenAI 的新“核弹”来了。</p><p></p><p>3月14日晚间，OpenAI宣布发布多模态大模型GPT-4。</p><p></p><p>“我们创建了GPT-4，这是 OpenAI 努力扩展深度学习的最新里程碑。GPT-4 是一个大型多模态模型（接受图像和文本输入，提供文本输出），虽然在许多现实世界场景中的能力不如人类，但在各种专业和学术基准上表现出人类水平”，OpenAI表示。</p><p></p><p>OpenAI 联合创始人 Sam Altman 表示，它是“迄今为止功能最强大、最一致的模型”，能够使用图像和文本。</p><p></p><p>在YouTube上的Live Demo中，OpenAI的总裁和联合创始人Greg Brockman展示了GPT-4拥有的强大技能。GPT-4可以总结文章、写代码、报税、写诗……更惊人的是，GPT-4只需10秒就可以做出一个网站。</p><p></p><p>在演示视频中，按如下操作：</p><p></p><p>1、在草稿本上用纸笔画出一个非常粗糙的草图</p><p></p><p>2、拍照告诉 GPT：我要做一个网站长这样，给我生成网站代码</p><p></p><p>3、网站做完，总共历时十秒钟左右</p><p></p><p>不禁令人感叹，又有多少人要失业了。有网友在社交平台表示，“时刻准备下岗吧”。</p><p></p><p>GPT-4 的技术论文：<a href=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</a>\"</p><p></p><p>GPT-4 系统模型卡介绍：<a href=\"https://cdn.openai.com/papers/gpt-4-system-card.pdf\">https://cdn.openai.com/papers/gpt-4-system-card.pdf</a>\"</p><p></p><p>最近这几个月，ChatGPT的爆火，让人们惊叹于人工智能强大的聊天能力。GPT4出来后，可以看到，在聊天之外，人工智能的能力已不断扩展其外延。</p><p></p><p>ChatGPT用的语言模型是 GPT-3.5。在谈到GPT-4比前一个版本强大在哪里时，OpenAI称，虽然这两个版本在随意的谈话中看起来很相似，但“当任务的复杂性达到足够的阈值时，差异就会出现”，GPT-4更可靠、更有创意，并且能够处理更细微的指令。该公司表示，GPT-4响应禁止内容请求的可能性比其前一个版本低82%。OpenAI表示，在内部评估中，GPT-4产生正确回应的可能性要比GPT-3.5高出40%。</p><p></p><p>而且GPT-4是多模态的，同时支持文本和图像输入功能。此外，GPT-4比以前的版本“更大”，这意味着其已经在更多的数据上进行了训练，并且在模型文件中有更多的权重，这也使得它的运行成本更高。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/28/281ebfb0c5e5938242dbe9ef7f9cf3ce.jpeg\" /></p><p></p><p>GPT-4 在一系列基准测试中的表现优于 GPT-3.5</p><p></p><p>OpenAI 称它使用了微软Azure来训练模型，但没有公布有关具体模型大小或用于训练它的硬件的详细信息。</p><p></p><p>据悉，GPT-4参加了多种基准考试测试，包括美国律师资格考试Uniform Bar Exam、法学院入学考试LSAT、“美国高考”SAT数学部分和证据性阅读与写作部分的考试，在这些测试中，它的得分高于88%的应试者。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b9a9092769af2d0a036619ce566e8e1b.png\" /></p><p></p><p>GPT-4 从图像生成食谱</p><p></p><p>OpenAI表示，已经与多家公司合作，要将GPT-4结合到他们的产品中，包括Duolingo、Stripe和Khan Academy。</p><p></p><p>GPT-4模型也将以API的形式，提供给付费版ChatGPT Plus的订阅用户，允许开发者付费将AI集成到他们的应用程序中。</p><p></p><p>微软表示，新款的必应（Bing）搜索引擎将运行于GPT-4系统之上。</p><p></p><p>在 OpenAI 宣布开发出 GPT-4 后，马斯克在推特上评论了这一消息，表达了他对人工智能对就业市场的潜在影响的担忧。马斯克在他的推文中写道：“我们人类还能做什么？我们最好继续使用 Neuralink！（马斯克旗下脑机接口公司）！”</p><p></p><h2>GPT-4：可生成更安全、更有用响应的OpenAI至高系统</h2><p></p><p></p><p>据介绍，凭借更广泛的常识和问题解决能力，GPT-4能为用户提供更准确的回答。</p><p></p><p>GPT-4的创造性和协作能力超越以往各个版本。</p><p></p><p>它能够生成、编辑并与用户一道完成创意和技术性创作任务，包括谱写歌曲、编写剧本或者学习用户的写作风格。</p><p></p><p>例如：</p><p></p><p>输入:</p><p></p><p></p><blockquote>用一句话解释《灰姑娘》的剧情，其中每个单词必须以字母表中从A到Z的下一个字母开头，不得重复字母。</blockquote><p></p><p></p><p></p><p>输出</p><p></p><p></p><blockquote>A beautiful Cinderella, dwelling eagerly, finally gains happiness; inspiring jealous kin, love magically nurtures opulent prince; quietly rescues, slipper triumphs, uniting very wondrously, xenial youth zealously.</blockquote><p></p><p></p><h2>GPT-4的高级推理能力已经超越ChatGPT</h2><p></p><p></p><p>ChatGPT：</p><p></p><p>输入</p><p></p><p></p><blockquote>Andrew从上午11点到下午3点有空，Joanne中午到下午2点有空，之后下午3：30到5点有空。Hannah中午有半小时空闲，之后下午4点到6点有空。如果Andrew、Hannah和Joanne要开个半小时的会，可以选择哪些时段？</blockquote><p></p><p></p><p>输出</p><p></p><p></p><blockquote>以下是空闲时段列表：-Andrew：上午11点至下午3点-Joanne：中午至下午2点，以及下午3：30至5点；-Hannah：中午至12：30，以及下午4点至6点。据此计算，三人都空闲的时间窗口只有一个：下午4点至4：30。因此会议可以安排在下午4点。GPT-4：</blockquote><p></p><p></p><p>输入</p><p></p><p></p><blockquote>Andrew从上午11点到下午3点有空，Joanne中午到下午2点有空，之后下午3：30到5点有空。Hannah中午有半小时空闲，之后下午4点到6点有空。如果Andrew、Hannah和Joanne要开个半小时的会，可以选择哪些时段？</blockquote><p></p><p></p><p>输出</p><p></p><p></p><blockquote>Andrew：上午11点到下午3点；Joanne：中午12点至下午2点，下午3：30至5点；Hannah：中午12点至12：30，下午4点至6点。三人均有空的时段：中午12点至12：30。</blockquote><p></p><p></p><h2>GPT-4在测试中也获得了超过ChatGPT的考核成绩（百分比位次）</h2><p></p><p></p><h4>统一律师考试</h4><p></p><p></p><p>ChatGPT :10%</p><p></p><p>GPT-4: 90%</p><p></p><h4>生物奥赛题</h4><p></p><p>ChatGPT :31%</p><p></p><p>GPT-4 (含视觉):99%</p><p></p><h2>比GPT-3.5准确性提高40%</h2><p></p><p></p><p>沿着对GPT、GPT-2和GPT-3的研究路径，OpenAI的深度学习方法利用更多数据和计算建立起愈发复杂且强大的语言模型。</p><p></p><p>OpenAI投入6个月时间，让GPT-4更安全、也更一致。在OpenAI的内部评估中，与GPT-3.5相比，GPT-4响应拒绝内容请求的几率降低了82%，生成可靠响应的几率提高40%。</p><p></p><h2>安全与对齐</h2><p></p><p></p><h4>人工反馈训练</h4><p></p><p>OpenAI引入了更多人工反馈，包括由ChatGPT用户提交的反馈，以改进GPT-4的行为。OpenAI还与50多位专家合作，在AI安全和保障等领域获得了早期反馈。</p><p></p><h4>在实际应用中不断提升</h4><p></p><p>OpenAI将以往模型在现实应用中的经验教训，引入了GPT-4的安全研究和监控系统当中。与ChatGPT一样，随着使用者越来越多，我们也将定期更新并改进GPT-4。</p><p></p><h4>GPT-4辅助的安全研究</h4><p></p><p>GPT-4的高级推理和指令遵循能力加快了特准的安全工作。OpenAI使用GPT-4辅助创建用于模型微调的训练数据，并在训练、评估和监控流程中对分类器进行迭代。</p><p></p><h2>仍存在缺陷</h2><p></p><p>OpenAI公司CEO Sam Altman 在Twitter上称，GPT-4是其模型“最有能力且最符合”人类价值观和意图的模型，尽管“它仍然存在缺陷”。</p><p></p><p>“它仍然存在缺陷，仍然有限，但它有明显的改进”，Sam Altman写道，“它比以前的模型更有创意，它的幻觉明显减少，而且它的偏见也更少。”</p><p></p><p>参考资料：</p><p></p><p><a href=\"https://openai.com/product/gpt-4\">https://openai.com/product/gpt-4</a>\"</p><p></p><p><a href=\"https://www.youtube.com/watch?v=outcGtbnMuQ\">www.youtube.com/watch?v=outcGtbnMuQ</a>\"</p>",
    "publish_time": "2023-03-15 11:08:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "文心一言发布在即，百度智能云升级三大配套云服务",
    "url": "https://www.infoq.cn/article/8CSP7FiAcFaMSWHIGOIg",
    "summary": "<p>随着ChatGPT、文心一言等AI应用的爆火，支撑人工智能所需的算力需求也随之暴涨。百度表示，将于3月16日发布生成式AI产品“文心一言”。为支持文心一言的超大规模计算需求，进一步实现文心一言的产业化落地，近期百度智能云也频繁公布文心一言配套设施的准备情况。</p><p></p><p>3月14日，百度智能云方面表示，从去年年底开始，百度智能云已经通过三大动作全面升级云服务能力：去年12月发布国内首个全栈自研的AI基础设施“AI大底座”、今年2月升级AI研发运营一体化（MLOps）能力、3月百度阳泉智算中心完成升级。据透露，“文心一言”背后的算力基础设施均由百度智算中心支持，后续百度多个智算中心也将为“文心一言”面向产业的规模化落地提供底层支撑。</p><p></p><h2>生成式AI产业落地面临三大挑战，云市场规则正在改变</h2><p></p><p></p><p>在生成式 AI 的热潮背后，云计算对于企业的价值发生了根本质变：从提供基础设施转变为提供智能服务，这同时也夯实了生成式AI产品与产业结合的更多可能性。百度创始人、CEO李彦宏表示，“文心一言”是基于百度智能云技术打造出来的大模型，它将根本性地改变云市场的游戏规则。</p><p></p><p>而这种颠覆式变革，也意味着文心一言等生成式AI产品在产业规模化落地上面临多重挑战。具体而言，挑战主要体现在以下三个方面：首先是智能算力，生成式AI产品的数据量巨大，运行需要空前强大的AI算力，这对现有计算机体系结构提出了挑战。其次是AI基础设施，文心一言等人工智能产品的计算场景复杂、计算架构多维，企业进行AI开发需要集芯片、框架、模型及应用为一体的全栈AI基础设施，端到端的智能化闭环AI开发的全流程。最后是AI工程化水平，AI生成式产品落地到产业实践时，需基于具体业务场景进行二次适配开发。而AI模型的开发运营全流程复杂程度高，任何一环操作不规范都将影响AI模型效果。AI工程化水平决定了AI能否突破产业落地的“最后一公里”。</p><p></p><p>面对云市场新的游戏规则，只有为企业解决以上三大挑战的云厂商才有资格拿到入场券。百度集团执行副总裁、百度智能云事业群总裁沈抖表示，云服务已从数字时代跃迁到智能时代，以前企业选择云厂商更多是看算力、存储等基础云服务，以后企业对云的需求会更加聚焦智能服务水平。</p><p></p><h2>文心一言即将发布，百度智能云升级三大配套云服务</h2><p></p><p></p><p>智算时代下，企业面临上述智能算力短缺、AI开发全流程复杂、AI产业落地工程化困难等诸多挑战，百度智能云凭借“云智一体“独特优势给出了答案。百度表示，将为产业提供三大方面的核心能力，助力产业智能化转型走上快车道。</p><p></p><p>其一，为企业提供巨量高性能智能算力，以支持文心一言等生成式AI产品的产业落地。百度目前已在山西阳泉、江苏盐城等地建设智算中心。其中，百度阳泉智算中心是亚洲最大单体智算中心，建设规模为4 EFLOPS（每秒400亿亿次浮点运算）AI算力，可满足各行业超大规模AI计算需求。昆仑芯科技战略负责人宋春晓表示：“人工智能芯片是算力的核心，昆仑芯2代已在百度文心大模型的应用中广泛落地，并为各行各业的智能化升级提供AI算力支持。”</p><p></p><p>据了解，百度智算中心持续创新计算架构，支持智算时代下企业不同业务场景的计算任务，提升企业的业务效率和创新能力。目前，百度智算中心已支持了文心预训练大模型、生物计算、自动驾驶等前沿AI应用。同时，基于自研创新技术可使PUE低至1.08，实现了高效节能的运行，从而降低客户的电费和运维成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0ac43fc7f98876393a8f64f434c2f24c.png\" /></p><p>（百度阳泉智算中心实景图）</p><p></p><p>其二，为企业提供新型AI基础设施，实现AI开发的降本增效。百度智能云通过对算力、框架、模型、AI应用进行封装，推出“百度AI大底座”。从高端芯片昆仑芯，到飞桨深度学习框架，到文心预训练大模型，再到AI应用，实现端到端的智能化闭环，从而把高门槛的AI技术，变成像水电能一样供企业按需取用，大幅降低企业开发成本，提升效率。百度智能云云计算产品解决方案和运营部总经理宋飞表示：“百度AI大底座可基于实际业务数据进行不断调优，使得资源利用率提升至70%，企业开发效率提升100%。”</p><p></p><p>最后，为企业提供AI研发运营一体化（MLOps）能力，加速生成式AI等大模型产品快速产业落地。百度AI中台总监忻舟表示，百度AI大底座将面向企业提供一系列AI研发运维工具。企业在接入文心一言后，可低成本、便捷地完成与业务场景的适配与二次开发，通过AI工程化能力帮助产业突破AI落地的“最后一公里”。</p><p>在低成本多架构的智能算力、“AI大底座”新型AI基础设施、MLOps&nbsp;AI工程化能力的支撑下，文心一言将推动产业智能化加速到来，带来真正的AI普惠。</p>",
    "publish_time": "2023-03-15 11:47:22",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "信息检索顶会WSDM CUP 2023揭榜，腾讯获两项任务冠军，成果基于混元AI大模型和太极机器学习平台实现",
    "url": "https://www.infoq.cn/article/6XPmgbG2sSW51frlfIZj",
    "summary": "<p>近日，信息检索领域国际顶级学术会议WSDM（Web Search and Data Mining）宣布了WSDM CUP 2023竞赛成绩，来自腾讯的研究团队基于大模型预训练、搜索排序以及集成学习等技术上的突破，在无偏排序学习和互联网搜索预训练模型赛道上的两项任务中获得冠军。</p><p>&nbsp;&nbsp;</p><p>ACM WSDM（Web Search and Data Mining） 会议是信息检索领域顶级会议之一，由SIGIR、SIGKDD、SIGMOD和SIGWEB四个专委会协调筹办，在互联网搜索、数据挖掘领域享有较高学术声誉。第16 届 ACM 国际 WSDM 会议于 2023 年 2 月 27 日至 3 月 3 日在新加坡举行，论文的接收率为17.8%。</p><p>&nbsp;</p><p>WSDM Cup由 WSDM 会议举办，本届 WSDM Cup 共计400余支队伍参加，分别来自中国、美国、新加坡、日本、印度等国家的知名高校和公司，大赛共设置三个赛道：无偏排序学习和互联网搜索预训练模型赛道（Unbiased Learning to Rank and Pre-training for Web Search）、跨语言连续体的多语言信息检索赛道（Multilingual Information Retrieval Across a Continuum of Languages）和视觉问答挑战赛道（Visual Question Answering Challenge）。</p><p>&nbsp;</p><p>此次腾讯「参赛队名：腾讯机器学习平台部搜索团队（TMLPS）」参加了无偏排序学习和互联网搜索预训练模型赛道，并在该赛道的两项子任务中（Pre-training for Web Search和Unbiased Learning to Rank）获得冠军。</p><p>&nbsp;</p><p>目前两项成果代码和论文均已发布到Github上（见：GitHub - lixsh6/Tencent_wsdm_cup2023）</p><p>&nbsp;</p><p>在深度学习领域，数据标注的质量对于模型的效果有着较为显著的影响，但是较高的标注数据成本一直是研究团队的阻碍之一，如何从技术上利用无标注的数据训练模型自然成为了成为学术界和工业界关注的热点。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/46/4619faee409940ca42bd431d14f4907f.png\" /></p><p></p><p>&nbsp;</p><p>论文：Multi-Feature Integration for Perception-Dependent Examination-Bias Estimation</p><p>地址：https://arxiv.org/pdf/2302.13756.pdf</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/2c/2cef11ea0093d51f0c49a406efc8e1f4.png\" /></p><p></p><p>本次比赛，针对基于搜索的预训练任务（Pre-training for Web Search），腾讯团队通过大模型训练、用户行为特征去噪等方法，在点击日志上进行基于搜索排序的模型预训练，进而使模型有效地应用到下游相关性排序的检索任务。通过预训练、模型微调、集成学习等多方面的优化，在人工标注的相关性排序任务上取得了较大的领先优势。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/19/19a320d0a016fab483e8fedef5b17469.png\" /></p><p></p><p>论文：Pretraining De-Biased Language Model with Large-scale Click Logs for Document Ranking</p><p>地址：https://arxiv.org/pdf/2302.13498.pdf</p><p>&nbsp;</p><p>在本次比赛的另一赛道无偏排序学习任务（Unbiased Learning to Rank）中，团队通过深入挖掘点击日志信息，充分利用包括文档媒体类型、文档展示高度和点击后的滑屏次数等特征对文档相关性进行无偏估计，提出了一种能够集成多种偏置因素的多特征集成模型，有效地提升了搜索引擎中文档排序的效果。</p><p>&nbsp;</p><p>据了解，夺冠团队的成果均基于腾讯混元AI大模型（下文简称“HunYuan”）和太极机器学习平台实现。目前，通过联合微信搜索团队，两项技术已经在微信搜一搜的多个场景落地相关技术，并取得了显著的效果提升。</p><p>&nbsp;</p><p>AI大模型（又称预训练模型）是指预先训练好，具有相对通用性的“一套算法”，具有“巨量数据、巨量算力、巨量模型”等特性。大模型通过学习样本数据的内在规律和表达层次，发展出接近、超越人类水平的“智能”，具备分析推理能力，能够识别文字、图像和声音等。</p><p>&nbsp;</p><p>2022年4月，腾讯首次对外披露HunYuan大模型研发进展。HunYuan集CV（计算机视觉）、NLP（自然语言理解）、多模态理解能力于一体，先后在MSR-VTT、MSVD等五大权威数据集榜单中登顶，实现跨模态领域的大满贯。2022年5月，在国际公认的CLUE（中文语言理解评测集合）三个榜单同时登顶。近日，HunYuan又迎来全新进展，推出国内首个低成本、可落地的NLP万亿大模型，并再次登顶CLUE。</p><p>&nbsp;</p><p>腾讯太极机器学习平台是集模型训练和在线推理于一身的高性能机器学习平台，具备万亿参数模型的训练和推理能力，为AI大模型预训练推理和应用落地提供了完整的端到端工程能力支撑，一站式解决算法工程师在 AI 应用过程中特征处理、模型训练、模型服务等工程问题。</p>",
    "publish_time": "2023-03-15 14:23:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Netflix 构建可伸缩注解服务：使用 Cassandra、Elasticsearch 和 Iceberg",
    "url": "https://www.infoq.cn/article/OyexDC2CWghbD2MsNJoA",
    "summary": "<p></p><h1>背景</h1><p></p><p></p><p>Netflix有数百个微服务，每个微服务都有自己的数据模型或实体。例如，我们有一个存储电影实体元数据的服务，或者一个存储图像元数据的服务。这些服务在未来的某个时刻希望对它们的对象或实体进行注解。我们的团队（Asset Management Platform）决定创建一个叫作Marken的通用服务，让Netflix的任何一个微服务都能注解它们的实体。</p><p></p><p></p><h1>注解</h1><p></p><p></p><p>人们有时候会把注解理解成标签。在Marken中，注解是一种元数据，可以被附加到任意领域对象上。我们的客户端应用程序想要生成许多不同种类的注解。下面是一个简单的注解，描述了某一部电影带有暴力内容。</p><p></p><p></p><blockquote>Movie Entity with id 1234 has violence.（ID为1234的Movie实体包含了暴力内容）</blockquote><p></p><p></p><p>更有趣的是，用户有时候希望能够保存时间数据或空间数据。图1是一个应用程序示例，剪辑师用它来评审他们的工作。他们希望将手套的颜色改为瑞克黑色，这样他们就能够标记这个区域，在本例中使用蓝色圆圈圈起来，并保存注解。这是评审应用程序的一个典型用例。</p><p></p><p>同时保存时间和空间数据的另一个例子是机器学习算法，它们可以识别帧中的字符，并保存如下内容：</p><p></p><p>在特定的帧（时间）；在图像的某个区域（空间）；字符名（注解数据）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/030aa1fdb68889ca8b5014cdc5d9fd69.png\" /></p><p></p><p></p><p></p><h1>Marken的目标</h1><p></p><p></p><p>我们希望创建一个注解服务，它将实现以下这些目标。</p><p></p><p>可以对任意实体进行注解。用户应该能够定义注解数据模型。注解可以进行版本控制。这个服务应该能够为实时（UI）应用程序提供服务，因此CRUD和搜索操作应该是低延迟的。所有数据都可以在Hive/Iceberg中进行离线分析。</p><p></p><p></p><h1>Schema</h1><p></p><p></p><p>因为Netflix的所有团队都可以使用注解服务，所以我们需要支持不同的数据模型。Marken中的数据模型可以使用Schema来描述——就像我们为数据库表创建Schema一样。</p><p></p><p>我们的团队有另外一个服务，它使用基于JSON的DSL来描述媒体资产Schema。我们对这个服务进行了扩展，也可以用它来描述注解对象的Schema。</p><p></p><p><code lang=\"text\">{\n      \"type\": \"BOUNDING_BOX\", ❶\n      \"version\": 0, ❷\n      \"description\": \"Schema describing a bounding box\",\n      \"keys\": {\n        \"properties\": { ❸\n          \"boundingBox\": {\n            \"type\": \"bounding_box\",\n            \"mandatory\": true\n          },\n          \"boxTimeRange\": {\n             \"type\": \"time_range\",\n             \"mandatory\": true\n          }\n      }\n    }\n}</code></p><p></p><p>在上面的例子中，应用程序想要在视频中表示一个跨越了一段时间的矩形区域。</p><p></p><p>Schema的名称叫BOUNDING_BOX。Schema有版本化，用户可以在数据模型中添加或删除属性。我们不允许出现不兼容的变更，例如，用户不能修改属性的数据类型。被保存的数据在“属性”部分，在本例中有两个属性。boundingBox属性的类型为“bounding_box”，表示一个矩形区域。boxTimeRange属性的类型为“time_range”，我们可以为这个注解指定开始和结束时间。</p><p></p><p></p><h1>几何对象</h1><p></p><p></p><p>为了在注解中表示空间数据，我们使用了<a href=\"https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg2ODc2OTMsImZpbGVHVUlEIjoieU9YdWFHb2Y3S1FVUm1KSSIsImlhdCI6MTY3ODY4NzM5MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.2HA_W8NwGE-TQf71fK_WrnHG0qbeyX6KRkiRSqXF2dU\">Well Known Text</a>\"（WKT）格式。我们支持以下这些对象：</p><p></p><p>PointLineMultiLineBoundingBoxLinearRing</p><p></p><p>我们的模型是可扩展的，可以根据需要添加更多的几何对象。</p><p></p><p></p><h1>时间对象</h1><p></p><p></p><p>有几个应用程序需要保存包含时间的视频的注解。应用程序可以将时间保存为帧数或纳秒。</p><p></p><p>要以帧为单位保存数据，客户端还需要保存每秒的帧数。我们把它叫作SampleData，包含了以下组件：</p><p></p><p>sampleNumber，即帧号；sampleNumerator；sampleDenominator。</p><p></p><p></p><h1>注解对象</h1><p></p><p></p><p>与Schema一样，注解对象也用JSON表示。下面是BOUNDING_BOX的注解示例。</p><p></p><p><code lang=\"text\">{  \n  \"annotationId\": { ❶\n    \"id\": \"188c5b05-e648-4707-bf85-dada805b8f87\",\n    \"version\": \"0\"\n  },\n  \"associatedId\": { ❷\n    \"entityType\": \"MOVIE_ID\",\n    \"id\": \"1234\"\n  },\n  \"annotationType\": \"ANNOTATION_BOUNDINGBOX\", ❸\n  \"annotationTypeVersion\": 1,\n  \"metadata\": { ❹\n    \"fileId\": \"identityOfSomeFile\",\n    \"boundingBox\": {\n      \"topLeftCoordinates\": {\n        \"x\": 20,\n        \"y\": 30\n      },\n      \"bottomRightCoordinates\": {\n        \"x\": 40,\n        \"y\": 60\n      }\n  },\n  \"boxTimeRange\": {\n    \"startTimeInNanoSec\": 566280000000,\n    \"endTimeInNanoSec\": 567680000000\n  }\n }\n}</code></p><p></p><p>第一个组件是这个注解的唯一性ID。注解是不可变对象，因此注解的标识总会包含版本信息。每当有人更新这个注解时，我们会自动增加它的版本号。注解必须与某个属于某个微服务的实体相关联。在本例中，这个注解是为ID为“1234”的电影创建的。然后我们指定了注解的Schema类型，在本例中是BOUNDING_BOX。实际的数据保存在JSON的metadata部分。就像我们上面讨论的，包含了一个边界框和以纳秒为单位的时间段。</p><p></p><p></p><h1>基础Schema</h1><p></p><p></p><p>与面向对象编程一样，我们的服务也支持Schema继承，这样客户端就可以在Schema之间创建“is-a-type-of”的关系。与Java不同的是我们还支持多重继承。</p><p></p><p>我们有几个机器学习算法，它们扫描Netflix的媒体资产（图像和视频），并创建非常有趣的数据，例如识别帧中的字符或识别匹配剪辑。然后，这些数据作为注解保存在我们的服务中。</p><p></p><p>作为一个平台服务，我们创建了一些基础Schema，方便为不同的机器学习算法创建新的Schema。一个基础模式（TEMPORAL_SPATIAL_BASE）具有以下这些可选的属性。这个基础Schema可以派生出任意的Schema，不限于机器学习算法。</p><p></p><p>Temporal（与时间相关的数据）；Spatial（几何数据）。</p><p></p><p>另一个BASE_ALGORITHM_ANNOTATION包含了以下可选的属性，机器学习算法通常会使用它。</p><p></p><p>label（字符串类型）；confidenceScore（双精度类型）——表示算法生成数据的置信度；algorithmVersion（字符串类型）——机器学习算法的版本。</p><p></p><p>一个典型的机器学习算法通过使用多重继承可以继承TEMPORAL_SPATIAL_BASE和BASE_ALGORITHM_ANNOTATION两种Schema。</p><p><code lang=\"text\">{\n  \"type\": \"BASE_ALGORITHM_ANNOTATION\",\n  \"version\": 0,\n  \"description\": \"Base Schema for Algorithm based Annotations\",\n  \"keys\": {\n    \"properties\": {\n      \"confidenceScore\": {\n        \"type\": \"decimal\",\n        \"mandatory\": false,\n        \"description\": \"Confidence Score\",\n      },\n      \"label\": {\n        \"type\": \"string\",\n        \"mandatory\": false,\n        \"description\": \"Annotation Tag\",\n      },\n      \"algorithmVersion\": {\n        \"type\": \"string\",\n        \"description\": \"Algorithm Version\"\n      }\n    }\n  }\n}</code></p><p></p><p></p><h1>架构</h1><p></p><p></p><p>基于我们的服务目标，在进行架构设计时必须牢记以下这几点。</p><p></p><p>我们的服务将被许多内部UI应用程序使用，因此CRUD和搜索操作的延迟必须很低。除了应用程序，我们还需要保存机器学习算法数据。其中一些数据属于视频帧级别，因此存储的数据量可能很大。我们选择的数据库应该是水平可伸缩的。我们预计服务的RPS会很高。</p><p></p><p>其他一些目标来自搜索需求。</p><p></p><p>具备搜索时间和空间数据的能力。能够使用不同的关联ID和附加的关联ID进行搜索。全文搜索注解对象中的不同字段。支持词干搜索。</p><p></p><p>随着时间的推移，搜索的需求只会增加，我们将在后续的小节中详细讨论这些需求。</p><p></p><p>考虑到我们团队的需求和专业知识，我们决定用Cassandra来保存注解。为了支持不同的搜索需求，我们选择了ElasticSearch。除了支持各种功能外，我们还有一些内部辅助服务，如ZooKeeper服务、国际化服务等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/39/39e7362d71f1e7184764180c40cc92d7.png\" /></p><p></p><p>Marken的架构</p><p></p><p>上图是Marken服务的架构图。左边是我们的几个客户端团队创建的数据管道，它们自动将新数据输入到我们的服务中。其中最重要的数据管道是由机器学习团队创建的。</p><p></p><p>Netflix的媒体搜索平台现在使用Marken来存储注解，并执行稍后将介绍的各种搜索操作。我们的架构使得从媒体算法中加载和摄取数据变得十分容易。这些数据被不同的团队使用，例如宣传媒体团队用它们来改善他们的工作流程。</p><p></p><p></p><h1>搜索</h1><p></p><p></p><p>注解服务（数据标签）的成功主要依赖了在不了解大量输入算法细节的情况下对标签进行的高效搜索。如上所述，被索引到服务中的每一个新注解类型（取决于算法）使用了基础Schema。这有助于客户端搜索不同的注解类型。客户端可以通过简单的数据标签或添加更多的过滤器（如电影ID）进行搜索。</p><p></p><p>我们定义了一种自定义查询DSL，支持对注解结果进行搜索、排序和分组。我们使用Elasticsearch作为后端搜索引擎支持不同类型的搜索查询。</p><p></p><p>全文搜索——客户端可能不知道机器学习算法创建了哪些标签。例如，标签可以是“shower curtain（浴帘）”，全文搜索可以让客户端通过使用标签“curtain”搜索找到注解。我们还支持标签的模糊搜索。例如，如果客户端想要搜索“curtain”，但他们错误地输入了“curtian”，服务将返回带有“curtain”标签的注解。词干搜索——由于Netflix支持全球不同语言的内容，我们的客户端需要支持不同语言的词干搜索。Marken服务包含了Netflix所有电影的字幕，包括多种不同的语言。举个词干搜索的例子——“clothing”和“clothes”的词根都为“ cloth”。我们使用ElasticSearch支持34种不同语言的词干搜索。时间注解搜索——如果视频注解包含了时间信息（开始和结束时间范围），那么它的相关性就更强了。视频的时间范围映射到了帧号。我们支持对提供的时间范围/帧数内的时间注解进行标签搜索。空间注解搜索——视频或图像的注解也可以包含空间信息。例如，定义标注对象在注解中的位置的边界框。时间和空间搜索——视频的注解可以同时包含时间范围和空间坐标。因此，我们支持搜索指定的时间范围和空间坐标范围内的注解。语义搜索——在理解用户查询的意图后搜索注解。这种类型的搜索会在概念上匹配相似的查询关键字，这与传统的基于标记的搜索不同，传统的基于标记的搜索会精确地匹配关键字。机器学习算法还摄取带有向量的注解（非实际标签）来支持这种类型的搜索。我们使用相同的机器学习模型将用户提供的文本转换为向量，然后使用转换后的“文本到向量”执行搜索，找到与搜索向量最接近的向量。根据客户端的反馈，这样的搜索提供了更为相关的结果，并且在没有找到与用户提供的查询标签完全匹配的注解的情况下不会返回空结果。我们使用Open Distro for ElasticSearch来支持语义搜索。我们将在以后的文章中详细介绍语义搜索。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/dc/dce3811ee6485d4989df72517f8888c2.png\" /></p><p></p><p>语义搜索</p><p></p><p>范围交集——我们最近开始支持针对特定标题的多个注解类型交集进行实时查询。客户端可以在视频特定时间范围或整个视频内搜索多个数据标签（由不同的算法产生，因此它们是不同的注解类型）。一个常见例子是找到“James in the indoor shot drinking wine”。对于这样的查询，查询处理器先找到数据标签（James、Indoor shot）和向量搜索（drinking wine）的结果，然后在内存中找到结果的交集。</p><p></p><p></p><h1>搜索延迟</h1><p></p><p></p><p>我们的客户端应用程序是UI应用程序，它们期望低延迟的搜索。如之前所述，我们通过使用Elasticsearch支持这样的查询。为了保持低延迟，我们必须确保所有的注解索引是均衡的，并且不会因为回填旧电影数据摄入算法而出现热点。我们采用了滚动索引策略，避免集群中出现这类热点，这些热点会导致CPU利用率峰值并降低查询的响应速度。普通搜索的延迟达到了毫秒级。语义搜索的延迟比普通搜索高一些。下图显示了普通搜索和语义搜索（包括<a href=\"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg2ODc2OTMsImZpbGVHVUlEIjoieU9YdWFHb2Y3S1FVUm1KSSIsImlhdCI6MTY3ODY4NzM5MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.2HA_W8NwGE-TQf71fK_WrnHG0qbeyX6KRkiRSqXF2dU\">KNN</a>\"和<a href=\"https://opendistro.github.io/for-elasticsearch-docs/docs/knn/approximate-knn/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg2ODc2OTMsImZpbGVHVUlEIjoieU9YdWFHb2Y3S1FVUm1KSSIsImlhdCI6MTY3ODY4NzM5MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.2HA_W8NwGE-TQf71fK_WrnHG0qbeyX6KRkiRSqXF2dU\">ANN</a>\"搜索）的平均搜索延迟。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18da2a426bb98eab0f02429653b6c137.png\" /></p><p></p><p>平均搜索延迟</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8d68c3b04418bce0fd2d2a55ba89351d.png\" /></p><p></p><p>语义搜索延迟</p><p></p><p></p><h1>伸缩性</h1><p></p><p></p><p>设计注解服务的一个关键挑战是处理Netflix不断增长的电影目录和机器学习算法需求。视频内容分析在跨应用程序内容利用中起着至关重要的作用。我们预计机器学习算法类型将在未来几年得到广泛发展。随着注解数量的增长及其在应用程序中的使用，解决可伸缩性问题就变得至关重要。</p><p></p><p>机器学习数据管道的数据摄取通常是批量进行的，特别是在设计新算法并为整体目录生成注解时。我们已经建立了一个不同的技术栈（实例集群）来控制数据摄取流，为客户端提供一致的搜索延迟体验。在这个技术中，我们使用Java线程池控制对后端数据库的写吞吐量。</p><p></p><p>Cassandra和Elasticsearch后端数据库为数据和查询不断增长的服务提供水平伸缩能力。我们从12个节点的Cassandra集群开始，扩展到现在的24个节点。今年基本上已经为Netflix的整体目录添加了注解。一些标题有超过3M的注解（其中大部分与字幕有关）。目前，这个服务大约有19亿个注解，数据大小为2.6TB。</p><p></p><p></p><h1>分析</h1><p></p><p></p><p>我们可以跨多个类型批量搜索注解，为一个标题或多个标题构建数据事实。对于这样的用例，我们将所有注解数据持久化在<a href=\"https://iceberg.apache.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg2ODc2OTMsImZpbGVHVUlEIjoieU9YdWFHb2Y3S1FVUm1KSSIsImlhdCI6MTY3ODY4NzM5MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.2HA_W8NwGE-TQf71fK_WrnHG0qbeyX6KRkiRSqXF2dU\">Iceberg</a>\"表中，这样就可以使用不同的维度批量查询注解，而不会影响实时应用程序CRUD操作的响应速度。</p><p></p><p>一个常见的用例是媒体算法团队会批量读取不同语言的字幕数据来改进他们创建的机器学习模型。</p><p></p><p></p><h1>未来的工作</h1><p></p><p></p><p>在这个领域还有很多有趣的工作要做。</p><p></p><p>我们的数据量随着时间的推移不断增加。我们修改过几次算法，与新版本相关的注解变得更加准确和实用。因此我们需要在不影响服务的情况下清理大量的数据。我们需要在低延迟交集查询大规模数据并返回结果方面投入更多的时间。</p><p></p><p></p><h5>原文链接：</h5><p></p><p><a href=\"https://netflixtechblog.com/scalable-annotation-service-marken-f5ba9266d428?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2Nzg2ODc2OTMsImZpbGVHVUlEIjoieU9YdWFHb2Y3S1FVUm1KSSIsImlhdCI6MTY3ODY4NzM5MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo4NjM1Mzc3OX0.2HA_W8NwGE-TQf71fK_WrnHG0qbeyX6KRkiRSqXF2dU\">https://netflixtechblog.com/scalable-annotation-service-marken-f5ba9266d428</a>\"</p><p></p><h5>相关阅读:</h5><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzA4NTU2MTg3MQ==&amp;mid=2655180031&amp;idx=1&amp;sn=6deb0568464e2ed75d846419404bd1e6&amp;chksm=8460739fb317fa89a1fd278e62c2e17684fa96d05b4aa50d3fd7dae1193fbd468a0a1f4cf961&amp;scene=27#wechat_redirect\">没有CTO的Netflix：为什么程序员都愿意来？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/3dc7d7358de9a4dce8930ac99\">Iceberg0.11 与 Spark3.0 结合</a>\"</p><p><a href=\"https://www.infoq.cn/article/w4VV1MBhw6VGuxHO9ui2\">Netflix 的 CEO：为什么我们愿意高薪雇佣程序员？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/31d5f47225000b78f129eedf9\">应用实践 | Apache Doris 整合 Iceberg + Flink CDC 构建实时湖仓一体的联邦查询分析架构</a>\"</p>",
    "publish_time": "2023-03-15 16:12:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Facebook iOS版：探索移动应用10年演进之路",
    "url": "https://www.infoq.cn/article/Wtg6eRqRfmHfHkhaoNmf",
    "summary": "<p>iOS版Facebook（FBiOS）是Meta公司所掌握的最古老的移动端代码库。自<a href=\"https://engineering.fb.com/2012/08/23/ios/under-the-hood-rebuilding-facebook-for-ios/\">2012年应用重写</a>\"以来，这版应用经过数千名工程师的改动和调整、被交付给全球数十亿用户，并可支持数百名工程师同时对其进行迭代。</p><p>&nbsp;</p><p><a href=\"https://engineering.fb.com/2012/08/23/ios/under-the-hood-rebuilding-facebook-for-ios/\">经过多年演进</a>\"，FBiOS的代码库已经跟典型的iOS代码库大有区别：</p><p>&nbsp;</p><p>充斥着C++、Objective-C（++）与Swift代码。包含几十个<a href=\"https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/DynamicLibraries/100-Articles/UsingDynamicLibraries.html\">动态加载库</a>\"（dylibs），以及很多无法一次性加载到Xcode中的类。Apple SDK的直接使用率几乎为零——所有内容都被打包或替换成了内部抽象的形式。在Fcaebook的自定义构建系统Buck的推动下，这款应用大量使用代码生成技术。如果构建系统不配备巨大的缓存，那么应用构建大概要花掉工程师们整整一天的时间。</p><p>&nbsp;</p><p>千万不要误会，FBiOS的整个架构设计过程从来就没有故意朝着这个混乱的方向前进。这款应用的代码库其实是过去10年间持续演进的体现，反映的是越来越多工程师参与到开发中来、对应用稳定性的强调以及改善用户体验等核心技术决策。</p><p>&nbsp;</p><p>如今，为了庆祝这套代码库的10岁生日，让我们一同回顾整个演变历程背后的重要决定和历史背景。</p><p></p><p></p><h1>2014年：建立自己的移动框架</h1><p></p><p>&nbsp;</p><p>在Meta对Facebook应用进行原生重写的两年之后，News Feed代码库开始出现可靠性问题。当时，News Feed的数据模型由苹果的默认数据模型管理框架Core Data负责支持。Core Data中的对象是可变的，这并不适合News Feed的多线程架构。更糟糕的是，News Feed还在使用双向数据流，这正源自苹果Cocoa应用中的默认设计模式Model View Controller。</p><p>&nbsp;</p><p>最终，这样的设计加剧了非确定性代码的产生，工程师们发现这些代码既难以调试、又很难进行bug重现。面对这样一种不可持续的架构，是时候做点什么了。</p><p>&nbsp;</p><p>在考虑新设计时，一位工程师研究了Facebook的（开源）UI框架React。React的声明式设计能够将Feed上棘手的命令式代码抽象出来，同时利用单向数据流降低代码的归因难度，因此在JavaScript社区中越来越流行。这些功能特性似乎很适合处理News Feed面对的挑战，只剩下一个问题……</p><p>&nbsp;</p><p>Apple SDK中不提供声明式UI。</p><p>&nbsp;</p><p>那时候距离<a href=\"https://developer.apple.com/swift/blog/?id=14\">Swift的发布</a>\"还有几个月，而SwiftUI（苹果的声明式UI框架）更是要到2019年才亮相。如果News Feed想要获得声明式UI，就必须得由开发团队自己动手打造。</p><p>&nbsp;</p><p>认真权衡了一番后，开发团队决定自己动手。</p><p>&nbsp;</p><p>经过几个月的构建和迁移之后，News Feed终于运行在了新的声明式UI与数据模型上，这让FBiOS的性能提高了50%。几个月后，他们将这套受React启发的移动UI框架推向开源，并正式命名为ComponentKit。</p><p>&nbsp;</p><p>时至今日，COmponentKit仍然是Facebook中原生UI的最佳构建选项。它通过视图重用池、视图扁平化和背景布局计算等功能，为应用带来了可观的性能改进。它甚至启发了SwiftUI乃至Android阵营的对手<a href=\"https://engineering.fb.com/2018/01/31/android/improving-android-video-on-news-feed-with-litho/\">Litho</a>\"。</p><p>&nbsp;</p><p>总而言之，选择用自定义基础设施替换UI和数据层代表着一种权衡。为了实现可靠、可维护且令人满意的用户体验，开发团队决定放下自己在Apple API上积累的专业知识，从零开始探索内部基础设施。</p><p>&nbsp;</p><p>FBiOS在最终用户体验与开发者体验/速度间的取舍，到这里才刚刚拉开帷幕。时间来到2015年，该应用的成功迅速引起了功能爆炸，一系列独特挑战也接踵而来。</p><p>&nbsp;</p><p></p><h1>2015年：架构转折点</h1><p></p><p>&nbsp;</p><p>2015年，Meta开始全力强调其“移动优先”的口号，FBiOS代码库的日均贡献量也开始急剧提升。随着越来越多产品被集成到该应用当中，程序的启动速度也越来越慢，甚至连普通用户都注意到了这一点。到2015年底，应用的启动时长已将近30秒，稍不留神就有可能被手机操作系统强制关闭。</p><p>&nbsp;</p><p>经过调查，开发团队发现了一系列会导致启动性能下降的因素。为了简洁起见，这里我们只提对于应用架构存在长期影响的原因：</p><p>&nbsp;</p><p>由于应用体量随着新的产品和功能的增加而膨胀，应用的“premain”时间正在无限制延长。应用的“模块”系统允许各个产品不受约束地访问所有应用资源，于是引发了<a href=\"https://en.wikipedia.org/wiki/Tragedy_of_the_commons\">公共资源争用</a>\"的闹剧。每个产品在启动时都会利用自己的“hook”执行高计算量操作，这就造成指向各产品的导航操作经常出现卡顿。</p><p>&nbsp;</p><p>而要想对优化和改进启动过程，相应的变更将从根本上改变产品工程师在FBiOS上的代码编写方式。</p><p>&nbsp;</p><p></p><h1>2016年：动态库与模块化</h1><p></p><p>&nbsp;</p><p>根据苹果关于改进启动时间的维基页面，在调用应用的“main”函数之前必须完成一系列操作。通常来说，应用本体的代码越多，启动所需的时间就越长。</p><p>&nbsp;</p><p>虽然“pre-main”只占30秒启动时长当中的一小部分，但却特别值得关注。因为随着FBiOS新功能的不断引入，这部分负载会无休无止地膨胀、延长。</p><p>&nbsp;</p><p>为了帮助缓解应用启动时间无限延长的问题，Facebook工程师开始将大量产品代码转移到动态库（dylib）当中，也就是延迟加载容器。通过这种方式，这部分代码就不需要在应用的main()函数前进行预加载了。</p><p>&nbsp;</p><p>最初，FBiOS dylib的结构如下所示：&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9ca6a2feeb9b3b4af67f8871e21e7fc0.png\" /></p><p></p><p>这里我们创建两个产品动态库（FBCamera和NotOnStartup），而第三个动态库（FBShared）是用于在各动态库和主应用的二进制文件间共享代码的。</p><p>&nbsp;</p><p>动态库的效果很好，FBiOS也终于遏制住了应用启动时间无限延长的问题。随着时光流逝，大部分代码最终都跑到了动态库里头，这样应用的启动性能就一直很快、不会受到应用中产品添加/删除的影响。</p><p>&nbsp;</p><p>事实上，动态库的加入了彻底改变了Meta产品工程师编写代码的方式。在此之后，NSClassFromString() 这类运行时API所需要的类存在于未经加载的动态库内，所以可能引发运行时故障。另外，因为FBiOS中大量原有核心抽象均建立在遍历内存中所有类的基础之上，因此FBiOS被迫重新审视这套核心系统的有效性。</p><p>&nbsp;</p><p>除了运行时故障之外，动态库还引发了一类新的链接器错误。如果Facebook（启动集）中的代码引用了动态库中的代码，则链接器会向工程师弹出以下错误：</p><p></p><p><code lang=\"null\">Undefined symbols for architecture arm64:\n  \"_OBJC_CLASS_$_SomeClass\", referenced from:\n      objc-class-ref in libFBSomeLibrary-9032370.a(FBSomeFile.mm.o)</code></p><p>&nbsp;</p><p>为了解决这个问题，工程师需要用特殊的函数将代码打包起来，由该函数在必要时加载动态库：</p><p>于是在一夜之间，原本的：</p><p>&nbsp;</p><p><code lang=\"null\">int main() {\n  DoSomething(context);\n}</code></p><p>&nbsp;</p><p>就变成了：</p><p>&nbsp;</p><p><code lang=\"null\">int main() {\n  FBCallFunctionInDylib(\n    NotOnStatupFramework,\n    DoSomething,\n    context\n  );\n}</code></p><p>&nbsp;</p><p>&nbsp;</p><p>这么改当然不是不行，但却带来了新的麻烦：</p><p>&nbsp;</p><p>特定于应用的动态库枚举将被硬编码至各种调用站点上。Meta的所有应用都必须共享同一个动态库枚举，读取方则须负责确定运行代码的应用是否使用了该动态库。如果使用了错误的动态库枚举，代码将失败，但这种失败仅发生在运行时上。由于应用内的代码和功能已经极为庞大，这个故障信号延后问题给开发工作制造了不少麻烦。</p><p>&nbsp;</p><p>最重要的是，我们在启动期间防止过量引入调用的唯一系统，是以运行时为基础来实现的。应用的很多版本都曾因临时加入回归而被迫推迟发布。</p><p>&nbsp;</p><p>总之，动态库优化确实遏制了应用启动时间的无限延长，但也标志着应用架构设计的重大转折点。FBiOS工程师将在接下来几年内重构这款应用，打磨那些因引入动态库而造成的粗糙“接缝”。最终，我们发布了有史以来最为健壮的应用架构。</p><p>&nbsp;</p><p></p><h1>2017年：重新审视FBiOS架构</h1><p></p><p>随着动态库的引入，我们开始重新审视FBiOS中的几大关键组件：</p><p>&nbsp;</p><p>“模块注册系统”不能再基于运行时。工程师需要一种新方法，以了解启动期间是否有代码路径会触发动态库加载。</p><p></p><p>为了解决这些问题，FBiOS求助于Meta的开源构建系统Buck。</p><p>&nbsp;</p><p>在Buck当中，每个“target”（即目标，包括app、dylib、library等）都需要通过配置来声明，例如：</p><p>&nbsp;</p><p><code lang=\"null\">apple_binary(\n  name = \"Facebook\",\n  ...\n  deps = [\n    \":NotOnStartup#shared\",\n    \":FBCamera#shared\",\n  ],\n)\napple_library(\n  name = \"NotOnStartup\",\n  srcs = [\n    \"SomeFile.mm\",\n  ],\n  labels = [\"special_label\"],\n  deps = [\n    \":PokesModule\",\n    ...\n  ],\n)</code></p><p>&nbsp;</p><p>每个“target”都列出了构建它所需要的各项信息（包括依赖项、编译器标志、源代码等）。在调用“buck build”时，它会将所有这些信息构建成一份可查询的图表。</p><p>&nbsp;</p><p><code lang=\"null\">$ buck query “deps(:Facebook)”\n&gt; :NotOnStartup\n&gt; :FBCamera\n$ buck query “attrfilter(labels, special_label, deps(:Facebook))”\n&gt; :NotOnStartup</code></p><p>&nbsp;</p><p>使用这个核心概念（再加上一些特殊的技术手段），FBiOS中出现了可以在构建期间生成应用中类和函数整体视图的buck查询。这些信息，也成为下一代应用架构的设计基石。</p><p>&nbsp;</p><p></p><h1>2018年：代码生成量激增</h1><p></p><p>&nbsp;</p><p>现在，FBiOS已经能利用Buck查询相关依赖项中的代码信息，并创建出能够动态生成“函数/类-&gt;动态库”的映射。</p><p>&nbsp;</p><p><code lang=\"null\">{\n  \"functions\": {\n    \"DoSomething\": Dylib.NotOnStartup,\n    ...\n  },\n  \"classes\": {\n    \"FBSomeClass\": Dylib.SomeOtherOne\n  }\n}</code></p><p>&nbsp;</p><p>使用该映射作为输入，FBiOS就能生成从callsites处抽象出动态库枚举的代码：</p><p>&nbsp;</p><p><code lang=\"null\">static std::unordered_map functionToDylib {{\n  { \"DoSomething\", Dylib.NotOnStartup },\n  { \"FBSomeClass\", Dylib.SomeOtherOne },\n  ...\n}};</code></p><p></p><p>&nbsp;</p><p>这种代码生成方式的优点包括：</p><p>&nbsp;</p><p>由于代码是根据本地输入重新生成的，所以不存在签入需求，也不存在大量合并冲突。考虑到FBiOS的工程体量每年都会翻一番，这将带来巨大的开发效率提升。FBCallFunctionInDylib不再需要特定于应用的动态库（所以不妨更名为「FBCallFunction」）。相反，该调用可以读取各应用在构建期间生成的静态映射。</p><p>&nbsp;</p><p>事实证明，这种将Buck查询与代码生成相结合的办法非常成功，FBiOS也因此将其作为新型插件系统的基石，最终取代了基于运行时的应用模块系统。</p><p>&nbsp;</p><p></p><h2>信号左移</h2><p></p><p>&nbsp;</p><p>借助Buck驱动型插件系统，开发团队得以将部分基础设施转为基于插件的新架构，让FBiOS用构建时警告取代了大部分运行时故障。</p><p>&nbsp;</p><p>在构建FBiOS时，Buck可以生成图表以展示应用中所有插件的位置，如下所示：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/65/652622b00c30ddb455c016c11db037ed.png\" /></p><p></p><p>从积极的方面来看，这套插件系统可以显示构建时错误以提醒工程人员：</p><p>&nbsp;</p><p>“插件D、E可能触发动态库加载。不允许这项操作，因为这些插件的调用者位于应用的启动路径之内。”“在应用中找不到用于呈现Profile的插件……因此无法导航至该屏幕。”“同时存在两个用于Groups呈现的插件（插件A，插件B），应删除其中一个。”</p><p>&nbsp;</p><p>对于之前的应用模块系统，这些错误会被看作“懒”运行时断言。但现在，工程师们可以正建立信心，知道在FBiOS构建成功之后，就绝不会存在功能缺失、启动过程中加载动态库、或者模块运行时系统中包含恒量之类的问题。</p><p>&nbsp;</p><p></p><h2>代码生成的代价</h2><p></p><p>&nbsp;</p><p>虽然FBiOS在转向插件系统之后大大提升了应用可靠性，也能为工程师快速提供提示信号，降低了不同移动应用之间的代码共享门槛，但这一切都是有代价的：</p><p>&nbsp;</p><p>Stack Overflow上查不到插件错误，而且可能在调试期间造成混淆。基于代码生成和Buck的插件系统，与传统iOS开发思路相去甚远。</p><p>&nbsp;</p><p>插件相当于给代码库引入了间接层。大部分应用都有一个包含所有功能的注册表文件，但此文件在FBiOS中由自动生成的，而且特别难以查找。</p><p>&nbsp;</p><p>毫无疑问，插件的引入让FBiOS一步步远离了我们所熟悉的iOS开发，但这样的取舍似乎是值得的。我们的工程师可以调整Meta旗下各类应用中的代码，保证只要插件系统这边不出问题，那更新后的版本就基本能在代码路径中顺畅运行。像News Feed和Groups这样的团队还可以为插件构建扩展点，确保产品团队能在不触及核心代码的前提下将其集成到自有界面当中。</p><p>&nbsp;</p><p></p><h1>2020年：Swift与语言架构</h1><p></p><p>&nbsp;</p><p>虽然本文的大部分内容都在讨论Facebook应用规模所引起的架构变化，但Apple SDK的演进也确实对FBiOS的某些架构决策造成了影响。</p><p>&nbsp;</p><p>2020年，FBiOS发现苹果那边仅限Swift使用的API数量越来越多，人们也更希望能在代码库中多用Swift。到这个时候，我们必须承认Swift一定会在Facebook应用中占据一席之地——无论我们愿不愿意。</p><p>&nbsp;</p><p>从历史上看，FBiOS曾使用C++作为构建抽象的杠杆。由于C++的零开销优势，它显著降低了代码体量。但<a href=\"https://en.cppreference.com/w/cpp/language/Zero-overhead_principle\">C++与Swift目前还无法实现互操作</a>\"，所以大部分FBiOS API（包括ComponentKit）必须通过某种“垫片”才能在Swift中运行——这无疑会造成代码膨胀。</p><p>&nbsp;</p><p>下图为FBiOS代码库中的语言架构问题：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/04/04139d6b38944809917a7b4005f839c4.png\" /></p><p></p><p>&nbsp;考虑到这一点，我们开始认真考虑什么时候、在哪里该使用哪种编程语言：&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/5502b6456daf2cf18a4eaeef59b85aa9.png\" /></p><p></p><p>最终，FBiOS团队建议将C++从面向产品的API/代码中全面清理出去，以便大家可以自由使用Swift和苹果未来提供的Swift API。通过插件，FBiOS可以抽象出C++实现，确保它们继续为应用提供支持；而对大多数工程师来说，又不必直接跟C++打交道。</p><p>&nbsp;</p><p>这样的工作流，标志着FBiOS工程师对于抽象构建的考量方式发生了转变。自2014年以来，框架构建中的最核心因素，就是对应用代码量和表现力的影响（正因为如此，ComponentKit才选择了Objective-C++，而非Objective-C）。</p><p>&nbsp;</p><p>Swift的加入第一次下调了开发者效率的优先级，预计未来还会出现更多类似的情况。</p><p>&nbsp;</p><p></p><h1>2022年：旅程刚刚走完1%</h1><p></p><p>&nbsp;</p><p>自2014年以来，FBiOS架构发生了重大变化：</p><p>&nbsp;</p><p>引入了无数内部抽象，包括ComponentKit和GraphQL。使用动态库将“pre-main”时长保持在最低水平，并有助于加快应用启动速度。引入了插件系统（由Buck提供支持），将动态库从工程师那边抽象出来，降低了代码在不同应用间的共享难度。引入了什么时候在哪里该用什么语言的评判准则，并开始转变代码库以反映这些语言准则。</p><p></p><p>与此同时，苹果则在手机、操作系统和SDK层面做出了激动人心的改进：</p><p>&nbsp;</p><p>新iPhone的性能越来越强，加载成本比以往低得多。操作系统持续改进，dyld3和chain fixups大大加快了软件代码的加载速度。推出SwiftUI，一种用于UI的声明式API，其中很多概念与ComponentKit相通。发布了经过改进的SDK和API（例如iOS8中的可中断动画），可供开发者据此构建自定义框架。</p><p>&nbsp;</p><p>随着Facebook、Messenger、Instagram和WhatsApp之间的可共享体验越来越多，FBiOS也在重新审视之前做出的一系列优化，思考其中哪些可以跟苹果平台的原生功能合并起来。现在看来，共享代码的最简单方法，就是直接使用应用免费提供的功能、或者直接在构建过程中消除一切依赖项。能做到这一点，应用之间就能顺畅对接、毫无滞涩。</p><p>&nbsp;</p><p>期待到2032年时，我们能在FBiOS的20岁生日时再相聚，看看那时会有哪些值得一聊的心得体会！</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://engineering.fb.com/2023/02/06/ios/facebook-ios-app-architecture/\">https://engineering.fb.com/2023/02/06/ios/facebook-ios-app-architecture/</a>\"</p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://www.infoq.cn/article/hK8dvE1FPdPbaGtO46Lu\">Facebook 是如何引入并使用 Rust 的？</a>\"</p><p><a href=\"https://www.infoq.cn/article/KdHX4iMFOT8UxlYAS1ei\">Facebook 怎样为数百万观众提供可靠的直播服务？</a>\"</p><p><a href=\"https://xie.infoq.cn/article/cb324c0966bcad310edf2b9a5\">跨平台开发成为移动应用程序开发趋势</a>\"</p><p><a href=\"https://xie.infoq.cn/article/444b7c4090093ce159d19a3ac\">移动应用程序开发新趋势</a>\"</p>",
    "publish_time": "2023-03-15 16:14:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]