[
  {
    "title": "全面拆解实时分析数据存储系统Druid",
    "url": "https://www.infoq.cn/article/rZVXjXqlGNEdDwZdpJ5c",
    "summary": "<p>&nbsp;</p><p></p><blockquote>本文对论文“<a href=\"https://www.micahlerner.com/assets/papers/druid.pdf\">Druid：一个实时分析数据存储系统</a>\"”进行了概括总结，对Druid的架构、存储格式、查询API等进行了简要介绍。如需深入了解更多的细节，请查看论文原文。</blockquote><p></p><p></p><h2>这篇论文研究的是什么</h2><p></p><p>&nbsp;</p><p>Druid是一个开源数据库，可以实现低延迟的近实时和历史数据分析。Druid最初是由广告技术公司MetaMarkets开发的，后来被Snap收购，现在已被Netflix、Confluent和Lyft等公司应用于各种不同的场景中。</p><p>&nbsp;</p><p>Druid的目标是支持近实时的和历史数据访问模式，这让它变得非常独特，并被应用在非常广泛的场景中——例如，近实时的数据摄取可以让应用程序（如生产警报）基于日志快速发现问题（类似于Netflix的应用场景），同时也可以基于大量历史数据执行警报逻辑。相比之下，许多数据仓库产品都是以“批处理”为基础，这导致记录指标时的时间与进行分析时的时间之间出现延迟。</p><p>&nbsp;</p><p>除了介绍系统的设计和实现外，这篇论文还讨论了系统组件可用性的降低是如何影响用户的。很少有论文会用这种方式来组织有关生产系统的论文，而且这种方式令人耳目一新。</p><p>&nbsp;</p><p></p><h2>这篇论文的贡献</h2><p></p><p>&nbsp;</p><p>这篇论文有以下几个贡献。</p><p>&nbsp;</p><p>对系统架构进行了描述；探索设计决策和实现；对系统查询API和性能结果进行了评估。</p><p>&nbsp;</p><p></p><h2>系统的工作原理</h2><p></p><p>&nbsp;</p><p></p><h3>分片和数据源</h3><p></p><p>&nbsp;</p><p>片段是Druid的一个关键抽象。它们是一种不可变（但有版本控制）的数据结构，其中保存了一系列记录。片段的集合组合成数据源，也就是Druid的数据库表。每个片段中保存了某个数据源在一个时间段内写入的记录。</p><p>&nbsp;</p><p><img src=\"https://static001.infoq.cn/resource/image/4b/22/4b74a219d0d4abdafb33a8390f998122.png\" /></p><p></p><p></p><h3>系统架构</h3><p></p><p>&nbsp;</p><p>Druid通过摄取数据来构建片段，然后在对查询做出响应时访问这些片段。</p><p>&nbsp;</p><p>Druid通过四种类型的节点来实现数据的摄入和查询：实时节点、历史节点、Broker节点和协调器节点。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/34/341fdbe657a5d0e3b7c03b4412e0e6d7.png\" /></p><p></p><p>与单个无状态节点不同，Druid将状态存储在两个数据源中。</p><p>&nbsp;</p><p>MySQL，其中包含了配置信息和元数据，比如片段的索引。Zookeeper，存储系统的当前状态（包括片段的副本保存在系统中的哪些分布式节点上）。</p><p></p><h4>实时节点</h4><p></p><p>&nbsp;</p><p>实时节点有两个职责：从生产者那里获取数据和响应用户对最新数据的请求。</p><p>&nbsp;</p><p>生产者将原始数据（比如数据库中的记录行）或转换后的数据（比如流式处理管道的输出）发送给实时节点——常见的生产者模式依赖了Kafka主题。Kafka（或其他消息总线）为数据提供了更好的可用性和可伸缩性——实时节点可以保存它们已经消费的偏移量，在发生崩溃或重启时可以重置到这个偏移量。为了提高伸缩性，可以用多个实时节点分别读取相同消息总线的不同子集。</p><p>&nbsp;</p><p>当实时节点在消费来自生产者的记录时，它会检查与记录关联的时间段和数据源，然后将记录路由到具有相同（时间段、数据源）键的内存缓冲区中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e1/e1e8da3d435ac63c6b93b957460ce649.png\" /></p><p></p><p>每个（时间段、数据源）缓冲区在被清除之前会暂时保留在节点上——由于资源有限，节点需要定期从内存中清除记录缓冲区。在回收时，内存缓冲区中的数据将被写入“深度”存储系统（如S3或谷歌云存储）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13c67e4e019eb808efb19f1c2e9928f1.png\" /></p><p></p><p>&nbsp;</p><p>除了数据摄取之外，实时节点还对数据查询请求做出响应。为了响应这些请求，实时节点会使用内存中的临时索引进行扫描。</p><p></p><h4>历史节点</h4><p></p><p>&nbsp;</p><p>历史节点从存储中读取不可变的数据片段，并对查询做出响应——协调节点（将在下一小节介绍）控制一个历史节点可以获取哪些片段。当一个历史节点成功下载了一个片段，它会告诉系统的服务发现组件（Zookeeper），然后用户查询就可以访问这个片段。不幸的是，如果Zookeeper离线，系统将无法提供新的片段——历史节点将无法告知已成功获取片段，所以Druid负责查询数据的组件将无法转发查询。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b9/b99243595896083ced0abfaf19ccdb4a.png\" /></p><p></p><p>使用不可变片段简化了历史节点的实现。首先，它简化了系统的伸缩——如果有多个请求涉及同一个片段，就会有更多的历史节点存储片段的副本，导致查询在集群中扩散。其次，操作数据片段而不是较低层次的抽象意味着历史节点可以简单地等待被告知有一个新版本的数据需要获取，而不需要监听片段是否发生了变化。</p><p></p><h4>协调器节点</h4><p></p><p>&nbsp;</p><p>协调器节点决定哪些片段存储在历史节点上，以及存储多长时间。</p><p>&nbsp;</p><p>为了做出决定，协调器节点从两个位置读取数据：MySQL和Zookeeper。MySQL保存了片段的信息，以及与每个段类型相关的元数据。Zookeeper保存了系统服务的所有片段的当前状态——实时节点和历史节点用它来宣布哪些片段是可用的。协调器节点还可以在整个系统中对片段进行负载均衡，以免对同一节点进行多次读取时出现“热点”数据。</p><p>&nbsp;</p><p>论文指出，一个集群中有多个正在运行的协调器节点，但同时只有一个“首领”——其他节点用于故障转移。如果协调器节点不可用（可能因为MySQL或Zookeeper出了问题），那么历史节点和实时节点将继续运行，但可能会出现超载（由于没有了负载均衡）。此外，论文还指出，这种情况会导致新数据不可用。</p><p></p><h4>Broker节点</h4><p></p><p>&nbsp;</p><p>最后，Broker节点接收来自外部客户端的请求，从Zookeeper读取状态，并根据需要将请求转发给历史节点和实时节点。Broker节点还可以在本地缓存数据片段，以应对未来可能出现的对相同数据的访问。</p><p>&nbsp;</p><p>如果Zookeeper不可用，那么Broker将使用“最后已知的状态”来转发查询。</p><p></p><h3>存储格式</h3><p></p><p>&nbsp;</p><p>如前所述，数据片段是Druid的一个关键抽象，一种用于存储数据的不可变数据结构。每一个片段都与一个数据源（Druid中的表）相关联，并包含特定时间段的数据。</p><p>&nbsp;</p><p>片段由两种类型的数据组成：维度和指标。维度是行聚合或过滤的值，而指标对应于数值数据（如计数）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b74a219d0d4abdafb33a8390f998122.png\" /></p><p></p><p>片段中还包含了版本号。如果一个片段发生变化，版本号会增加，并发布一个新的片段版本——如果已经确定的片段加入了延迟事件，就会发生这种情况。协调器节点会告诉历史节点获取新版本并删除旧版本，从而实现向新版本段的迁移。因为采用了这种方式，Druid被认为实现了多版本并发控制（MVCC）。</p><p>&nbsp;</p><p>重要的是，片段是按照列（而不是行）来存储数据的——这种方法被称为“列式存储”。这种设计被用于其他几种数据库（如Redshift和Cassandra）和文件格式（如Parquet）中，因为它提供了性能优势。</p><p>&nbsp;</p><p>例如，如果一个查询选择了列的子集，那么数据库只需要查询这些列的数据子集。基于行的解决方案需要扫描每一行，并选择相关的列。虽然这两种扫描都会产生相同的结果，但基于行的扫描（几乎）肯定会访问不必要的列，而这些列不是查询所需要的，也不会出现在查询结果中。</p><p></p><h3>查询API</h3><p></p><p>&nbsp;</p><p>论文中对HTTP查询API进行了描述，用户可以指定数据源、时间范围、过滤和聚合。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/08/081d2d7efab2bb7d1194bee95f85fc79.png\" /></p><p></p><p>&nbsp;</p><p>近期版本的查询API与论文中描述的有所不同。当前版本的Druid提供了一个<a href=\"https://druid.apache.org/docs/latest/querying/sql.html\">SQL风格的API</a>\"来编写和提交查询。论文还说明了为什么Druid还不支持连接查询，尽管近期的工作已经实现了这个想法。</p><p></p><h2>如何评估这项研究</h2><p></p><p>&nbsp;</p><p>为了评估这个系统，论文对部署在MetaMarkets的Druid的性能和规模进行了评测。</p><p>&nbsp;</p><p>因为Druid最初是为低延迟查询而设计的，所以使用生产流量跟踪来评估延迟性能。</p><p>&nbsp;</p><p></p><blockquote>对于所有不同的数据源，平均查询延迟大约为550毫秒，90%的查询在1秒内返回，95%在2秒内返回，99%在10秒内返回。</blockquote><p></p><p>&nbsp;</p><p>数据摄入延迟是Druid设计的另一个重点。MetaMarkets的生产系统能够以最小的延迟和显著的吞吐量摄取不同形式和大小的数据集。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/de/de6678d34ba33c837a8b5f7efd38d340.png\" /></p><p></p><p>&nbsp;</p><p>论文还指出，虽然摄入延迟存在差异，但可以通过为相关组件添加更多的资源来解决这个问题（如果特别关注这个属性，实现者可能会做出这样的决定）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/94/940bd064d7d2e7fc7d784b34fd009c19.png\" /></p><p></p><p></p><h2>结论</h2><p></p><p>&nbsp;</p><p>我发现Druid论文很有趣，因为它的设计目标是同时处理实时和历史数据分析。</p><p>&nbsp;</p><p>这个系统代表了实现上述设计目标的一个步骤——Druid是“<a href=\"https://en.wikipedia.org/wiki/Lambda_architecture\">Lambda架构</a>\"”的第一个实现。最近的<a href=\"https://www.oreilly.com/radar/questioning-the-lambda-architecture/\">Kappa</a>\"和Delta架构似乎是对Druid最初建议的架构的改进。</p><p>&nbsp;</p><p>我很喜欢这篇论文，因为它讨论了系统在退化状态下的行为。随着Druid后续的演进，论文的一些细节可能会过时，但它的一些系统设计想法仍然是很独特的。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://www.micahlerner.com/2022/05/15/druid-a-real-time-analytical-data-store.html\">https://www.micahlerner.com/2022/05/15/druid-a-real-time-analytical-data-store.html</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2022-08-04 10:42:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "明略科技CTO郝杰：会话式AI应该是“静悄悄”的辅助智能",
    "url": "https://www.infoq.cn/article/hq44bi4BhmUv9TuSc5ma",
    "summary": "<p></p><p></p><blockquote>AI&nbsp;一定要落在实处，一定要追求它能落地成功。不要做飘在天上的“阳春白雪”。</blockquote><p></p><p></p><p></p><h3>明略科技新任CTO：一位平衡型的技术管理者</h3><p></p><p></p><p>今年4月27日，明略科技官宣了一则任命消息，宣布任命郝杰为首席技术官（CTO），全面主持研发部门的管理工作，负责制定技术方向与路线，搭建研发体系与流程，输出高质量的产品研发能力，保持技术领先性，构建技术壁垒。</p><p></p><p>明略科技创始人、CEO吴明辉表示，郝杰加入后，将进一步强化明略科技在人工智能技术领域的产研能力及技术布局。</p><p></p><p>郝杰是语音语义领域的技术大牛。</p><p></p><p>资料显示，郝杰是清华大学信号与信息处理专业博士，IEEE Senior Member，是国际顶级 AI 学术大赛 20 个细分赛道第一名获得者。加入明略科技前，郝杰是OPPO语音语义首席科学家，更早之前，他曾担任东芝（中国）首席科学家、五八集团技术专家，率先在工业界实现了语音和语义技术的产品化落地，主导研发成功了中国最早量产的汽车前装语音导航，世界上最早量产的电视机语音唤醒、离线口语翻译手机软件等。</p><p></p><p>郝杰在接受InfoQ采访时表示，在 To C 的软硬一体化的人工智能领域做了3年后，他非常看好To B 企业智能服务赛道的崛起，这促使他加入了明略科技。</p><p></p><p>郝杰形容自己是一位平衡型的技术管理者。</p><p></p><p>这种“平衡”一方面体现在他的履历上。在此前20多年的职业生涯中，郝杰既在跨国公司工作过，也在本土企业工作过；在传统制造业工作过，也在互联网公司工作过；曾在软硬一体化和偏偏硬件的公司工作过，也在纯粹的软件公司工作过。在产研追求上，郝杰既讲求务实地落地，也追求行走在学术前沿。在技术管理方面，郝杰也有着平衡型的人才观，他崇尚纺锤形的人才梯队的合理性，讲究头部人才、肩部人才均衡搭配。</p><p></p><h3>下一阶段研发重点：明智中台</h3><p></p><p></p><p>郝杰告诉InfoQ，他是以创业的心态加入明略科技的。</p><p></p><p>在他看来，明略科技正处在第三次“创业”的阶段。第一次“创业”是在2006年，吴明辉创办了广告舆情监测系统 — 秒针系统；第二次“创业”是2014年，明略数据成立，通过数据提供支持分析决策的行业人工智能解决方案；第三次“创业”从2019年开始做会话智能平台 — 明智工作。</p><p></p><p>“这个过程中，不仅伴随着产品线的扩展，明略自身的组织也发生了多次变化和调整，故我将其看作是三次创业”。</p><p></p><p>目前在应用层，明略科技聚焦两大产品线 — 秒针产品线和明智产品线。秒针产品线，专注媒体投放、效能改善，针对舆情分析，挖掘营销效能、新产品研发方向等场景。明智产品线包括SCRM营销服一体化、智能助理、OA增强、销售增强、会话智能等场景。</p><p></p><p>这两大产品线都建立在一个产研底座 —— 明智中台上。</p><p></p><p>明智中台既是一个数据中台，也是一个AI能力中台。它不仅仅是一个技术平台，明略科技还往这个底座上扩充了一些新的概念、能力和功能，明智中台上有可以独立售卖的产品单元，如客户数据中台和营销自动化（CDP+MA）等产品模块。</p><p></p><p>郝杰表示，明智中台将是今年研发部门的发力重点，会在这个底座上方做一些偏前端的应用，可以使其灵活地、积木式地组装明智中台上的能力，低成本地快速包装成一些面向客户的创新产品。</p><p></p><p>“如果没有明智中台，我们的产品矩阵就变成了一大片独立的产品了，彼此之间关系不大，各自为战，这样产研效率比较低”，郝杰说道。</p><p></p><p>有了明智中台，就可以把众多的前端产品或应用产品中的众多模块间的相同点做抽象，把共通的部分沉淀在明智中台里。例如，很多应用产品模块中都具备搜索、推荐、问答、数据分析等功能，专门的团队将这些功能下沉到明智中台，一次性封装好，就像积木一样，做成一个个公共组件（Common&nbsp;Building&nbsp;Blocks，CBB）。</p><p></p><p>明智中台，就成了公共组件的集合体，应用产品经理可以根据用户需求，选择明智中台中的若干个CBB，进行简单的、轻量级的封装，来实现产品功能。这样，产研效率就大幅提升，而且降低成本，提升了标准化产品的毛利率。</p><p></p><p>郝杰表示，他加入明略后，带领研发团队的一个重要的工作目标是打造标准化的产品。“只有标准化程度高了，复用率才高，才能从一个场景迁移到另一个场景，从一个行业迁移到另一个行业，且在迁移的过程中，降低定制开发或二次开发成本，提高毛利率”。</p><p></p><p>在TO B行业，打造标准化的流程尤其重要。因为TO B行业的客户经常有五花八门的需求，但如果企业一直难以拒绝一些定制化的开发需求，久而久之，To B软件开发公司就沦为客户的外包公司，自身收入的毛利率也会因此降低。明略科技正在打造一套IPD集成产品开发流程，聚焦标准化产品打造，这套流程能够将标品的需求和定制开发的需求区分开来。</p><p></p><h3>明智工作：提供会话智能的AI能力</h3><p></p><p></p><p>接下来，郝杰及其团队在应用产品上的重点将主要放在明智工作上。</p><p></p><p>在秒针和明略数据时期，在过去十几年服务各行业客户的过程中，明略科技发现，各行业的企业对营销服务流程透明化的需求增加。企业希望员工的销售过程可以量化测量，“可见可测”能够驱动提升成单率和客户的满意度，这正是明略工作这款产品诞生的背景。</p><p></p><p>明智工作的核心是会话智能的AI能力。明智工作基于腾讯企业微信，帮助各行各业的销售解答用户的问题。利用数据和会话分析，帮助销售做销售管理、商机转化、销售卡点、销售旅程等。通过会话智能的B2B产品，可以帮助销售快速、低成本地获取营销过程中的素材、话术等以获取知识，捕捉最佳销售话术、销售实践等，加以推广，提升整体销售效率。</p><p></p><p>明略科技推出的软硬一体化的会话智能产品“灵听”，可以针对线下门店做语音收集、识别、转写、分析，销售最佳话术的赋能培训等。例如在线下的连锁药店或商场中的化妆品柜台店员，有一部分佩戴着明略科技的智能语音工牌。这些店员的销售过程会被录制下来，上传到服务器，进行数据的收集、整理和分析，帮助销售解答顾客的问题。</p><p></p><p>上述应用场景背后采用了声学、语音识别、语义理解、意图识别、话术理解、质检等AI技术。其中，声学和语音识别技术是明略科技的特色技术，在处理智能语音工牌数据的服务器上，运行的都是明略自己的声学和语音识别算法，针对线下门店的声学环境，就录音环境、混响音响等声学条件做了专门的定制优化，也针对线下门店所需要的销售赋能、销售增强的一系列流程SOP做了专门的调优。“这样达成的语音识别就不是通用的语音识别了，而是线下会话智能专用的语音识别，识别率明显高于供应链上的第三方”，郝杰说道。</p><p></p><p>郝杰表示，与服务于To C赛道的手机语音助手、智能音箱等需要唤醒的被动机器人不同，明略在TO B赛道上强调的是主动机器人。</p><p></p><p>在企微侧边栏，明智工作可以预制主动机器人, 相当于人类的助理。侧边栏的主动机器人会“跳”出来帮用户解答问题,它能实时监听对话，并从中挖掘关键词，这些关键词会作为搜索查询词，搜索后台的文档库、话术库、素材库、产品库、聊天问答的剧本库等，搜索到一些相关的能够“命中”问题的文档，构建出搜索页面里一个短的列表，在侧边栏上，用户只要一点鼠标，就立刻发给对话者。</p><p></p><h3>落地之道：“贪食蛇”策略</h3><p></p><p>会话智能产品如何实现应用落地？</p><p></p><p>如果用一个坐标轴来表示，横轴的长度代表垂直行业的个数，纵轴的长度代表场景的个数，那么，垂直行业乘以水平的场景构成的二维平面上会被划分成N个格子，一个格子代表一个细分行业、细分场景。</p><p></p><p>这就是明略科技的会话智能产品的应用蓝图，明略希望，未来能够覆盖到整个二维平面80%以上。</p><p></p><p>郝杰详细介绍了这个应用蓝图的实现路径。</p><p></p><p>“我们采取‘贪食蛇’的策略，围绕着头部行业、重点场景，逐步提升扩展覆盖率”，选择三到五个头部（重点）行业、三到五个重点场景，在二维平面上，就选择了一个相对聚焦的由十几个方格构成的局部（蓝图）。就像玩‘贪吃蛇’游戏，就近吞并。这与人工智能的贪心算法类似，先‘吃’下来一个行业头部的几个重点场景，把几个大客户拿下来。之后，行业中的中长尾的客户也就能拿下来了，采取头部带动中长尾这样的扩张策略，实现对场景逐步覆盖”。</p><p></p><p>在多行业、多场景、大范围的应用会话智能过程中，常常遇到一些挑战，例如，如果技术识别率或准确率上不去怎么办？很多To C、To B的公司做智能类的应用常常会遇到的一个技术瓶颈是，准确率做到百分之八十就上不去了，这样的准确率，用户并不会买单。</p><p></p><p>在这种情况下，要提升识别率，就需要挖掘特定场景下的行业知识、先验知识。通常，要先进行标签化，因为人类的认知就是从简单的分类给事物打标签做起的。因此，在先验知识或行业知识中，最重要的就是分类标签。在明智中台里，有各种各样的标签，如客户中台里的客户标签，业务中台里面，与业务流程相关的标签等。目前明略已积累了各行各业各种场景下数量庞大的标签。</p><p></p><p>此外，还需要在算法和标签库的先验知识的基础上做改造。比如，语音识别算法，在没有线下门店相关行业和场景的标签库前提下就是一个通用的语音识别标签库。把标签库里的这些词汇预先编入到通用的语音识别词典中去，就构建出一个包含了新词、热词的更大的搜索网络。</p><p></p><p>“在此基础上，针对专门性的场景，通用的语音识别率、准确率可能在60%-75%之间。而依靠对场景的理解和建模，依靠这些先验知识，能将识别率拔升到75%-90%之间”，郝杰表示，这是明略科技在To B赛道上的生存之道。</p><p></p><h3>会话式AI的发展现状和趋势</h3><p></p><p></p><p>现阶段，不止明略，会话智能是很多企业尤其是大厂竞相布局的赛道。</p><p></p><p>不过，现在关于会话智能，还没有一个相对成熟的定义。郝杰认为，会话智能就是在工作会话流中，在人与人交流过程中，能适时出现的一些辅助智能。</p><p></p><p>值得注意的是，在业内，一种说法是对话式AI，明略将其翻译成会话式AI。会话和对话有什么区别？字面意思上看，对话对应的英文单词是“dialog”，会话对应的是“conversation”。</p><p></p><p>另一方面，“会话”和To C领域的“对话”不同。To C赛道更多的是人机之间的沟通，AI就是一个语音助手。而To B赛道中的会话智能本质上是人与人之间的会话，如单聊、群聊等，它不应该受到太多的机器打扰。“如果机器能够提供一定的智能，这种智能最好是在需要的时机悄悄出现，然后悄悄退下去，因为它只是一种辅助性的智能”。郝杰表示。</p><p></p><p>它辅助的仍然是人和人之间的沟通。它以人类助理的形式出现。人类助理能做到的事，尽可能的让机器助理做到。与等人呼唤才出来的助理（被动机器人）不同，明略的主动机器人“蹲守”在所有的会话聊天过程中。在人人沟通的过程中，如果能在侧边栏或者某一个角落预置一些主动性的机器人，实时推荐一些与业务流程密切相关的知识和信息，对提升交流的效率很有帮助。</p><p></p><h3>写在最后：AI落地一定要落在实处</h3><p></p><p></p><p>“像我这种一辈子搞AI、搞算法的人，我们比较相信算法和知识的结合。如果光搞算法，抛开场景，抛开行业认知，就搞不好AI”。采访最后，郝杰谈到了包括会话智能在内的AI技术的未来。</p><p></p><p>郝杰认为，“AI&nbsp;一定要落在实处，做AI一定要追求它能落地成功。不要做飘在天上的‘阳春白雪’。这要求我们一方面吃透算法，一方面要融会贯通知识，通过深耕行业实现融会贯通”。</p>",
    "publish_time": "2022-08-04 10:50:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Jetpack Compose终于能稳定支持Wear OS，并带来了适用于手机和平板的1.2版本更新",
    "url": "https://www.infoq.cn/article/Qp9CeVh5UAJpLXgGrEHy",
    "summary": "<p>近日，谷歌安卓团队<a href=\"https://android-developers.googleblog.com/2022/07/jetpack-compose-1-2-is-now-stable.html\">发布</a>\"Jetpack Compose 1.2版本，该版本提供了开发者所需要的更多 API，以支持更高级的用例。例如可下载字体、Lazy grids、窗口插图、嵌套滚动互操作以及更多工具支持，还有针对平板电脑和 Chrome 操作系统的改进。</p><p></p><p>在发布 Jetpack Compose 1.2版本的同时，官方还发布了Compose for Wear OS 1.0 ——使得 Compose 也支持 Wear OS 应用开发。这是Compose智能手表平台UI工具包的第一个稳定版本，在这之前，智能手表应用开发者一直被“落下”。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8c/8c4b0457c2d05d092252a4743fe011d6.png\" /></p><p></p><p>Jetpack Compose是官方推荐的为手机、平板和可折叠设备开发新安卓应用的框架。1.0 版本在去年7月份发布，结合Kotlin的语言生态，设计了新的声明式 UI 开发范式，旨在与谷歌的 Material Design 系统配合使用。</p><p></p><p>谷歌的安卓开发者关系工程师 Kseniia Shumelchyk 说：“在大多数情况下，基于 Compose 的 UI 可以减少代码量并加快开发过程。”</p><p></p><p>智能手机应用程序开发人员在 Compose 1.2 中获得了一些重要更新。Lazy grids，通过只对网格的可见部分进行合成来提高性能，已经从实验阶段转为稳定阶段。WindowInsets类，用于处理屏幕上不可用的区域及其与应用程序窗口的交互，是一个基于Accompanist库中先前工作的新类，谷歌用它来试验Compose的新功能并填补API的空白。此外，动画支持中添加了缓动曲线，用于实现快速加速和逐渐减速等效果。还有嵌套滚动支持和新的鼠标事件，以及各种错误修复。</p><p></p><p>安卓开发有很多方式，包括使用 Dart 语言的跨平台框架 Flutter，或其他方法，如 React Native。不过，Jetpack Compose 是最接近原生解决方案的那个，它为安卓功能提供了很好的支持，而无需尝试跨平台（尽管用 Kotlin 编写的非可视代码也可以在其他地方使用）。</p><p></p><p>“你应该押注Jetpack......Flutter对简单的应用来说是很好的选择，但却不适合复杂的场景，”Hacker News的一位开发者声称。另外也有人表示，学习Compose框架需要付出“很大的前期成本”，但尽管如此，它是“安卓前端开发体验的未来”。</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://android-developers.googleblog.com/2022/07/jetpack-compose-1-2-is-now-stable.html\">https://android-developers.googleblog.com/2022/07/jetpack-compose-1-2-is-now-stable.html</a>\"</p><p></p><p><a href=\"https://devclass.com/2022/07/28/jetpack-compose-comes-to-android-wear-os-plus-1-2-update-for-smartphones-and-tablets/\">https://devclass.com/2022/07/28/jetpack-compose-comes-to-android-wear-os-plus-1-2-update-for-smartphones-and-tablets/</a>\"</p><p></p><p>延展阅读：<a href=\"https://www.infoq.cn/article/qmeK2NDH8ZP2sbBGwFoE\">《为什么除了 Flutter 之外，我们还需要另一个跨平台开发框架？》</a>\"</p>",
    "publish_time": "2022-08-04 12:23:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊聊 Flink Table Store：流批一体存储最新进展｜InfoQ大会早班车第16期",
    "url": "https://www.infoq.cn/article/P1hjhu0IKuBwy9lbY442",
    "summary": "<p>Flink 的最新路线是什么？Flink 社区都有哪些热点问题？大会早班车邀请阿里云技术专家、Flink PMC 李劲松老师一起聊聊 Flink Table Store 最新进展。</p>\n<p>2022年QCon北京站即将落地，[点击直达官网]<br />\n(<a href=\"https://qcon.infoq.cn/2022/beijing/?utm_source=infoq&amp;utm_medium=zaobanche&amp;utm_campaign=full&amp;utm_term=0722\">https://qcon.infoq.cn/2022/beijing/?utm_source=infoq&amp;utm_medium=zaobanche&amp;utm_campaign=full&amp;utm_term=0722</a>)。</p>",
    "publish_time": "2022-08-04 15:29:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "减少超十万 CPU 内核，省下数千台主机，Uber 弄了个自动化CPU垂直扩展年省数百万美元",
    "url": "https://www.infoq.cn/article/EPDMUdEtsymGTGzyPO40",
    "summary": "<p></p><blockquote>本文描述了一个自动化的 CPU 垂直扩展系统的实现，在该系统中，优步（Uber）上运行的每个存储工作负载都被分配到了理想数目的内核。如今，该框架已被用于调整超过 50 万个 Docker 容器，自其建立以来，已净减少了超过 12 万个内核的分配，从而每年节省了数百万美元的基础设施支出。</blockquote><p></p><p></p><p>在<a href=\"https://www.infoq.cn/article/IXcb-HzEA8Kd6obNB9eB\">优步（Uber）</a>\"，我们在容器化环境中运行所有的存储工作负载，如 Docstore、 Schemaless、M3、<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651024527&amp;idx=2&amp;sn=7e5422dc08347aa22336e94842de5c2f&amp;chksm=bdbe94dc8ac91dcae4b1ecdba044e8cf15e803ee0481424ad9eae5369b98a1e3abb6c237dcac&amp;scene=27#wechat_redirect\">MySQL</a>\"、<a href=\"https://www.infoq.cn/article/wPmrjZ5Sygxowv5sOc68\">Cassandra</a>\"、Elasticsearch、etcd、Clickhouse 和 Grail。总的来说，我们在将近 7.5 万台主机上运行了超过 100 万个存储容器，其中 CPU 内核数超过了 250 万个。为了降低相邻组件间互相干扰的风险，每个工作负载都分配了一组独立的 CPU 内核，并且主机不会超额配置。我们还运行了一个多区域复制设置，它允许数据流量作为事件响应的一部分从整个区域中流出。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f83d1aace9ca59f7734869658161f94.png\" /></p><p>图 1：优步状态管理平台的关键指标。</p><p></p><p>一个主要挑战是为每个容器分配正确数量的 <a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651112645&amp;idx=5&amp;sn=5c3a9f5a48525f931d2f1068787e58e4&amp;chksm=bdb93c968aceb580e3abb9616024cfac6bb159552952e2d02a3255f535eb943427a35d3ea507&amp;scene=27#wechat_redirect\">CPU 内核</a>\"。 直到最近，为每个容器设置的适当内核数量都是由负责每种存储技术的工程师手动确定的。</p><p></p><p>这种方法的优点是，领域专家有责任监控他们的每项技术并做出正确的决策。缺点是，需要人工来完成这项工作，而且当设置会导致成本或可靠性问题时，这往往会成为一种响应式的扩展策略，而不是一种主动的方式，即根据实际使用情况垂直扩缩容器，以确保以尽可能低的成本实现一致的性能。</p><p></p><h2>为 CPU 垂直扩展选择正确的度量指标</h2><p></p><p></p><p>正确调整容器大小的第一步是定义我们所说的“合适大小”。简而言之，我们希望在不影响容器中运行的工作负载的性能的情况下，为每个容器分配尽可能少的资源。</p><p></p><p>可以使用不同的策略来确定要分配给每个存储容器的正确内核数目。一种非常直接的方式是在核心业务指标（例如，P99 延迟）和<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651117338&amp;idx=2&amp;sn=6119c27b5524df6c87deeadbf1dac1ef&amp;chksm=bdb92f498acea65fb94572b075a8219985bbe4fd75e962a63e3d7aef6a9719c59414ab70df38&amp;scene=27#wechat_redirect\">容器</a>\"分配之间建立反馈回路。如果反馈回路足够紧凑和快速，则可以提高或降低分配，以确保始终能有正确分配。然而，这种方式不太适合管理存储工作负载，原因如下：</p><p></p><p>在主机之间移动存储工作负载可能需要数小时。由于数据需要与计算资源一起携带，因此必须避免使用在主机之间频繁移动工作负载的模型。负载在一周之内可以很容易地改变 2-5 倍。由于负载变化如此之大，很难创建一个模型来确定要分配的最佳内核数量，因为大多数情况下，容器都会被超额配置。不同的用例将有不同的关键指标来进行监控。构建一个适用于批处理工作负载的模型将与低延迟用例（比如，为 Uber Eats 应用程序提供餐厅菜单）大不相同。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/13/13df401e2c1271c37991a05bb34fbfb0.png\" /></p><p></p><p>图 2：展示了存储容器的 <a href=\"https://www.infoq.cn/article/2017/10/apple-open-sources-arm-darwin\">CPU </a>\"利用率（蓝色）、整个期间测量的峰值利用率（绿色）、当前分配（橙色）和要达到的最佳分配（红色）。在数周的时间内，扩缩器在几周内逐渐将分配收敛到最优值。</p><p></p><p>我们没有监控关键业务指标，而是基于每个存储容器的外部测量 CPU 利用率构建了一个模型。该模型确保了历史测量的峰值 CPU 利用率和分配给容器的内核数量之间的特定比率。峰值使用率和分配之间的比率将被称为 CPU 使用率。图 2 显示了基于过去 14 天 CPU 使用率的模型如何确定峰值使用率（绿色），并由此计算目标分配（红色）。该图还显示了当前 CPU 分配（黄色）如何逐渐收敛到绿线的。</p><p>这种方式的好处如下：</p><p></p><p>CPU 利用率指标始终可用。这确保了我们可以创建一个“适合所有人的模型”，避免了为每种存储技术或用例创建模型的耗时工作。CPU 利用率指标每周都相当稳定，因此在大多数情况下，过去两周就能相当准确地预测未来几周的峰值使用情况。在区域故障转移（failover）期间，CPU 利用率往往会以可预测的方式增加。通过设定目标，比如 40% 的 CPU 利用率，可以相当肯定的是，在区域故障转移期间，CPU 利用率不会超过 80%，在最坏的情况下，负载会短暂地增加一倍。有关如何计算峰值 CPU 利用率的更多详细信息将会在下一节中介绍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f138ca3e9a85f074b9c30251eaf60b6a.png\" /></p><p></p><p>图 3：对大多数 Schemaless 实例应用 CPU 扩展前后的峰值 CPU 利用率直方图。低（Low）是指峰值使用率低于 25%，高（High）是指峰值利用率高于 45%。处于低类别从来都是不理想的，但有时是必要的。对于不受事件 / 故障转移影响的存储实例来说，处于高类别是有意义的。</p><p></p><p>图 3 显示了 Schemaless 技术启用 CPU 垂直扩展前后的峰值 CPU 使用率的直方图。默认情况下，扩缩器设置为以 40% 的峰值 CPU 使用率为目标。选择 40% 是为了确保有空间进行区域故障转移（可能会使负载增加一倍）。之所以选择 40%，是因为我们不想超过大约 80% 的 CPU 利用率。由于启用了超线程，当 CPU 利用率超过 80% 时会出现拥塞问题。</p><p></p><p>对比图 3 中的前后，我们可以观察到超额配置分配（低类别）的比率显著下降了。它之所以没有完全消失，主要是因为 Schemaless 运行在基于 Raft 的领导者 / 追随者 (Leader/Follower) 设置中，每个集群只有一个领导者（leader）。只有领导者可以提供一致的读取，并且对于某些用例，它的请求率明显高于其他用例。在任何给定的时间里，任何其他容器都可以成为领导者，因此，来自同一集群的所有容器都要均衡扩缩。</p><p></p><p>从图 3 也可以清楚地看出，高类别容器的比例有所上升。这实际上是有意为之的，因为我们已经意识到，在区域故障转移期间，一些存储集群的负载不会增加太多。因此，对于这些集群，我们可以设定一个明显更高的峰值使用率。</p><p></p><p>正确调整与 Schemaless 相关的所有容器的大小的最终效果是总体减少了大约 10 万个内核，即约 20%。Uber 使用的典型主机有 32 核或 48 核，分配率在 83% 左右，在大多数情况下，CPU 内核是瓶颈。因此，这 10 万个内核可以节省 3000 台主机（终端用户的延迟不变）。</p><p></p><p>CPU 垂直扩缩器 不仅节省了大量的成本，而且还确保了全面一致的性能和可靠性。在区域故障转移期间，这一影响非常明显，因为现在容器普遍地被分配了所需的资源，因此不会像过去那样产生延迟下降。</p><p></p><h2>计算分配目标</h2><p></p><p></p><p>上一节讨论了为什么可以使用 CPU 容器指标来垂直调整存储工作负载的大小。在本节中，我们将更详细地介绍如何准确地计算目标。术语 Pod，借用自 Kubernetes，在下文中它将用于描述在单个主机上运行的存储工作负载的容器集合。</p><p></p><p>如前所述，计算每个 Pod 要设置的 CPU 分配模型是：基于计算峰值 CPU 利用率，然后将其转换为确保给定峰值 CPU 利用率的分配。另一个重要的注意事项是，同一存储集群中的所有 Pod 必须分配相同数量的内核。原因是存储集群内的职责可能会随着时间的推移而变化，因此必须为所有 Pod 分配足够的资源，以便它们能够成为集群中最繁忙的 Pod。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1347fa11638da3fa1a590b0ca9b2f17.png\" /></p><p></p><p>图 4：计算给定存储集群的峰值 CPU 利用率所涉及的步骤。默认情况下，总是回溯两周，以确保周末峰值在数据集中得到很好的体现。</p><p></p><p>图 4 显示了如何根据过去 14 天的 CPU 利用率数据计算峰值 CPU 利用率。CPU 利用率数据是使用 cexporter 收集的，并作为时间序列发布到我们的监控堆栈 M3 中。该算法的步骤如下：</p><p></p><p>从同一存储集群所有 Pod 的原始 CPU 利用率信号开始。使用两周的窗口与优步系统负载变化的时间尺度相匹配，因为我们以每周模式为主，峰值负载发生在周五和周六晚上。使用 2 周回溯可以确保数据集中始终包含 2 个周末。将原始时间序列降采样（downsample）到 8 小时分辨率。在此步骤中，每个 Pod 的原始时间序列被降采样为 8 小时分辨率，计算每个时间窗口的 P99 CPU 利用率。8 小时时间间隔的 P99 确保 CPU 利用率在每 8 小时的窗口中最多有 5 分钟超过这个值。我们已经尝试了从 4 小时到 24 小时的不同采样窗口。使用 8 小时似乎可以提供良好的信噪比，可以避免过度索引异常值，但也不会错过重要的峰值。将每个 Pod 信号压缩为集群信号。在此步骤中，根据时间戳来选择最繁忙的 Pod 的值。这会将每个 Pod 的信号压缩为集群级信号。对于像 Cassandra 这样的存储技术，每个集群有大量的 Pod，因此取而代之的是根据时间戳选择 P95 值。将第三高峰值定义为集群的峰值 CPU 利用率。在最后一步中，从集群的 42 个数据点（14 天 *3 个数据点 / 天）中提取峰值 CPU 利用率。峰值 CPU 利用率被定义为第三高的数据点。通过选择第三高的数据点，我们避免了对异常值的过度索引。在确定了每个集群的峰值 CPU 利用率后，我们将配额计算为：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f7291f69d8646a84228c8c04b5c58df.png\" /></p><p></p><p>配额被四舍五入到最接近的整数，以避免小数内核分配。我们希望避免由于使用 cpusets 进行工作负载分离而导致的小数内核分配。</p><p></p><h2>总&nbsp; 结</h2><p></p><p></p><p>自 2021 年初启用 CPU 垂直扩展以来，优步通过该工具减少了超过 12 万个内核分配，节省了数百万美元的硬件开支。同时，我们通过确保所有存储 Pod 的大小一致性，提高了平台的整体可靠性。</p><p>由于工程师现在只需要表达所需的利用率，而不必手动计算和执行分配更改，因此在正确调整存储集群大小方面所花费的工程工作也大大减少了。他们正在进行根据故障转移行为和临界性确定每个存储群集要设置的最佳利用率的工作。</p><p></p><p>原文链接：</p><p>https://eng.uber.com/vertical-cpu-scaling/</p>",
    "publish_time": "2022-08-04 17:05:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2022 阿里云飞天技术峰会即将召开，三大看点抢先剧透！",
    "url": "https://www.infoq.cn/article/dAtp5isx8L4a7MOM3gHz",
    "summary": "<p>阿里云飞天技术峰会将于 8 月 11 日在深圳举行，峰会以“聚焦核心技术，激活企业内生动力”为主题，邀请众多高新技术领军企业，围绕“企业如何在新一代云计算体系架构之上激活业务、技术、产品的内生动力”这一核心话题展开探讨，共商后疫情时代企业增长的破局之道。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/9f/9f282dcdaf257179517b1aab6b6d22a6.png\" /></p><p></p><p>名额有限，扫码报名</p><p>&nbsp;</p><p>本次峰会，小编为你总结出了三大看点：</p><p></p><h2>看点一：主论坛——行业先锋最佳实践</h2><p></p><p>&nbsp;</p><p>过去 13 年，阿里云自研出飞天云操作系统，并不断推出自研芯片、服务器、计算、存储、网络等产品或服务。不久前，阿里云发布了云基础设施处理器 CIPU，预示着阿里云将推动云计算从以 CPU 为中心的体系架构向以“飞天操作系统+ CIPU ”为中心的体系架构演进。时隔两月，阿里云飞天技术峰会落地深圳，这一次，阿里云又将释放出怎样的行业信号呢？</p><p>&nbsp;</p><p>在本次峰会的主论坛上，阿里云将携手核心客户，围绕新一代计算体系架构（飞天+ CIPU ）、洛神网络、盘古存储、神龙计算等阿里云核心技术的优势及相关产业应用进行详解，内部技术、线下揭秘。对分布式网络、大规模数据计算及存储、云原生等技术感兴趣的小伙伴，千万不要错过哦~</p><p>&nbsp;</p><p></p><h2>看点二：七大分论坛——前沿技术场景实践</h2><p></p><p>&nbsp;</p><p>分论坛将围绕七个不同的技术角度，邀请众多技术大咖现身分享，选择自己感兴趣的方向，提前 Mark 并扫码报名吧~</p><p>&nbsp;</p><p>「分布式云最佳实践」 13:30-16:20</p><p>分布式云正在成为企业上云的新范式，作为国内最早一批进行云计算研发与实践的企业之一，阿里云在分布式云上有着怎样的技术实践与经验分享呢？本专场将围绕云计算的发展与演进、弹性计算、分布式云场景实践等话题展开分享，更有重磅产品发布及授牌仪式等你围观~</p><p></p><p>「云原生企业级数据湖」 13:30-15:05</p><p>不久前，阿里云云原生数据湖产品通过了工业和信息化部中国信息通信研究院大数据能力专项评测，荣获“云原生数据湖基础能力专项评测证书”。作为国内首批获此殊荣的云原生数据湖产品，究竟有何技术亮点？又有怎样的场景实践经验分享呢？本专场将围绕数据湖 3.0、数据湖构建管理、数据湖架构演进、数据湖场景实践等话题展开分享。</p><p></p><p>「AIOps 与可观测」 13:30-15:20</p><p>一方面，随着 AI、大数据技术在 IT 运维领域的落地，AIOps (智能运维) 正在成为行业追捧的焦点；另一方面，企业对于运维的要求不再局限于被动发现问题，希望更及时、主动、准确地发现问题与洞察原因，为事前预防、事中处理、事后复盘提供决策依据，“可观测”成为当前的热门技术之一。本专场将围绕 AIOps 场景实践、云原生可观测技术最佳实践、面向 AIOps 的可观测平台数据实践等话题展开分享。</p><p>&nbsp;</p><p>「万物上云的智能云网络」 13:30-15:00</p><p>万物上云的时代，网络至关重要。在网络层，洛神云网络已经推出了 3.0 新平台架构，支持中心云到本地云和边缘云一致性的云网络体验，并能通过全新的物联网云连接器和智能接入网关实现万物上云。本专场将围绕阿里云智能云网络的技术突破以及场景应用实践展开分享。</p><p>&nbsp;</p><p>「云原生加速应用构建」 13:30-16:00</p><p>从“上云”到“云上”原生，云原生提供了最优用云路径，云原生的技术价值已被广泛认可。当前行业用户全面转型云原生已是大势所趋，用户侧云原生平台建设和应用云原生化改造进程正在加速。本专场将围绕云原生应用构建、云原生 IT 成本治理、云原生稳定可观测、云原生 AI 的 GPU 实践等话题展开讨论。</p><p>&nbsp;</p><p>「无影产品技术与实践」 13:30-15:55</p><p>5 月 18 日，阿里云举行了「无影云应用线上发布会」，会上提到无影云应用将实现多生态应用免部署与快速构建，应用即点即用，为用户提供安全、易用、高效且低成本的云上应用管理与使用体验。本次峰会，阿里云无影产品线核心成员也将在此专场，围绕无影云上创新引擎、核心技术突破、企业级解决方案、多场景应用实践等话题展开分享，更有生态伙伴签约仪式，快来围观~</p><p>&nbsp;</p><p>「云钉一体·企业数字化转型」 13:30-16:00</p><p>两年前，阿里巴巴公布“云钉一体”战略，预示着阿里云与钉钉全面融合。时至今日，恰逢企业数字化转型的浪潮，“云钉一体”有着怎样的突破？在企业数字化转型过程中又能发挥怎样的价值呢？本专场将围绕企业数字化“云钉一体”解决方案、数字化项目管理、低代码应用解决方案、“云钉一体”场景实践等话题展开分享。</p><p></p><h2>看点三：产品体验区——核心产品打卡体验</h2><p></p><p></p><p>除了干货满满的主论坛、分论坛演讲外，本次技术峰会还设置了核心技术及产品的打卡体验区，包括飞天展示区、无影展示区、钉钉展示区等，可视化的技术展示、可交互的场景体验……更多亮点，等你来探。</p><p>&nbsp;</p><p>阿里云 X InfoQ 联名邀请，名额有限，码上报名！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e5/e5bb464a37af19e973315fc85618302c.png\" /></p><p></p>",
    "publish_time": "2022-08-04 18:36:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "北美数字支付兴起，加拿大技术人才紧缺 | 独家专访 Snaplii CEO",
    "url": "https://www.infoq.cn/article/pswHwkFsaZlcT0VbmwNV",
    "summary": "<p></p><blockquote>本文专访嘉宾：Spencer Xu，Snaplii 创始人兼 CEO。</blockquote><p></p><p>&nbsp;</p><p>一个广为人知的事实是，中国金融市场直接跳过了“信用卡时代”，跳跃进入了“移动支付时代”，大部分开发者，好像对以卡为核心的信贷管理系统了解并不多，反而对移动支付、数字营销认知颇深。</p><p>&nbsp;</p><p>中国支付清算协会发布的《2022中国支付产业年报》显示，我国银行机构处理的移动支付业务笔数和金额分别是 2012 年的 282.67 倍和 228.13 倍。实体卡的发卡量虽然仍在上涨，但增速已连续四年下降，目前仅维持在 3% 的水平。</p><p>&nbsp;</p><p>实际上，即便是<a href=\"https://xie.infoq.cn/article/5bd1f0f75bdf252f4126386c0\">移动支付</a>\"，也已趋于饱和。在今日的科技领域，市场头部玩家已经固定，<a href=\"https://xie.infoq.cn/article/920452058c903cda8a7dba4c8\">区块链</a>\"、AI、高可用保障体系，乃至底层的基础软件，都已形成较为稳定的采购体系。</p><p>&nbsp;</p><p>一般而言，当市场成熟到此种程度，新兴企业会选择出海，东南亚、非洲、南美，都是常见选择。但 Snaplii 创始人兼 CEO Spencer Xu 对 InfoQ 透露，现在北美市场也是一个好选择，但北美市场不能“出海”，最好是“重新生长”。</p><p>&nbsp;</p><p></p><h2>这里不能“出海”，但可以“重新生长”</h2><p></p><p>&nbsp;</p><p>整个北美的金融体系都是相对陈旧的，信用卡作为民众进行消费行为的基础设施，其体系建设相当完善，以至于在很长一段时间里，并没有“推翻重来”的必要。所谓移动支付更便捷，更像个因果颠倒的结论——欧美民众以往拿着信用卡消费，也并没有觉得不够便捷。</p><p>&nbsp;</p><p>“如果你坐过纽约的地铁，你会感觉它又破又旧，跟我们中国的完全不一样”，Spencer Xu 说：“那么是纽约市政府没钱建新地铁吗？当然不是，其根本问题在于纽约地铁建成时间太早，因此显得陈旧，但又没有足够强的动机去‘推翻’旧地铁，建设新地铁。”（注：纽约第一条地铁线路通车于 1904 年 10 月 27 日，运行于市政府与 145 街/百老汇交叉口之间，距今已有超过 100 年的历史。）</p><p>&nbsp;</p><p>从旧系统过渡到新系统，体验上的革新，其实只是一方面，更多在于在数据层面是否足够有说服力。</p><p>&nbsp;</p><p>Spencer Xu 讲了两个故事来进一步说明这个问题。</p><p>&nbsp;</p><p>第一个故事源自一位创业公司的老板，这家公司位处传统金融领域信用卡体系下，为客户提供相关服务。而这位老板也十分努力，受到资本市场的认可，达成融资 200 万美元。但在经营复盘的过程中，他发现仅信用卡盗刷这一个问题，就让他损失了 200 万美元，基本等于融的这些钱都用来埋盗刷的坑了。</p><p>&nbsp;</p><p>信用卡常见有两种盗刷方式：第一，在 POS 机或 ATM 机上做手脚，通过读取你的卡信息，伪造一张卡；第二，趁机抄录你的实体卡信息，在一些审核不完善的渠道消费。</p><p>&nbsp;</p><p>关于盗刷，长久以来都没有太好的解决方式，其根因在于信用卡体系本身。在信用卡体系下，一切行为围绕“卡”来发生，一切关键信息绑定的是卡，只要卡不是绝对安全的，就总会出现漏洞。</p><p>&nbsp;</p><p>第二个故事源自整个北美银行业的数据盘点，有分析显示，当下北美银行业的获客成本可能高达 1000 美元/位，且在沿用信用卡体系的情况下，缺少根本性的提升方案。</p><p>&nbsp;</p><p>在中国，在移动支付的情况下，客户扫码完成消费，其信息、行为自然进入下一个商业循环，消费完成只是整个商业链条的起点。但在信用卡体系下，客户刷卡消费，消费以后将卡放回钱包，一切宣告终结。</p><p>&nbsp;</p><p>况且，在很多偏远或经济欠发达地区，根本就没有银行服务网点，民众不在银行的服务范围内——这里说的还不只是非洲，仅在东南亚，就有近三分之一的人不在银行业务覆盖范围内。</p><p>&nbsp;</p><p>所以，北美的支付系统，不仅在体感上让人觉得“不够先进”，近两年也积累了很多数字层面的重建依据。</p><p>&nbsp;</p><p>Spencer Xu 创立的公司 Snaplii，是这次重建浪潮中最引人瞩目的那一个。Snaplii 孵化自北美收单机构 SnapPay，2021 年 3 月对外官宣，2022 年 1 月完成 Pre-A 轮融资，前期主要服务亚裔社区，相当于北美的“花呗”。</p><p>&nbsp;</p><p>看起来，Snaplii 的经营情况也非常不错。据称，Snaplii 在没有特别花钱做市场推广、CAC 获客成本低于 4 美元的情况下，月用户增长均超过 150%，预计在 2022 年将有 10 倍的用户增长。</p><p>&nbsp;</p><p>Snaplii 的一位早期投资者表示，“公司自成立以来投资回报率增长了400%，包括我在内的很多投资人对Snaplii继续前进很有信心。”</p><p>&nbsp;</p><p>Spencer Xu 成了 2021 福布斯北美精英华人 Top 60，同时也对 InfoQ 表示：“我做的几家公司都比较重视现金流的健康情况，不会先融钱把客户‘砸’到一个量级，再考虑其他问题。”</p><p>&nbsp;</p><p>不过值得注意的是，无论是 Spencer Xu 还是他的 Snaplii，亦或是北美其他同处于这场浪潮的金融科技企业，都对所谓“移动支付”有着更进一步的理解——相比于“移动支付”，他们更愿意将其称为“数字化支付”。</p><p>&nbsp;</p><p>Spencer Xu 说：“北美以前也有移动支付，将储蓄卡、信用卡变成虚拟的电子卡，‘移动’式支付，但这本质还是‘卡体系’，一切数据、行为围绕‘卡’来展开。数字化支付，其核心应该是人，人是主体，我们围绕‘人’来设计基础设施。”</p><p>&nbsp;</p><p>现在，我们很多的消费行为是刷脸，验证手机号码、身份证号码，其中心是人，而不只是一张电子卡片。</p><p>&nbsp;</p><p>不过，虽然北美的金融科技行业存在新机会，但也很难让其他国家的出海企业大展拳脚 —— 毕竟，银行业务和国家经济、安全息息相关，难以接受强力的外国资本、企业进入。所以截止到目前，北美的金融科技领域创业，更像是一场闭门 Party。</p><p>&nbsp;</p><p></p><h2>北美不是一个整体，加拿大技术人才紧缺</h2><p></p><p>&nbsp;</p><p>如果关于北美数字化支付的讨论仅终结于此，你可能会觉得北美的企业家们未免太过迟钝，可事实也并非如此。</p><p>&nbsp;</p><p>Chime 是北美最成功的数字化银行，这一类金融科技公司被人称之为“NeoBank”。然而 Chime 成立于 2013 年，距今已有十年，却仍未上市或形成垂直领域的垄断，对比同期中国企业在 O2O、金融科技企业的发展节奏，并不是很快。Chime 尚且是一家硅谷企业——Spencer Xu 说：“我们这里有个形容：对个人来说，在加拿大企业工作一年就是一年；考虑到加班和工作量，在硅谷工作一年等于三年。”</p><p>&nbsp;</p><p>他随后补充道：“但在中国企业工作一年等于五年，在 ‘BATH’ 工作一年可能等于七、八年……北美的很多企业家不是没看到数字银行的机会，只是没那么‘卷’，或者说，竞争没有那么剧烈 —— 在中国，如果你看到个机会，立刻就有很多人开始做，差不多两年后都快形成垄断了，三年后已经完事了，没机会了。北美这做了十年，还没上市呢。”</p><p>&nbsp;</p><p>但不够卷，或许也对整个产业的人才梯队产生了影响。北美并非一个整体，尤其是在人才方面，因为毗邻美国，加拿大有大批的技术人才流向了硅谷。</p><p>&nbsp;</p><p>2022年各国软件工程师平均工资显示，加拿大开发者平均工资位列全球第五（第一名是美国），但加拿大同时也是对软件开发者需求最旺盛的国家，位于其后的国家分别是澳大利亚、俄罗斯、瑞典和新西兰。</p><p>&nbsp;</p><p>尽管金融科技企业的第一驱动力不一定是技术，Spencer Xu 也代表 Snaplii 公司表达了对技术人才的渴求：</p><p>&nbsp;</p><p>“中国的移动支付、数字化支付成熟度可以说是全球领先，即便是出海，现在东南亚也早已人满为患。国内的同学其实可以考虑一下加拿大，这里竞争环境相对宽松。”</p><p>&nbsp;</p><p></p><h2>中国开发者受到欢迎</h2><p></p><p>&nbsp;</p><p>恰恰是因为国内<a href=\"https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247570927&amp;idx=3&amp;sn=69c4f38b48490c87a220f822069dc830&amp;chksm=fbeb6c20cc9ce536dfea9b2ef68227b22d26120be01996ac5b8143bad601d5a0ef39a0ccb182&amp;scene=27#wechat_redirect\">金融科技</a>\"领域业务，用极短的时间完成了从 1 到 100 的进化，现在这些久经战火、经验丰富的中国开发者，受到全球，尤其是加拿大企业的热烈欢迎。</p><p>&nbsp;</p><p>Spencer Xu 也以 Snaplii 为例，详细聊了他们给技术人才的福利待遇：</p><p>&nbsp;</p><p>“此前我们了解到一些人才年薪可能达到 200 万美元，我们可能提供不了这么高的薪资，但可以保证一定是个很 Decent（体面）的薪水。此外，Snaplii 目前整体的发展情况比较符合加拿大政府的规划，四个月左右我们就能确定员工能否拿到绿卡，工作 1 - 2 年就能实际完成办理。最后就是，我们相当于早期的蚂蚁，竞争环境也比较良好，期权翻个几十倍，还是非常有可能的。”</p><p>&nbsp;</p><p>Snaplii 目前研发团队人数在 20 人以内，Spencer Xu 本人的经营风格是稳扎稳打，保持现金流健康，不盲目扩张，也不急于求成。所以，在接下来的一到两年内，据 Spencer Xu 规划，公司研发团队人数会翻一到两倍。而其近期的主要招聘目标，将围绕在中高级工程师，相当于阿里的 P7 - P9 级别。</p><p>&nbsp;</p><p>多文化团队，文化建设与管理往往是个难题，Spencer Xu 也坦承这一类问题比较难以解决，但目前 Snaplii 的情况还好：</p><p>&nbsp;</p><p>“目前我们主要服务 50 万到 100 万人口的亚裔社区，这已足够支撑公司 50 亿到 70 亿的估值。服务亚裔社区，当然整体文化对中国开发者是非常友好的，再加上不管是公司还是加拿大，目前都是多元文化。很多同学虽然也是白皮肤，但来自俄罗斯，论英语可能和我们中国小伙伴不相上下……所以整体氛围都是比较友善的。”</p><p>&nbsp;</p><p>另外一种抹平文化差异的行为，并非来自于国家或种族差异，而是传统金融企业和新兴金融科技企业之间的技术文化冲突，Spencer Xu 对 InfoQ 说，Snaplii 目前是互联网式企业文化主导的公司。</p><p>&nbsp;</p><p>当然，不管是在何种文化下工作，自身的能力和素质永远是第一位的。Spencer Xu 给开发者们的建议是：</p><p>&nbsp;</p><p>“我们不应该关注今天谁的企业更强、今天谁的企业规模更大、今天什么样的事情更重要，而应该更多去关注明天谁大、明天谁强、明天什么事情更重要。现在国内硬科技很火，国外 Web3 很红火，我自己经常会想，在 Web3 时代，先不琢磨挣多少钱，我们应该怎么去服务好别人？人们需要什么样的服务？我相信只要切入点是对的，其他一切都是水到渠成的事情。”</p>",
    "publish_time": "2022-08-04 19:33:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]