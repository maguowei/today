[
  {
    "title": "Java近期新闻： JReleaser 1.2、Spring Batch、PrimeFaces、Quarkus、JobRunr与Apache Beam",
    "url": "https://www.infoq.cn/article/lf8oLh7w0pphOigclNdG",
    "summary": "<p>最近，Java社区相对比较平静，本期的新闻包括JDK 19、JDK 20、Spring Batch 5.0.0-M5、Quarkus 2.11.3、JReleaser 1.2.0、PrimeFaces 12.0.0-M3、JobRunr 5.1.8、Apache Beam 2.14.0和Apache Johnzon 1.2.19。</p><p></p><h4>JDK 19</h4><p></p><p><a href=\"https://openjdk.org/projects/jdk/19/\">JDK 19</a>\"依然处于<a href=\"https://openjdk.java.net/jeps/3#rc\">发布候选</a>\"阶段，预计GA版本会在2022年9月20日发布。<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"包含了文档的链接，比如<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec//api/index.html\">完整的API规范</a>\"以及一个<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec/apidiffs/overview-summary.html\">标注的API规范</a>\"，后者对比了JDK 18（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-18%2B36\">Build 36</a>\"）和JDK 19（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B36\">Build 36</a>\"）的差异。InfoQ会持续跟进，提供更详细的新闻。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B12\">Build 12</a>\"发布，它是对Build 11的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B11...jdk-20%2B12\">更新</a>\"，包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2020%20and%20%22resolved%20in%20build%22%20%3D%20b12%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该版本的更多细节，请参阅<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Spring框架</h4><p></p><p>经过前段时间的忙碌，最近Spring团队比较安静。</p><p></p><p>在通向<a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a>\"&nbsp;5.0.0的道路上，<a href=\"https://spring.io/blog/2022/08/24/spring-batch-5-0-0-m5-is-available-now\">第五个里程碑版本</a>\"发布，其更新包括：删除<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/test/JobLauncherTestUtils.html\">JobLauncherTestUtils</a>\"中Job的自动装配，迁移至JUnit Jupiter以及文档的改进。这个发布版本还升级了依赖，包括Spring Framework 6.0.0-M5、Spring Data 2022.0.0-M5、Spring Integration 6.0.0-M4、Spring AMQP 3.0.0-M3、Spring for Apache Kafka 3.0.0-M5、Micrometer 1.10.0-M4和Hibernate 6.1.2.Final。最后，Spring Batch 5.0.0-M5还弃用了两项内容，分别是用于游标/分页的Hibernate&nbsp;<a href=\"https://docs.spring.io/spring-batch/docs/current/reference/html/readersAndWriters.html#itemReader\">ItemReader</a>\"和<a href=\"https://docs.spring.io/spring-batch/docs/current/reference/html/readersAndWriters.html#itemWriter\">ItemWriter</a>\"接口，取而代之的是基于Jakarta Persistence规范的接口，另外，因为发现在JUnit中存在两个提供相同功能的静态方法，<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/test/AssertFile.html\">AssertFile</a>\"类也被弃用。关于该版本的更多信息，请参阅<a href=\"https://github.com/spring-projects/spring-batch/releases/tag/5.0.0-M5\">发布说明</a>\"。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-11-3-final-released/\">发布了</a>\"Quarkus 2.11.3.Final，该版本对<a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=2108396\">CVE-2022-2466</a>\"进行了全面修复，该漏洞是在<a href=\"https://quarkus.io/guides/smallrye-graphql\">SmallRye GraphQL</a>\"服务器扩展中发现的，它会导致服务器请求无法正确终止。此外，还对mariadb-java-client&nbsp;3.0.7、postgresql&nbsp;42.4.1和42.4.2以及mysql-connector-java&nbsp;8.0.30进行了升级。关于该版本的更多信息，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.11.3.Final\">发布说明</a>\"。</p><p></p><h4>JReleaser</h4><p></p><p><a href=\"https://jreleaser.org/\">JReleaser</a>\"&nbsp;1.2.0版本<a href=\"https://andresalmiray.com/jreleaser-1-2-0-has-been-released/\">发布</a>\"&nbsp;，它是一个简化项目发布的Java工具，该版本的特性包括：支持将<a href=\"https://flatpak.org/\">Flatpak</a>\"作为打包器；允许basedir作为一个命名模板；允许通过Twitter4J在Twitter上发布消息文件，在这个过程中每一行都会是一条单独的消息，并且会跳过空行；它会通过日志发现-add-launcher参数没有传入，进而提供了配置未使用的自定义启动器的方案。另外，还有很多的依赖升级，包括jsonschema&nbsp;4.26.0、github-api&nbsp;1.308、slf4j&nbsp;2.0.0、aws-java-sdk&nbsp;1.12.270 and 1.12.290和jsoup&nbsp;1.15.3。关于该版本的更多信息，请参阅<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.2.0\">发布说明</a>\"。</p><p></p><h4>PrimeFaces</h4><p></p><p>在通往<a href=\"https://www.primefaces.org/\">PrimeFaces</a>\"&nbsp;12.0.0的道路上，<a href=\"https://twitter.com/primefaces/status/1562367103772282880\">第三个候选版本</a>\"已经发布，其特性包括：修复了<a href=\"https://primefaces.github.io/primefaces/11_0_0/#/components/autocomplete\">AutoComplete</a>\"组件在<a href=\"https://myfaces.apache.org/\">Apache MyFaces</a>\"上无法运行的问题；新的showMinMaxRange属性，允许导航范围超过最小/最大日期，其默认值为true；<a href=\"https://primefaces.github.io/primefaces/11_0_0/#/components/datatable\">DataTable</a>\"组件提供了新的showSelectAll属性，在列的标题中会显示“select all checkbox”。更多细节可以在<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aclosed+milestone%3A12.0.0-RC3\">问题列表</a>\"中找到。</p><p></p><h4>JobRunr</h4><p></p><p><a href=\"https://www.jobrunr.io/\">JobRunr</a>\"的创始人和主要开发者<a href=\"https://www.linkedin.com/in/ronalddehuysser/\">Ronald Dehuysser</a>\"发布了<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v5.1.8\">5.1.8版本</a>\"，这是一个在Java中执行后台进程的工具，该版本包含了为后台job服务器关闭指标的功能。</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Beam 2.41.0版本<a href=\"https://www.mail-archive.com/announce@apache.org/msg07525.html\">发布</a>\"，它包含了大量的缺陷修正，并且为Python&nbsp;<a href=\"https://beam.apache.org/documentation/transforms/python/elementwise/runinference/\">RunInference</a>\"转换为Java提供了对<a href=\"https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/values/KV.html\">KV</a>\"类的支持。关于该版本的更多信息，请参阅<a href=\"https://beam.apache.org/blog/beam-2.41.0/\">发布说明</a>\"。关于Apache Beam的更深入介绍可以参阅InfoQ的<a href=\"https://www.infoq.cn/article/DNHzwEIkQyJgShdGHz6L\">技术文章</a>\"。</p><p></p><p><a href=\"https://johnzon.apache.org/\">Apache Johnzon</a>\"的1.2.19版本发布，该项目完整实现了JSR 353，即<a href=\"https://jcp.org/en/jsr/detail?id=353\">Java API for JSON Processing</a>\"（JSON-P），和JSR 367，即<a href=\"https://jcp.org/en/jsr/detail?id=367\">Java API for JSON Binding</a>\"（JSON-B）规范，<a href=\"https://twitter.com/rmannibucau/status/1561611201108484097\">发布</a>\"的特性包括：在<a href=\"https://johnzon.apache.org/apidocs/org/apache/johnzon/jsonschema/generator/PojoGenerator.html\">PojoGenerator</a>\"类中对枚举的基本支持；在onEnum回调中添加JSON-Schema；能够确保枚举使用JsonbProperty时，导入它；暴露PojoGenerator类中的toJavaName()方法给子类。关于该版本的更多信息，请参阅<a href=\"https://johnzon.apache.org/changelog.html\">发布说明</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/java-news-roundup-aug22-2022/\">Java News Roundup: JReleaser 1.2, Spring Batch, PrimeFaces, Quarkus, JobRunr, Apache Beam</a>\"</p>",
    "publish_time": "2022-09-13 09:07:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Stack Overflow 2022报告：亚马逊云科技的软件开发“武器库”",
    "url": "https://www.infoq.cn/article/69cDiK84CkeW7CEZXg9j",
    "summary": "<p></p><p>前不久，备受期待的 Stack Overflow 2022 年度开发者调查报告终于出炉。作为软件开发行业最具专业性和影响力的开发者调研活动，Stack Overflow 收集了全球 180 个国家和地区的开发人员反馈，涵盖流行的操作系统、编程语言、框架和库、云平台、数据库、机器学习技术等多个细分主题。</p><p></p><p>Stack Overflow 在报告中表示，收回的 5 万 6 千份有效回复体现出了一些对塑造当今软件开发和实践的工具和环境的深刻见解（great insights）。这些结果也有助于我们在技术选型和开发环境选型时进行参考，因此我们摘取了部分亮点进行解读。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f0/f0af2106a2bc8e11805bbc200c7025fc.jpeg\" /></p><p></p><p></p><h2>云原生开发</h2><p></p><p></p><p>Stack Overflow 年度报告的“云平台”调查问题希望了解开发者在过去一年中主要在哪些云平台中进行开发工作。在针对专业开发者群体中，亚马逊云科技以 51.01% 的比例位列第一，其次是 Azure、Google Cloud 以及 Firebase。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82d634a683fbcdbfbe8230e15a3bd65b.jpeg\" /></p><p></p><p></p><h3>从本地开发到云原生开发的演进</h3><p></p><p></p><p>在调查结果中，有的平台在 IDE 和云端开发环境上特别有优势，有的平台是基于云原生的平台即服务（PaaS），使软件开发人员可以无需担心底层基础架构就能轻松部署代码，有的是用于创建移动和 Web 应用程序的统一后端即服务 (BaaS) 平台。</p><p></p><p>处于第一位的是亚马逊云科技。亚马逊多年持续投入建设云开发环境，也有对应的一些产品。亚马逊云科技于 2017 年发布了 Cloud9 IDE，前身是一个著名的 WebIDE 开发平台。2019 年，亚马逊云科技发布了 Cloud Development Kit（CDK）云开发工具包，它是一项基础设施即代码服务，封装了亚马逊云服务的配置细节和粘合逻辑。另外，亚马逊还提供了基于云开发平台的 Serverless 架构、DevOps 一体化等诸多功能，实现生态的闭环。</p><p></p><p>从 Stack Overflow 的报告可以看出，基于云的开发平台，已经成为了各厂商的必争之地。虽然本地化开发目前还很普遍，但是云开发也有一些显著的好处。比如说在传统的软件开发方法中，开发者一般是在自己的电脑上进行开发和测试，然后在物理机或云上运行，但一些 CPU 和内存密集型的任务，在某些情况下编译或测试可能非常耗时且占用大量资源。然而大多数工程师的电脑有 CPU 和内存的限制，编译会浪费大量时间。开发环境上云之后，云服务就足以解决存储、计算资源上的弹性需求，云上按需计费也能节省边际成本。</p><p></p><p>另外，云上协同开发还可以让团队之间共享统一的预定义环境，不需要一而再地处理不同的平台、工具、版本和依赖项，一致的编译、测试环境让团队成员无需配置复杂环境即可上手，甚至可以突破时间、地域限制，让处于全球范围内、不同工作时间的开发团队使用统一的、定制的环境。云开发也意味着应用程序从开发、集成到测试、部署和生产都在使用一致的环境，有助于减少可能在生产中暴露出来的错误和其他问题的数量。</p><p></p><p>自前几年起，Kubernetes 和 Docker 开始流行，容器化技术让应用程序更加具有可移植性，这意味着它可以在任何云环境上运行，并且只需少量集成工作。而随着云原生技术的发展，原始定义现在可以扩展到包括一系列技术，而不是与容器严格相关，例如 Serverless 和流式传输等，能够让开发者更充分利用云计算模型，在云中设计、开发和运行工作负载也更加容易。</p><p></p><p></p><h3>Serverless 架构</h3><p></p><p></p><p>Serverless 是云原生技术发展的高级阶段。Serverless 最早的框架产品源于 2014 年亚马逊推出的 Amazon Lambda。Lambda 的推出开启了云计算的新时代，之后所有的大厂都在跟进，比如微软、谷歌、IBM 都先后推出自己的 Serverless 产品。在这之后，Serverless 也从愿景层面逐步走向落地，在企业里应用开来。</p><p></p><p>从最初认为 Serverless 是 FaaS（函数即服务），到 FaaS（函数即服务）和 BaaS（后端即服务）的集合，人们对 Serverless 的认知不断的变得清晰。对亚马逊云科技这样的云厂商而言，Serverless 不仅局限于计算服务，而是指一种端到端的架构。除了我们比较常提起的 Lambda 外，还覆盖了计算、存储、网络、容器、数据库等，集成多个方面的服务，才能快速地构建现代化应用。</p><p></p><p>开发人员在使用 Serverless 服务和架构时，只需要关注业务逻辑，不再需要部署、管理或扩展服务器。云服务本身可以快速、无缝地自动扩展，以适应流量峰值。</p><p></p><p>事件驱动型架构（EDA）是一个典型的 Serverless 架构，常见于使用微服务的现代应用程序，或者有解耦组件的任何应用程序。它以事件为媒介，实现组件或服务之间最大松耦合的方式。现在的企业，普遍采用了微服务架构，而结合微服务和事件驱动架构，能更好地解决关键业务的实时、可扩展等问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f5/f53d8727d4ba4515224221c2c31fc903.png\" /></p><p></p><p>事件驱动型架构有三个主要组成部分：事件发起者、事件路由器和事件使用者。事件源产生事件，并将事件发布至事件路由器。事件路由器进行事件筛选并推送给相应的事件使用者。事件使用者或者处理事件，或者受事件影响，并为之采取相应的操作。通过此架构，事件源和事件使用者解耦，从而使它们能够独立扩展、更新和部署。</p><p></p><p>使用事件驱动型架构的优势也是十分明显的，通过解耦，使服务之间相互独立，利于扩展和提高可用性。同时，使用事件路由器 Amazon EventBridge 或 Amazon Simple Notification Service（SNS）将帮助筛选并将事件推送给使用者，无需编写自定义代码，大幅提升开发的敏捷性。</p><p></p><p>这种架构对于成本的优化也是显著的，事件是按需发生的，这意味着我们无需为空闲资源付费。比如上图中的作为事件使用者的 Lambda 函数，只需要为 Lambda 处理事件时的函数请求数量和执行代码所花费的持续时间付费。</p><p></p><p>随着 Serverless 各方面的功能和性能的提升，其采用率也在持续增长。据 Datadog 2021 年发布的无服务器状态报告，开发人员正加速采用无服务器架构：2019 年之后 Amazon Lambda 的使用率显著增加，2021 年初，Amazon Lambda 函数的平均每天调用频率是两年前的 3.5 倍，且半数 Amazon Web Services 新用户已采用 Amazon Lambda。而据 Amazon Web Services 公布的数据显示，亚马逊已有数十万家客户在各种场景下用 Amazon Lambda 来构建他们的服务。</p><p></p><p></p><h3>低代码平台</h3><p></p><p></p><p>Serverless 是一种范式转变，可以减少服务器运维工作，如果再加上减少手动编码的方式，我们就能够更快地进行业务开发和交付。各云厂商近几年都在低代码开发平台上投入了不少力量，亚马逊也于 2017 年发布了 Amazon Amplify。</p><p></p><p>从云计算开始，技术发展在不断将底层平台进行抽象，低代码平台通过将底层平台云化，屏蔽复杂的使用规则，用 BaaS 层接口提供后端服务，让开发者将重心放到业务流程和界面定制上。也因此，低代码的核心部分之一是前端开发。Amazon Amplify 平台采用的是集成 UI 原型设计平台 Figma 的方式，允许设计师和前端开发人员在设计和开发活动上进行协作。例如，开发人员只需将新的组件设计从 Figma 拖放到 Amplify Studio 的应用程序中，设计好的 UI 会自动转换为 JavaScript 或 TypeScript，让开发人员可以完全控制应用程序的设计和功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c406b646228c773e751f67b40127475b.jpeg\" /></p><p></p><p>低代码开发平台的另一优势是加速全栈开发的速度。我们可以看到 Stack Overflow 的报告涉及的技术越来越多，也说明了随着应用程序的复杂性增加，我们开发人员需要在开发过程中处理越来越多的事情，包括框架和平台的选择、安全配置、数据库、CI/CD 部署等等。对于开发人员来说，全栈开发变得非常复杂，需要具备非常全面的技能。但通过低代码提供的堆栈环境，以及全生命周期管理能力，让开发人员可以以简单的方式管理从 UI 设计、代码开发到部署的端到端应用程序开发，进一步降低全栈开发难度。在 Amazon Amplify 中，它是通过 CLI 命令等方法实现快速地创建后端和数据库（在内部使用 Lamda、S3 和 DynamoDB），从而在短时间内完成一套全栈 Web 和移动应用程序。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/3615da0f26da877bd94f1cfdb7b62d9a.jpeg\" /></p><p></p><p>低代码还能减少对 AI 或机器学习专业人员的依赖，可以降低 AI 应用的失败率。在亚马逊的低代码平台中就提供了如 AI/ML、mapping 等服务。我们可以在构建的全栈应用程序时，轻松调用 Analytics 功能，收集事件数据分析用户操作，然后调用 AI/ML 服务“预测”用户的下一步操作。或者也可以根据自己的需求调用其它比如文字翻译、语音识别、图像处理等云服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/6582b37163cfe8ce8649e4fce4dc5b81.jpeg\" /></p><p></p><p></p><h2>机器学习</h2><p></p><p></p><p>在低代码平台中，对 AI/ML 服务的调用，也是在释放人工智能的力量。人工智能的应用现在越来越普遍，渗透到了企业的各种业务场景应用当中，发挥着重要且积极的影响。日常开发中，我们也会经常遇到需要应用 AI/ML 技术的地方，而云上的机器学习服务更加齐全，不仅提供了多样性的选择，而且还兼顾了易用性。</p><p></p><p>机器学习技术的普及也和云计算的发展密不可分。一方面，机器学习有着庞大的计算和数据存储需求，几乎机器学习的每一步训练与推断都需要庞大的云端集群来提供算力或存储资源支持。而云服务提供商凭借海量的集群资源，以及按需按消耗付费的计价模型，再加上这几年云服务持续的降低成本，让机器学习与人工智能已经变成了人人都用的服务。</p><p></p><p>另一方面，云服务厂商在机器学习的工具库上，提供了非常好的深度和广度，来满足用户的不同需求。机器学习本身是一个“Right tools for the right job”的事情，需要根据具体的业务和场景，选择最合适的工具。亚马逊云科技采取开放包容的工具选择策略，让云端可以和客户的整个环境做到良好的集成。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9af405082c411a95ad8d8c85cdf2b5e.jpeg\" /></p><p></p><p>从机器学习技术栈的 3 个层面分别阐述：</p><p></p><p>在底层机器学习框架方面，云厂商需要支持各种主流的机器学习基础框架和标准接口，如 TensorFlow、PyTorch、Apache MXNet、Gluon、Keras 等。这些框架也都出现在了今年 Stack Overflow 年度报告“受开发者欢迎的库”调查结果中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9defe56a6f7d5527484cab4dd298eb1f.jpeg\" /></p><p></p><p>而亚马逊云科技不仅支持上述机器学习基础框架和接口，还针对 TensorFlow、PyTorch 和 MXNet 三个主流框架进行了专门的优化适配，并支持通过 Amazon Glue、Amazon Kinesis 等数据接口集成来最大限度方便框架的使用。这些设计使其可以方便地支持开发者以及数据科学家们运行流行机器学习框架以及运行使用多种框架。</p><p></p><p>在底层计算层也是如此，无论是 AI 芯片还是计算实例，云厂商也可以让用户根据不同的应用场景，根据自己的实际需求自由选择各种 GPU 实例、ARM 实例、机器学习专用推理芯片。</p><p></p><p>在上层 AI 服务层面，开发者可以根据自身需求，在云上有选择的使用各种 AI/ML 服务，比如文本分析、代码检查、聊天机器人、需求预测、文档分析、企业搜索、反欺诈、图像视频分析、个性化推荐、实时翻译、文本语言转换、转录，等等。为自己的系统应用补充所需要的智能化组件，通过简单的 API 调用即刻补足智能拼图缺失的一角。</p><p></p><p>在承上启下的中间层，像 <a href=\"https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db\">Amazon SageMaker</a>\" 这样的工具平台，提供了一项全托管端到端机器学习服务，这也是亚马逊云科技机器学习服务层面的核心产品，可帮助数据科学家、开发人员以及机器学习专家快速构建、训练并托管规模化机器学习模型。开发者只需要关心自己输入什么数据，自己想用什么框架和什么算法，其他的各种参数调优什么的脏活儿就让机器自己用机器学习来做，减轻了机器学习流行中数据清洗、建模等步骤的复杂性。</p><p></p><p>随着机器学习应用变得普遍，各种 MLOps 工具也变得越来越多，而且机器学习项目的开发工作流程仍然非常反复，所以对于开发人员来说，管理工作还具有挑战性。</p><p></p><p>例如，当尝试一种新算法或调整超参数时，开发人员和数据科学家通常在 Amazon SageMaker 上进行成千上万次实验，需要手动管理所有实验。随着时间的流逝，追踪性能最佳的模型和利用在实验过程得出的经验教训变得越来越困难。</p><p></p><p>2020 年， SageMaker Studio 正式发布，这是亚马逊云科技创建的一个全集成的 ML 开发环境——也是业界首创。它统一了 ML 开发所需的所有工具，将数百种机器学习功能，包含训练好的模型、设置好的容器镜像，都集成到基于 Web 的开发环境 Amazon SageMaker Studio 中。</p><p></p><p>开发人员可以通过单个窗格管理整个 ML 工作流，在可视化界面中编写代码、跟踪实验、可视化数据，以及针对 ML 工作流进行调试和监控，不需要切换来切换去，从而极大地提高了开发效率。</p><p></p><p>这种集成并简化后的开发环境对机器学习初学者也特别友好。以 Stack Overflow 报告最受开发者喜爱的 Hugging Face Transformers 为例，其官方网站默认使用 Amazon SageMaker 来训练和部署模型，提供了相应的<a href=\"https://xie.infoq.cn/article/fb833598f8919e89fd1168264\">入门指导</a>\"。Hugging Face 提供的深度学习容器（DLC）与 SageMaker 结合，可以让开发者跳过从头开始构建和优化训练环境的复杂过程，立即开始训练模型。在亚马逊云服务上，免费注册账户，然后用 Huggingface Sagemaker，只需简单几行代码就可以开始训练并部署 Hugging Face Transformers 模型。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c1/c1d717ed026bed33bbbc1c886b5b586d.jpeg\" /></p><p></p><p></p><h2>云数据库</h2><p></p><p></p><p>在 Stack Overflow 的报告中，还有一项特别有意思的调查项目，即“薪资待遇最好的技术”，其中在针对编程语言的统计中，使用 Clojure 语言的开发者收入最高；在针对框架和库的统计中，Apache Spark、Apache Kafka 和 Hadoop 排行最高，说明大数据类的工作收入较高；在针对数据库的统计中，DynamoDB 数据库开发者的薪水是最高的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/99201a2b2626b7e0d7e8cd1fdcf4b757.jpeg\" /></p><p></p><p>在这里就不得不介绍一下薪酬最高的开发数据库 DynamoDB 是何许人也，DynamoDB 是非关系型数据库的开山鼻祖，它起源于亚马逊于 2007 年发表的一篇划时代论文《Dynamo: Amazon’s Highly Available Key-value Store》。这篇论文影响了很多 NoSQL 数据库的设计，<a href=\"https://www.infoq.cn/article/aws-dynamodb-dive-in\">也最大程度地将 consistent hashing 这个概念从学术界引入了工业界</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8a/8a6a0cc2f7795c9a6f5356740169e9de.jpeg\" /></p><p></p><p>Dynamo 论文推动了行业大规模变迁至非关系型数据库，并最终促成新一代的适用于互联网的云数据库 DynamoDB 的诞生。现在，DynamoDB 可处理每日超过 10 万亿请求和每秒超过 2000 万峰值请求，并且还具有详细的企业级特性，如支持 ACID 事务，使用户能够大规模构建业务关键型应用程序，从而被众多企业应用到核心业务中。今天有许多全球发展最快的企业，如 Lyft、Redfin、Disney、Zoom 等企业，都依靠 DynamoDB 的规模和性能来支持其关键任务负载。</p><p></p><p>在今年 7 月的 USENIX ATC’22 上，Amazon DynamoDB 团队再次发布了他们的新论文《 A Scalable, Predictably Performant, and Fully Managed NoSQL Database Service》，论文里包含了云数据库跨分区吞吐量的均匀分布是如何设计的，如何用多 Paxos 来保持副本同步的机制，MemDS 分布式缓存的设计方法等硬核内容。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/06fab638a25eaf2968b1c2f2367019cd.jpeg\" /></p><p></p><p>DynamoDB 的架构</p><p></p><p>更难得的是，这篇论文还涵盖了 DynamoDB 的架构设计，以及它如何不断演进以满足客户的需求，这种涉及演进的论文相对也比较少见。</p><p></p><p>过去 10 多年，该数据库的研发人员加入了包括二级索引支持、可扩展流式数据捕获、自适应容量等等功能。不断增加的功能，不仅涉及底层可用性、持久性、安全性和规模等，还包括易用性等。这些功能让用户不再需要配置集群，只需创建一个表存储数据，即可轻松实现无缝缩放。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/54/54a036ec338eeb54079dd19c477b809a.jpeg\" /></p><p></p><p>DynamoDB 的发展</p><p></p><p>从工程角度看，这应该是近年来大规模分布式系统最实用的论文之一，其中包含的那些云数据库设计方法，估计也会给业界带来一些启发。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>我们从 Stack Overflow 调查报告出发，介绍了当前的开发工具、开发环境热点技术方向。</p><p></p><p>出色的开发工具也是软件开发者的生产力放大器。现在软件开发几乎渗透到了经济的各个领域，甚至可以说未来每个公司都会是软件公司。而开发软件必须要有好用的开发工具，如果说软件是技术进步的助推器，那么开发工具是技术进步的二阶助推器: 助推器的助推器。</p><p></p><p>随着云原生时代的来临，以及组织代码规模的扩张，开发模式不断变得复杂，也促进一些大型企业，特别是云厂商提供更好的开发环境。同时云服务提供商通过将自己的服务，集成到流行的开发工具中，使得开发者能够使用自己熟悉的工具来管理云服务。对于云厂商来说，开发工具对于开发成本的优化，以及软件交付效率的提升，可以通过用户得到千百倍的放大，为用户带来巨大的经济价值，从而也能进一步促进云厂商自身的发展。</p><p></p><p>“云平台”、云数据库这些排行榜是云计算行业的一个缩影，Stack Overflow 开发者调查报告反馈出亚马逊云科技为开发者提供了称心应手的软件开发“武器库“，而这些开发工具收到了来自不同开发者的多方面的积极评价，这离不开亚马逊云科技对开发者的重视和对开发工具不断打磨与创新。当我们评估用什么云服务时，也不妨同时看看企业是否重视工具的打造，所提供的开发工具是否趁手，毕竟这两个之间是互相促进的，“双驱动”带来的效率提升会更加可观。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e8d5e25aac3673ef79f502e7d09cbdf.jpeg\" /></p><p></p><p>作为云计算领域的行业风向标活动，2022 亚马逊云科技中国峰会将于 10 月 13 日 -10 月 14 日于线上举办，与会者有机会与国内外尖端技术讲师、构建者、业界领袖面对面深入交流，全面了解亚马逊云科技在云开发、人工智能、机器学习、数据库、大数据分析、物联网、安全等方面最新的云计算解决方案。点击链接了解更多详情：<a href=\"https://summit.awsevents.cn/2022/signin?source=I4txnunRTQh30eQ4v/ulfA==&amp;tab=1&amp;type=2\">https://summit.awsevents.cn/2022/signin?source=I4txnunRTQh30eQ4v/ulfA==&amp;tab=1&amp;type=2</a>\"</p><p></p><p>参考链接：</p><p></p><p>参考链接：</p><p><a href=\"https://aws.amazon.com/cn/solutions/case-studies/redfin/\">https://aws.amazon.com/cn/solutions/case-studies/redfin/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/solutions/case-studies/lyft/\">https://aws.amazon.com/cn/solutions/case-studies/lyft/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/dynamodb/\">https://aws.amazon.com/cn/dynamodb/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/blogs/china/machine-learning-plugs-wings-for-digital-transformation/\">https://aws.amazon.com/cn/blogs/china/machine-learning-plugs-wings-for-digital-transformation/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/amplify/studio/\">https://aws.amazon.com/cn/amplify/studio/</a>\"</p><p><a href=\"https://www.youtube.com/watch?v=T4MQrRDo20w\">https://www.youtube.com/watch?v=T4MQrRDo20w</a>\"</p><p><a href=\"https://www.cirrushq.com/wp-content/uploads/2022/03/AWS-UG-EDI-Amplify-Studio.pdf\">https://www.cirrushq.com/wp-content/uploads/2022/03/AWS-UG-EDI-Amplify-Studio.pdf</a>\"</p><p><a href=\"https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db\">https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db</a>\"</p><p><a href=\"https://xie.infoq.cn/article/fb833598f8919e89fd1168264\">https://xie.infoq.cn/article/fb833598f8919e89fd1168264</a>\"</p><p>https://www.infoq.cn/article/aws-dynamodb-dive-in</p>",
    "publish_time": "2022-09-13 11:02:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "里程碑！PyTorch正式加入Linux基金会，社区治理这一核心将不会改变",
    "url": "https://www.infoq.cn/article/OYS7T01SgBBZvCqNT04E",
    "summary": "<p>当地时间9月12日，Linux基金会在其官网宣布，PyTorch已经正式加入Linux基金会。</p><p></p><h2>PyTorch正式加入Linux基金会</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf9c37347d63bf34453fc6de1bed5371.png\" /></p><p></p><p>&nbsp;</p><p>Linux基金会表示，其实很难用一篇文章来描述清楚PyTorch的加入对基金会的意义有多么重大，但还是希望尽可能将其表达出来。</p><p>&nbsp;</p><p>以下为基金会全文：</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/TblGFGRIjAKLu6JKYBqv\">PyTorch</a>\" 是当今世界上最重要和最成功的机器学习软件项目之一。我们很高兴与项目维护者、贡献者和社区合作，将PyTorch带入到一个中立的“家园”，在那里它可以继续强劲地增长并快速地创新。我们感谢Meta团队孵化出了PyTorch并让它成长为一个庞大的生态系统，更要感谢 Meta团队对于Linux 基金会的信任，正因为有了这样的信任才让PyTorch加入<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651130293&amp;idx=2&amp;sn=fd6dc3927e04a667860941633c52d7de&amp;chksm=bdb8f1e68acf78f00aafa670e4803a74f24c2a2e8f8eff59d50ed1948a0cb8e7922f57b3785f&amp;scene=27#wechat_redirect\">Linux</a>\"成为可能，才让这场史诗般的旅程得以呈现。</p><p>&nbsp;</p><p>人工智能、机器学习和深度学习对于当前和未来的技术创新至关重要。与人工智能、机器学习社区和它们生成的代码相关的一切都将飞速发展起来。<a href=\"https://archsummit.infoq.cn/2022/hangzhou/track/1272\">AI/ML</a>\"也是一个真正“开源优先”的生态系统。大多数流行的 AI 和 ML 工具和框架都是<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136062&amp;idx=4&amp;sn=14910cd2372b3c08e5b09a1225648b9e&amp;chksm=bdb8d86d8acf517bd272ece0155eca8e5714ff6e047a2dc194b4734099ea80c3d0186f28a629&amp;scene=27#wechat_redirect\">开源</a>\"的。社区十分重视透明度和开源精神。在开发让AI和ML落地的工具和解决方案时，开源社区正在并且未来也将发挥着主导作用，随着时间的推移，开源社区将使这些工具和解决方案变得更好</p><p>&nbsp;</p><p>&nbsp;基于上述所有原因，Linux 基金会明白，在人工智能和<a href=\"https://archsummit.infoq.cn/2022/hangzhou/track/1280\">机器学习</a>\"领域，开源是重中之重。Linux 基金会已经托管并与许多项目合作，这些项​​目要么直接为基础 AI/ML 项目（LF AI 和数据）做出贡献，要么为其用例做出贡献并与其平台集成。（例如，LF Networking、AGL、Delta Lake、RISC-V、CNCF、Hyperledger）。&nbsp;</p><p>&nbsp;</p><p>PyTorch正是扩展并建立在这些努力之上。显然，PyTorch 是用于开发、测试和部署 AI/ML 和深度学习应用程序的最重要的基础平台之一。如果你需要在 AI 中构建一些东西，如果你需要一个库或一个模块，那么 PyTorch 中很可能会为此提供一些东西。任何一款AI应用程序中，都可能有着PyTorch的身影。从提高疾病诊断和心脏病发作的准确性，到<a href=\"https://www.infoq.cn/article/UuQUfYXAdEuQt36MsD0e\">自动驾驶</a>\"汽车的机器学习框架，再到天文学家的图像质量评估工具，PyTorch 无处不在。</p><p></p><p>&nbsp;</p><p>PyTorch最初由Meta的AI团队孵化，在以社区为中心的管理之下，PyTorch现已发展成为一个由贡献者和用户组成的庞大社区。PyTorch 的精髓之处（以及它的维护者的功劳）在于，它的确是如今许多AI和ML项目的基础平台，它是一把真正的瑞士军刀。正如开发人员在 Linux 之上构建了我们今天所知的大量技术一样，许多AI/ML 社区也是在 <a href=\"https://www.infoq.cn/article/7Azz9NMpjuI4zmV4S4oC\">PyTorch </a>\"之上构建而成。PyTorch进一步支持了新兴技术和不断变化的用户需求。截至 2022 年 8 月，PyTorch 是世界上与 Linux 内核和 <a href=\"https://qcon.infoq.cn/2022/beijing/track/1291\">Kubernetes</a>\" 并列的五个增长最快的开源软件社区之一。从 2021 年 8 月到 2022 年 8 月，PyTorch 统计了超过 6.5万次提交.&nbsp;超过 2400 名贡献者以提交问题或PR或编写文档的方式参与了这项工作。这些数字使 PyTorch 成为历史上最成功的开源项目之一。&nbsp;</p><p>&nbsp;</p><p>像 PyTorch 这样有可能成为关键技术基础平台的项目，保持中立对它更有益处。中立性和真正的社区所有权使 Linux 和 Kubernetes 在变得更加成熟的同时继续加速和增长，从而超越预期。用户、维护者和社区开始将它们视为可以永久依赖和信任的公共资源的。通过创建一个中立的家园——PyTorch 基金会，我们共同为PyTorch打造了一个透明、社区治理和规模无可限量的未来。</p><p></p><h2>加入后，PyTorch不会有大的改变</h2><p></p><p></p><p>作为 Linux 基金会的一部分，PyTorch 及其社区将受益于我们的许多计划和支持社区，例如培训和认证计划（我们已经在进行中）、社区研究（例如我们的项目旅程报告），当然还有其他社区活动等。PyTorch 社区将在<a href=\"https://www.infoq.cn/article/8V7UcWWhXXeCg6xOsKvQ\"> Linux 基金会</a>\"内部和周围工作，PyTorch社区也有一个可以访问LFX 协作门户的入口，我们将为PyTorch社区提供指导并帮助 PyTorch 社区确定未来的领导者、寻找潜在的员工、并观察共享的社区动态。</p><p></p><p>PyTorch 通过良好的维护和开源社区管理达到了目前的状态。我们不会改变 PyTorch 的任何优点。事实上，我们迫不及待地想向 Meta 和 PyTorch 社区学习，以改善基金会其他项目的经验和成果。对于那些想要更深入地了解我们的 PyTorch 基金会计划的人，我邀请您加入 Soumith Chintala（PyTorch 的联合创始人）和 Ibrahim Haddad 博士（PyTorch 基金会的执行董事），在周四进行题为PyTorch 的现场讨论：开源 AI/ML 的基础。</p><p>&nbsp;</p><p>我们感谢 Meta 对“将火炬传递给我们”（双关语）的信任。与社区一起，我们可以构建（甚至更多）非常伟大的东西，并为支撑我们现在和未来生活的宝贵技术的全球遗产增添光彩。欢迎，PyTorch！我们等不及要开始了。</p><p></p><p>参考链接：</p><p></p><p>https://linuxfoundation.org/blog/welcoming-pytorch-to-the-linux-foundation/</p>",
    "publish_time": "2022-09-13 12:23:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "历时三年替换掉二十年老系统，这个团队选择“一次性到位” | 卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/SbPCPlTopJQsGAv1IPmB",
    "summary": "<p></p><p>作者 | Tina</p><p>采访嘉宾 | 沈勇毅、孔伟、苏彦春</p><p></p><p>作为传统 IT 铁三角的核心腹地，金融行业过去十年的“去 IOE”运动备受关注。这种在过去 30 年中被广泛使用的集中式架构逐渐难以适应金融业务的线上化、数字化、智能化需求，正在逐渐被替换。因为需要修改底层技术，涉及到很多代码的重写、技术架构的重组和迁移，去 IOE 基本上是一种“小步慢走”的过程，本身就是 5-10 年的工作。</p><p></p><p>金融行业的变革从银行开始，逐渐带动了保险行业。这几年保险行业的数字化转型走得特别快，一众头部保险公司都在自我改革以适应时代的改变。</p><p></p><p>金融企业的数字化转型，通常是规划长远、实施复杂的项目，需要有懂技术、有大型项目经验的人，做出既稳妥又大胆的决策，而一般的企业不可能无限制在技术上进行投入，那么在投入有限、人才缺乏、技术实力储备不足等刚性约束条件下，转型之路究竟该怎么走？绝大多数机构并没有清晰的答案。</p><p></p><p>作为一家中型金融机构，民生人寿保险也曾面临上述困难。2019 年的时候，民生开启了一场快节奏、深层次的数字化转型，将用了近二十年的架构，一举搬上了混合云架构上。原来需要 5-10 年时间的项目，也只花了 3 年就宣告完成。民生保险探索出来的这条数字化转型路径，或许也能给亟需变革的其他中小型企业带来一点启发。</p><p></p><p></p><h2>重构核心系统，一次性到位进行转型</h2><p></p><p></p><p>在 1955 年首届财富 500 强名单中，只有 12.2% 的公司在 2014 年仍然保持在该位置。虽然一些下滑是因为品牌重塑或并购，但其中大部分反映了许多曾经的大牌未能在现代社会中生存下来的事实。在技术不断进步的环境中，未以正确的方式接受变革并进行创新，这些衰亡的企业是带有警示意义的例子。</p><p></p><p>一般企业都是循序渐进的发展，但是新技术的革新，让企业的 IT 环境可能进行革命性的变化，没有壮士断腕的决心，可能真的无法适应业务的发展而被淘汰。</p><p></p><p>一边是当前企业都有变革的压力，另一边是金融企业里的特殊现状。</p><p></p><p>金融行业有自己的特性，使用的是一些成熟的技术或者在其它领域已经应用多年的技术。而现在，数字化转型普遍是将已有互联网的技术、流程、实践置于服务的构思和交付方式的核心。这也就是说，彻底、全面的转型意味着“不破不立”。</p><p></p><p>民生人寿保险面临的状况也是如此。在 2003 年成立的时候，受制于当时的技术环境，民生人寿保险采用了传统的 IOE 架构，以及单体应用。技术架构的层面发展到现在，已经变得陈旧，应用之间的耦合度也非常高，很难去适应现在快速业务的变化。</p><p></p><p>在过去二十年的时间里，民生保险在集中化的 Oracle 数据库中积累了大量数据，但各方面的指标口径没有进行统一，数据也缺少标准治理。</p><p></p><p>民生保险的转型目标是，用“民生保险”公众号和官网将 90% 常用的业务实现线上处理、用“掌上民生”实现保单销售全流程线上化，通过引入人工智能实现运营服务的自动化，打造了“业务中台”和“数据中台”双中台模式，以支撑公司转向以客户为中心的经营模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/478eddce5733ac398d782aec3aa3c088.png\" /></p><p></p><p>图源：<a href=\"https://m.gelonghui.com/p/525770\">https://m.gelonghui.com/p/525770</a>\"</p><p></p><p></p><h2>技术选型是项目中最大的风险点</h2><p></p><p></p><p></p><blockquote>寿险行业的数字化转型在此之前并没有成熟的案例。</blockquote><p></p><p></p><p>作为求稳的金融企业之一，民生保险没有在老系统上进行“修修补补”，而是进行彻底变革。民生新一代的 IT 建设分为两大部分，一部分是建设新一代的业务核心系统，另一部分是重建技术架构。</p><p></p><p>在基础架构选型的时候，民生保险探索过多种路径，包括超融合，自己搭建 Kubernetes 集群支撑应用，基于 MySQL、PostgreSQL、CDH 用开源搭建大数据平台，但考虑到使用的效果和维护的成本，最终还是放弃了完全使用开源的实现方式。</p><p></p><p>原来使用的 Oracle 产品有自己的特色，能同时适用于交易场景和分析场景，所以在这一块儿上并没有一个对等的可取代它的软件。</p><p></p><p>现在，互联网的实现思路是将交易型的数据库和分析型的数据库拆解开来，再加上大数据平台去做海量数据的建模或者计算能力的支撑。基于此，民生选择了分布式数据库<a href=\"https://www.infoq.cn/article/YoxwIvkHZ07vijEi6W9M\"> TDSQL</a>\"、TBase 等来<a href=\"https://www.infoq.cn/article/AB_DU5f7OxCWerOKp2Th\">替换掉 </a>\"Oracle。</p><p></p><p>同时考虑到新一代的业务架构是基于分布式 Kubernetes 集群，适应未来 5 到 10 年的发展变化，核心应用比较倡导微服务网格化和基于云的研发应用一体化的模式，所以底层基础架构一开始定位为公有云服务。</p><p></p><p>但在把主流国内云厂商看了一遍之后，从数据资产的私有化来考虑，发现公有云的方式不完全满足现在金融行业的需求，于是民生保险跟腾讯深度合作，为大部分的数据和核心应用建立了一个私有云，再用公有云承载对外流量，以及实现活动场景下的弹性扩展预留。</p><p></p><p>新一代业务系统和新一代云数据中心都是采用的最新的技术，跨度很大，选择新技术也意味着接受挑战。针对复杂的技术和业务场景面临很多未知的情况，前期在做第一轮试验性“掌上民生”App 产品时候，怎么运行，怎么快速解决技术上的问题，没有一个可以用来参考的标准，还需要充分融合整个应用架构和云平台 PaaS 的能力，来寻找一个最佳的均衡点，所以这个项目中最大的风险也是来自于初期。</p><p></p><p>整体的架构设计和探索“花了大概 5、6 个月的时间才能定下来”，民生保险数据服务部副总沈勇毅表示，这也是整个项目开头最难的一个点。</p><p></p><p>“采用新技术总会有一定的风险，作为吃螃蟹的人，总归是要慢慢摸索”，沈勇毅介绍说。但经过了半年的并行期以后后面就很顺了，因为已经很清晰地知道自己的技术路线怎么走，业务转型的时候要考虑哪些问题，就相对来说按部就班地去做，只是看时间到底拉的多长。</p><p></p><p>传统金融机构的技术架构升级有着复杂的步骤，比如先建立一个数据中心，再建立第二个数据中心，逐步考虑兼容，是一个 5 到 10 年长远的发展过程。民生保险的数字化转型从 2019 年启动，采用比较先进的混合云基础架构和云原生的业务架构，一步到位地实现了两地三中心、同城双活、灾备，到投产上线、存量迁移，总共只花费 3 年时间，创造了一个行业里少见的案例。</p><p></p><p></p><h2>技术投入要讲究一个“均衡点”</h2><p></p><p></p><p></p><blockquote>CXO 控制着整个项目的风险系数。</blockquote><p></p><p></p><p>在企业的<a href=\"https://www.infoq.cn/article/PV03IOu8CgoNldNzGG7Z\">转型过程</a>\"中，技术只是一个应用，任何改变，如果没有考量到“人”的因素，必然无法达到真正的转型。</p><p></p><p>人的因素可以分为两个部分。</p><p></p><p>一方面是面向“消费者”。数字化转型的根本起源是“业务诉求”。因为人口众多，所以各行业都大量增加了线上业务，进行深加工，所以底层的数字化转型它其实不是一个技术层面的推动，它是一个业务层面的推动，是出于业务的需要。</p><p></p><p>民生保险在转型是将视频、图章、监管、报送等等这些系统业务进行线上化，线上业务还需要有数据的二次加工和分析。在具体业务场景上，推动业务层面去使用“新技术”，改变业务模式、运营模式、服务体系，这些都是面向消费者的事情。</p><p></p><p>另一方面，“组织内部的人”更是转型的成败关键。</p><p></p><p>技术和产品的问题总能够去解决，引入新技术不是最难的事情，这可以通过引入比如腾讯这样的云服务商作为合适的合作伙伴，借助于各行各业的经验支撑技术的转型。而业务上的问题，主要靠组织和管理层面。“一把手”董事长的决心和战略决定了“转型”的基调，然后管理层才能从公司层面明确建设目标，制定规划，内部各部门的协调和合作，从顶层向下推动整个公司转型。</p><p></p><p>在数字化转型中，CTO 或 CIO 也起着比较决定性的作用。一方面，作为“总设计师”，他需要根据企业的实际情况来去选择一个最佳的路径。</p><p></p><p>数字化转型的路径不止一种，基础好一点的可能循序渐进，每年可能动一点点，但是它的代价可能是花费的时间会很长很长。之前的基础差一点的，在技术大的变革时代，可能采取相对大胆激进的策略，能够在比较短的时间内能实现弯道超车，达到既定的目标，但是可能执行起来的整体风险也会比较高。一步到位还是逐步迭代，这些需要 CTO 或者 CIO 来做决策和选型。</p><p></p><p>“CTO 控制整个项目的风险系数，在不同的阶段去调整不同的风险”，作为民生保险信息化服务部门负责人，沈勇毅的角色也相当于 CTO 或者 CIO。另一方面，CTO 还需要靠确定整个组织架构，构建符合数字化的新的人才和体系。“民生这个项目的周期跨度 3 年，这也是我们有史以来最长的一个项目。参与的人数也很多，就我们自己民生和各个厂商的参与人数基本上全部加起来高峰的时候有 400-500 号人。”</p><p></p><p>在多厂商的管理上，合作能力的配合上，实施能力的管理上，包括民生自己内部多部门的管理和协调上，其实都有一些挑战。另外是人员能力，涉及到很多新技术引入，虽然很多新技术在互联网行业已经成熟，但对民生这样的一个金融企业来说，这个技术却是全新的。对民生保险来说，项目的实施需要很多懂技术，又有很多有大型项目经验的人员去推动。而且项目实施之后，技术怎么去沉淀，怎么去传承，怎么去保证确保所有的技术迭代和稳定的运转，这都是需要想办法解决的问题。这也是大多数转型中的中小企业需要面对的问题：作为一个甲方企业，不能无限制的在技术上去投入。</p><p></p><p>沈勇毅表示技术人员的投入也要讲究一个“均衡点”，民生的办法是借助于腾讯这样的厂商来接一部分基础云平台的部署和持续运维问题，同时也要清楚双方边界。但在应用层面还是要做到自主可控，培养自己的技术队伍。民生已经有专门的技术架构的团队，也是为了适应整个云的变化，近几年重构了这个团队，从原有的 IOE 的模式直接进行了转型，更多地去实现管理的职能或职责，做好资源分配和运用。</p><p></p><p></p><h2>切割二十年的老系统</h2><p></p><p></p><p>民生保险混合云有着自己的模式，基于国产自主生态的私有云、公有云、信创云混合的新一代基础设施。</p><p></p><p>民生将内部区域划分为几个大功能区，公有云更多是服务一些外网的业务，比如官微、官网、掌上民生。在项目实施过程中，开箱即用的公有云还承担着一个比较大的作用，就是在紧急的时候充当测试环境，毕竟私有云的搭建还包括购买服务器和网络等。</p><p></p><p>办公和核心放在了私有云上，这也是比较传统一些的 IT 交付模式。私有云基于腾讯云专有云全栈解决方案 TCE （Tencent Cloud Enterprise）打造，包括 70% 节点基于通用 x86 架构的私有云和 30% 节点基于全国产芯片为基础的私有云。腾讯专有云和公有云由同源同构的一套代码实现而来。腾讯专有云在金融行业落地时，还在网络、硬件、服务、网络安全、防护上，针对金融用户的属性做了深度定制。</p><p></p><p>作为腾讯云金融的主打技术产品之一，TCE 最早的实践案例可以追溯至微众银行，逐步扩展到交通、工业制造、传媒、零售、政府、泛互联网等行业，打造了建设银行、深证通、中国银联、永辉零售云、央视频等多个行业标杆。据腾讯介绍，TCE 本身历经数十次版本迭代，增强的功能和特性超过 500 项，涉及代码数百万行，也有完整的交付管理流程和自动化工具，从需求调研包括高低阶方案的设计，到基础设施包括云平台的实施，以及数据跟业务的投产迁移。</p><p></p><p>民生保险于今年 5 月 1 号开始切割，当时处于疫情全封闭的状态，数百名项目参与人员居家隔离，实现远程 “云上线”。关键线上业务还挺多，需要去做一些协同和管理。“大家都是各自在家里，去做了一个这么大的切换。这还是挺厉害的”，沈勇毅感慨。</p><p></p><p>项目切换过程中，大家的工作有一个“完整的清单”，每一个任务由谁负责，大家都要清楚自己在做什么，明白自己执行到了哪一个步骤，都需要非常明确和细致。在各个组织结构上分得很清楚，由“总控”去整体把控，底下有各个执行组、指令组，各个平台的支撑组、支持组，还有各模块的用户验证组，以及腾讯也有一支支持队伍，大家不断地相互之间去协调和通信，经历一个月的多轮预演，最后正式切换。</p><p></p><p>难度和风险最大的有两个，第一个技术选型，在第一次引入新技术试错的时候，第二个是最后一次性切割的时候。</p><p></p><p>“按照我们现在整个策略，迁移过程当中绝对不大会有一次性迁掉的那种模式，但是就算分阶段，分步骤慢慢去切割，到最后也有一次整个的最后切割。就像 5 月份‘云切割’就是最终的一个版本，最终的一个全量的扫尾切割。失败的可能性最大的就是存量扫尾切割这一块。”</p><p></p><p>“因为所有的历史的问题，历史的债，肯定需要在那个点上做一个切割和梳理。我们也是一个快 20 年的一个公司，那么积累的历史问题不会少。其实在最后一次迁移过程中，我们还是遇到了一些不一定需要临时去解决的问题，这些问题我们会放到后面慢慢再梳理。”</p><p></p><p>减少风险的办法，就是“最后一次切割之前，一定要把风险看得清楚，把问题理得清楚，再去做这件事情。”</p><p></p><p>如今，“新一代”的业务系统已经稳定运行数月，各方面能力得到了明显提升，也曾在切割之后支撑了民生有史以来并发量最高的一个业务节点。另外，云平台成本提供同样的计算资源的情况下，要比原来至少节省一半以上的成本。且从安全性上来说，应对一些重保也是会比原来要好很多。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>数字化发展和数字化转型已成为全球多个国家的战略。</p><p></p><p>可以说企业进行数字化转型不是可选项，而是必答题。企业数字化转型的动力也是现实的：在疫情时代，数字化协同能让企业能够去高效地运转下去；线上化和新渠道上的用户运营是企业活下去的关键动力；新技术能够更加地降本增效，提升服务体验。</p><p></p><p>民生保险的弹性、稳定的云原生方案，也是保险企业转型的一个典型样本。对比国内外保险行业，沈勇毅认为，无论是全球还是亚洲的同类企业，虽然他们在业务逻辑设计和敏捷方法论上更为先进，但国内企业借助敏捷加上分布式交付，以及云厂商的成熟运转模式，在引入新技术的速度上比国外企业要快不少。</p><p></p><p>服务过几千家金融企业的腾讯专家也表示，不管在保险行业还是在金融行业，甚至在一些现在比较特殊的制造行业来看，中国在各个业务场景，各个行业的业务场景上面是足够丰富的，也是领先于其它国家的。在使用所谓的互联网技术或者使用所谓的数字化转型技术上，几乎所有的行业都不落后于国外，甚至快于国外。</p><p></p><p>最重要的是，互联网企业在创新和创造的过程之后，能将这些技术变成了一种成熟的基础架构技术，赋能给金融行业、制造行业等，让这些技术应用得比国外更快、更强。</p><p></p><p>采访嘉宾：</p><p></p><p>沈勇毅，民生保险数据服务部副总经理</p><p></p><p>孔伟，腾讯云专有云产品中心首席产品架构师</p><p></p><p>苏彦春，腾讯金融云交付总监</p><p></p><p></p><h4>内容推荐</h4><p></p><p></p><p>本文选自《<a href=\"https://www.infoq.cn/minibook/EQzDrPI1dT9G8V6alV1I\">中国卓越技术团队访谈录</a>\"》（2022 年第三季），本期精选了阿里达摩院数据库、得物、华润云、民生保险、众安保险、字节跳动 AppInfra 等技术团队在技术落地、团队建设方面的实践经验及心得体会。</p><p></p><p>《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。</p><p></p><p>访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang_wechat，请注明来意及公司名称。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9f/9f66c137b5399abf731a2f0a1e31936c\" /></p><p></p><p></p><p></p><p></p><p></p><p>​​​​​​</p><p></p>",
    "publish_time": "2022-09-13 12:24:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "构建下一代万亿级云原生消息架构：Apache Pulsar 在 vivo 的探索与实践",
    "url": "https://www.infoq.cn/article/ZyNHQsXPD0N7VwHcUbTT",
    "summary": "<p></p><p></p><p>本文整理自 vivo 互联网大数据工程师陈建波与全利民在 Apache Pulsar Meetup 上的演讲《Apache Pulsar 在 vivo 的探索与实践》，介绍 vivo 在集群管理与监控上应用 Pulsar 的实践。</p><p></p><p>vivo 移动互联网为全球 4 亿 + 智能手机用户提供互联网产品与服务。其中，vivo 分布式消息中间件团队主要为 vivo 所有内外销实时计算业务提供高吞吐、低延时的数据接入、消息队列等服务，覆盖应用商店、短视频、广告等业务。业务集群已达每天十万亿级的数据规模。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d3087576321f59954c60f2595c77ed87.png\" /></p><p></p><p>图 1. vivo 分布式消息中间件系统架构</p><p></p><p>上图为系统的整体架构，其中数据接入层包括数据接入、数据采集服务，支持 SDK 直连；消息中间件由 Kafka 和 <a href=\"https://www.infoq.cn/article/z8NxTrFR8R1G11lkchyM\">Pulsar </a>\"共同承担，其中 Pulsar 的承载量达到千亿级别；数据处理部分使用 Flink、Spark 等组件。</p><p></p><p>目前，Kafka 采用多集群方式，根据不同的业务量级、重要性分别使用不同的集群提供服务，比如计费集群、搜索集群、日志集群。在 <a href=\"https://www.infoq.cn/article/ic2tSdHdZ8KKf4u9SsYp\">Kafka 集群</a>\"的内部，则采用物理隔离的方式，根据不同业务的重要性，将不同业务的 Topic 控制在不同的资源组内，避免业务之间相互影响。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/759c6e8ec108a2e30589ea63875b48fe.png\" /></p><p></p><p>图 2. Kafka 集群资源隔离</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/24/2461f1fee86083a7567332e36d8f111e.png\" /></p><p></p><p>图 3. Kafka 集群流量均衡</p><p></p><p>资源组内部则会针对 Topic 流量、分区分布、磁盘容量、机器机架等指标生成迁移计划进行流量均衡，以此增强 Kafka 可靠性。目前 Kafka 已在多集群部署、资源隔离、流量均衡三个方面保障了基本的稳定性和资源利用率，但是在此之外，系统仍存在一些问题。</p><p></p><p></p><h2>应对业务流量数十倍增长，引入 Apache Pulsar</h2><p></p><p></p><p>过去几年来，Kafka 集群承载的业务量迅速增长，流量上涨数十倍，带来诸多问题：</p><p></p><p>Topic 及 Topic 分区总量不断增加，集群性能受到影响：Kafka 高性能依赖于磁盘的顺序读写，磁盘上大量分区导致随机读写加重；业务流量增加迅速，存量集群变大，需要将老的业务进行资源组隔离迁移或者集群拆分。无论是资源组隔离还是集群的隔离的方式，由于集群不可以进行动态扩缩容，机器不能够进行灵活调配，都存在利用率不高、运维成本增加的问题；机器扩容慢，需要做长时间流量均衡，难以应对突发流量。集群规模越大，问题越突出；消费端性能扩展太依赖分区扩容，导致集群元数据疯狂增长；集群数量对应的机器基数大，硬件故障概率高，出现硬件故障时影响会直接传导到客户端，缺少中间层容错。</p><p></p><p>面对庞大的集群、流量和多样化的业务场景，综合考虑集群的稳定性和维护成本等因素，vivo 需要一个功能更丰富、适用更多场景、扩展能力更强的消息组件。</p><p></p><p><a href=\"https://www.infoq.cn/article/4P6SN4xzYtLtPgIRmzkU\">Pulsar </a>\"如何解决 vivo 存在的问题，可以首先看一下 Pulsar 的架构设计。Pulsar 采用计算存储层分离架构。计算层的 Broker 节点是对等且无状态的，可以快速扩展；存储层使用 BookKeeper 作为节点，同样节点对等。这种分离架构支持计算和存储层各自独立扩展。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70b6f70c3c605bf365b0a5c5a8d62875.png\" /></p><p></p><p>图 4. Pulsar 存储计算分离</p><p></p><p>其次，Pulsar 的各个节点都是轻量化的，在出现故障和宕机时可以快速恢复。一般情况下可以通过快速上下线来解决某个节点机器的问题。同时 Broker 层可以作为 BookKeeper 层的容错层，可以防止故障直接传导至用户端。</p><p></p><p>Pulsar 扩容时无需长时间的数据迁移，且支持实时均衡。Broker 层抽象了 Bundle 概念，可以用有限的 Bundle 映射海量 Topic，Topic 可以随着 Bundle 迁移，通过动态迁移 Bundle 可以更好地应对流量突发场景。BookKeeper 分层分片的架构让数据分布均匀，在 Broker 层有一个选择机制，在扩容时可以将数据写入存储量小的节点，扩容时无需数据迁移，提供更好的流量高峰应对能力。Bookie 进行数据刷盘时会对批量数据自动进行数据排序，可以避免 Kafka 中的随机读写。</p><p></p><p>Pulsar 提供了四种消息模型：Exclusive、Failover、Shared 和 Key_Shared，其中 Shared 模型允许一个分区同时被多个消费实例订阅消费，并采用 Round Robin（轮询）方式将数据推送到各个消费实例。因此消费能力的扩展不会过于依赖分区扩容，慢消费的消费实例也可以在 Shared 模型中得到解决。Key_Shared 模型则是在 Shared 的基础上对应对顺序性有要求的场景，可以按照 Key 来消费。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/57cf72d884af0003c70c41178eda1c4c.png\" /></p><p></p><p>图 5. Pulsar 订阅模型</p><p></p><p>Pulsar 的设计架构带来了海量分区支撑、消费扩展、精准限流、流量均衡、快速扩缩容、故障恢复、分层存储、云原生容器部署、异地多活等特性和优势，可以帮助集群更好地实现高可用、高扩展，提高了更高的弹性。</p><p></p><p></p><h2> Apache Pulsar 集群管理实践</h2><p></p><p></p><p>下面我们从流量控制和数据管理方面，分享 vivo 在使用 Pulsar 过程中的集群管理经验。</p><p></p><p></p><h3>Bundle 的管理</h3><p></p><p></p><p>在集群流量控制层面，比较关键的一点就是 Bundle 的管理。Bundle 负责控制用户流量到 Broker 的具体分布。Broker 与 Topic 之间没有直接联系，而是在 Broker 之上抽象出 Bundle 概念，通过 Bundle 与 Topic 建立关系；Topic 通过名称计算哈希值，并散列分布到一致性哈希环中，而哈希环的每一段都是一个 Bundle。另外 Load Manager 根据 Bundle 的负载情况将后者分配到对应的 Broker 上，将 Bundle 数据存储在 ZooKeeper 中。由此以来就间接实现了 Topic 与 Broker 之间的联系（可参考近期 StreamNative 发布的 <a href=\"https://mp.weixin.qq.com/s?__biz=MzUyMjkzMjA1Ng==&amp;mid=2247491872&amp;idx=1&amp;sn=538df7ad042d43bc40d96cf78f1e8525&amp;scene=21#wechat_redirect\">Broker 负载均衡技术文章</a>\"）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/29/29e6ca52b06e353dbefa4b7ca0c2fe73.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/21/21bb5c7ecf417384f0b9392de6554291.png\" /></p><p></p><p>图 6. Bundle 与 Topic 建立关系</p><p></p><p>这里需要注意：</p><p></p><p>Bundle 的个数影响均衡效果，因为通过一致性哈希来确认 Topic 应该落在哪个 Bundle 上， Topic 与 Bundle 会存在不均衡分配，某些 Bundle 分配的 Topic 可能较多或较少。Bundle 越多，每个 Bundle 承载的 Topic 越少，粒度越细。依赖于 Pulsar 的负载均衡算法，均衡效果更好；否则若 Bundle 太大，无论如何卸载都很难平衡负载；Bundle 数据和 Broker 映射元数据都维护在 ZooKeeper 中，需要做好 Bundle 数量的规划。</p><p></p><p>针对以上两点，我们根据 Broker 来设置 Bundle 数量设置最小最大值来控制，还可以对流量较大的 Topic 针对性扩大分区，让分区均匀分配到 Broker Bundle 上。</p><p></p><p>Pulsar 虽然提供了海量分区能力，但是过多的 Topic 或者分区产生的 lookup 也会对集群产生较大的压力。集群管理者需要提前规划 Bundle 和分区设置，杜绝滥用。</p><p></p><p>另外对 Bundle 的操作需要注意：</p><p></p><p>Pulsar 本身提供了卸载操作，可以解除 Bundle 和 Broker 的关联关系，将 Bundle 重新分配。线上流量较大时应卸载 Bundle 而不是整个命名空间，因为卸载后者会导致其上的全部 Bundle 与对应的生产者、消费者断开，重新进行 lookup。利用 Bundle split 对流量较大的 Bundle 进行拆分，增加命名空间的 Bundle 数量，降低影响。</p><p></p><p>总体而言，用户需要注意流量的均衡与集群的稳定性，在集群管理之初就做好 Bundle 的数量管理和相关测试，谨慎对待大批量 Bundle 卸载等运维操作。</p><p></p><p></p><h3>数据的管理</h3><p></p><p></p><p>接下来我们从数据的存储、过期、删除三个方面来分析。</p><p></p><p></p><h4>Ledger 翻转</h4><p></p><p></p><p>首先介绍数据写入 ledger 的过程。每一个 Topic 分区在一段时间内只创建一个 Ledger 维护分区写入的 Entry 的数据归属。Topic 分区写入的数据以 Entry 的形式，经过 Broker 写入 Netty 线程处理队列，线程依次根据 Entry 的 Ledger Id，对 Ledger 目录数取模，写入到目标磁盘 Ledger 目录，最终以 Entry Log 和 RocksDB 的索引方式存储。需要注意，Ledger 是一个分区在一段时间内写入数据的逻辑管理单位，维护了这段数据存储的 Bookie 位置。一个 Topic 分区在一段时间内写入的数据只被一个活跃 Ledger 管理，待该 Ledger 达到翻转条件后才会关闭 Ledger 并重新计算，创建新 Ledger 继续写入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/22/2274eda6614ca7efe6fab8a4a0c2e86b.png\" /></p><p></p><p>图 7. Ledger 翻转示意</p><p></p><p>Ledger 翻转后，数据才会写入新的数据目录。在 Pulsar 中，在满足 Ledger 最小翻转时间以及以下条件之一后触发 Ledger 翻转：</p><p></p><p>已达到 Ledger 最大翻转时间；已达到 Ledger 的最大 Entry 数量；已达到 Ledger 的最大大小。</p><p></p><p>默认值：</p><p></p><p><code lang=\"makefile\">触发ledger翻转的最小时间：\nmanagedLedgerMinLedgerRolloverTimeMinutes=10\n\n触发ledger翻转的最长时间：\nmanagedLedgerMaxLedgerRolloverTimeMinutes=240\n\n触发ledger翻转的最大entry数：\nmanagedLedgerMaxEntriesPerLedger=50000\n\n触发ledger翻转的最大大小：\nmanagedLedgerMaxSizePerLedgerMbytes=2048\n</code></p><p></p><p>注意两个问题：</p><p></p><p>Ledger 过大：最小翻转时间是防止 Ledger 元数据过快增长的手段，但实践发现如果 Topic 分区流量较大，Ledger 的实际值可能远超上述设置的上限阈值。Ledger 只有在翻转后才会创建新的 Ledger，Ledger 过大会导致某段时间内写入某个磁盘的数据过多，产生磁盘存储不均衡的问题；针对 Ledger 为对象的一些操作也会受到影响，产生无法及时卸载数据到二级存储、数据卸载时间较长、还未卸载成功但 Ledger 已经过期等问题。Ledger 间不均衡：Ledger ID 以集群维度进行递增。在分区的维度，按照 Ledger ID 对 Ledger 存储目录数进行取模的方式无法对多磁盘进行均衡写入。但保持 Ledger 间的大小一致，在一定程度上会对多磁盘目录的写入均衡有比较大的改善。</p><p></p><p>总而言之，建议根据业务消息情况适当调整 Ledger 翻转参数和有针对性地增加大流量 Topic 分区数量，可以防止 Ledger 过大、大小不均衡的问题。</p><p></p><p></p><h4>数据过期</h4><p></p><p></p><p>数据过期主要分为四个阶段：</p><p></p><p>第一阶段：未被 Ack 的消息</p><p></p><p>Backlog 消息：该段数据不会被删除</p><p></p><p>第二阶段：已经 Ack 的消息</p><p></p><p>订阅主动 Ack 后，标记为非 backlog 消息，有多个订阅时以最慢的为准TTL：若某 Topic 没有活跃订阅，超过 TTL 存活时间的消息会被主动 Ack ，本质上是移动 cursor</p><p></p><p>第三阶段：消息保留时间检查</p><p></p><p>Retention：对已经 Ack 的消息的保留策略，按保留周期和保留大小设置来保留消息</p><p></p><p>第四阶段：消息删除</p><p></p><p>Deleted：超过 Retenion 范围的消息则被删除。超过 rentention 保留周期和保留大小的消息，系统会从当前已经 ack 消息的最新位置往前检查并获取已经过期的 ledger，将其标记删除。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/28/285e39c562f454cc709134f140e4f717.png\" /></p><p></p><p>图 8. 消息保留时间检查与消息删除</p><p></p><p>从上述的消息阶段演化来看，Pulsar 提供了较大的消息管理空间，但也略显复杂。建议集群维护者建立简单统一的规则处理数据保留策略，如可以设置 TTL = Retention 保留周期值。</p><p></p><p></p><h4>数据删除</h4><p></p><p></p><p>此处介绍数据的物理删除。Bookie 在处理数据写入过程时，会将同一段时间内的数据经过排序 flush 到同一个 Entry Log 文件中，将索引存放在 RocksDB 中。由于多个 Ledger 的数据可能会同时写入同一个 Entry Log，因此 Entry Log 便不能被简单直接的删除。对此 BookKeeper 会启动一个 GC（GarbageCollector） &nbsp;线程进行检查和物理删除操作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3ea6fc2305325524f5a512f32d60c06f.png\" /></p><p></p><p>图 9. 数据物理删除流程</p><p></p><p>Entry Log 维护元数据信息（ EntryLogMetadata），该元数据记录了 Ledger 列表、大小与剩余有效数据比例。</p><p></p><p>GC 清理线程在每个 gcWaitTime 时间间隔：</p><p></p><p>扫描 Entry Log 的元数据信息，对于已经没有有效数据的 entry log 直接进行删除。判断是否满足 compaction 条件，满足 compaction 条件后 GC 线程会读取每一个 Entry 判断其是否过期，一旦过期就会丢弃，否则会将数据写入新的 Entry Log。</p><p></p><p>Compaction 分为 minorCompaction 和 majorCompaction，二者区别在于阈值。默认情况下，minorCompaction 清理间隔 1 小时，阈值 0.2；majorCompaction 清理间隔 24 小时，阈值 0.8。阈值是 Entry Log File 中的剩余有效数据占比。</p><p></p><p><code lang=\"ini\">minorCompactionInterval=3600\nminorCompactionThreshold=0.2\nmajorCompactionThreshold=0.8\nmajorCompactionInterval=86400\n</code></p><p></p><p>在实际使用中，如果机器节点的磁盘较小且数据迟迟得不到删除，为了及时清除数据，应该按照业务流量和磁盘空间适当调整数据清理间隔时间、有效数据阈值，并配合 compaction 限速策略减小对集群的影响。</p><p></p><p></p><h2>Pulsar 监控实践</h2><p></p><p></p><p>vivo 的 Pulsar 指标监控链路架构如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bc/bc275ffbb77c4885169f5db2e1149733.png\" /></p><p></p><p>图 10. vivo 针对 Pulsar 监控指标搭建的监控架构</p><p></p><p>该架构中：</p><p></p><p>采用 Prometheus 采集 Pulsar 指标；应用 Prometheus 远程存储特性将格式化后的指标发送到 Kafka；Druid 消费 Kafka 数据后可以作为 Grafana 的数据源，配置 Grafana 面板查询指标。</p><p></p><p>为什么不使用 Prometheus 存储数据？因为有些数据较久远，一旦集群规模增加，监控指标数量级会很大。Prometheus 对资源依赖重，我们只采用了它的采集能力。</p><p></p><p>下图是常用的关键指标：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9ddadd1e715c4081c35548a7589057c8.png\" /></p><p></p><p>图 11. 关键监控指标</p><p></p><p>指标类型分为：</p><p></p><p>客户端指标：用来排查客户端出现的异常Broker 端指标：监控 topic 流量、调整 broker 间流量差距Bookie 端指标：排查读写延迟等问题</p><p></p><p>除了官方指标外，团队还开发了 Bundle 相关的一些指标：</p><p></p><p>分区数、流量等在 Bundle 的分布Broker 端记录读写延迟的 P95/P99 值基于请求对列实现 Broker 端网络负载指标等。</p><p></p><p></p><h2>问题优化与最佳实践</h2><p></p><p></p><p></p><h3>负载均衡参数</h3><p></p><p></p><p>负载均衡的目的是对资源平均分配，差异大会影响稳定性。对负载均衡设置的目标是节点流量偏差 20% 以内，每天均衡频次在 10 次以内，否则客户端会频繁断连、重连。优化后的参数如下：</p><p></p><p><code lang=\"ini\"># load shedding strategy, support OverloadShedder and ThresholdShedder, default is OverloadShedder\nloadBalancerLoadSheddingStrategy=org.apache.pulsar.Broker.loadbalance.impl.ThresholdShedder\n\n# enable/disable namespace Bundle auto split\nloadBalancerAutoBundleSplitEnabled=false\n\n# enable/disable automatic unloading of split Bundles\nloadBalancerAutoUnloadSplitBundlesEnabled=false\n\n#计算新资源使用量时的CPU使用权重（默认1.0）\nloadBalancerCPUResourceWeight=0.0\n\n#计算新的资源使用量时的堆内存使用权重（默认1.0）\nloadBalancerMemoryResourceWeight=0.0\n\n#计算新资源使用量时的直接内存使用权重（默认1.0）\nloadBalancerDirectMemoryResourceWeight=0.0 \n</code></p><p></p><p>下面三个参数改为零，是因为集群使用了相同的机型，团队更关注流量均衡，对内存和 CPU 不是特别关注。</p><p></p><p>以一个具体产品案例来看，其中有 1 个 Topic、30 个分区、180 个 Bundle：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fc/fc9415c2ec82d39a814348c5f2bdef43.png\" /></p><p></p><p>图 12. 1 个 Topic、30 个分区、180 个 Bundle 的每秒入流量</p><p></p><p>上图节点间流量差异较大，由 Bundle unload 导致。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a03efd91943b17f40f6faf0faf8739f.png\" /></p><p></p><p>图 13. 1 个 Topic、30 个分区、180 个 Bundle 下，Bundle 上 Topic 分区情况</p><p></p><p>上图可看出，有两个 Bundle 分配了四个分区，远超其他 Bundle。实践中出现以下问题：</p><p></p><p>均衡频次高，一天大概有 200 多次客户端连接频繁切换，流量波动大每个 Bundle 的分区数量分布差异大</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05bf257db4bba88ad52cf551a7574fef.png\" /></p><p></p><p>图 14. 1 个 Topic、30 个分区、180 个 Bundle 的入流量分布</p><p></p><p>优化过程中，关键在于将分区打散到不同 Bundle 上，但分区数量太少很难做到。Topic 通过哈希算法分配到 Bundle 上在前文已经介绍。此案例中，问题在于分区数量少。</p><p></p><p>于是团队将分区增加到 120 个，效果如下：</p><p></p><p>节点间流量差异小均衡频次降低，一天大概有 10 次左右客户端连接切换减少，流量波动较小每个 bundle 的分区数量分布差异降低</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c6c1576b0e5105e55d590be70a7e29b.png\" /></p><p></p><p>图 15. 1 个 Topic、120 个分区、180 个 Bundle 的每秒入流量</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d5/d5233a9938024724759ceb0e27c189ea.png\" /></p><p></p><p>图 16. 1 个 Topic、120 个分区、180 个 Bundle 下，Bundle 上 Topic 分区情况</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d9/d99bbc9a265d56b0f56bf3e3f7fd6016.png\" /></p><p></p><p>图 17. 1 个 Topic、120 个分区、180 个 Bundle 的入流量分布</p><p></p><p></p><h3>客户端发送性能</h3><p></p><p></p><p>在和上述业务相同的场景中，分区数量增加后，系统滚动重启后出现了流量下降情况：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7f9647dc2159850d38faeab5736dc011.png\" /></p><p></p><p>图 18. 单个 Topic，30 个分区增加到 120 个，系统滚动重启后流量下降</p><p></p><p>客户端配置参数：</p><p></p><p>memoryLimitBytes=209715200 （默认为 0）maxPendingMessages=2000 &nbsp;（默认 1000）maxPendingMessagesAcrossPartitions=40000 （默认 50000）batchingMaxPublishDelayMicros=50 （默认 1 毫秒）batchingMaxMessages=2000 （默认 1000）batchingMaxBytes=5242880 （默认 128KB）</p><p></p><p>满足三个 batch 数据中的任何一个的情况下就会触发打包、发送。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1f/1fd734fd04ed74b505135c15ee90fa19.png\" /></p><p></p><p>图 19. 重启后 maxPendingMessages（队列长度）出现下降</p><p></p><p>这里 maxPendingMessages（队列长度）=min(maxPendingMessages, maxPendingMessagesAcrossPartitions/partitionNum) 。而分区数添加（30 -&gt; 120）后，需要重启客户端才对队列长度生效。重启后 maxPendingMessages 队列长度 从 40000/30 = 1333 变为 40000/120 = 333，出现了明显下降。</p><p></p><p>另外，测试发现 batchingMaxMessages 调小后性能提升 10 倍之多：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72dee8d12cab8a6b3a9a4ef8899625ed.png\" /></p><p></p><p>图 20. 单个 Topic，30 个分区增加到 120 个，调整后性能提升</p><p></p><p>建议 batchingMaxPublishDelayMicros 不要过大，确保 batchingMaxMessages 比 maxPendingMessages 要大，否则等待 batchingMaxPublishDelayMicros 才会发送。</p><p></p><p></p><h3>宕机导致集群流量骤降</h3><p></p><p></p><p>某个分区队列满后会导致发送线程阻塞，影响所有分区的整体发送和集群稳定性：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/837567d0c85296b625630ee29fe86fd9.png\" /></p><p></p><p>图 21. 执行 Kill-9 一台 Broker 后，其他 Broker 流量下降</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/ea46c0e3279861e2b677f0b3acb3f54a.png\" /></p><p></p><p>图 22. 第四个分区已满，发送线程阻塞在 canEnqueRequest 上，等待时间长，其他未满分区的发送也被影响。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7bb1e6a8cfb60c32f9af6f5cef782acf.png\" /></p><p></p><p>图 23. 极端情况下，第四个分区已满，其他分区等待中。发送线程会在第四个分区阻塞等待，其他线程无法发送。</p><p></p><p>针对这一问题的优化思路，首先是能者多劳，让发送快的分区尽可能多发送；然后是将阻塞点从 ProducerImpl 移到 PartitionedProducerImpl；如果分区 ProducerImpl 出现队列已满阻塞较长时间，就将该分区排除。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/0070e2c99aa9d2b5ea7dbc3f7d3097b3.png\" /></p><p></p><p>图 24. 宕机导致集群流量骤降优化思路</p><p></p><p>实践中可分为可用 Producer 和不可用 Producer 两个列表。在 ① 中，两个列表都处于初始化状态并可用；在 ② 中，某个可用分区阻塞一段时间后可以等待一段时间；若不可用就移动到不可用列表中，如 ③ 所示；当分区可用比例达到阈值再挪回可用列表，如 ④ 所示。</p><p></p><p>经过优化后，宕机 Broker 流量可以快速转移到其他 Broker：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/3428dbd6dc684f80b4dede68cbbe3905.png\" /></p><p></p><p>图 25. 优化后 Broker 流量分流并上涨</p><p></p><p>注：优化只支持 RoundRobinPartitionMessageRouterImpl 路由策略。</p><p></p><p>在单个 ProducerImpl 对应的 Broker 出现处理慢、网络慢等导致发送响应慢的情况，都可能会导致发送线程阻塞，业务发送消息的速度受限于最慢的 ProducerImpl 的速度。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>本文分享了 vivo 在 Pulsar 集群管理与监控的经验，并介绍 vivo 在负载均衡等方面的最佳实践。</p><p></p><p>由于服务端的问题很难通过监控指标进行分析，vivo 在未来计划实现生产端到消费端的全链路监控能力。大数据团队希望整合大数据组件，支撑 Flink、Spark、Druid 等核心下游组件打通落地。</p><p></p><p>同时，vivo 内部目前 Pulsar 与 Kafka 同时运行，团队将尝试基于 KoP 对存量 Kafka 万亿流量尝试迁移，降低 Kafka 迁移成本；并探索容器化落地，充分发挥 Pulsar 云原生优势。</p><p></p><p>作者简介：</p><p></p><p>全利民，vivo 大数据工程师，负责 vivo 分布式消息中间件建设陈建波，vivo 大数据工程师，曾任微服务应用架构师，负责 vivo 分布式消息中间件的建设</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140025&amp;idx=1&amp;sn=ca1cf244eb8a12c3561fad45e4300066&amp;scene=21#wechat_redirect\">奇葩事儿：删除用户云数据还无法恢复，只赔 3 万；微信键盘来了，体积 524MB；谷歌希望将效率提高 20%：暗示将裁员？｜ Q资讯</a>\"​</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139876&amp;idx=1&amp;sn=b5479b58f06e714877092811902bf015&amp;chksm=bdb8d7778acf5e617885b343a0fa9932b961ec5ad16a2bca0b3db0770c4ab67d247b26a22dee&amp;scene=21#wechat_redirect\">“不搞职级、人人平等” 25 年后行不通了？Netflix 破天荒引入细分职级：气走老员工</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139040&amp;idx=1&amp;sn=1eee3c77db28fd14ef9a18d201dd80ce&amp;chksm=bdb8d3b38acf5aa5c63957fc7975fc1118319ae52a1697b388d358b88752daef0cae83953661&amp;scene=21#wechat_redirect\">缺少软件开发文化，大众汽车陷入困境，CEO 也被赶下了台</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138876&amp;idx=1&amp;sn=6b41efee0d73ab9537025f0f2e547fc7&amp;chksm=bdb8d36f8acf5a79fac65237c89d8e72058bef5a792dfa15c238ed7f64e940cc4587f6984a2b&amp;scene=21#wechat_redirect\">我庆幸果断放弃了 SwiftUI：它还不够成熟</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2022-09-13 13:26:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度百舸2.0升级发布：产业智能化升级需要怎样的基础设施？",
    "url": "https://www.infoq.cn/article/1XLRGUVLIylAkRG8Sf8Y",
    "summary": "<p>当今企业面临数字化转型和智能化升级的挑战，作为承载了庞大算力的云基础设施，成为企业打破这种挑战的重要支撑。</p><p></p><p>过去所说的算力，一般都是以 CPU 为主的传统算力。经过数十年发展，已经形成了庞大的市场规模。</p><p>随着<a href=\"https://www.infoq.cn/article/zjNolqefbu6PgizTmZhm\">产业智能化升级</a>\"的深化，大家再提算力的时候，注意力就会更多的放到以 GPU 等为主的智能算力上来。</p><p></p><p>在过去几年，智能算力高速增长，已经快占据到算力总量的一半，和传统算力平分秋色。</p><p></p><p>这给产业智能化提供了充足的算力支持。比如自动驾驶、生物医药、行业大模型、智算中心等行业和领域，走在了智能化升级的前沿。这些行业的快速发展，也将反过来拉动了智能算力规模的高速增长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f73b132822f3a04d6ae18b1486a80bb.png\" /></p><p></p><p>算力和产业的相互影响，促进了双方都在快速发展，不断变化。这也说明需要构建新型智能计算基础设施，支持产业智能化的深化。</p><p></p><p>那智能算力的未来应该是什么样子，才能更好地满足产业智能化升级的需求呢？</p><p></p><p>百度智能云认为，随着 AI 应用场景更加丰富、超大模型不断的出现、云上 AI 任务的管理复杂性越来越高，芯片多元化、算力规模化、以及云原生化，将成为未来智能算力发展的重点方向。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99222a5355d401029be5b23b6394ef7f.png\" /></p><p></p><p>为了建设 AI 原生的云计算基础设施，我们去年推出了百度百舸·AI 异构计算平台。基于产业智能化和智能算力发展大趋势，我们今年升级发布了 2.0 版本。</p><p></p><p>百度百舸 2.0 在 AI 计算、AI 存储、AI 容器等模块上，能力进行了增强，功能进行了丰富，同时全新发布 AI 加速套件。</p><p></p><p>AI 加速套件，通过存训推一体化的方式，对数据的读取和查询、训练、推理进行加速，进一步提升 AI 作业速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c3e3c13762d278de0a8c169a8566b1d.png\" /></p><p></p><p>首先我们来看 AI 相关的计算和网络部分。</p><p></p><p>为了提升集群通信效率，我们全新发布了弹性 RDMA 网卡。相比传统专用的 RDMA 网络，弹性 RDMA 网络和 VPC 网络进行了融合，使得用户的使用成本更低。相比传统的 TCP 网络，弹性 RDMA 的通信延时降低了 2-3 倍。同时，弹性 RDMA 还支持 GPU Direct RDMA，进一步提升 AI 集群训练速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82af5c0d542e0658c6243ebebf96e67e.png\" /></p><p></p><p>百度持续投入 AI 的全栈能力建设，昆仑芯是其中重要的部分。</p><p></p><p>今天，我昆仑芯二代的云服务器也发布上市，为用户提供多元化的智能算力。昆仑芯二代采用了 XPU-R 架构，支持硬件级别的虚拟化，同时为用户快速地使用昆仑芯二代，我们提供了专属镜像。</p><p>针对典型 AI 负载，第二代昆仑芯的性能，相比一代提升了 2-3 倍，平均加速比是业界主流 GPU 的 1.5 倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf0397ecfdc7512121f2610cfe0aa404.png\" /></p><p></p><p>在 AI 存储部分，百度百舸 2.0 进行了全面升级，提升性能的同时降低使用成本。</p><p></p><p>我们全新发布了并行文件存储 PFS 的裸金属版本，支持 IB 网络，可将计算对数据的访问延迟降低至百 us 级别。</p><p></p><p>同时，对象存储 BOS 新增了原生层级 namespace，可以将元数据访问速度提升 4 倍以上。</p><p></p><p>在存储性能大幅度提升的同时，我们通过 Bucketlink 将 PFS 和 BOS 打通。这不仅提升了数据湖的访问性能，同时降低数据存储成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/256ec6a6be56f3d14ef424ab6d612104.png\" /></p><p></p><p>在 AI 加速部分，我们推出的存训推一体化加速方案，全面加速了数据湖存储访问、分布式训练和推理效率。</p><p></p><p>数据湖存储加速 RapidFS，这是一个分布式缓存系统，可以加速数据集访问，训练效率提升 5~10 倍。</p><p>分布式训练加速，能有效提升分布式训练的性能，在典型模型场景下吞吐提升 50%~150%。</p><p></p><p>在模型完成训练进行部署后，通过推理加速，提升 AI 应用的响应速度。在典型模型场景下时延降低 40%~60%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/7128aa6f977fddb139f836fee4e13af5.png\" /></p><p></p><p>在 AI 容器部分，百度百舸 2.0 在业界率先推出了双引擎 GPU 容器虚拟化方案，可以满足各类场景的要求，提升 GPU 资源利用率。</p><p></p><p>这个双引擎 GPU 容器虚拟化方案，包括内核态和用户态两种虚拟化方案。</p><p></p><p>内核态虚拟方案是我们今年全新发布的，能够为业务提供强隔离环境。</p><p></p><p>用户态虚拟方案，是百度内部大规模使用了多年的方案，支撑了各类 AI 业务的落地。今年我们对他进行了增强，进一步提升资源利用率。</p><p></p><p>更详细内容可以参考<a href=\"http://mp.weixin.qq.com/s?__biz=MzkxOTM4MTM3Ng==&amp;mid=2247484679&amp;idx=1&amp;sn=066458ed00d2ec842af15a4f0e7ea558&amp;chksm=c1a3b1e8f6d438fe9b58b302db494f98d8f280875d606e8756dff38fe5a5ce2c7cb3ce8adcb6&amp;scene=21#wechat_redirect\">《双引擎 GPU 容器虚拟化，用户态和内核态的技术解析和实践分享》。</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4b67f1732596008a030ade50ffb5b32.png\" /></p><p></p><p>在完成各个模块的升级后，百度百舸 2.0 的优异性能，在测试结果中得到了充分展现。</p><p></p><p>在今年 6 月 30 日发布的 MLPerf Trainning v2.0 的榜单中，百度百舸和百度飞桨联合提交的 BERT Large 模型 GPU 训练性能结果，在同等 GPU 配置下排名第一，超越了高度定制优化且长期处于榜单领先位置的 NGC PyTorch 框架。</p><p></p><p>从图中可以看到，百度百舸和百度飞桨的组合方案比其他结果快 5%-11% 不等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6047b02e67bd562c04280755240613a.png\" /></p><p></p><p>百度百舸在行业智能化升级的深化过程中发挥了重大作用。</p><p></p><p>百度百舸支持了文心大模型的落地。这是全球最大中文单体模型，2600 亿参数规模。</p><p></p><p>百度百舸提供了千卡规模、单集群 EFLOPS 级别的算力，配备了 1.6Tbps 的高速网络，提供百万 IOPS 的并行文件存储系统。</p><p></p><p>通过 AI 容器提供的容错、架构感知等手段，为文心大模型的训练提供了稳定的运行环境，满足长时间周期的业务需要。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/634740914ab805e2945f9cb718ddfb43.png\" /></p><p></p><p>在自动驾驶领域，百度百舸为用户提供了软硬一体的智能基础设施。</p><p></p><p>在高性能的智能基础设施基础上，百度智能云针对自动驾驶算法、通过显存卸载、算子融合、梯度融合等手段，可以将 Transformer 算法训练吞吐提升了 1.5 倍以上，加速了自动驾驶的研发进程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1eda78c8dec554dab0582ee94e6f58e1.png\" /></p><p></p><p>在生科医疗领域，百度百舸提供高性能生物计算的平台，作为高通量药物发现的引擎，可以满足 EB 级海量数据、千亿级参数的大模型训练，使得蛋白质结构的预测模型的迭代周期，从过去月级别提升至天级别。</p><p></p><p>其中，高性能网络为大规模的集群训练提供微秒级的通信时延。通过算力统一调度，满足不同场景的算力需求。同时，借助数据湖存储和对象存储之间打通后的能力，为用户降低数据存储成本一半以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d07dce6363593a20f37f680bf77d1ee3.png\" /></p><p></p><p>基于百度百舸的智算中心，能够提供普惠多元的 AI 算力，支持 AI 应用的大规模发展，做到产业的全场景覆盖，推动城市数字经济的高速发展。</p><p></p><p>最近，百度智能云 - 昆仑芯（盐城）智算中心落地汽车产业重镇盐城，可为盐城周边的智能经济发展提供庞大的 AI 算力和海量的数据处理能力，加速智能化升级。</p><p></p><p>该智算中心将成为当地科技创新的动力源泉，向长三角区域源源不断地输出最前沿的科研创新成果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eaf4f422292e9f9ec9199a64336a2fa3.png\" /></p><p></p><p><a href=\"https://cloud.baidu.com/summit/summer_summit_2022/index.html\">点击视频回放链接，可以查看全部内容。</a>\"</p>",
    "publish_time": "2022-09-13 14:05:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一年 100% 云原生化，众安保险架构演进的探索与实践",
    "url": "https://www.infoq.cn/article/xAWCqCUkkWKqFQTdhhsQ",
    "summary": "<p>采访嘉宾 | 欧昀、鄢晶</p><p></p><p>金融行业的蓬勃发展，业务规模的不断扩张，用于支撑业务运行的系统和基础设施也日趋庞杂，强监管安全合规的属性又使得他在云原生的选择上比其他行业多了一丝谨慎，面临更多挑战。</p><p></p><p>众安保险从 2016 年就开始探索实践云原生相关技术，在服务治理、自动化运维等方面积累了大量的经验。为了深入了解众安在金融保险领域的探索和思考，近日，InfoQ 采访了众安保险技术团队，围绕金融保险云原生架构治理问题逐一展开探讨。</p><p></p><h3>众安云原生之路：从追随者到实践者</h3><p></p><p></p><p>2016 年，众安就开始逐步尝试云原生技术，届时众安已充分意识到云原生技术本身适用于任何行业，慢慢地众安对云原生的理解也从早期概念的追随到现在大规模落地的实践者甚至是布道者。这个模式的转换更多的是依据云原生的定义搭配众安自身的演进实现，同时结合业务实际，由浅至深，由点到面的过程。</p><p></p><p>早期云原生在定义过程中，主要是应用的容器化，以及面向服务架构，容器编排等等。随着云原生生态的逐渐成熟，众安现在更关注的是标准实践之后的深度治理，比如在不可变基础设施，微服务三要素等落地规范的定义下，如何最大化的实现云原生技术红利，并不断探索云原生标准的最佳实践等。</p><p></p><p>众安对云原生理解总结为一个词就是弹性。主要分为三个方面，分别对应弹性基础设施，弹性应用架构，以及弹性研发交付流程，也分别对应容器、微服务和持续交付相关技术。容器轻与快的特性能够让企业实现按需的编排使用，对于需要使用的资源实现快速的弹性伸缩。微服务应用架构则是作为部署与交付的介质，低耦合的设计能够充分发挥容器和持续交付的能力。此外借助 DevOps 实现的持续交付流程则能够使众安更快、更敏捷的去响应需求的变化。总的来说，云原生为众安提供了一套指导思想，让企业以更轻更快的方式去实现构建部署以及交付应用。</p><p></p><h3>众安架构演进：迈向云原生</h3><p></p><p></p><p>同其他互联网公司相似，众安的技术架构也是一直在演进与升级的，整体可以分为三个阶段。</p><p></p><p>第一阶段是在成立之初采用的传统单体架构，满足业务快速上线。第二阶段，随着互联网业务对新开通高并发、低延时的要求，众安开始进行微服务架构的升级，这个阶段又可以细分为闭源与开源两个过程，最初使用国内大厂闭源的技术组件，之后慢慢拥抱开源生态。第三阶段就是现阶段，采用基于 K8s 构建云原生的架构，包含了容器化的基础设施、微服务架构、服务治理、DevOps 体系建设等等。</p><p></p><p>众安在进行架构演进的过程中，首先会进行目标架构的规划，解决方案的规划也会成为目标架构演进过程中的目标路径。这就意味着方案规划需要符合长期的目标架构，同时在中短期也要能够解决当前或者即将面临的问题。另外众安将技术架构的关键能力聚焦在业务复杂度提升和数据量变高带来的海量数据、低延时高并发等互联网式的极端流量问题之上，这也要求众安停下来去审视当前的技术架构是否能够支撑业务形态的转变，以适应未来五到十年的变化为目标去进行架构规划。</p><p></p><h4>云原生架构建设思路</h4><p></p><p></p><p>众安在云原生架构上的建设思路，恰如众安对云原生的定义理解，也是分为三个层次，包含基础设施层，应用架构层，以及研发管理层。基础设施层次建设改造主要是指的是容器化的改造，包含容器服务，容器编排，以及如何将应用部署在容器当中等。其重点在于容器云平台的搭建，众安采用 K8s 并在其之上自研了一套自己的多集群统一管理容器云方案，实现了全公司全环境容器服务以及编排的统一管理。另外，通过镜像可视化编排、镜像插件等手段去标准化约束基础镜像，实现业务系统快速进行容器环境的适配。在此之上面向云原生设计并落地了新一代数字化保险系统称之为无界山 2.0。</p><p></p><p>在应用架构与研发管理层，众安主要采取架构标准化与微服务治理和自研 DevOps 体系的思路，我们在下文服务治理段落将进行详细讲解。关于标准化的约束，众安集成在流程与工具当中，形成一套事前自动生成、事中标准指导以及事后检查的机制。</p><p></p><p>在体系建设方面众安采用核心能力拥抱开源，服务能力进行自研的方式建设基础设施、应用架构和持续交付体系。在开源工具的选择上，众安会充分考虑一些 CNCF 认证的项目与规范，同时也会采取像社区共建、团队贡献、定制私有等方式，和社区保持长期稳定的一种参与关系。</p><p></p><p>此外众安在云原生安全方面也有着非常重要的考量，一方面会借助云上的安全产品去建设基本硬件级的安全防护能力。另一方面众安面向金融场景，围绕容器、应用、数据、业务方面进行安全能力自研孵化网络安全、应用安全、数据安全产品，形成面向不同行业和场景的安全合规、业务安全的风险管理解决方案。同时众安将安全能力和研发管理流程深度集成形成了现有的 DevSecOps 体系，这些都是众安在规划架构上的思考。</p><p></p><h4>强监管行业安全上云</h4><p></p><p></p><p>保险银行证券都是属于强监管的金融行业，上云对于他们来说既是挑战，也是机遇。最基础最关键的就是如何选择一个好的云服务商，根据行业的一些特性，可以从合规、安全、数据一致性等高要求来考虑。因此在架构升级上众安会主要从两个方面考虑。</p><p></p><p>首先在业务方面，传统的金融产品和服务，存在一定的门槛，效率低下，同质化严重，可能无法满足客户的特定需求，客户更多的需要线上化、个性化、场景化的金融产品和服务。</p><p></p><p>其次在技术层面，金融行业属于信息化程度相对比较高的一个行业，传统的金融 IT 架构存在较多问题，比如研发周期长，协作沟通问题，运维成本高、创新比较慢等等，还会遇到人才储备不足的难题。</p><p></p><p>结合目前数字转型在整个行业的深化，众安看到了越来越多的云原生技术在行业上的运用。众安开始逐步尝试云原生技术在生产实践中的运用，充分利用和发挥云的优势，同时做到灵活、低成本的方式构建弹性和可扩展的应用。在帮助研发的过程中，将研发的焦点，由资源为中心转向以应用为中心，利用弹性的概念去充分发挥云的优势，帮助提升产研的能力，支撑业务的创新。整体来说的话，众安认为云原生技术能够为金融行业，尤其是互联网金融行业带来巨大的红利，为众安构建新一代的数字化基础设施，以及帮助企业数字化转型带来强大的推力。</p><p></p><h4>最大挑战只有一个：技术升级不能影响业务</h4><p></p><p></p><p>技术升级最不缺的就是挑战，整个架构升级切换的过程，众安的技术专家表示，就像大家说的“开着飞机换引擎”，最主要的挑战就一个，技术升级的同时不能影响业务。在整个迁移的过程中，遇到了大家熟知的微服务问题，容器化，DevOps 等等，既不能影响生产业务，又不能影响日常开发的运维流程，挑战还是比较大的。众安主要分了两个阶段去尝试：</p><p></p><p>第一阶段，众安早期的业务形态，主要是围绕电商场景去开展，这个时期需要在很短的时间内做更多的生态，比如健康生态、汽车生态等等。早期的业务架构并不是很匹配未来的业务情况，因此早期有业务架构升级的需求，所以众安在做业务架构的同时，也将底层的技术架构做了升级，完成了早期云原生基础设施的转换。</p><p></p><p>第二阶段，有了云原生的基础，通过云原生的基础能力，众安对基础设施进行了底层的封装之后，确保上层应用运行环境的稳定，同时众安加强了 PaaS 层服务能力的建设，降低开发者对底层基础设施和公用组件的使用门槛和成本，这也可以帮助后续做到无感升级。同时为了降低日常运维的流程，众安还自研了 DevOps 产品，实现从构建到部署的自动化，并将标准化延伸业务交付。</p><p></p><h4>从探索容器到服务治理</h4><p></p><p></p><p>众安云原生的发展阶段也可以分为三个阶段：容器探索阶段、微服务化、服务网格治理。</p><p></p><p>前面提到，众安从 16 年就开始起步探索容器技术，以 Docker Swarm为技术核心建设了第一代容器管理和应用平台，在一些边缘应用上进行了小规模的试点应用。实践下来，在网络及其稳定性方面存在比较大的问题。</p><p></p><p>时间来到 18 年，这个时期众安以 K8s 为技术核心建设云原生基础设施，将微服务应用部署到容器环境。在容器微服务化阶段众安的迁移改造已经比较彻底，实现了业务应用100%容器化。</p><p></p><p>目前正处于第三服务网格服务治理阶段，当下众安主要以 Istio 和 Agent 为技术核心实现网格化的服务治理，对以 K8s 为主的云原生基础设施进行进一步的增强。</p><p></p><p>总的来说，阶段二的迁移最具挑战，迁移的过程耗时将近一年，无论是涉及到的系统规模，还是复杂度都是最高的。另外由于底层基础设施形态的转变，技术复杂度也比较高，众安通过蓝绿验证的方式，通过网关的能力进行流量的逐步切流，利用这种手段做到业务逐步迁移，保证了迁移过程中业务的连续性不中断，实现业务的无感迁移。</p><p></p><p>提及转向云原生收益之前先介绍一下众安的基建规模，众安这边的主机规模，按照 4C8G 这种机器的规格去计算的话大概是在一万加以上，应用规模是一千多个，技术人员的规模大概是在两千以上。众安技术架构在转向云原生之后，结合资源弹性编排带来的成本节省，以及 DevOps 体系建设和落地，有效提升了需求交付率，缩短了交付周期。从统计的数字上来看，21 年众安发布次数在 12 万次以上，相交于云原生之前增长了 22 倍，关于转向云原生，众安还是获得了非常明显的收益。</p><p></p><h4>目前的难题</h4><p></p><p></p><p>架构演进是一个持续的过程，企业会不断面临各种各样的问题与挑战，众安分享了其中一个多语言环境下架构治理问题。关于如何看待多语言，首先众安保险不希望开发语言成为公司吸纳各路人才的阻碍，不同的编程语言也会有他适合的一些应用场景，比如说人工智能 Python 会比较适合，云原生 Go 会比较适合，企业级的一些业务系统可能 Java 会比较适合。</p><p></p><p>在语言栈选择上众安秉承着开放的策略，但语言栈的开放带来的就是维护复杂度、治理困难的问题。为了实现统一架构的治理目标，将治理能力不断下沉到基础设施是众安认为唯一的标准答案。众安方案的抓手是流量劫持，从东西向流量和南北向流量这边分别去展开。对于南北向流量众安将治理的能力放在网关层，同时众安的目标也是建设 API、业务、安全的三合一网关；对于东西向流量众安则是依托服务网格技术，在全公司全场景覆盖，提供基础设施级的流量权限与可观测能力。</p><p></p><h3>众安架构服务治理方案</h3><p></p><p></p><p>随着众安技术伴随整个业务发展进入第九年，公司在业务形态和体量上都发生了巨大的变化，整个技术架构如何去支撑业务的线上运营与发展就就变成了非常有挑战的课题。</p><p></p><p>众安保险内部架构治理遵循公司统一架构目标，以技术架构、业务架构作为支撑点，主要分为三个方面。第一，基础设施层面众安要求百分百部署在云上，充分使用云服务提供的计算、存储、网络等能力；第二，在技术架构方面，众安基于云构建了技术中台，能够向业务系统提供统一的容器、中间件等 PaaS 能力；最后在应用层面，业务系统统一使用类 Spring Cloud 生态的微服务架构。</p><p></p><p>总的来说，目前众安已经形成了较为完善的云原生生态的建设，治理着超过上万服务的大规模集群。</p><p></p><h4>强监管的金融行业属性</h4><p></p><p></p><p>首先金融保险属于强监管的行业，安全合规是红线，金融保险架构治理也会有一些特殊的地方。因此众安在做基于架构标准的时候就会设定一些合规性的下限，在业务设计的过程中要帮助和指导大家去考虑合规性需求的扩展和一致性。其次，由于整个金融行业存在一些“历史包袱”，尤其是一些中小型金融企业，对于技术改造存在较大的风险和挑战。</p><p></p><p>所谓金融企业的“历史包袱”，可以从两个方面展开来讲。第一是业务上的挑战，第二是技术方面的挑战。大家可能知道，组织结构会决定技术的架构，众安早期遵循的一套架构叫做“胖前置，瘦核心“，这是因为众安前期强调的业务形态是前台的业务部门高效迭代的能力。在整个架构升级过程中，尤其上发展到现在业务稳步发展的阶段之后，就会更加关注业务的效率和质量，然后持续加大一些业务中台和技术中台的投入。最后在整个过程中不但有底层的业务架构的升级，以及匹配到技术架构的升级，整协同过程中组织架构的一些调整也会有冲击。还有一点可以补充的是，像传统的金融行业的业务系统，大家可能知道企业使用的像小型机，重量级的一些数据库，甚至闭源的厂商，都是比较普遍的。关于这个方面，金融企业上云也会存在一些阻力。</p><p></p><p>不过受访专家表示，众安也相信技术先进性会让之前的一些业务开展由不可能会变成可能，同时也在不断鼓励金融创新，鼓励技术先进性的探索也会成为众安架构治理的一个重要环节。此外，在服务治理的过程中也会发现新的一些架构和交互对于传统的业务流程和组织结构带来的一些冲击，众安也发现转变企业的文化，打破部门的一些壁垒，夯实数字化的一些群众基础也是非常重要的事情。</p><p></p><h4>三大企业架构治理方案</h4><p></p><p></p><p>众安在企业架构治理课题上具体来讲有以下几个方向：</p><p></p><p>首先是微服务治理，众安根据自身业务覆盖广、周期长的特性，使用开源体系落地实践的方案。以 Spring Boot 为基础，在此基础之上建设了可递进、可共建的统一微服务应用框架，为业务系统提供框架组件版本的统一管理能力，同时开放共建能力也可以让各事业线的技术团队参与到标准的制订以及演进过程当中。</p><p></p><p>众安采用无侵入为主、多语言的异构体系为辅的技术方案。尽量避免对业务代码产生侵入，升级也能够做到尽量减少对业务这块的一些感知与影响。简单来说就是 Istio 配合 Agent，或者称之为 Agent 加 Mesh 双治理的体系。众安应用服务技术体系，虽说是拥抱多语言，但实际上更多还是以 Java 占据绝对的比例。目前众安使用这两种技术体系共同完成不同业务场景的覆盖，这也是金融保险行业比较先进的治理方式。</p><p></p><p>再谈数据治理，众安作为国内较早开始数字化转型的企业之一，非常注重数据带来的价值，为此众安还成立了专门的数据治理组织。数据治理上众安保险主要关注两个方面，一是数据质量，二是数据安全，目前两个方面众安都是通过一些平台化的能力进行治理。</p><p></p><p>数据质量方面众安搭建了企业内部的数据质量平台，通过不断去维护运营过程中积累的像业务和数据的一些相关规则。比如说保险，保险是受强监管的，在业务处理的事前、事中、事后都要及时地对相关数据进行质量监控。另一方面，在数据安全上，众安自研了关于数据管理方面的平台，取名绿洲数据服务中心，通过系统对数据的一些流转和使用，进行相应的数据相关的一些权限和安全的控制。</p><p></p><p>最后是 DevOps 治理方面，或者叫研发过程的治理。这里众安是以一站式研发管理作为指导思想来建设一体化的 DevOps 平台，并且从文化、组织和工具层面对众安的研发一体化的体系进行落地。</p><p></p><p>众安整个 DevOps 体系的设计遵循了两个理念，一个是运维 N+1 的一个理念，一个称作“小工具大平台”的理念。什么意思呢？首先运维 N+1，指的是一个基础运维，N 个运维场景，也可以理解为是一个运维中台，N 个运维平台。</p><p></p><p>众安使用运维控制管道概念去提供基础的调度能力，去屏蔽底层比如容器调度、主机调度甚至文件调度，实现统一的命令和文件管道，同时上层工具平台遵循统一的数据和API标准。在此标准之上众安建设了像持续交付，可观测，数据治理包括 ITSM、IT 治理等众多的应用场景。“小工具大平台”则指的是众安运维体系模块化的设计，通过微前端等的一些技术手段，去实现模块的按需组合，并且按照研发角色例如开发运维测试等形成不同的工作视图。</p><p></p><h3>金融基建新挑战</h3><p></p><p></p><p>此外，信创基础设施作为当下较为火热的课题，众安在此方面亦有相关动作。金融安全关系国家命脉，在自助可控的重要性方面尤为突出。众安积极响应国家战略，在基础设施、核心系统方面的信创适配工作有着很大的投入并产生了不错的成果，面向行业推出了安全、运维、基础架构等领域的众多满足信创要求的产品。另外，众安保险具备金融、互联网双重行业特性。同时区别于传统公司，众安的基础架构体系 100% 构建于云上，是在云上进行大规模生产实践的典型案例。在与云商等产业机构联合共创之下，快速设计了有众安特色的信创云方案并进行尝试，目前已经有一定比例的科技投入。同时众安也非常愿意以科技赋能行业为目标持续输出相关产品与经验。</p><p></p><h3>写在最后</h3><p></p><p>中国信通院云大所云计算部副主任陈屹力曾提到，云原生是保险行业新一轮数字化升级的必经之路，众安在金融保险领域的成功实践也验证了这一点，尽管目前大多数企业还处于探索阶段，但在未来几年，金融保险行业将全面迎来云原生时代。</p><p></p><h4>嘉宾介绍：</h4><p></p><p>欧昀</p><p>众安保险首席技术专家、公司技术平台部负责人，曾任职阿里巴巴技术专家，15年以上互联网项目技术经验。主要负责保险业务中台和技术中台规划和落地，参与完成公司技术战略制定和落地，实现科技赋能保险。</p><p></p><p>鄢晶</p><p>众安保险高级技术专家，平台架构部技术负责人，在微服务，Devops，云原生技术领域有丰富的实践经验。主导了众安新一代智能运维平台的建设。</p><p></p><p></p><h4>内容推荐</h4><p></p><p></p><p>本文选自《<a href=\"https://www.infoq.cn/minibook/EQzDrPI1dT9G8V6alV1I\">中国卓越技术团队访谈录</a>\"》（2022 年第三季），本期精选了阿里达摩院数据库、得物、华润云、民生保险、众安保险、字节跳动 AppInfra 等技术团队在技术落地、团队建设方面的实践经验及心得体会。</p><p></p><p>《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。</p><p></p><p>访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang_wechat，请注明来意及公司名称。</p>",
    "publish_time": "2022-09-13 14:37:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库内核杂谈（二十四）- Hologres，支持Hybrid serving/analytical Processing的数据引擎（2）",
    "url": "https://www.infoq.cn/article/65zC4wl1zoDko1GRvQFS",
    "summary": "<p>欢迎阅读新一期的<a href=\"https://www.infoq.cn/theme/46\">数据库内核杂谈</a>\"。新一期的杂谈特别安排在中秋节后，祝大家中秋快乐（主要还是忙得又拖更了）。本期的杂谈继续来学习蒋晓伟老师发表在VLDB2020上的文章：<a href=\"http://www.vldb.org/pvldb/vol13/p3272-jiang.pdf\">Alibaba Hologres: A Cloud-Native Service for Hybrid Serving/Analytical Processing</a>\"。这一期，着重介绍存储，执行的技术细节。</p><p>&nbsp;</p><p></p><h2>数据模型（Data Model）</h2><p></p><p>首先介绍Hologres的数据存储模型（data model）。对于每一张表，用户需要设置一个clustering-key和一个全局唯一的row locator（我觉得就可以理解为row key）。如果clustering-key本身就是唯一的，就会被默认用作row locator；如果不是，会有一个额外的唯一标识（uniquifier）和clustering-key组合成为row locator 。</p><p>&nbsp;</p><p>一个逻辑数据库（database）里面的所有tables都会按照某种规则组成多个table groups（后续写作TG）。这个规则可能是根据access pattern来定的。一个TG，还会被进一步被分拆（shard）到多个table group shards（后续写作TGS）。每个TGS，会保存一部分的base data（理解为表数据）和与之对应的所有的Indexes信息。每一部分的base data加上相关的indexes信息就被划为一个tablet。Tablet有两种存储模式，row tablet（行存）和column tablet（列存）。它们分别被用来针对点查询和分析型查询。一个tablet，取决于access pattern，可以被存为row tablet，或者column tablet，或者两者都存（可惜文中，并没有给出具体的case，什么时候会存储成什么？让用户来设置的话，感觉有点复杂）。</p><p>&nbsp;</p><p>Tablet里存储的数据需要一个唯一的key，所以对于base data tablet来说，上面讨论的row locator就能作为唯一的key。对于secondary indexes（二级索引）的tablets来说，如果这个index是唯一的，那index column本身就能成为唯一的key。否则，base table的row locator会被一起作用，作为唯一的key 。举个例子，假设一个table有2个二级索引，1个是唯一的key（k1-&gt;v1），另一个不唯一（k2-&gt;v2）。那么base table的key就是 ，唯一key的二级索引的key就是，而非唯一key的二级索引的key就是。</p><p>&nbsp;</p><p>文中也介绍了，为啥要把多个table组合成TGS。因为绝大部分的写入，会access一些相关的table，已经对应的indexes。把这些tables合成一个TGS，就可以把相关的多个写操作转换成一个atomic write，并且只有一个write log entry被记录到文件系统中，由此提升性能。此外，将经常需要被join的表组成TGS，也能避免join的时候需要重新shuffle数据（如果基于同一个row key进行hash的话）。</p><p>&nbsp;</p><p></p><h2>Table Group Shard（TGS）介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b271b8487d4c55f0df28dfc085a8eadc.png\" /></p><p>（TGS 介绍图片）</p><p>&nbsp;</p><p>TGS是Hologres里数据管理的基本单位。结合上面的TGS图片来讲解。一个TGS由一个write ahead logger（WAL）和多个tablet构成。所有的tablets，无论是row tablet，还是column tablet，都是以log-structured-merge-tree（LSM tree）形式存储：一个mem-table，和多level的不可变的shard-tables=。所有的shard-tables都保存在distributed file systems里面（这边用的是阿里的盘古分布式文件系统）。<a href=\"https://xie.infoq.cn/article/253f731e621992c7d3f032092\">LSM tree的工作方式</a>\"就不在这边赘述了。 每个tablet也会保留一个metadata文件来记录这些mem-table和shard-tables的状态，和RocksDB的工作方式类似。所有的数据都有版本记录（MVCC），且读操作和写操作是完全分离的。并且，系统设计里保证一个TGS只有一个writer可以写WAL，但允许多个reader同时读。</p><p>&nbsp;</p><p>写操作：Hologres支持两种类型的写操作：单TGS写和分布式批量写。这两种类型的写操作都可以被认为是原子的。单TGS写通过单个writer写WAL保证原子性，而分布式批量写通过两阶段事务保证。</p><p>&nbsp;</p><p>单TGS写：继续结合上图来看。1）WAL manager会给当前的write request分配一个LSN（现在的时间戳和一个递增数字），2）创建一个log entry（涵盖replay的所有数据）在log文件里。写操作等到log文件存储成功才commit。3）写操作会作用到tablet的mem-table里。4）当mem-table写满的时候，会触发LSM tree写到shard-tables里。level compaction是异步发生的。</p><p>&nbsp;</p><p>分布式批量写：通过两阶段提交事务来保证原子性。FE（Front-end）节点在接到写操作时，会锁住所有需要参与的TGS。然后，每个TGS会1）获得一个LSN，2）作用写操作到所有的mem-tables，3）如果需要，触发LSM tree写。参与的TGS在完成操作后会发结果vote给FE，FE会决定是否要commit还是abort。如果FE决定commit，每个TGS会commit log，否则，前面的操作都会被作废（典型的两阶段提交）。</p><p>&nbsp;</p><p>分布式TGS管理：文中也快速讨论了一下分布式的TGS管理，目前，TGS的writer和多个reader都是co-located在一个节点上，但Hologres在支持允许read-only replicas部署在一个remote节点上来进一步平衡读写负担。并且支持两种read-only replicas：1）完全synced replicas可以支持任何读操作，2）部分-synced replicas来支持数据只存在shard-tables里的数据。</p><p>&nbsp;</p><p></p><h2>Row Tablet介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96cd1333be1584d6ddfabccbaa445f84.png\" /></p><p>（Row Tablet 介绍图片）</p><p>&nbsp;</p><p>Row tablet是针对高性能的点查询做优化支持的。结合上述图片来看Row tablet的结构：Row tablet的mem-table 结构是 Masstree，数据是按照key进行排序的。而写到文件中的shard-文件则被分为了数据block和index block。index block记录了每个data block的offset以及对应的starting key来加速读取。</p><p>&nbsp;</p><p>为了支持mult-version data，Value值存了三类信息：一是non-key的value columns的值； del_bit代表这行是否被删除了；和LSN version信息。</p><p>&nbsp;</p><p>读操作：每个读操作需要输入读key和LSN。结果的获取类似于读LSM-tree，通过读取mem-table和文件系统重的shard-table；只有有key重合的shard-table文件才会被扫描。</p><p>写操作：典型的LSM-tree，会specify column-values，del_bit和LSN。如果mem-table满了，会trigger flush到shard-table上。</p><p></p><p></p><h2>Column Tablet介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd872817c2aea22f120687b34b1153d5.png\" /></p><p>（Column Tablet 介绍图片）</p><p>&nbsp;</p><p>相对于row tablet, column tablet用来更好地支持某个column的scans。结合图片来介绍。和row tablet不同的地方在于，column tablet，除了维护一个column-store的LSM tree，还需要额外维护一个delete map（由于是column store的限制）。Column tablet的mem-table的存储格式是Apache Arrow（一种高效的columnar memory format）。数据会按照顺序被写进mem-table里面。在文件系统的shard-table里，数据依然是按照key来排序，但从逻辑上被划分为row groups。某一个column，它的值按照row group的划分，会存储到不同的物理data block上。一个column的data blocks会被连续的存储在一起来支持sequential scan。同时在，shard-file里，会保存index-block和meta block来加速读取，index-block存储了row相关的信息，而meta block，则存储了每个column的data block的相关信息，比如offset, value ranges, total row count等等。</p><p>&nbsp;</p><p>delete map本身其实是一个row tablet：key就是shard file或者mem-table的ID，然后value就是一个bitmap来表示这个shard-file里面，哪些records被删除了。</p><p>&nbsp;</p><p>读写操作本质都是对mem-table以及shard-file的flush操作，和row-table并没大区别。</p><p></p><p></p><h2>Hierachical cache</h2><p></p><p>文中也介绍了Hologres，为了进一步提升性能，采用了多阶段的caching来减少IO和计算cost：local disk cache, block cache 和 row cache。Local disk cache就是用来cache shard-files来避免频繁数据的IO读写操作。在这之上，内存为主的block cache用来存储shard-file里面的读取的blocks。在block cache上，我们还保留了一层内存机制的row cache来存储最近被查询过的row tablets，以加速读取。&nbsp;</p><p></p><p></p><h2>Query Execution Pattern</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af00b4b64b10477d4e80071f64d27007.png\" /></p><p>（Query Execution 示例图）</p><p></p><p>结合图片来看Hologres在收到一个查询请求后，是如何一步一步执行的。1）在收到查询语句后，在FE节点上的query optimizer会生成一个DAG的执行计划；并且把这个计划按照shuffle boundaries（类似于map-reduce里面的map-reduce阶段）划分成多个阶段（fragments）。Fragments有三种，读，写fragments，以及数据处理fragments。每个fragments可以生成多个并行的instances来处理相应的数据。比如，对于每一个TGS，都可以起一个并行的reader或者writer fragment。</p><p>&nbsp;</p><p>FE节点会把这个执行计划发给coordinator节点，然后被coodinator节点分发到相应的worker节点上。读写fragments总是会被分派到host某个TGS的worker节点，数据处理节点可以被任意分配，来保持load balancing，并且也会考虑到数据传输的local性。在每个worker节点里，一个fragment可以进一步被拆分成多个work units（WU）来做具体的执行工作。WU是执行的基本单位。</p><p>&nbsp;</p><p></p><h2>Execution Context</h2><p></p><p>另一个值得一提的优化就是Hologres构建的execution context。因为Hologres需要支持多用户的并发查询需求。这会导致多个WU同时执行的时候会不可避免地进行context switch。而过多的context switch会造成性能瓶颈。为了解决这个问题，Hologres构建了一个user-space thread（就是协程吧），称为execution context（EC），用来记录WU的资源使用情况。调度EC不会牵涉到任何系统调用，所以EC之间的context switch就非常小。Hologres以EC为调度基本单位，计算资源也以EC的粒度被分配。EC在执行中，会跑在一个线程上。</p><p>&nbsp;</p><p></p><h2>Pull-based query execution</h2><p></p><p>Hologres采用了类似于Volcano模式的执行计划，异步的pull-based query execution。首先由coordinator会发送pull request到底层的WU，WU会继续发送pull request到下游WU里，直至到leaf WU，会开始读取mem-table或者shard-file里的数据。这个和大部分的执行引擎类似。</p><p>&nbsp;</p><p></p><h2>总结和一些思考</h2><p></p><p>读完整篇paper，最让我觉得最最创新的地方应该就是在Tablet中支持了row tablet和column tablet来同时优化<a href=\"https://xie.infoq.cn/article/a04f154de08ec69cbf5ff9795\">OLTP和OLAP workloads</a>\"。其他的<a href=\"https://www.infoq.cn/article/fd6mk3yGUEsfTm0D6QZW\">NewSQL</a>\"系统可能选择在更上层的架构中支持全部：比如通过CDC同步OLTP的数据到OLAP系统中。目前另一趋势就是updatable data structure比如<a href=\"https://hudi.apache.org/\">Apache Hudi</a>\"和<a href=\"https://iceberg.apache.org/\">Apache Iceberg</a>\"。目前工作的团队也在这方面探索，我也想借这个机会深入学习一下，以后写到内核杂谈和大家分享。感谢阅读！</p><p></p><p></p><h2>内核杂谈微信群和知识星球</h2><p></p><p>内核杂谈有个微信群，大家偶尔会讨论些数据库相关话题。但目前群人数超过200了，所以已经不能分享群名片加入了，可以添加我的微信（zhongxiangu）或者是内核杂谈编辑的微信（wyp_34358），备注：内核杂谈。</p><p>&nbsp;</p><p>除了数据库内核的专题blog，我还会push自己分享每天看到的有趣的IT新闻，放在我的知识星球里（免费的，为爱发电），欢迎加入。</p><p><img src=\"https://static001.geekbang.org/infoq/62/62e530824eee913af1a76fe28707a2b6.webp\" /></p><p></p>",
    "publish_time": "2022-09-13 14:43:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "CTO在企业数字化转型的过程中扮演什么角色 | 第三期完整版（上）",
    "url": "https://www.infoq.cn/article/ASFrj4IwtQjK9eBpSOAZ",
    "summary": "<p>《行知数字中国》第三期，InfoQ邀请到了过去30年亲历过中美高科技行业、零售业、金融业和制造业等不同行业的 IT 老兵向江旭。</p>\n<p>他曾在引领科技创新潮流的硅谷深耕技术研发，回国后赶上中国蓬勃发展的移动互联网时代，又以技术管理者的身份亲历了数家企业的数字化转型历程，在一次次跨越边界、不断探索的过程中，他对”数字化转型“的理解始终如一。</p>\n<p>在本期视频中，他将结合其亲身经历，分享数字化转型和创新的经验和教训。</p>",
    "publish_time": "2022-09-13 16:14:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "高管空降数字化，怎样应对局面？ | 第三期完整版（中）",
    "url": "https://www.infoq.cn/article/UipwTesLtZvD0hmAIr3f",
    "summary": "<p>《行知数字中国》第三期，InfoQ邀请到了过去30年亲历过中美高科技行业、零售业、金融业和制造业等不同行业的 IT 老兵向江旭。</p>\n<p>他曾在引领科技创新潮流的硅谷深耕技术研发，回国后赶上中国蓬勃发展的移动互联网时代，又以技术管理者的身份亲历了数家企业的数字化转型历程，在一次次跨越边界、不断探索的过程中，他对”数字化转型“的理解始终如一。</p>\n<p>在本期视频中，他将结合其亲身经历，分享数字化转型和创新的经验和教训。</p>",
    "publish_time": "2022-09-13 16:30:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "京东零售平台：前端组件资源共享与中心化管理实践",
    "url": "https://www.infoq.cn/article/MgILbHevE0WOp87VRAuA",
    "summary": "<p>你好，我是<a href=\"https://qcon.infoq.cn/2022/guangzhou/presentation/4791\">陈俊生</a>\"，来自京东零售平台业务中心。本文的主要话题是<a href=\"https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247511992&amp;idx=1&amp;sn=0551fae2126b8786c4d896d470651424&amp;chksm=f9521afbce2593ed9e6f6b9bee0f14b4be3cea55f491e9733140e431b7513802d34880198aa8&amp;scene=27#wechat_redirect\">京东玲珑平台</a>\"基于 MF 的组件化共享工作流的成果分享，主要针对目前跨团队之间协作、进行研发资源共享的痛点问题，介绍基于 Webpack Module Federation 的前端组件化共享方案，分享如何打造一个前端组件共享工作流，最后实现前端组件资源共享以及中心化管理的实践过程。</p><p></p><h4>1. 业务背景</h4><p></p><p></p><p>目前在玲珑产品下有很多个平台，比如说可能有前台、运营平台以及编辑器等。这些平台分别是由不同的团队去进行开发的，并且每个团队都有沉淀自己的一些基础组件或者是业务组件。比如 Button、Select、Modal 等等，其实这些组件都有一些共通的逻辑是可以复用的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fa/fa070e791f4d8e038d315d2cca45e72e.png\" /></p><p></p><p>基于这种情况，因为每个团队开发的组件资源沉淀在各自的项目当中，导致各个项目的这些组件资源沉淀无法进行集中维护和统一管理。同时，因为这些平台都同属一个产品下，所以有很多共同业务，这样就催生出来很多业务逻辑相同的组件。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ac/ac9aeb9bbde61ba2483b48aa49866caa.png\" /></p><p></p><p>如上图所示，有一些业务组件水印，需要在前台、运营、编辑器三个平台使用，但由于涉及不同的团队，团队之间共享这些组件变得比较困难和麻烦。可能有的时候求快，就直接把代码从其他团队的项目仓库里面复制粘贴过来，但是这样带来的问题就是可维护性非常差。其次，可以通过 npm 包的方式去进行共享，但是这种方式它的更新链路非常长。因此，我们希望打造一个统一的设计系统，统一整个业务所有平台的设计标准。在这种业务背景下，组件共享以及如何做到，变得尤为重要。</p><p></p><p>那如何实现？首先是我们需要去做一个组件资源沉淀的统一管理；其次是做一个组件共享；最后需要去统一前后台设计标准。这三个目标我们如何去实现？下文将逐一展开。</p><p></p><h4>2. 组件共享方案</h4><p></p><p></p><p>组件共享怎么做？这里先大致介绍一下组件共享的几种方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d2/d2d445e91caee8bb85b0434eab7ebc57.png\" /></p><p></p><p>第一种是大家最熟悉的就是 CV 大法，直接从一个项目复制到另一个项目，速度非常快。但是问题也很明显，可维护性低，同时各个项目就各自多了一套代码，当需求发生变更时需要各自更新。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/71/713ca8174623f2049ec7ee665e9f7905.png\" /></p><p></p><p>第二种是大家比较熟悉的 NPM 包共享的方式，这种方式简单易上手，也是目前最常见的。但问题是各个项目引用的时候都会打包构建一次，如果项目比较大，可能会导致构建时间很长。同时这种共享方式的更新链路很长，可能出现一个项目都已经发布上线一段时间了，另一个项目还保留着之前的版本。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ef/ef59119362cafdc039cc60d01fb3f5e8.png\" /></p><p></p><p>第三种是通过 CDN + Webpack externals 的方式进行组件共享，这种方式其实和 npm 差不多。它有一个优点是可以去抽离一些公共库，但是无法做到按需加载，必须以 script 标签形式提前引入。一般我们使用这种 CDN 的方式，都是通过 on package 一个 npm 包的静态链接这样的形式去加载。其实还是需要发布一个 npm 包，所以它的更新链路和 npm 包的更新链路是一样的。</p><p></p><p>接下来就是本文的重点，Webpack Module Federation，它是 <a href=\"https://www.infoq.cn/article/omvuugHYthUT8ZOTAIgI\">webpack 5</a>\" 的一个新特性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/eac8a843554179a8a80ec027b385d2af.png\" /></p><p></p><p>那 Module Federation（MF） 方案是如何共享的？如上图所示，这种方案可以让图中的玲珑前台去动态加载运营平台的原子组件，反之，运营平台也可以动态去加载玲珑前台的业务组件。这种方案的优势是依赖的共享资源不需要重复构建，同时可以实现依赖共享。因为 MF 是 webpack 5 的新特性，所以强依赖 webpack 5 。如果你是 webpack 4 及其以下版本，可能你需要先升级到 webpack 5。</p><p></p><h4>3. Module Federation（MF）</h4><p></p><p></p><p>那 Module Federation 它是什么？以及它是如何进行资源共享的？其实，MF 的设计动机就是为了让多个团队可以共同开发一个或者多个应用，简而言之，就是使应用之间能共享组件开发资源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/003e6c95ff7bdd298852cd5f72fb3b9a.png\" /></p><p></p><p>首先来看下传统的 Single Build 方式。假如 B 团队开发了运营后台，并开发了水印组件，同时 A 团队开发的前台项目也需要使用这些组件，那么，B 团队就先把这些组件打包成一个 npm 包来供 A 团队使用，他们只要安装这个包，然后在本地构建依赖打包、发布、上线就可以了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/95/95e92c5279b6616e55d7da6730b2762c.png\" /></p><p></p><p>如果使用 npm 的方式进行共享，它的组件更新传导链路就如上图所示。如果水印组件有优化更新，B 团队重新打包发布了一个新版，然后用在运营平台上，再重新打包，然后发布上线。同时这里需要手动通知 A 团队进行原子组件库 npm 包的更新，A 团队（前台）需要更新版本后再重新打包发布上线。可以看出，组件更新传导链路非常长，如果有更多项目引用到了这个包，那这条链路会继续增加。</p><p></p><p>那 Module Federation 它是怎么做的?</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1a/1abc420f81203357425a5a6bc5924260.png\" /></p><p></p><p>MF 的共享模式，如果 B 团队的后台直接将水印组件以 MF 的方式暴露出去，玲珑前台会直接通过异步 chunk 的方式去动态加载后台的组件资源，同时会共享这些组件所依赖的 React，然后它会把这个 React 打包成一个 Shared Chunk。那 Module Federation 是怎样把这个水印组件打包出来的，以及它的具体形式如何？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/30/3066f43cd63d7a20e809308438bed959.png\" /></p><p></p><p>首先 MF 应用可以导出一些组件，我们把它叫做一个 container。这个 container 它有一个入口文件，一般叫做 remoteEntry.js，并且 remoteEntry.js 是可以自定义的。它的核心内容主要是两个方法，一个是 get 方法，get 你可以理解为它是这个入口文件里面的组件配置表，MF 资源它导出了哪些组件，它就在 get 方法里面去进行配置，然后你就可以通过这个 get 方法拿到对应的组件资源。</p><p></p><p>另一个是 init 方法，它会去做 shared scope 对象的初始化，将你配置的共享依赖放到 share scope 对象里面去。如图所示，入口文件导出了两个组件，一个是 watermark 水印组件，一个是 button 组件。两个组件都会分别打包成一个 chunk.js，同时它会去依赖一个 react.js。当访问这个水印组件的时候，它就会把水印的 watemark.trunk 以及 react.trunk 一起加载过来。</p><p></p><p>具体的路径：首先是前台去加载水印组件，它会先去加载 remoteEntry.js，也就是 container 的入口文件。紧接着，它会去拿到调用 get 方法，再去拿水印组件具体的 chunk，同时进行 share scope 的创建，以及将 React 放到它本地的 share scope 里面去。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/818bb5270fb37038fce1accc11dd7e33.png\" /></p><p></p><p>在这个时候，MF 会去比较原子组件所依赖的 React 版本和玲珑前台依赖的 React 版本是否一致，这里是通过 semver 版本工具库的方式去比较的。如果不一致，假如玲珑前台依赖的 &nbsp;React 版本高于水印组件所依赖的 React 版本，默认会使用版本号更高的那个 React。如果一致，它会优先使用水印组件依赖的 React 版本，因为它在执行 init 方法的时候，会去覆盖前台的 share scope，将水印组件依赖的 React 版本覆盖掉前台的资源，所以它加载的就是水印组件所依赖的 react.js。如果说你想要一个固定的版本的话，也可以在配置里面去配。</p><p></p><p>接下来，了解下对应的 webpack 配置。首先一体化平台这里需要新增一个 webpack 5 内置的 ModuleFederationPlugin，然后进行这个插件的配置。如上图右侧所示，name 就是导出的资源名称，filename 就是入口文件，exposes 配置是需要导出的组件以及对应的目录，最后再将需要共享依赖的库放到 shared 里去。因为多个版本 React 的运行时实例对于 React 来说是敏感的，一般情况下只能存在一个版本的 React ，所以这里需要将它放到共享依赖里去。图中此处是简写状态，如果想要让这个 React 是单例的形式去加载的话，后面还可以再加一个 single time 为 true 的配置。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b4/b4e951b9f208d2c362186dcad0fdf9e6.png\" /></p><p></p><p>那如何使用呢？玲珑前台在加载的时候，也是需要新增 webpack 5 内置的 ModuleFederationPlugin，然后配置 remote 远程资源地址，也就是玲珑运营平台的 remoteEntry.js，这里的 LingCore 可以自定义指定，后面 ling 下划线 core 这个名称对应一体化平台导出来的名称，@符号后再加上资源地址，最后再将 React 共享依赖放到 share 的配置里面去就可以了。水印组件的使用方式和平常使用的普通 npm 包类似，直接 import 进来就可以了，也可以通过 lazy import 的方式加载进来。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5b/5b3a52a729f413d9737ba40605de4871.png\" /></p><p></p><p>然后，来看下 MF 共享模式的组件更新传导链路。一体化平台更新了水印组件，只需要重新打包发布即可，玲珑前台因为加载了线上资源，所以会跟着一起更新，这样一来，链路短了很多。所以由此也能看出，我们使用 MF 做一个组件共享，最大的特点就是它能实现实时更新。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f3/f3867c0480bfb705b61a2dd7acc30862.png\" /></p><p></p><p>那 MF 相对于 NPM 共享方式，有哪些优势？首先组件更新链路更短，发布了就实时更新。其次 MF 可以实现依赖共享，在运行时动态去判断加载哪一方的依赖，然后它不需要重复编译，因为本身 MF 资源是已经编译过的代码。如果用 npm 包的话，那每一个用到这个 npm 包的项目，都需要重复构建重复编译。所以 MF 无需重复编译，这样也带来一定程度的编译速度提升。上图所示就是一个老项目在引入 MF 资源之后的编译时间测试，能看出有些许的速度提升。当然引用的 MF 资源越多，这个对比就会越明显。</p><p></p><p>最后是 MF 的应用场景。首先就是目前的场景，组件共享。其次是它可作为一个编译速度提升的方案。目前市面上 UmiJS ，算是 SSR 的一个框架，它推出了 MFSU 的一个新功能，这个新功能其实就是当你第一次编译过后，后面再重新编译它就会非常快。怎么做到的？就是通过 Module Federation 来做到的。因为之前编译好的那些组件它已经把它 MF 化了，后面就不需要再重复编译，只需要编译你修改的那些文件就可以了。</p><p></p><p>第三个应用场景就是微前端场景。MF 其实就是天然的一种微前端场景，可以去动态地加载其他的应用，但是它跟国内目前其他的一些框架有一点概念上的不同，比如说 qiankun、icestark 之类的微前端框架。比如 qiankun 这种框架，它是以应用级别去进行页面的聚合。MF 则是以 JS 模块这种方式，粒度更细。所以其实也可以去探索基于 MF 的一种微前端的场景。</p><p></p><h4>4. 基于 MF 的组件共享工作流</h4><p></p><p></p><p>介绍完 MF ，可以大致了解到它组件共享的模式。我们基于 MF 打造了一套组件共享工作流，做到组件共享与研发资源统一管理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/561c137d7d642a0f6bc7b87101b1865a.png\" /></p><p></p><p>如果使用 MF 的方式来做项目间的组件共享，自然而然就会想到将每一个项目导出的 MF 共享资源集中到一个大池子里面，在这个大池子里面做中心化管理，于是我们就做了一个组件共享平台，让每一个独立的项目都可以发布它的研发资源到这个平台。基于组件共享平台的 MF 共享模式，后台去加载水印组件时就直接去访问了我们的共享平台的资源，前台也是如此，这里和之前的区别只是资源地址变了。另外，基于 MF 平台的组件更新传导链路，其实就是原子组件更新后发布到 MF 平台，依赖 MF 平台资源的两个项目就会实时更新。不再需要本地再重复构建。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/97/977b1f0c44ed5f74d01f6edddf1ec028.png\" /></p><p></p><p>这个组件共享平台体系由三个部分构成：首先是一个脚手架工具，我们称之为 MF-CLI，主要作用是用于本地开发时导入和导出组件库到我们的平台；然后是组件共享平台，主要是存放组件库以及做一些组件的中心化管理；然后是一个 NGINX 转发服务器，它主要做一些跨域处理、缓存处理以及请求转发的工作，这样可以保证目标网站加载资源时是最新的状态。</p><p></p><p>接下来，看一下组件共享平台是如何工作的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/88/88f5c70728e761cacdeb48527544cda6.png\" /></p><p></p><p>首先发布一个组件库。用户可以在自己项目的根目录去执行一个 init 命令，然后我们会去生成 mf.config.js，这个 mf.config.js 需要去配置导出的那些组件，再配置一下 Webpack，然后去执行一个 mf export 命令，这样就可以去发布这个组件库。同时组件共享平台会去创建一个组件库，生成一个 OSS 资源，用户就可以通过 NGINX 服务器绑定的对应域名去访问到我们的资源。</p><p></p><p>那使用资源的时候是怎么做的？首先也是去用户项目的根目录去执行一个 init / import 这个组件库的名称，会拿到对应组件库的配置，之后回来生成 mf.config.js。然后再把远程的组件配置写到 mf.config.js 里面去，再进行一个 webpack 配置，最后你就可以在本地进行开发。当开发去访问这个远程资源的时候，NGINX 服务器在做跨域和缓存的处理，再把相关的资源返回给前端，这就是一个整体的流程。</p><p></p><p>接着分享下我们工作流里导出一个组件库的流程。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/27/2744869792d8db3c8510c3cf50ca961b.png\" /></p><p></p><p>首先导出组件库在执行 init 命令的时候，它会去生成一个 mf.config.js。在这里需要去定义一个 MF 应用的名称，以及对应的 ModuleFederationPlugin 的配置，需要写在 MF 的字段里面。然后还需要配置本地的编译命令以及对应的输出目录，同时再修改一下 webpack 配置，添加一个 ModuleFederationPlugin 就可以了。</p><p></p><p>下一步就是去执行 mf export 命令。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b0626e0d48c1357e2892fe01225a1405.png\" /></p><p></p><p>当我们去执行 mf export 的时候主要是做了三件事，首先是执行配置的 build 命令，打包编译当前项目，然后基于导出配置去生成一个 TS 声明文件，最后生成 Storybook 或是 Markdown 文档。这个在执行 init 命令的时候，可以自由去选择。把这三者结合起来就生成 MF 静态资源，然后将之上传至 MF 平台。这就是导出组件库的一个流程。</p><p></p><p>我们在使用组件库的时候也是去执行 init 或者 input 命令，拿到对应的组件库，然后去生成一个 mf.config.js，把对应的远程的配置帮你写进去，以及对应的 share 配置也会帮你写进去。再修改一下 webpack 配置，就可以在本地进行开发。所以整体的流程对用户项目的侵入性是非常低的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/74/7416797957627050a8c1d61563f75266.png\" /></p><p></p><p>再看一下 init 的时候，它中间还有一步可能会去下载和导入这个声明文件，以及生成一个初始文档。在导入声明文件以及生成这个初始文档的时候，会在本地项目增加一些文件。总体来说，这个方案是比较轻量的，不会对本地的项目有太多的侵入性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/66/663154b8113f924ac78c67aa18860935.png\" /></p><p></p><p>关于组件文档生成，我们推荐使用 <a href=\"https://www.infoq.cn/article/ppCkZkKx0rr9z55w*GFJ\">Storybook</a>\" 来写组件使用文档以及组件预览，脚手架工具会自动根据本地 Storybook 配置去寻找导出组件的 Storybook 并打包编译。如果本地没有 Storybook 配置，你也可以选择使用 Markdown 作为组件文档。</p><p></p><p>因为 MF 更新是实时更新，只要发布了就会更新，我们也提供版本化的功能，类似 NPM 的版本流程，但区别是无需更新版本后重装依赖。有时线上的某个 MF 资源非常重要，为了确保发布之后不会出现问题，可以打开发布控制功能，它可以限制团队里的成员随意发布 MF 资源。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ed/ed7eb684a240adc5095f6d5b2fcaf27c.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5d/5d9a2073633088346cb508a25b4f1ff3.png\" /></p><p></p><p>如果说你的组件库打开了这个发布控制开关，在你发布这个组件库的时候，它不会直接去覆盖线上的资源，会先去生成一个测试的 remote，之后它会去消息通知到每一个使用组件库的使用方。使用方拿到这个测试的 remote 就可以根据本地的环境配置，去配置测试环境的 remote，如果测试成功，就可以回到平台进行点击发布上线的按钮，然后去覆盖线上的 remote。为了确保万无一失，我们在覆盖线上 remote 的时候会去生成一个发布记录，这个发布记录你可以将它回滚，如果你发上去后发现有问题，可以拿以前的发布记录再给它回滚一次，它就会把以前的发布内容回滚到线上。</p><p></p><p>我们已经基于这套工作流，成功的使用了 MF 。我们的前台项目使用了原子组件库、以及业务组件库，这些组件库都是非前台团队开发的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3a/3a1da36a34138a0e9a9f22a0f05c58c3.png\" /></p><p></p><p>从这个图里可以看出后台团队开发的原子组件库应用到了前台，以及这里的业务组件库用在了 3 个平台上，这都是通过访问组件共享平台的资源实现的。我们的前台、运营平台、编辑器都使用到了业务组件库的组件，然后前台和运营平台都使用了同一套的原子组件库。这样的话整个设计标准进行了统一。</p><p></p><h4>5. 总结与展望</h4><p></p><p></p><p>最后，我们打造了这样一套组件共享工作流，它对我们团队来说有些什么收益以及对未来的展望呢？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a8/a88de44e643a783b3349e992115dcb1a.png\" /></p><p></p><p>首先，通过实现基于 MF 的组件化共享工作流，我们搭建起一个组件共享平台，沉淀了不同团队的研发资源，同时组件研发负责人通过该平台进行中心化管理，可以做到组件检索、版本管理、发布控制、资源共享、权限控制等这些操作。同时基于这套工作流我们实现了高效的组件共享协作模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/81/81bb1b901e4dd1c6bd0c319f61dae161.png\" /></p><p></p><p>旧的流程我们可能直接 copy 代码或是用 npm 包的方式去引入，这样带来的问题就是组件更新链路非常长或者是非常难维护。新的流程我们就直接进到 MF 平台去寻找所需的组件，如果有的话直接 input 到本地的项目，就可以去进行开发和预览了。当它更新的时候，只需要更新对应的组件库就可以了。</p><p></p><p>当然，目前该平台还存在一些问题：首先，组件使用上，用户只能去平台进行检索查找，为了更加方便开发者去使用以及提升整个平台的生态，我们后续会开发一个 VSCode 插件，方便大家更好地使用平台组件。其次，目前 MF 是基于 webpack 5 这个脚手架工具实现的，之后会考虑其他打包工具的适配，因为有些项目可能是用 rollup 或者是 vite 去开发的，当然目前社区上已经有一些插件实了 rollup 或者是 vite 的 MF 的适配。最后就是我们也尝试在一个微前端项目中使用 MF 组件，不过也遇到了一些问题，大体上 MF 是可以替代目前的微前端框架的，我们也会尝试去探索基于 MF 的微前端框架，比如做一些像是沙箱隔离、样式隔离等。</p><p></p><p>最后一句话结束本文的分享，“用 MF 的最好时机，就是现在”。</p><p></p><h4>作者介绍</h4><p></p><p>陈俊生，零售平台业务中心高级前端工程师，凹凸实验室成员，2018 年加入京东。目前主要负责羚珑智能设计平台的技术架构开发。曾经主导过京东设计资产平台以及京东 D2C 产品 DECO 编辑器技术架构设计与开发。专注于前端技术架构 / 工程化 / Node.js 服务领域，具有较为丰富的实战经验与较好的技术视野。</p><p></p><h4>活动推荐</h4><p></p><p></p><p>将于 10 月 30-31 日举办的<a href=\"https://gmtc.infoq.cn/2022/beijing/schedule\"> GMTC 全球大前端技术大会（北京站）</a>\"上，来自阿里的前端技术专家<a href=\"https://gmtc.infoq.cn/2022/beijing/presentation/4579\">光弘</a>\"老师将分享《基于 LowCodeEngine 的阿里低代码组件体系的建设和实践》，带你了解低代码组件为组件研发领域带来的变化以及机会点。此外，本次 GMTC 北京站还设置了 <a href=\"https://gmtc.infoq.cn/2022/beijing/track/1312\">TypeScript</a>\"、<a href=\"https://gmtc.infoq.cn/2022/beijing/track/1317\">跨端技术选型</a>\"、<a href=\"https://gmtc.infoq.cn/2022/beijing/track/1326\">前端 DevOps 实践</a>\"、<a href=\"https://gmtc.infoq.cn/2022/beijing/track/1303\">IoT 动态应用开发</a>\"、<a href=\"https://gmtc.infoq.cn/2022/beijing/track/1350\">大前端监控</a>\"、<a href=\"https://gmtc.infoq.cn/2022/beijing/track/1311\">移动端性能与效率优化</a>\"等共 12 个专题，50+ 大厂技术专家现场分享，<a href=\"https://gmtc.infoq.cn/2022/beijing/schedule\">点击此处</a>\"查看更多精彩内容，感兴趣的同学联系票务经理：+86 18514549229</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/43/43a5111fb90f1d159d7ddb77c68bcabd.jpeg\" /></p><p></p>",
    "publish_time": "2022-09-13 16:53:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我们可以对数字化报以多大期望值？| 第三期完整版（下）",
    "url": "https://www.infoq.cn/article/ymjYEy8q6dF3egDpuqs4",
    "summary": "<p>《行知数字中国》第三期，InfoQ邀请到了过去30年亲历过中美高科技行业、零售业、金融业和制造业等不同行业的 IT 老兵向江旭。</p>\n<p>他曾在引领科技创新潮流的硅谷深耕技术研发，回国后赶上中国蓬勃发展的移动互联网时代，又以技术管理者的身份亲历了数家企业的数字化转型历程，在一次次跨越边界、不断探索的过程中，他对”数字化转型“的理解始终如一。</p>\n<p>在本期视频中，他将结合其亲身经历，分享数字化转型和创新的经验和教训。</p>",
    "publish_time": "2022-09-13 16:56:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "图数据库和知识图谱在微财风控系统中的探索和应用",
    "url": "https://www.infoq.cn/article/iOokIrlEdQkx7uaqhvKc",
    "summary": "<p>近年来随着监管力度的不断提升，金融机构业务的不断发展，交易方式越发便利的背景下。客户、账务、资金等关系也越发复杂，黑产也更加隐蔽，对内部风控要求也在不断加强。传统的关系型数据库在这种复杂的关系网络上发挥的效果越发有限，在多维度的查询上很难在合理的时间内返回结果。图数据库作为复杂关系网络分析的一个强有力的工具，如何高效的发挥其在高性能、高扩展、高稳定性方面的能力，显得至关重要。</p><p></p><h2>1 当前图数据库和知识图谱的现状和存在的问题</h2><p></p><p></p><p>图数据更接近于自然社会中的关系，很好的解决了复杂关系网络的查询性能问题，其更能快速的发现隐藏关系，弥补了分析手段上的缺失。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cf/af/cff688c139f0d34303556f3yyfd5c2af.png\" /></p><p></p><h3>1.1 风控领域内使用现状</h3><p></p><p></p><p>作为知识图谱存储和展示的核心，图数据库商业化和开源社区都有很多选择。如：阿里云的GDB、腾讯的KonisGraph、Nebula Graph、Neo4j、JanusGraph等；借助于图数据库为领域知识的积累、业务降本提效、风险预测等提供有力支持。</p><p></p><p>知识图谱作为图数据库广泛和基础的应用，在目前业内风控领域</p><p></p><p>1.&nbsp;贷前：</p><p></p><p>欺诈团伙挖掘：基于专家经验的团伙挖掘、自动规则挖掘。风险事件预警：基于新客户对风控场景影响，触发风险事件达到预警效果。</p><p></p><p>2.&nbsp;贷中：</p><p></p><p>交易转账：实时跟踪资金流向和交易信息在线预测。风险跟踪：实时跟踪异常指标，扫描客户风险，实现风险早发现早阻断。</p><p></p><p>3.&nbsp;贷后：</p><p></p><p>洗钱欺诈分析：根据多度交易行为快速甄别可疑交易。失联修复：为已经失联的客户提供中间人联系。</p><p></p><p>等方面都发挥着极其重要的作用。</p><p></p><h3>1.2 在微财使用现状</h3><p></p><p></p><p>随着好分期金融产品业务的不断发展，信贷业务相关数据也在⽇益增多。这些数据原先也只作为⼀些外部信息存储，⽆法形成有效的知识，更谈不上构建知识图谱来为公司提供推理和预测。为此综合已有的信贷业务基础数据，历史交易数据及⾃有的和三⽅的⻛险数据等，使⽤图数据库构建成的关系⽹项⽬，通过实体与实体之间的关系，快速挖掘⽤户特征，涉⿊分析，并基于已有的⿊名单挖掘隐藏的团伙关系等，成为反欺诈中的关键⼯具。</p><p></p><p>主要有以下应用场景：</p><p></p><p>1.&nbsp;为贷后提供失联信息修复：支持通话记录，附近地址，同IP设备号等维度联系人修复。</p><p>2.&nbsp;可视化及用户画像：提供子图展示，关键路径提示，用户画像展示功能。</p><p>3.&nbsp;图特征支持业务：根据图计算提供各种聚类特征，供模型和策略使用。</p><p>4.&nbsp;欺诈团伙挖掘：根据已有黑名单欺诈人员，基于多维度关联聚类算法，实现欺诈团伙的挖掘。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/49/ee/49a1f28c5031b1c4cb9666e2bb7866ee.png\" /></p><p></p><p></p><h2>2 微财实践过程中遇到的一些问题</h2><p></p><p></p><p></p><h3>2.1 前期数据如何制备及入库，实现冷启动</h3><p></p><p></p><p>对于图数据库的构建，离线基础数据的导入是前提，在Hive中我们存有4T左右的数据需要导入, 如此大的数据量，制备成需要的格式数据导入比较困难，并且要满足性能上需要是难点。</p><p></p><p>解决方案：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/69/0b/692f2a424d933e237e9c53ace813900b.png\" /></p><p></p><p>针对海量数据制备导入，JanusGraph提供了bulk loading方式导入，但是基于Hadoop支持三种导入数据的格式：GryoInputFormat/GraphSONInputFormat/ScriptInputFormat。我们选中的是GraphSON格式，这种数据格式与Json较为类似，方便理解转换，但是也有一定的区别。为此我们自定义了一种数据格式FlatGraphSON，使得从Hive table中抽取数据后，便于MapReduce任务读取数据，制备成GraphSON格式数据。</p><p></p><p>FlatGraphSON是一种介于GraphSON和Hive table之间的数据格式，是Hive加工各类数据的结果格式， 又是用于生成GraphSON格式图数据的数据格式。</p><p></p><p>具体定义如下：</p><p></p><p>边的格式为: 'EDGE' # from_vertex_value # to_vertex_value # [property_name : property_value]顶点的格式为: 'VERTEX' # vertex_value [ # property_name : property_value [: meta_property_name : meta_property_value]&nbsp;]</p><p></p><p>Hive生成数据后，通过MapReduce任务读取对应HDFS文件处理生成的GraphSON格式数据，最后使用bulk loading方式导入。其中有一个问题是官方bulk loading当时还不能提交到Spark Yarn上，需要改造源码以提高性能。</p><p></p><p></p><h3>2.2 落地部署怎么做到平滑切换</h3><p></p><p></p><p>风控系统处于整体业务中的核心环节，对于稳定性以及服务持续可用性要求很高</p><p></p><p>线上服务不能暂停，服务请求不能丢失；必须使用完整的图数据提供风险计算结果（生成风险特征等。</p><p></p><p>当遇到例如新增数据源、修改图数据库schema或是上线新图，需要对系统进行升级重启操作时，如何能保证服务的持续可用性呢？</p><p></p><p>解决方案：</p><p></p><p>1.&nbsp;建立两个完全一致的图，可以在通过HBase 的clone_snapshot复制表方式快速实现，部署两套相同的服务分别读取两个库。两套系统可以通过不同的consumer-group消费消息。</p><p>2.&nbsp;在数据库中设置标志位例如0和1，每次只有一个系统对外服务，另外一个系统作为备份库。</p><p>3.&nbsp;当需要升级图时，通过标志位控制，比如现在1处于备份状态，0处于上线状态，我们可以先对1系统进行升级。升级结束后再将标志位换成0，让升级好的系统对外服务，然后再对0系统进行升级。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/81/1c/819d80db454207a04151a05ca7ce991c.png\" /></p><p></p><h3>2.3 超级节点处理</h3><p></p><p></p><p>图数据库中不可避免的问题就是super vertex，其带来问题：</p><p></p><p>顶点的度数服从幂律分布，（比如通讯录中的名人，或者百度地址等）一般图中都存在super vertexMapReduce框架下数据清洗时，单个key对应极多value会导致reducer OOMHBase（JanusGraph存储端）column有极多会导致性能急剧下降图遍历时节点过多会导致查询爆炸</p><p></p><p>解决方案：</p><p></p><p>1.&nbsp;对于确定没有任何实际意义的实体(比如设备号：00000000-0000-0000-0000-000000000000, 00000000)直接过滤掉</p><p>2.&nbsp;不能过滤掉，边等价转换为顶点属性集合（成为属性边），使用时即可直接使用属性进行过滤，将原先50多亿条边缩减为10多亿条</p><p>3.&nbsp;另外对应geo范围查询节点过多导致性能急速下降问题，可以采用limit方式配合实际业务进行截断，以达到性能要求</p><p></p><p></p><h3>2.4 图数据可视化展示</h3><p></p><p></p><p>如何直观的看到实体间的联系，方便策略和模型同学观察发掘特征，可视化是关键。Cytosacpe.js是桌面版Cytosacpe对应的JavaScript版本，对于桌面版我们在过去以及最近的分析中已经用到，对于JavaScript版本在先前的项目中也用其做过demo，从使用体验来看还是比较方便的，做出的图也比较酷炫。可以比较完美的展示关系网的联系，并做一些定制化。</p><p></p><p>成果：某条包含黑名单用户的路径</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6c/fb/6c3cbdf530080bcd8a8746cd5eb0f8fb.png\" /></p><p></p><p></p><h2>3 上线后的效果</h2><p></p><p></p><p></p><h3>图特征支持业务</h3><p></p><p></p><h4>案例一：GPS80米范围内放款审核失败用户数</h4><p></p><p></p><p>之前对于这种场景，我们需要先去获取数据库中用户下单时最近一次采集到的GPS信息，通过GPS经纬度信息获取到范围内对应的用户（这一步需要配合Mysql 的空间索引或者依赖Redis GeoHash来实现），再通过用户去进件表中查找其对应的进件，筛选出失败的进件用户。</p><p></p><p>解决方案：</p><p></p><p>需要用到JanusGraph中的Geoshape类型 ，JanusGraph默认结合Elasticsearch作为混合索引存储引擎，其可以方便快捷的获取GPS半径内的Vertex，先通过用户对应GPS地址，查找范围内其余用户，继而再通过用户，筛选出放款审核失败的用户，统计其数量。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/56/ef/56136e2d73a1f6f16044893507afdcef.png\" /></p><p></p><p>具体代码如下：</p><p></p><p><code lang=\"text\">GraphTraversal vertices = g.V()\n.has(GraphConstants.P_V_GPS, geoWithin(\n// lat, lng, radius in km\nGeoshape.circle(\n((Geoshape)point.get()).getPoint().getLatitude(),\n((Geoshape)point.get()).getPoint().getLongitude(),\nkm\n)))\n.as(\"x\").select(\"x\")\n.out(GraphConstants.E_APPLICATION_ID).out(GraphConstants.E_LEND_VERIFY_ID)\n.has(GraphConstants.P_V_IS_FINAL_PASSED,0).count();</code></p><p></p><p>注意：当需要插入数据后立马进行查询需要加上配置index.[x].elasticsearch.bulk-refresh=true，否者可能会导致查询不到当前插入的点，导致数据丢失。（[x]表示用户名称，也就是配置index.search.backend中的search）</p><p></p><p></p><h4>案例二：同一设备号近30天内有过申请授信的IP数</h4><p></p><p></p><p>这场景下需要通过进件用户的设备号，相同设备号关联出最近30天内有过申请授信的用户，这些用户对应的IP数量。通过对IP数量的分析可以获知是否是团伙作案的可能。传统实现下我们需要通过设备表关联出用户，然后用户表关联授信表，再关联IP表才能获取到数据，这需要关联四张表，关联的数据量已经爆炸。</p><p></p><p>解决方案：</p><p></p><p>通过设备号查出入边的用户顶点，筛选出其中有过进件的用户顶点，再而统计用户顶点出边对应的IP顶点数。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/d1/16/d11361b1401ee2055a99f06834acbf16.png\" /></p><p></p><p>具体代码如下：</p><p></p><p><code lang=\"text\">g.V(userKey)\n    .out(GraphConstants.E_DEVICE_TOKEN)\n    .in(GraphConstants.E_DEVICE_TOKEN)\n.as('x')\n    .out(GraphConstants.E_APPLICATION_ID)\n    .select('x')\n    .out(GraphConstants.E_IP).count();</code></p><p></p><p></p><h3>欺诈团伙进行挖掘</h3><p></p><p></p><p></p><h4>案例一：团伙发现</h4><p></p><p></p><p>正所谓“近朱者赤近墨者黑”、“人以类聚，物以群分”，通过已有黑名单系统，在关系网络中的染黑计算，我们可以得知坏人推荐坏人来，好人推荐好人。根据用户wifi实体是否关联多个高风险用户、黑名单用户之间是否有公共联系人、黑名单客户之间的公共路径和节点等，我们可以快速的定位到欺诈团体，对其进行快速封杀。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/91/47/91a6256f7b9862f21e9afbfcd65c8847.png\" /></p><p></p><p>由此可见在图数据库中业务实现逻辑清晰，无需额外维护Elasticsearch中的索引数据，对于多维度的关联关系可以很自然的关联起来，减少关联的复杂度，无需耗时耗内存的join操作，相对应查询性能上也可以有很大的提升。目前图数据库中存放了近20亿条边和1.8亿个顶点，为线上提供1800+特征计算支持 ；挖掘出26w个短号和15w个公共服务电话；拦截发现欺诈团伙一千多次。</p><p></p><p></p><h2>4 未来规划</h2><p></p><p></p><p></p><p>1.&nbsp;图实时计算服务和特征挖掘：完善目前的关系网，打通与数仓的屏障，搭建一站式平台实现图数据查询和分析，图模型管理对接功能。开发自动化特征挖掘以及风险预测功能，实现规则引擎自动化预警拦截。</p><p></p><p>2.&nbsp;构建图形推理功能：基于逻辑推理和概率推理两种方式，结合现有的推理算法，开发推理功能减少人审带来的误判、漏判行为，保证风控的精准度，为分析人员提供更多的参考。</p><p></p><p>3.&nbsp;非结构化数据NLP处理：包含自然语言的消歧分析以及针对目前公司所有数据进行分类，搭建数据清洗平台，使非结构化的数据能够被快速筛选、保存和利用起来。</p><p></p><p>4.&nbsp;Graph3.0架构探索：在高性能、高扩展、运算快、智能化等方面进一步突破。</p><p></p><p>风控和黑产的对抗一直都在，未来也将持续下去，只有不断的提升攻防水平，才能将各种风险降到最低，微财在这方面也将继续不断的探索前进。</p><p></p><p></p><h4>作者介绍：</h4><p></p><p></p><p>梁军 微财数科 高级工程师</p><p>吴迪 微财数科 产品技术负责人</p><p>李军 微财数科 技术总监</p><p>李俊永 微财数科 资深工程师</p><p>周正杭 微财数科 资深工程师</p>",
    "publish_time": "2022-09-13 17:25:48",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Uber是怎么改进A/B测试实践的",
    "url": "https://www.infoq.cn/article/CzZVxqt00YFa5hMehi4r",
    "summary": "<p></p><p>作者 | Sergey Gitlin、Krishna Puttaswamy、Luke Duncan、Deepak Bobbarjung、Arun Babu A S P</p><p>译者 | 平川</p><p>策划 | Tina</p><p></p><p>摘要：经过一年多的努力，我们为 Uber 的试验和特性标记生态打下了坚实的基础，相关的一切都已经转移到了新系统上，包括 2000 多名开发人员、集成的超过 15 个合作伙伴的系统、10 多个移动应用、350 多个服务。我们弃用了 Morpheus 中超过 5 万个过时的试验。</p><p></p><p>本文最初发布于 Uber 工程博客。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e1/e1ac08e1f3e5d593bdc53c6b88a21d83.png\" /></p><p></p><p></p><h2>简介</h2><p></p><p></p><p>“在劣质数据上费力进行计算，也许可以将收益从 95% 提高到 100%。5% 的收益，总数也许并没有多少。但在时间和人力成本相同的情况下，对收集过程或是试验设计来一次能力范围内的彻底整改，经常可以将收益提高 10 到 12 倍。在试验结束后咨询统计学家，就好比要让他做尸检。或许他可以告诉你死因。但是，为了利用他在这方面的经验，就必须诱导他发挥想象力，让他可以提前预知其中的困难和不确定性，如若不然，他的调查也会困难重重。”（R. A. Fisher 在第一届印度统计学大会上的主席致辞）<a href=\"https://www.gwern.net/docs/statistics/decision/1938-fisher.pdf\">https://www.gwern.net/docs/statistics/decision/1938-fisher.pdf</a>\"</p><p></p><p>尽管 A/B 测试的统计学基础已有百年之久，但在规模很大的情况下，构建一种正确可靠的 A/B 测试平台和文化仍然是一项巨大的挑战。按照 Fisher 的上述观点，仔细构建 A/B 测试平台的构建块，确保收集到的数据都是正确的，对于保证试验结果的正确性至关重要，但这个过程很容易出错。Uber 经历过一段类似的旅程，本文就是介绍我们为什么以及如何重建 Uber 的 A/B 测试平台。</p><p></p><p>Uber 有一个名为 Morpheus 的试验平台，是 7 年多以前构建的，兼具特性标记和 A/B 测试功能。从那时开始，Uber 就在范围、用户、用例等方面对 Morpheus 做了大幅扩展。</p><p></p><p>2020 年初，我们在深入观察这个生态系统之后发现，有很大比例的试验存在致命的问题，经常需要重跑。要想获得高质量的结果，就需要对试验和统计学有专家级的理解，还需要完成大量艰辛的工作（自定义分析、管道化等）。这会降低决策速度，而且经常需要重新运行效果不佳的试验。</p><p></p><p>在评估了用户问题和 Morpheus 的内部结构后，我们得出结论，其核心抽象所能支持的试验设计非常有限，即使与这些设计的差异很小，也会导致对照组（control group）和试验组（treatment group）的用户无法对比，对试验结果产生不利的影响。举一个非常简单的例子，在逐步推广一个对照组用户和试验组用户三七分的试验时，由于推广和试验组分配逻辑的特殊性，推广到 10% 的用户没有问题，但推广到 5% 的用户就不行。此外，该系统无法支持 Uber 多样化的用例所需要的高级试验配置，或其他大规模试验所需要的高级功能，如监控 / 回滚对业务指标产生负面影响的试验。因此，我们决定用恰当的抽象从头开始重新构建一个平台。</p><p></p><h2>我们要在系统中实现什么目标？</h2><p></p><p></p><p>我们的目标是让公司可以敏捷地、高质量地运行各种试验。</p><p></p><p></p><h3>高水平的质量保障</h3><p></p><p></p><p>在公司中，试验系统的作用是通过提供试验结果的可信洞察来为决策赋能。为此，一个好的试验系统应该始终提供正确的结果，保证：</p><p></p><p>决策过程有良好的信息支撑，使所做的决策（有望）是好决策；结果普遍可信，使团队能够结合实际情况迅速采取行动，而不需要无休止地重新调查令人惊讶的试验结果，重新运行有问题的试验，并基于二次猜测做出决策。</p><p></p><p>Morpheus 的工作方式使它只适用于简单的试验，除此之外就很难保证结果是正确的。加之 Uber 的试验要求多样而复杂，这导致很多数据有问题，造成了巨大的浪费：人工调查和分析以及重新运行试验都很常见，这会拖慢开发速度，并分散对其他优先事项的注意力。有时，试验结果有问题，却没有人意识到。</p><p></p><p>新系统应该提供有保证的正确结果：无论用户选择什么样的试验设计，任何人都可以相信试验结果，不需要自定义的验证，也不需要对统计学的深刻理解或对平台的详细了解。</p><p></p><p>除了统计学上的正确性，系统可靠性也是试验平台所必须的，因为那是公司运营中非常核心的内容。我们现有的试验系统是 7 年多以前开发的，当时是作为软件栈中的一个可选依赖。然而，多年来，特性标记已成常态，试验系统成为移动应用和后台服务的必备依赖。用户思维发生了这样的转变，但系统却没有及时跟进。当后台没有响应时，客户端就会因为故障自动关闭，导致所有移动应用和后台服务都因试验栈的故障而严重瘫痪；多年来，我们已经多次遇到过这样的故障。我们希望，新系统能提供适当的保护措施，以确保 Uber 的服务对试验系统的故障有很好的容错性。</p><p></p><p></p><h3>高水平的用户生产力</h3><p></p><p></p><p>最终用户主要通过移动应用来使用 Uber。但 Morpheus 的性质使我们很难在这些应用上进行试验。在 Morpheus 的编程模型中，试验组是在客户端代码中指定的（见下图）。因此，试验的修改（如新增一个试验组或修改现有的试验组）需要一个构建 - 发布周期，这会把我们的速度拖慢 2-4 周。为了解决这个问题，我们希望尽可能地将试验与代码变更解耦，以便创建 / 删除 / 修改试验时可以不用等待移动应用构建 / 发布。此外，我们希望简化客户端接口，并对客户端隐藏试验配置和服务的复杂性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/56/56bcfdd948f24af89a0e0613411e30bf.png\" /></p><p></p><p>图 1：试验感知伪代码</p><p></p><p>第二个问题是，在 Uber 快速发展期间，我们的配置栈出现了碎片化。我们有一个针对试验和移动特性标记的配置系统，还有一个针对后端配置和后端特性标记的软件。移动和后端用户工作流完全隔开了，使得同时涉及移动和后端服务的试验很难做，我们需要付出双倍的努力来添加与安全 / 合规等相关的特性，而且，由于系统的细微差别所导致的问题也很难调试。此外，碎片化意味着更高的维护成本。</p><p></p><p>第三，试验分析的局限性成了数据科学家最大的辛苦之源。构建这个分析生态系统只是为了支持用户随机试验。对任何新的随机化单元做分析都需要自定义管道和设置，使得管道在不同的组织出现了多种变体，导致了不一致。分析中使用的指标也没有标准化。用户使用他们自定义的指标，不同的组织有不同的指标，无法横向比较。领导层很难推断和比较各组织的试验影响情况，甚至很难对跨组织的试验做出一致性的评价，然而，随着 Uber 成为一个业务线交叉的统一平台，这种需求却越来越常见。此外，由于该系统在生成对照组 / 试验组时经常会出现系统性的不平衡，所以进一步开发分析功能并不可行（例如，我们以前尝试开发过监控试验负面影响的功能，那从一开始就注定要失败）。</p><p></p><p></p><h3>灵活支持多样化的试验设计，匹配 Uber 的各种产品开发需求</h3><p></p><p></p><p>虽然有一些试验用例可以通过将分组比例固定为 50/50 来解决，但许多用例都需要更复杂的设置。新系统设计的一个关键需求是支持 Uber 遇到的各种用例，并能满足未来的潜在需求。</p><p></p><p>试验通常需要运行复杂的逻辑，而这些逻辑决定了试验何时何地上线，以及在试验过程中哪一部分用户可以获得新产品。在试验过程中，有时会因为外部因素修改这些逻辑，有时候，这些随时间推移而进行的修改成了试验设计的关键组成部分。需要在不同的粒度级别上运行试验；用户需要随机化的单元类型可以随用例变化。需要跨后端、移动端、Web 界面或它们的组合运行试验。有许多用例需要分层试验，如：涉及多个自定义特性的保留分组；依赖试验和特性标识；在多个不同的试验之间划分流量；用于不同试验的多个保留分组。在某些情况下，同一个特性需要单独在不同的区域 /App/ 操作系统上测试。所有这些灵活性需求的满足都应该以不增加客户端代码开发的复杂性为前提。</p><p></p><p>除了上面提到的功能，新的系统设计应该能够满足未来广泛的扩展需求，而且不需要进行大的架构调整。</p><p></p><p></p><h2>架构</h2><p></p><p></p><p>在这一节中，我们将介绍新平台架构的核心概念。</p><p></p><p></p><h3>参数——将代码和试验解耦</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/191da4718f147d6261397309b79881a0.png\" /></p><p></p><p>图 2：配置驱动的 A/B 测试伪代码</p><p></p><p>利用参数将代码和试验解耦。客户端（移动或后端）代码不会引用试验名称或试验组，而是根据参数值生成分支。参数总是会有一个安全的默认值（通常相当于“对照”路径），以确保在没有重写值或由于网络问题而未能收到重写值时，客户端可以顺畅运行。</p><p></p><p>试验被设置为在后端重写参数的值。参数是客户端唯一可见的概念——可以在后端设置任意数量的试验，为给定的参数或参数集提供不同的值，但客户端并不知道这些试验的存在。根据调用期间传递的上下文，不同的客户端可能接收到不同的参数重写值。后端服务根据上下文向客户端传递参数值，与参数值分支相关的客户端代码就会执行。如果试验人员确定需要一个与起初完全不同的试验设计，那么他们只需禁用当前试验，并使用相同的参数设置一个新试验——不需要修改代码。同样，在旧试验结束后，可以使用相同的参数运行新试验以测试新想法。</p><p></p><p>上图展示了客户端和服务器之间的调用流，以及参数和试验之间的关系。</p><p></p><p></p><h3>统一配置和试验栈</h3><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/68/68183792c80614b89920c3082d49048a.png\" /></p><p></p><p>图 3：统一 A/B&amp; 远程配置架构</p><p></p><p>我们选择将试验构建为 Flipr 之上的一个覆盖层。Flipr 是 Uber 的后端配置系统，其中存放了参数，如果要基于参数运行一个试验，就可以自动调用试验系统获取参数的重写值。要不然就使用默认参数值。这一决策将移动端、后端和试验配置全部统一到了一个系统中，提供了重用支持，统一了开发工作流，使得跨不同端面（surface）运行试验变得简单了。</p><p></p><p></p><h3>试验</h3><p></p><p></p><p>我们的试验系统只基于一个概念，即试验（experiment），完全没有其他结构：没有单独的保留结构（holdout constructs）、流量分割器、层 / 域等。更复杂的试验功能可以以试验为基础构建出来，如下所述。</p><p></p><p>试验的核心包括 3 个关键组成部分：</p><p></p><p>随机化：单元映射到试验组的方式；试验计划（treatment plan）：从上下文和单元随机化（试验组）到行动（参数值）的映射；日志：记录试验附加信息的辅助结构。</p><p></p><p></p><h4>随机化</h4><p></p><p></p><p>试验基础：我们需要一些随机的东西，和试验单元、环境或其他任何信息都没有关系；这种随机性有助于我们区分，在其他条件完全相同的环境中，针对其他条件完全相同的试验单元所采取的行动。</p><p></p><p>在特定的试验中，我们使用一个由试验键值决定的盐对单元标识符进行散列，从而随机化单元。试验键值是唯一的，这就可以保证，只要 Uber 的其他系统没有使用相同的散列逻辑，所有试验经过随机化后都是彼此独立的。</p><p></p><p>更具体地说，在我们的构建中，单元的桶（bucket ）为该单元的哈希值与试验中指定的特定模数（通常为 100）的整除残差。从结构上看，单元的桶在给定的试验中永远不会变，而且很容易复制。</p><p></p><p>试验组是多套桶。在实践中，我们将所有试验组组织成一棵树，树中的每个节点（试验组）都是一组范围连续的桶。例如，在一个将单元分成 100 个桶的试验中，根节点是 all_units，桶为 [0…99]，可划分为 control[0…49] 和 treatment[50…99]。试验组可以根据需要进一步拆分，例如，可以将 treatment[50…99] 分为 t1 [50…59]、t2 [60…69] 和 t3[70…99]。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7a/7ad65e3dc45d3fd540b8d7d3ceaab3d7.png\" /></p><p></p><p>图 4：试验组分配</p><p></p><p>拆分试验组的能力让我们能够设计更复杂的试验，在试验执行过程中并入更改（例如，在试验运行时将控制体验反馈给更多的用户）。</p><p></p><p></p><h4>试验计划</h4><p></p><p></p><p>试验计划规定了在每种上下文中对每个试验组做什么。</p><p></p><p>上下文（Context）是我们所掌握的关于一个试验单元的知识，包括地理信息，如用户所在的城市或国家，设备特征，如操作系统（iOS 或 Android），以及其他在试验评估时可能用到的信息。</p><p></p><p>在我们系统中，行动（Action）就是我们返回的参数值，即受试验影响的参数（一个试验有一个或多个受影响的参数）。</p><p></p><p>例如，我们可以考虑在旧金山运行一个和特定按钮颜色有关的试验。在这种情况下，试验将声明基于参数 button_color 进行操作，与 context.city = San Francisco 匹配的对照单元 button_color = green，同一上下文下的试验单元 button_color = black。所有不在旧金山的单元，按钮会有一个默认的颜色，可以是绿色、黑色、蓝色或其他任何颜色。</p><p></p><p>上下文的某些方面也可以随机生成：例如，为了逐步推广试验，我们使用（伪）随机生成的推广桶，其中，推广随机化与试验组分配无关。</p><p></p><p></p><h4>相同参数的多个试验</h4><p></p><p></p><p>作为试验计划的一部分，试验人员可以声明试验需要捕获上下文空间的哪些部分供其专用，以及哪些部分可以用于运行相同参数的其他试验。这样，就可以在不同城市、不同设备操作系统或其他需要的上下文子集上独立运行不同的试验，只要相同参数的试验不存在重叠即可。我们利用一个自定义的逻辑引擎，在配置时检测是否有两个影响相同参数的试验存在重叠，只要不重叠，就可以创建或更新试验。</p><p></p><p></p><h4>日志记录</h4><p></p><p></p><p>要想具备强大的试验分析功能，正确的数据不可或缺。试验日志的目标是找出该单元什么时候第一次暴露在给定是试验中——例如，单元处于这样一个情况：在不同的试验组中为单元提供了不同的参数值。实现方法是在访问被试验重写的参数时发出日志消息。在一个分布式系统中，要知道哪是第一次暴露并不容易，所以我们会在每次访问参数时发出日志消息，并稍后在数据管道中对这些日志做去重处理。</p><p></p><p>在单元所处的上下文中，如果所有试验组指定的参数值都相同（即单元体验没有差异），则不会发出日志消息。这样做的原因是，如果体验没有差异，也就不会有需要评估的影响，所以就没必要记录日志了。最后，日志发送对客户端代码来说是透明的。</p><p></p><p>虽然日志记录的理念很简单，但在工程上，要保证任何日志数据都不丢失是一项不小的挑战，尤其是在规模很大（远大于每秒 1M 条消息）的情况下。我们需要仔细优化和组织日志记录代码，尽可能避免未向用户提供体验却记录了数据的情况，反之亦然。但是，一旦记录了数据，基于日志对试验做实际的分析就完全与服务和配置层解耦了。只要配置和服务层记录并提供试验组分配外生的单元簇（cohorts），分析就可以以此为基础，专注于从有效的试验中获取最大价值。</p><p></p><p></p><h4>正确性</h4><p></p><p></p><p>虽然正式阐述系统特性超出了本文的范围，但值得注意的是，在这里介绍的架构中，无论用户选择什么样的试验设计（配置），所有的试验组都可以相互比较——除了实际的效果之外，它们之间不会有系统性的差异。只要在第一次接触到有差别的体验之前（这在我们的系统中就是返回有差别的参数值），描述上下文和 / 或决定分析中包含哪些单元（例如，第一条日志）的任何东西都独立于试验组分配，就可以保证这一点。</p><p></p><p></p><h3>参数约束</h3><p></p><p></p><p>上一小节介绍了试验是什么。我们如何在这个简单的结构与复杂的分层设计之间架起一座桥梁呢？答案就是参数约束。</p><p></p><p>试验可以把城市位置或设备操作系统作为其试验计划的约束条件（例如，试验只在美国的 iOS 系统上运行），类似地，它也可以将其他参数作为该逻辑的一部分。例如，用户可以选择只在满足约束条件 parameter_a == true 时运行试验。鉴于参数可以由试验来控制，这就为各种有细微差别的设置打提供了可能，满足了现实世界的用例——由于试验是随机化的，而且相互独立，即使试验设置很复杂也没问题。唯一的限制是，要避免循环依赖（确保依赖图是一个 DAG）。</p><p></p><p>以下是参数约束支持的部分用例：</p><p></p><p>流量划分。将这一特性与在相同参数上运行多个试验的能力相结合，我们就可以利用 traffic_splitter 试验控制 traffic_slice 参数将流量随机分片，并运行不同的下游试验，每个试验都包含一个约束条件，如 traffic_slice==“A”，并且只控制其所在分片的参数值。保留组（Holdouts）：这个基元也使得保留组成为可能。我们可以有个试验创建一个 Uber 级的保留组（通过设置参数 uber_holdout = true），然后是组织级的保留组，用于未被 uber_holdout 捕获的单元，再然后是更小的团队级的保留组。保留试验本身也可以有复杂的配置，如指定 Uber 员工或高管不包含在保留组中，以便他们可以快速体验产品变化，或者只在特定的地理区域应用保留组逻辑。依赖试验 / 特性标识。有时候，只有在启用了特定特性时试验才能运行——但该特性本身可能还在试验阶段，或者有复杂的推广逻辑，用于确定哪里可以用，哪里不可以用。在这种情况下，下游试验可以引用启用主特性的参数，并且只在这个参数设置为 true 时才运行。</p><p></p><p></p><h3>数据管道泛化</h3><p></p><p></p><p>考虑到新增随机化单元是一个常见用例，我们将管道设计成了通用的，不对随机化单元做任何假设。试验日志以及管道为所有随机化单元生成的数据都相同，包括：试验键值、unit_id、单元暴露于特定试验的时间戳、单元暴露时传递的上下文、访问的参数名，以及一些杂项元数据。所有分析库也都是对这些通用数据进行分析，而不对管道层中的单元做任何假设。只有在分析时，用户才会选择与该单元相关的指标来连接底层数据。保持管道通用的决定使得引入新的试验单元变成了简单的配置更改，并且无需任何更改就可以利用其余的基础设施和管道。</p><p></p><p></p><h3>分析引擎泛化</h3><p></p><p></p><p>Morpheus 提供了一个生成和查看分析结果的 UI，但后台的统计分析程序包是用 Scala 编写的，并且隐藏在服务中，这使得数据科学家很难使用这个包进行自定义分析，导致统计分析工作重复进行且不标准。</p><p></p><p>在新系统中，我们将统计分析程序包构建成了一个 Python 程序包，并构建了一个 UI 分析层来调用这个包。我们在内部与数据科学社区分享了这个 Python 包，因此，数据科学家可以用它在 Jupyter 笔记本中做探索性分析，或者用它进行在 UI 层难以实现的深层次分析。虽然 UI 层已经能够支持大多数分析用例，但通过 DS 原生工具链提供相同的分析引擎，使有能力的用户可以进行更复杂的分析，也加深了用户对系统工作机制的了解。</p><p></p><p>分析程序包集成了 uMetric，并将其作为唯一的指标来源。鉴于试验是使用指标的主要用例，这使我们能够巩固 uMetric 作为公司指标单一来源的地位，并进一步提升了用户和团队之间的指标共享 / 标准化水平。</p><p></p><p>为了支持团队各种各样的试验分析需求，我们提供了高度灵活的按需分析，让用户可以回答有关其创新效果的细粒度问题。</p><p></p><p>每项分析都由两个关键部分组成：要分析的单元簇（cohort ）和分析该单元簇时使用的指标。</p><p></p><p>单元簇是一项特定分析所聚焦的单元集合。我们为以下两种单元簇定义提供了广泛的支持：</p><p></p><p>有日志单元簇：基于试验日志（如，在 3 月 1 日到 3 月 30 日之间进行试验的单元）；无日志单元簇：单元簇的定义方式不依赖于日志（如，在试验开始前 28 天内至少出行 1 次的用户）。</p><p></p><p>对于 Uber 乃至整个行业运行试验来说，有日志单元簇分析可能是更标准的方法。它让用户能够准确关注受试验影响的单元，通常提供的结果比较精确。</p><p></p><p>另一方面，无日志单元簇分析为我们提供了一种分析试验的备用方法，可以在因为中断及其他问题导致部分日志丢失时使用。它还提供了一种方法，让我们可以分析不同试验中单元簇的试验结果。这样的分析可能不那么强大，但在我们的架构中，却是非常健壮。</p><p></p><p>为了支持细粒度的洞察，我们为用户提供了很大的灵活性，让他们可以划分单元簇和指标。</p><p></p><p>本质上讲，单元簇可以根据单元首次进入试验之前定义的任何数据进行划分；这让我们能够提供对比结果，诸如对 iOS 和 Android 用户的影响比较、对新用户和现有用户的影响比较，同时保证，即使进行了单元簇细分，不同试验组之间的单元簇仍然具有可比性。</p><p></p><p>对于给定的单元簇或单元簇的某一划分，也可以利用指标维度对指标进行细分，因此，我们可以评估 UberX 和 UberXL 对完成行程的影响。由于通过 uMetric 进行了指标标准化，试验中报告的对指标的影响，与世界各地的团队所依赖的报告仪表板中的指标，计算方式是一致的。</p><p></p><p></p><h3>可靠性：SDK 和参数值回退</h3><p></p><p></p><p>鉴于移动端和后端开发都非常依赖试验系统，我们希望这个系统在可靠性上能有大幅提升，以消除我们之前看到的一类影响非常大的中断事件。为此，我们做了很多工作。</p><p></p><p>首先，如前所述，参数总有一个安全默认值。对于移动应用，这个默认值是随移动应用本身一起提供的。对于后端服务，默认值是由 Flipr 在本地（在主机上）提供的。这样，在出现网络故障或延迟的情况下，就有一个值可以保证客户端运行在安全的代码路径上。</p><p></p><p>其次，我们为 Uber 使用的所有语言（Go/Java/Android/iOS/JS/ 等）和客户端（Web/ 移动 / 后端）构建了 SDK。移动端 SDK 会缓存从后端接收到的前一个有效负载；如果出现问题，移动应用会回退到这个缓存，如果缓存不存在且后端不可用，则它们会回退到默认值。对于后端，如果试验不可达或出现超时，客户端会回退到 Flipr 默认值（在本地提供）。这种多层回退显著提高了可靠性。</p><p></p><p>第三，SDK 会在体验分叉之前自动发出试验日志。自动记录日志消除了手工记录日志带来的麻烦和缺陷。随着时间的推移，我们已经对 SDK 做了大量的优化（缓存 / 删除 / 日志批处理等)，这让所有的试验用户无需额外付出任何努力就能从中受益。</p><p></p><p>第四，SDK 支持一个名为参数预取的特性——提前获取一批参数以降低延迟，但要到稍后访问它们时才会发出日志（将获取与日志记录解耦）。这就解决了这样一种用例：正在试验的特性对参数访问延迟很敏感，但在用户流的早期对延迟不那么敏感。在需要显示特性之前支付延迟成本，在实际需要时提供对参数的即时访问——并在那个时间点自动发出日志——可以提供响应式的用户体验和准确有效的试验。</p><p></p><p></p><h2>挑战及经验总结</h2><p></p><p></p><p>一个团队：构建试验平台需要多种技能。系统作为一个整体从从统计学的角度来看应该是正确的，而且需要具备可扩展性和可靠性，用户体验要流畅，以保证用户的生产力。系统设计决策不能简单地分为工程和 DS：错误处理和服务性能优化的微小细节就可能会对结果的统计属性产生重大的影响，因此需要 DS 的参与——另一方面，统计分析实现的细节关系到可靠性，扩展到更大数据量的方式，大规模执行需要多少计算资源，等等。我们真正作为一个团队成功地开展了相关工作，特别是工程团队和数据科学团队之间的紧密协作。我们有共同的架构审查、联合代码所有权、同一个团队路线图 / 优先级，以及共同的社交活动。合作伙伴集成：该试验平台与许多合作伙伴的系统实现了紧密集成：推送 / 电子邮件沟通、目标定位、市场细分、活动管理、无代码工作流等。这些系统贡献了所有试验的近 40%。尽早集成所有这些系统，经常使用其中多个系统的客户就更容易过渡到新系统。协作规划与集成优先显著缩短了采用时间，这项工作很值得。沟通：Uber 的大多数人每天都在使用这个平台，对于这项规模如此大的基础性变革来说，沟通并让客户参与进来至关重要。为此，我们做了以下几件事:在问题发现和设计阶段听证会上仔细聆听客户声音，理解需要解决的痛点；尽早广泛地向关键客户展示新的架构和特性，说明能给他们带来什么好处，并根据他们的反馈进行设计迭代；在推出平台时做好演示，增进人们对新平台的理解，推动新平台的顺利采用；定期召开听证会，获得产品反馈——修改路线图，并重新排列优先级，首先解决最迫切的需求。采用、迁移和弃用：认真考虑新平台的采用策略，将有价值的试验移植到新平台，并从早期就开始弃用数以万计的过时试验（多年之前的），这些都非常关键。我们将弃用过程分为多个阶段，从风险最高的试验开始，然后扩展到其他试验。我们有自定义的程序，专门用于弃用特定类别的试验。我们构建了一套工具来迁移、监控和禁用大部分过时试验。这大大减少了分布式团队所必须完成的工作，让他们只关注不能自动迁移或集中弃用的试验。对于分布式团队来说，这仍然非常痛苦。新平台的采用是同步进行的。</p><p></p><p></p><h2>小结</h2><p></p><p></p><p>经过一年多的努力，我们为 Uber 的试验和特性标识生态打下了坚实的基础，相关的一切都已经转移到了新系统上，包括 2000 多名开发人员、集成的超过 15 个合作伙伴的系统、10 多个移动应用、350 多个服务。我们弃用了 Morpheus 中超过 5 万个过时的试验。</p><p></p><p>下一阶段，我们将致力于构建许多特性，以提高可用性、用户体验、性能、自动化监控、自动化推广，以及我们总体的试验能力，并将产品更快地提升到下一个等级。我们会在未来的博文中分享更多的细节。敬请期待！</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139040&amp;idx=1&amp;sn=1eee3c77db28fd14ef9a18d201dd80ce&amp;chksm=bdb8d3b38acf5aa5c63957fc7975fc1118319ae52a1697b388d358b88752daef0cae83953661&amp;scene=21#wechat_redirect\">缺少软件开发文化，大众汽车陷入困境，CEO 也被赶下了台</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138876&amp;idx=1&amp;sn=6b41efee0d73ab9537025f0f2e547fc7&amp;chksm=bdb8d36f8acf5a79fac65237c89d8e72058bef5a792dfa15c238ed7f64e940cc4587f6984a2b&amp;scene=21#wechat_redirect\">我庆幸果断放弃了 SwiftUI：它还不够成熟</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138875&amp;idx=1&amp;sn=0d28c021dff1e449d43764ddd18f7960&amp;chksm=bdb8d3688acf5a7e5608650730bd14716ac6a34802880f5d856cccf693e572290bd2d267edc6&amp;scene=21#wechat_redirect\">英伟达回应“对中国断供部分高端 GPU”；月薪 3.6 万工程师日均写 7 行代码被开；12 年黑进 40 多家金融机构老板赚百万获刑 ｜Q 资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138672&amp;idx=1&amp;sn=22a4495af1ff90c5590bc4e313a09230&amp;chksm=bdb8d2238acf5b354a48c9ff9c170235832de8bf23b998f34a7457cc9539a5d32d0045f5ee0b&amp;scene=21#wechat_redirect\">在阿里达摩院搞了四年数据库，我来聊聊实际情况 | 卓越技术团队访谈录</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-09-13 19:14:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Salesforce 构建可扩展 API 的旅程",
    "url": "https://www.infoq.cn/article/wgezEOT0e3PX2tNaIGJW",
    "summary": "<p></p><p>API 对于组织来讲正变得越来越重要，但是，构建安全、可扩展的 API 并非易事。本文从执行环境、API 技术、安全性等角度出发，介绍了如何构建高效、可扩展的 API。</p><p></p><p>本文最初发表于 Salesforce 站点，经作者 Nitesh Kumar 授权，由 InfoQ 中文站翻译分享。</p><p></p><p>API 是一个重要的工具，允许合作伙伴、开发人员和其他应用消费我们提供的微服务，与之进行通信，并基于此构建各种各样的功能。</p><p></p><p>高质量的 API 要能够随着业务生态系统的发展而扩展，构建这样的 API 并不是一件容易的事情，需要对所有的事情进行通盘思考和规划，涉及到选择哪种执行环境，甚至要决定该使用哪种 API 技术。</p><p></p><p>那么，我们是如何实现的呢？在本文中，我将会分析在 Salesforce 为 Activity Platform 构建 API 的经验，它可以作为你自己编写 API 的一个指南。Activity Platform 是一个大数据处理引擎，每天会摄取和分析超过 1 亿次的客户互动，以自动捕获数据并产生分析、推荐和 feed。Activity Platform 提供了 API 来为我们的客户交付这些功能。</p><p></p><p></p><h2>选择执行环境</h2><p></p><p></p><p>根据需求不同，执行环境可以是裸机、虚拟机（VM）或者应用容器。我们选择了使用应用容器，因为它可以在物理机或 VM 上运行，一个操作系统实例能够支持多个容器，每个容器都在自己独立的执行环境中运行。简而言之，容器是轻量级、可移植、快捷的，并且易于部署和扩展，所以它们天然适合微服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6e/6e7a18ce456ef21d0838eaa0899d9e12.png\" /></p><p></p><p></p><h3>关于容器编排</h3><p></p><p></p><p>如果你像我们这样决定使用容器，容器编排能够帮助你实现自动化部署，管理容器、扩展以及网络。在这方面，有很多可选的容器编排工具，比如 Kubernetes、Apache Mesos、DC/OS（with Marathon）、Amazon EKS、Google Kubernetes Engine（GKE）等。</p><p></p><p>我们使用的是 Hashicorp 的 Nomad 集群。它非常简单、轻量级，并且能够编排任何类型的应用，而不仅仅是容器。它能够无缝与 Consul 和 Vault 集成，实现服务发现和 secret 管理。我们可以很容易地将需求描述为一个待执行的任务（task），比如内存、网络、CPU，以及我们水平扩展服务所需的实例数量。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0ce8509cb141ca0d946bc96eed4a9fd2.png\" /></p><p></p><p></p><h3>选择 API 技术</h3><p></p><p></p><p>为了构建 API，我们选择了使用 <a href=\"https://www.infoq.cn/article/HfkjC5CdT1XXTsd44b3A\">GraphQL</a>\"。如果你没有听说过它的话，它是其他可选技术（如 REST、SOAP、Apache Thrift、OpenAPI/Swagger 或 gRPC）的一个替代方案。</p><p></p><p></p><h4>我们为什么选择 GraphQL</h4><p></p><p></p><p>我们想要构建的 API 能够服务于多种客户端，涵盖 Web 和移动应用。它需要具备高效、强大和灵活的特点。</p><p></p><p>鉴于以下的原因，<a href=\"https://www.infoq.cn/article/dvOaNoDmu9E4u5NDkQ4E\">GraphQL </a>\"是最合适的方案：</p><p></p><p>GraphQL 是数据库无关的技术，能够从任何地方为我们预先定义的业务领域提供数据。这意味着为了满足一个查询，底层可以使用 Cassandra、Elasticsearch 或其他模块的现有 API。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/18/187492db68a218af50067525db3cc551.png\" /></p><p></p><p>它允许客户端精确请求想要的数据，避免过量加载（overfetching）或加载不足（underfetching）。如果 API 返回的数据超出了客户端的需求，这会导致性能问题，如果返回的数据比预期要少，那么会进行多次网络调用，从而减缓渲染时间。GraphQL 能够避免这两种情况。尽管大多数的 API 都实现了版本管理，但是 GraphQL 是一个无版本化的 API。因为它只会返回明确请求的数据，所以我们可以通过添加新的类型以及类型上的新字段来增加功能，避免带来破坏性的变更。GraphQL 使用强类型系统，所有的类型都是使用 Graph SDL 以模式（schema）的方式进行定义的。它可以作为客户端和服务器的契约，避免请求 / 响应结构的混淆。GraphLQ 支持内省（introspection），所以模式定义可以通过各种工具进行共享和下载，如 GraphiQL、GraphQL-playground 或 cli 工具。</p><p></p><p></p><h4>GraphQL 实战</h4><p></p><p></p><p>我们在 Classification Insight API 中使用了<a href=\"https://www.infoq.cn/video/YIShfqdvkUw0M8PC9DYu\"> GraphQL</a>\"。Classification Insight 提供了用户的信息，并且能够帮助会议的参加者了解其他参会人员的头衔和角色。我们使用 Kotlin 和 graphql-java（GraphQL 的一个 Java 实现）实现该 API。</p><p></p><p>第一步：定义模式（如 schema.graphqls）。每个 GraphQL 服务会定义一组类型。GraphQL 模式中最基本的组件是对象类型，它代表了一种我们可以从服务中获取的对象。</p><p></p><p>在如下的模式中，我定义了一个名为“getClassificationInsightsByUser”的查询，在后面的内容中，我们可以通过发送如下的载荷到 API 来调用查询：{ getClassificationInsightsByUser(emailAddresses: [“test1@gmail.com”, “test2@gmail.com”]) { userId, title } }</p><p></p><p>schema.graphqls</p><p></p><p><code lang=\"typescript\"># 描述我们能够获取什么内容的对象类型\ntype ClassificationInsightByUser {\n  organizationId: ID!\n  userId: String!\n  emailAddress: String!  \n  title: String!\n}\n# 定义所有查询的Query类型\ntype Query {\n  getClassificationInsightsByUser(\n    emailAddresses: [String!]!  \n  ): [ClassificationInsightByUser]\n}\n\nschema {\n  query: Query\n}\n\n</code></p><p></p><p>第二步：实现 Datafetcher（也被称为解析器）来解析 getClassificationInsightsByUser 字段。简单来讲，解析器就是由开发人员提供的一个函数，用来解析模式中定义的每个字段并从配置的资源（如数据库、其他 API 或缓存等）中返回值。</p><p></p><p>在本例中，我们的 Query 类型提供了一个名为 getClassificationInsightsByUser 的字段，它接受 emailAddresses 参数。该字段的解析器函数很可能会访问一个数据库，并构造和返回 ClassificationInsightByUser 对象的一个列表。</p><p></p><p><code lang=\"kotlin\">// 假设我们已经定义了数据类\n// （如ClassificationInsightByUser）来存放数据\n\n// 编写自己的datafetcher类\nclass ClassificationInsightByUserDataFetcher:\n  DataFetcher?&gt; \n  \n  // 重载DataFetcher的get函数\n  override fun get(env: DataFetchingEnvironment):\n    List? {    // 在提交的查询中获取参数\n    val emailAddresses = env.getArgument&gt;    (EMAIL_ADDRESSES)\n    // 编写逻辑从其他API或者通过调用控制器/服务从业务层获取数据\n    // 在这里，为了简单，返回静态数据\n    return EntityData.getClassificationInsightByUser(emailAddresses)\n  }\n}\n</code></p><p></p><p>第三步：初始化 GraphQLSchema 和 GraphQL Object（借助 graphql-java）来辅助执行查询。</p><p></p><p><code lang=\"kotlin\">// 借助工具函数，将所有模式文件加载为字符串\nString schema = getResourceFileAsString(\"schema.graphqls\")\n// 根据模式文件创建typeRegistry\nval schemaParser = SchemaParser()\nval typeDefinitionRegistry = TypeDefinitionRegistry()\ntypeDefinitionRegistry.merge(schemaParser.parse(schema))\n// 运行时装配，我们将自己的查询类型装配到解析器中\nval runtimeWiring = RuntimeWiring()\n  .type(\"Query\", builder -&gt; builder.dataFetcher(\n            \"getClassificationInsightsByUser\", ClassificationInsightByUserDataFetcher()\n          )\n  )\n  .build();\n// 创建graphQL Schema\nval schemaGenerator = SchemaGenerator();\nval graphQLSchema = schemaGenerator\n  .makeExecutableSchema(typeDefinitionRegistry,runtimeWiring);\n// 创建graphQL\nval graphQL = GraphQL.newGraphQL(graphQLSchema).build();\n</code></p><p></p><p>第四步：编写 servlet（MyAppServlet），处理传入的请求</p><p></p><p><code lang=\"kotlin\">override fun doPost(req: HttpServletRequest, resp:\n    HttpServletResponse) {\n  val jsonRequest = JSONObject(payloadString)\n  val executionInput = ExecutionInput.newExecutionInput()\n  .query(jsonRequest.getString(\"query\"))\n  .build()\n  // 使用graphQL执行查询 \n  // 它将会调用解析器来获取数据并且只返回请求的数据\n  val executionResult = graphQL.execute(executionInput)\n  \n  // 发送响应\n  resp.characterEncoding = \"UTF-8\"\n  resp.writer.println(mapper.writeValueAsString(executionResult.toSpecification()))\n  resp.writer.close()\n  \n}\n</code></p><p></p><p>第五步：在应用中，嵌入 Web 服务器（本例中使用的是 Jetty）。</p><p></p><p><code lang=\"kotlin\">// Server\nval server = new Server();\n\n// HTTP连接器，在生产环境中要使用HTTPS\nval http = ServerConnector(server)\nhttp.host = \"localhost\"\nhttp.Port = 8080\nhttp.idleTimeout = 30000\n\n// 搭建handler\nval servletContextHandler = ServletContextHandler()\nservletContextHandler.contextPath = \"/\"\nservletContextHandler.addServlet(ServletHolder(MyAppServlet()), \"/api\")\nserver.handler = servletContextHandler\n// 启动jetty服务器以监听请求\nserver.start()\nserver.join()\n</code></p><p></p><p>第六步：构建并启动应用，请使用 CI/CD 工具来创建、发布和部署 Docker 镜像到集群中。</p><p></p><p></p><h3>确保 API 的安全性</h3><p></p><p></p><p>在 Salesforce，安全性是首要任务。我们的 API 仅供注册用户访问，而且他们只能访问有权限的数据。在这方面，你可以探索 OAuth 2.0（JWT 授予类型和基于角色的访问控制）和开放策略代理（Open Policy Agent ，OPA）来满足访问控制的需求。</p><p></p><p>作为最佳实践，认证中间件应该放在 GraphQL 之前，并且要在业务逻辑层有唯一一个地方负责授权，避免在多个地方都要进行检查。除了认证和授权，在设计 API 时还应考虑速率限制、数据脱敏（data masking）和载荷扫描。</p><p></p><p></p><h3>总&nbsp; &nbsp; 结</h3><p></p><p></p><p>我们已经展示了如何构建一个可扩展、高效、安全的 API。在这个过程中，我们使用应用容器进行扩展，使用 GraphQL 和嵌入式 Jetty 确保高效和轻量级，并优先考虑了 API 的安全性。</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139876&amp;idx=1&amp;sn=b5479b58f06e714877092811902bf015&amp;chksm=bdb8d7778acf5e617885b343a0fa9932b961ec5ad16a2bca0b3db0770c4ab67d247b26a22dee&amp;scene=21#wechat_redirect\">“不搞职级、人人平等” 25 年后行不通了？Netflix 破天荒引入细分职级：气走老员工</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139040&amp;idx=1&amp;sn=1eee3c77db28fd14ef9a18d201dd80ce&amp;chksm=bdb8d3b38acf5aa5c63957fc7975fc1118319ae52a1697b388d358b88752daef0cae83953661&amp;scene=21#wechat_redirect\">缺少软件开发文化，大众汽车陷入困境，CEO 也被赶下了台</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138876&amp;idx=1&amp;sn=6b41efee0d73ab9537025f0f2e547fc7&amp;chksm=bdb8d36f8acf5a79fac65237c89d8e72058bef5a792dfa15c238ed7f64e940cc4587f6984a2b&amp;scene=21#wechat_redirect\">我庆幸果断放弃了 SwiftUI：它还不够成熟</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138875&amp;idx=1&amp;sn=0d28c021dff1e449d43764ddd18f7960&amp;chksm=bdb8d3688acf5a7e5608650730bd14716ac6a34802880f5d856cccf693e572290bd2d267edc6&amp;scene=21#wechat_redirect\">英伟达回应“对中国断供部分高端 GPU”；月薪 3.6 万工程师日均写 7 行代码被开；12 年黑进 40 多家金融机构老板赚百万获刑 ｜Q 资讯</a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-09-13 19:37:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Crossplane支持的自定义资源数量突破了Kubernetes的限制",
    "url": "https://www.infoq.cn/article/Yiqriipkfzw1gBBdyzUl",
    "summary": "<p></p><p></p><blockquote>在过去的几个月里，Crossplane 支持的自定义资源数量突破了 Kubernetes 的限制。在这篇文章中，我们将探讨下由 Upbound 工程师发现的限制，以及我们如何帮助克服它们。</blockquote><p></p><p></p><p>本文最初发布于 Upbound Newsletter。</p><p></p><p>在过去的几个月里，<a href=\"https://www.infoq.cn/article/cLmwdUxeOKkqfizMGfty\">Crossplane</a>\" 支持的自定义资源数量突破了 Kubernetes 的限制。在这篇文章中，我们将探讨下由 Upbound 工程师发现的限制，以及我们如何帮助克服它们。</p><p></p><p></p><h2>背景</h2><p></p><p></p><p>Upbound 创建了 Crossplane，帮助人们创建云控制平面。这些控制平面位于云提供程序之上，允许你自定义它们暴露的 API。平台团队使用 Crossplane 为开发人员提供更简单、更安全的自助服务云接口。</p><p></p><p>Crossplane 使用我们所谓的云提供程序来扩展控制平面，以支持新的云——例如，安装 AWS 提供程序使得控制平面可以按照自己的概念和策略来封装 AWS。Crossplane 提供程序扩展了 Crossplane，使其可以支持底层云提供程序支持的所有 API。我们称这些 API 为托管资源或 MR。</p><p></p><p>MR 是构建块，使用 Crossplane 定义的 API 就是由 MR 组成。要使用 Crossplane 构建控制平面，你需要：</p><p></p><p>定义你希望控制平面暴露的 API。安装用于支撑那些 API 的提供程序。告知 Crossplane，当有人调用你的 API 时要创建、更新或删除哪个 MR。图片:</p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a8077211db8226e2cb4d2de6eca1cb2.png\" /></p><p></p><p></p><p>配置 Crossplane 暴露一个简单的 PostgreSQLInstance API，该 API 以托管资源 RDSInstance 为基础。</p><p></p><p>Crossplane 提供程序旨在成为相应云提供程序高保真、全覆盖的代理。在本文写作时，AWS 暴露了大约 1000 个 API 端点，也就说，安装 AWS 提供程序并实现 AWS API 全覆盖的话，扩展之后的 Crossplane 将支持大约 1000 种新的 MR。实现 AWS、Azure 和 GCP 提供程序全覆盖的多云控制平面将支持大约 2000 个 MR。在后台，每个 MR 都由一个<a href=\"https://www.infoq.cn/article/2015/05/Kubernetes-Borg-Eurosys\"> Kubernetes</a>\" 自定义资源定义（CRD）来定义。</p><p></p><p><a href=\"https://www.infoq.cn/article/jUhMWqTYAaD6z3okKjNj\">Kubernetes </a>\"API 服务器是 Crossplane 控制平面的关键组件。Upbound 很早就发现了 Kubernetes 控制平面的优势，并选择以它为基础构建 Crossplane。该 API 提供了一个可扩展的 JSON REST API，并内置支持可靠的持久化（即 etcd）和一些有用的特性，如基于角色的访问控制（RBAC）、Webhooks（可以在 API 调用提交到存储之前更改或验证包含在该调用中的数据。）</p><p></p><p>API 服务器区分“内置”API 资源和“自定义（API）资源”，前者主要支持容器相关的概念，如 Pod、部署和服务，而后者可以代表任何东西。Crossplane MR 是一种 Kubernetes CR。API 服务器使用 CRD 来获知新类型的 CR。CRD 包含 API 服务器暴露一个新 CR 所需的所有信息——例如，它的类型和 OpenAPI 模式。这是一种相当新颖的方法；API 服务器暴露一个 API，你可以调用这个 API 告知服务器其他需要暴露的 API。</p><p></p><p>在 Crossplane 之前，即使是最高级的 Kubernetes 用户也只能用少量的 CR 来扩展他们的 API 服务器——或许创建数十个 CRD。随着 Crossplane 开始支持数以百计的 MR，我们发现了 Kubernetes 能够处理的 CRD 上限。</p><p></p><p></p><h3>API 发现</h3><p></p><p></p><p>我们观察到的问题可以归结为两部分：客户端和服务器端。客户端问题主要包含在一个称为发现（Discovery）的过程中。像 kubectl 这样的客户端使用这个过程来发现 API 服务器支持什么 API。其他的暂且不说，这使得客户端能够“自动补全”API 类型。例如，当有人输入 kubectl get po 时，它可以知道他们的意思是 kubectl get pods。</p><p></p><p>发现过程的主要问题是它需要客户端“浏览”API 服务器的许多端点。自定义资源由 API 服务器像下面这样在端点提供出来：<a href=\"https://example.org/apis////%E2%80%8C%E4%BE%8B%E5%A6%82%EF%BC%8C%E4%B8%80%E4%B8%AA%E5%90%8D%E4%B8%BA\">https://example.org/apis////‌例如，一个名为</a>\" cool-db、类型为 Instance、属于 API 组 rds.aws.upbound.io/v1 的 MR 将像下面这样提供：</p><p></p><p><code lang=\"ruby\">https://example.org/apis/rds.aws.upbound.io/v1/instances/cool-db\n</code></p><p></p><p>为了发现这个端点，客户端需要查询：</p><p></p><p><a href=\"https://example.org/apis\">https://example.org/apis</a>\" 获取支持的 API 组清单，如 rds.aws.upbound.io。<a href=\"https://example.org/apis/rds.aws.upbound.io\">https://example.org/apis/rds.aws.upbound.io</a>\" 确定组内有什么版本，如 v1。<a href=\"https://example.org/apis/rds.aws.upbound.io/v1\">https://example.org/apis/rds.aws.upbound.io/v1</a>\" 确定版本 v1 存在什么类型的 CR。</p><p></p><p>当 CR 的类型数以千计时，客户端需要查询许多 API 端点才能完成发现过程。例如，“三大”云提供商——AWS、Azure 和 GCP——提供了大约 2000 种 Crossplane MR，它们分布在大约 300 个 API 组和版本中，也就是说，客户端必须发起大约 300 个 HTTP 请求来执行发现。从根本上说，这没有那么糟糕——相对于现代的网速而言，这些请求的响应相当小，客户端可以利用 HTTP/2 来避免许多到 API 服务器的 TCP 连接开销。关于发现过程的可扩展性问题主要是由客户端速率限制器所做的假设和缓存造成的。</p><p></p><p></p><h3>客户端速率限制</h3><p></p><p></p><p>我们注意到的第一个客户端问题非常明显——每隔 10 分钟，kubectl 的发现结果缓存就会失效，它会发出如下所示的日志信息，然后最多要等 5 到 6 分钟才真正开始做你要求它做的事：</p><p></p><p><code lang=\"ruby\">Waited for 1.033772408s due to client-side throttling, not priority and fairness, request: GET:https://api.example.org/apis/pkg.crossplane.io/v1?timeout=32s\n</code></p><p></p><p>这个问题很容易解决。kubectl 中执行发现的部分使用了一个速率限制器，以确保它不会造成 API 服务器过载。当我们最初注意到这些日志时，速率限制器允许客户端平均每秒发起 5 次请求，而突发请求最多为 100 个。</p><p></p><p>解决这个问题的权宜之计是放宽速率限制。如今，发现仍然受限于每秒 5 次请求，但每秒突发请求最多可为 300 个。在 Cruise 和 Upbound 等公司的工程师的要求下，kubectl 在 v1.22 版本发布时及时提高了这一限值。发现缓存的过期时间也被配置为 6 小时，而不是 10 分钟。从 Kubernetes v1.25 开始，所有基于 client-go 库构建的客户端都将享受到提高后的限值。</p><p></p><p></p><h3>客户端缓存写入</h3><p></p><p></p><p>下一个客户端问题诊断起来有点难。我们的分析显示，即使完全禁用速率限制，执行 300 来个 API 组的发现也需要将近 20 秒。一开始，我们以为这是因为网络限制——通过现代互联网连接下载发现数据就需要大概 20 秒。幸运的是，我们注意到，在 macOS 上确实需要 20 秒，但在 Linux 上几乎是瞬间完成。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/936904348f8356a2dba312d155b85c54.png\" /></p><p></p><p>大量的时间消耗在 diskv.WriteStream 互斥量中。</p><p></p><p>幸运的是，kubectl 提供了一个便捷的 -profile 标识，让我们可以深入了解时间花在了哪里。在尝试了多种不同类型的分析器后，我们注意到，互斥量分析器显示，kubectl 94% 的时间消耗在了一条与发现数据缓存相关的代码路径上。</p><p></p><p>我们发现，kubectl 用来缓存发现数据的 diskv 库被配置成了 fsync 所有缓存文件——大约 300 个发现端点，每个一个。这个系统调用可以确保操作系统将写入特定文件的数据一路刷写到持久化存储。在 macOS 上，Go 使用 F_FULLSYNC fnctl 为将数据持久化到磁盘提供了强有力的保障。显然，这比其他操作系统要慢许多，苹果不建议这么做，除非是在数据持久化特别重要的地方。</p><p></p><p></p><blockquote>F_FULLFSYNC 所做的事情和 fsync(2) 一样，然后它会要求磁盘驱动器将缓冲区的所有数据刷写到持久化存储设备上（参数被忽略）。目前，这已经在 HFS、MS-DOS(FAT) 和通用磁盘格式（UDF）文件系统上实现。完成这个操作可能需要相当一段时间。</blockquote><p></p><p></p><p>到底是苹果的存储层从根本上就比其他系统的慢，还是说他们的硬件更真实的反馈了完全持久化数据所需的时间，人们有一些不同的看法。无论如何，对于一个很容易重建的缓存来说，这一调用所提供的保障等级并不是必须的。</p><p></p><p>从 Kubernetes v1.25 版本开始，Upbound 更新了 kubectl（及所有基于 client-go 的客户端），使用校验和来保证发现缓存的一致性，而不是 fsyncs。我们在读取时检测有错误的条目并使其失效，而不是费力在写入时持久化缓存。这种方法在 macOS 提供了类似的一致性，但速度比之前快大约 25 倍（在 Linux 上快大约 2 倍）。</p><p></p><p>修复前，写入并读取一个缓存值需要大约 22 毫秒：</p><p></p><p><code lang=\"go\">$ go test -v -bench . -run '^Bench'\ngoos: darwin\ngoarch: arm64\npkg: k8s.io/client-go/discovery/cached/disk\nBenchmarkDiskCache\nBenchmarkDiskCache-10            60    22272642 ns/op\nPASS\nok    k8s.io/client-go/discovery/cached/disk  2.582s\n</code></p><p></p><p>修复后，写入并读取一个缓存值需要大约 0.7 毫秒：</p><p></p><p><code lang=\"go\">$ go test -v -bench . -run '^Bench'\ngoos: darwin\ngoarch: arm64\npkg: k8s.io/client-go/discovery/cached/disk\nBenchmarkDiskCache\nBenchmarkDiskCache-10          1534      761469 ns/op\nPASS\nok    k8s.io/client-go/discovery/cached/disk  1.483s```\n</code></p><p></p><p></p><h3>客户端改进前瞻</h3><p></p><p></p><p>人们将发现速率限制与美国债务上限进行了比较——每次债务到达上限时就提高上限。对于 Crossplane 上请求最密集的用例，目前的限制仅仅是够用而已，但应该无法坚持多久。越来越多的人要求把它们完全删除。</p><p></p><p>客户端速率限制的本质是请求避免过多导致 API 服务器过载。这直觉上是个好主意，但有两个问题：</p><p></p><p>速率限制器的状态不会存续到客户端生命周期之后。大多数 kubectl 命令 2 到 3 秒就可以完成，因此，可供速率限制器用来决策的上下文很少。如果每个 kubectl 命令需要一秒钟完成，那么一个紧凑的命令循环将被有效地限制在每秒 300 个请求。客户端之间不会相互协调——如果许多客户端的请求同时爆发，每秒发出 300 个请求，那么 API 服务器仍然会过载。</p><p></p><p>API 优先级和公平性（AP&amp;F）（在 v1.20 版本中成为 API 服务器的一个 Beta 特性）可以克服上述问题。它使用服务器端队列和流量削减来保护 API 服务器。有了 AP&amp;F：</p><p></p><p>每个 API 服务器的优先级数量都可配置。类似 RBAC 的规则根据资源类型、用户、命名空间等对请求进行优先级分类。请求可能在多个队列之间随机分片（shuffle-sharded），以大幅减少噪音客户端对对等客户端的影响，即使优先级相同。当 API 服务器过载时，请求会收到一个低开销的 HTTP 429 “请求太多”响应。</p><p></p><p>减少执行发现所需 HTTP 请求数量的工作也在进行当中，为的是可以去掉速率限制。有一份 Kubernetes 增强提案（KEP）已获批准，该提案建议添加一个聚合 HTTP 端点以供发现使用，并计划在 Kubernetes v1.26 中提供 Alpha 支持。有了这个端点，客户端就能够通过请求单个 HTTP 端点来执行发现。这个聚合发现端点还将支持基于 ETag 的缓存，允许客户端只在已知缓存过期的情况下下载发现数据。</p><p></p><p></p><h3>OpenAPI 模式计算</h3><p></p><p></p><p>与第一次看到有关客户端速率限制的报告同时，我们还注意到，Kubernetes API 服务器在 CRD 负载下会行为异常：</p><p></p><p></p><blockquote>我看到了各种不可思议的错误，从 etcd leader 更换到 API 服务器报告没有 CustomResourceDefinition 这种类型，再到 HTTP 401 未授权，尽管我的证书在后续的请求中依然有效。</blockquote><p></p><p></p><p>首先我们看到，请求过了很长时间才得到处理，如果确实得到了处理的话。在创建完数百个 CRD 之后，这种行为似乎会持续大约一个小时。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71e0fc868ad190f4ab7979a1c8439248.png\" /></p><p></p><p>在创建了 765 个 AWS CRD 之后，紧接下来的一段时间 CPU 利用率非常高。</p><p></p><p>从监控仪表板上可以看出，在创建了许多 CRD 之后，紧接下来的一段时间 API 服务器 CPU 利用率非常高。有趣的是，我们注意到，当我们向一个已经有很多 CRD 的 API 服务器大批量添加 CRD 时，CPU 利用率居高不下的时间更长。</p><p></p><p>通过对 API 服务器 CPU 利用率的分析，我们发现，CPU 利用率升高的主要原因是计算 OpenAPI v2 聚合模式的逻辑。每次添加或更新一个 CRD 时，OpenAPI 控制器会：</p><p></p><p>为定义好的 CR 创建一个 swagger 规范。将已知所有 CR 的 swagger 规范合并成一个大的规范。将合并后的规范序列化成 JSON，以便可以由 /openapi/v2 端点提供出来。</p><p></p><p>就是这样，每次添加或更新一个 CRD，API 服务器就要完成序列化工作，而随着 CRD 数量的增加，这项工作的开销也会越来越大。一次性添加许多 CRD 会导致这种情况发生在一个紧凑的循环中，那很容易耗尽 API 服务器的 CPU 预算。</p><p></p><p>鉴于这种情况，我们算是很幸运了。在早期，有人报告了内存利用率在创建 CRD 之后会提升的情况后，API 服务器维护人员就识别了问题所在并着手修复，而且同步降低了我们观察到的 CPU 利用率。这个修复使得端点 /openapi/v2 的模式计算延迟——所有处理延迟到客户端实际向该 API 端点发起请求时。在 Upbound 的小小帮助下，Kubernetes v1.23.0 中加入了这个修复，并反向移植到了 v1.20.13、v1.21.7 和 v1.22.4 等补丁版本中。</p><p></p><p></p><h3>etcd 客户端</h3><p></p><p></p><p>在引入新的、更高效的 OpenAPI 模式计算方法后，我们迅速发现了 API 服务器的下一个瓶颈——持续提升的内存利用率。我们在试验过程中发现，在 API 服务器上，每个 CRD 要占用 4MiB 多一点的物理内存（驻留集大小或 RSS）。图片:</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/968affe292b44c3a97fbf11e1888bdb8.png\" /></p><p></p><p>API 服务器安装 780 个 CRD 后的内存使用情况</p><p></p><p>对于像 Google Kubernetes Engine（GKE）这样的托管 Kubernetes 服务，这特别成问题，因为它们经常会限制 API 可以使用的 CPU 和内存。当预测到 API 服务器需要更多的资源时——比如创建了更多节点，这些服务能够优雅地对它进行纵向扩展。遗憾的是，在本文写作的时候，大多数 API 服务器都没有考虑到创建的 CRD 会越来越多，而且要到 API 服务器反复出现“OOM killed”（因超出内存预算而终止）时才开始扩展。</p><p></p><p></p><blockquote>虽然 ProviderRevision 获取健康状况只需要大约 150 秒，但区域 GKE 集群之后至少会有 3 次进入修复模式。在区域集群的“RUNNING”和“RECONCILING”状态之间，每次运行 kubectl 命令，我们都观察到了与之对应的各种错误，最明显的是连接 API 服务器时的连接错误和 I/O 超时。集群要一个多小时才能稳定下来。不过，在此期间，控制平面会间歇性地短时可用。</blockquote><p></p><p></p><p>我们测试过的所有 Kubernetes 服务（即 GKE、AKS 和 EKS）都或多或少地受这个问题所影响。它们都可以自愈，但在此之前，API 服务器会有 4-5 秒到 1 个小时不等的时间不可用。请注意，集群不会完全停止运作——Kubelets 和容器会继续运行——但它会停止所有的协调工作。</p><p></p><p>我们再次求助于 Go 的内置分析工具，并很快就有了一些发现。原来，一个名为 Zap 的日志库占用了 API 服务器超过 20% 的内存。颇具讽刺意味的是，Zap 显然是为低开销而设计的，但却不小心被滥用了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/53/53f08ab7f69bd9ada7efb69dc4ddda9e.png\" /></p><p></p><p>在一台有 1878 个 CRD 的空闲 API 服务器上，zapcore.newCounters 占了 23% 的内存。</p><p></p><p>实际上，API 服务器会为每个版本的 CR 创建一个 etcd 客户端（即每个 CRD 至少创建一个 etcd 客户端），并且每个 etcd 客户端都会实例化自己的 Zap 日志记录器。这会导致数百个冗余的日志记录器，对内存造成重大影响，同时，API 服务器和存储数据的 etcd 数据库之间也会产生数百个不必要的 TCP 连接。</p><p></p><p>大多数 Kubernetes API 系统维护人员似乎都认为，这个问题的正确修复方式是所有 CR 端点共享一个 etcd 客户端。不过，由于我们是在 Kubernetes API 发布周期后期提出的这个问题，所以我们选择做一个小的策略性修复，使所有 etcd 客户端共享一个日志记录器。即将于 8 月底发布的 Kubernetes 1.25 将包含这一修复，下一波补丁版本 Kubernetes 1.22、1.23 和 1.24 也会包含这一修复，也会在大致相同的时间发布。我们希望，内存利用率缩减大约 20% 可以缓解我们在托管 Kubernetes 服务中观察到的问题。</p><p></p><p></p><h3>服务器端改进前瞻</h3><p></p><p></p><p>长期来看，我们在服务器端的工作未来将集中在降低 CRD 的计算资源成本。近期，我们已经开始大幅减少 API 服务器使用的 etcd 客户端数量，从每个 CR 版本一个减少到每个传输一个（即每个 etcd 集群）。我们还与 GKE、EKS 和 AKS 的工程团队合作，以确保他们的服务能够处理 Crossplane 安装的 CRD 数量。</p><p></p><p>早期的调查还表明，API 服务器会受垃圾收集优化所影响。我们做了一个简单的实验，在一台安装了大约 2000 个 CRD 的空闲 API 服务器上，当堆增长 50% 时触发垃圾收集（默认是在堆增长 100% 时触发），其结果是，峰值 RSS 内存利用率减少了 25%。更频繁的垃圾收集对 CPU 的影响是否可以接受，还需要进一步的测试来确定。一旦 Go 1.19 发布，或许可以试下新的内存限制设置，它提供了 Go 运行时会尝试遵守的一个软内存限制。</p><p></p><p></p><h2>小结</h2><p></p><p></p><p>在过去的 12 个月里，Crossplane 社区已经确定了一个新的 Kubernetes 扩展维度——定义的自定义资源的数量——并推动其突破其限制。Upbound 工程师帮助诊断和消除了这些限制，包括：</p><p></p><p>限制性的客户端速率限制器。缓慢的客户端缓存。低效的 OpenAPI 模式计算。冗余、高昂的成本、etcd 客户端。</p><p></p><p>在本文大部分问题的诊断中，Alper Rifat Uluçınar 都提供了很大的帮助——感谢 Alper！如果你觉得这篇文章有趣，那么你可能也会喜欢他最近在 KubeCon 大会上所做的关于这个话题的演讲。</p><p></p><p>原文链接：<a href=\"https://blog.upbound.io/scaling-kubernetes-to-thousands-of-crds/\">https://blog.upbound.io/scaling-kubernetes-to-thousands-of-crds/</a>\"</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140027&amp;idx=1&amp;sn=d5570bc90a0841a478bfe4a459e78fa1&amp;chksm=bdb8d7e88acf5efe5b617c832547fd49351901039a670c3d1cbdee1b3630df4ef59db868c20e&amp;scene=21#wechat_redirect\">历时三年替换掉二十年老系统，这个团队选择“一次性到位”&nbsp; | 卓越技术团队访谈录</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140026&amp;idx=1&amp;sn=975eca537f138a3526aa4a50b58ab3fa&amp;chksm=bdb8d7e98acf5eff6d777b5db5604670c81e76c3cc53fd6b12f1d9173e76ad85a7aeb7a44105&amp;scene=21#wechat_redirect\">对峙数年后，微软对 Java 的态度 180°大反转</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140025&amp;idx=1&amp;sn=ca1cf244eb8a12c3561fad45e4300066&amp;chksm=bdb8d7ea8acf5efc62732bef1c5d7613ad265110a86ed2aa6facf96d6fa6ad4c715e6118f4dd&amp;scene=21#wechat_redirect\">奇葩事儿：删除用户云数据还无法恢复，只赔 3 万；微信键盘来了，体积 524MB；谷歌希望将效率提高 20%：暗示将裁员？| Q 资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139876&amp;idx=1&amp;sn=b5479b58f06e714877092811902bf015&amp;chksm=bdb8d7778acf5e617885b343a0fa9932b961ec5ad16a2bca0b3db0770c4ab67d247b26a22dee&amp;scene=21#wechat_redirect\">“不搞职级、人人平等” 25 年后行不通了？Netflix 破天荒引入细分职级：气走老员工</a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138672&amp;idx=1&amp;sn=22a4495af1ff90c5590bc4e313a09230&amp;chksm=bdb8d2238acf5b354a48c9ff9c170235832de8bf23b998f34a7457cc9539a5d32d0045f5ee0b&amp;scene=21#wechat_redirect\"></a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-09-13 20:07:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微服务的测试策略",
    "url": "https://www.infoq.cn/article/Xu49VJAZNuqpxTX31RvE",
    "summary": "<p></p><p></p><p>微服务应用程序是一组通过网络进行通信的分布式程序，有时也会与第三方服务和数据库交互。微服务是网络化的，与传统的单体应用程序相比，它的故障点更多。为此，我们需要一种不同的、涉及面更广的测试方法。那么，我们该如何测试一个微服务应用程序？测试金字塔还有效吗？当涉及到第三方服务并可能出现网络中断时，我们该如何测试？在这篇博文中，我们将尝试回答所有这些问题。</p><p></p><p>本文最初发布于 semaphore 博客。</p><p></p><p><a href=\"https://www.infoq.cn/article/0OOSDdvcwhu7DYCVukCR\">微服务应用程序</a>\"是一组通过网络进行通信的分布式程序，有时也会与第三方服务和数据库交互。微服务是网络化的，与传统的单体应用程序相比，它的故障点更多。为此，我们需要一种不同的、涉及面更广的测试方法。</p><p></p><p>那么，我们该如何测试一个微服务应用程序？测试金字塔还有效吗？当涉及到第三方服务并可能出现网络中断时，我们该如何测试？在这篇博文中，我们将尝试回答所有这些问题。</p><p></p><p></p><h2>微服务测试面临的挑战</h2><p></p><p></p><p><a href=\"https://www.infoq.cn/article/7FgqsQVNa1a2BbHyjZf2\">微服务架构</a>\"是一种意义深远的范式变迁，我们必须重新考虑传统的测试技术。与经典的单体架构相比，微服务在许多方面都有所不同：</p><p></p><p>分布式：微服务部署在多台服务器上，地理位置可能也不一样，这会增加延迟，而且会受网络中断所影响。测试要依赖网络，即使代码没问题，也可能会失败，导致 CI/CD 管道中断，开发受阻。自治：只要不破坏 API 兼容性，开发团队就可以随时部署他们的微服务。测试区域扩大：每个微服务都至少会暴露数个 API 端点，因此，测试覆盖面要更大。多语言：开发团队可以选择最适合其微服务的语言。在一个大型系统中，可能无法找到一个适用于所有组件的测试框架。产品是一个活动目标：由于微服务是由自治团队单独部署和构建，所以需要额外的检查和边界，以确保它们部署后仍然可以正常运行。</p><p></p><p>所有这些特点都让我们不得不考虑新的测试策略。</p><p></p><p></p><h2>微服务测试金字塔</h2><p></p><p></p><p>测试金字塔是自动化软件测试的规划工具。传统的金字塔包含 3 种类型的测试：</p><p></p><p>单元测试集成测试端到端测试。</p><p></p><p><a href=\"https://www.infoq.cn/video/pSpXUzehUWsdNfQLfIbj\">微服务</a>\"金字塔新增了两种类型：组件和契约测试</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7be2301a241f8783695677565a0cda73.png\" /></p><p></p><p>这是微服务测试金字塔的一个版本。其他版本可能顺序上会有所不同。有些版本可能将契约测试包含在了集成层。事实上，金字塔更多的是一份指南，而非一成不变的东西。</p><p></p><p>接下来，我们将对金字塔的每一层做进一步的介绍。</p><p></p><p></p><h2>微服务的单元测试</h2><p></p><p></p><p>单元测试是粒度最小（数量最多）的测试形式之一。单元由可以单独测试的类、方法或函数组成。单元测试是开发实践中不可分割的一部分，比如测试驱动开发或行为驱动开发。</p><p></p><p>与单体相比，微服务中的单元可能更需要通过网络调用来完成其功能。这时候，我们可以让代码访问外部服务——就得接受延迟和不确定性，也可以调用测试替身，因此，我们有如下两种处理微服务依赖的方法：</p><p></p><p>独立单元测试（Solitary unit tests）：如果我们需要测试结果始终是确定的，就应该使用这种方法，通过模拟（mocking）或存根（stubbing）来隔离要测试的代码和外部依赖。社交单元测试（Sociable unit tests）：社交测试允许调用其他服务。在这种模式下，我们把测试的复杂性推到了测试或过渡环境。社交测试是非确定性的，但如果测试通过，我们对结果会更有信心。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3b/3b497df800d93781761f93ac1d02530c.png\" /></p><p></p><p>我们可以使用测试替身独立运行单元测试。我们也可以让要测试的代码调用其他微服务，这就是我们正在讨论的社交测试。如你所见， 可信度与稳定性之间的平衡将贯穿本文始终。模拟可以加快测试速度，降低不确定性，但模拟越多，测试结果的可信度就越低。虽然也有缺点，但社交测试更实用。因此，你要在这两种类型的测试之间做好权衡取舍。</p><p></p><p>如果你想实际看下独立测试和社交测试的例子，可以读一下 Dylan Watson 在 dev.to 上发表的那篇不错的博文。</p><p></p><p></p><h2>微服务的契约测试</h2><p></p><p></p><p>当两个服务通过接口耦合时，契约就形成了。契约详细列出了所有可能的输入、输出及其数据结构和副作用。服务的消费者和生产者必须遵守契约描述的规则才能进行通信。</p><p></p><p>契约测试可以保证微服务遵守契约。它们不会全面测试服务的行为；它们只确保输入和输出具备期望的特性，服务执行时间和性能都在可接受的范围内。</p><p></p><p>契约测试可以由生产者运行，也可以由消费者运行，还可以两者都运行，这取决于服务之间的关系。</p><p></p><p>消费者端契约测试由下游团队编写并执行。测试时，微服务连接到生产者服务的模拟版本，检查它是否可以消费其 API。生产者端契约测试在上游服务中运行。这类测试会模拟客户端可以发起的各种请求，验证生产者是否符合契约。生产者端测试让开发人员可以知道他们什么时候会破坏消费者兼容性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/60/605d436ad71a6c1c27d8feb2e4f84a4c.png\" /></p><p></p><p>契约测试可以在上游或下游运行。生产者端测试可以检查服务变更是否会给依赖它的服务造成破坏。消费者端测试使用上游生产者的模拟版本（并非真正的生产者服务）来运行消费者端组件，验证消费者是否可以发起请求，并消费生产者提供的期望响应。我们可以使用类似 wiremock 这样的工具来再现 HTTP 请求。如果两端都通过了契约测试，那么生产者和消费者就是兼容的，应该能够通信。持续集成时应该总是运行契约测试，以便在部署前发现不兼容的情况。</p><p></p><p>你可以在 Pact 的 5 分钟入门指南里在线试用契约测试。Pact 是一个基于 HTTP 的测试工具，可以编写和运行基于消费者或是生产者的契约测试。</p><p></p><p></p><h2>微服务的集成测试</h2><p></p><p></p><p>微服务的集成测试方式与其他架构略有不同，其目标是通过微服务交互来识别接口缺陷。与契约测试总有一端是模拟的不同，集成测试使用真实服务。</p><p></p><p>集成测试不关注服务的行为或业务逻辑。集成测试是为了确保微服务可以与其他微服务以及自己的数据库交互。我们希望通过集成测试来发现类似 HTTP 头缺失、请求 / 响应对不匹配这样的问题。因此，集成测试通常在接口层实现。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/10/106c4a7a1400450450e2ae3fad1017a8.png\" /></p><p></p><p>使用集成测试来检查微服务是否可以与其他服务、数据库和第三方端点通信。建议读下 Vitaly Baum 关于微服务存根的博文，看下实际的集成代码测试。</p><p></p><p></p><h2>微服务的组件测试</h2><p></p><p></p><p>组件是一个较大的系统中可以完成一项职责的一个微服务或一套微服务。</p><p></p><p>组件测试是验收测试的一种，使用模拟资源或 mocking 来替换服务，孤立地检查组件的行为。</p><p></p><p>组件测试比集成测试更全面，它们既会测试快乐路径，也会测试不快乐路径——例如，测试组件如何响应模拟网络中断或恶意请求。我们想知道组件是否满足其消费者的需求，很像我们在验收测试或端到端测试中所做的那样。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3e89d0c15baf74ec27bb20e6547087c5.png\" /></p><p></p><p>组件测试执行一组微服务的端到端测试。超出组件范围的服务都是模拟的。</p><p></p><p>执行组件测试的方法有两种：进程内和进程外。</p><p></p><p></p><h3>进程内组件测试</h3><p></p><p></p><p>在组件测试的这个子类中，测试执行器在和微服务相同的线程或进程内。我们以“离线测试模式”启动微服务，所有的依赖都是模拟的，这让我们无需网络就可以运行测试。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/33/331ed845a214b8e3c5044c31ca883d01.png\" /></p><p></p><p>组件测试在和微服务相同的进程内运行。测试在适配器中注入一个模拟服务，以模拟与其他组件的交互。</p><p></p><p>进程内测试仅适用于组件是单个微服务的情况。乍看之下，组件测试和端到端测试或验收测试非常类似。唯一的区别是，组件测试只选取系统的一部分（组件），并将其与其余部分隔离开来。它会对这个组件做全面的测试，以验证它是否提供了用户或消费者需要的功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/64/6410e58e8ba369bce15c07d7d8ea5cbd.png\" /></p><p></p><p>组件测试和端到端测试可能看上去类似。但区别在于，端到端测试在一个类生产环境中测试整个系统（所有微服务），而组件测试只隔出系统的一部分进行测试。两种测试都会从用户（或消费者）的角度来检查系统行为，模拟用户可能执行的操作。我们可以使用任何语言或框架来编写组件，但最流行的可能要数 Cucumber 和 Capybara 了。</p><p></p><p></p><h3>进程外组件测试</h3><p></p><p></p><p>进程外测试适用于任意大小的组件，包括由许多微服务组成的组件。在这类测试中，组件被（原封不动地）部署在一个测试环境中，所有的外部依赖都是以模拟或存根方式提供。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f8/f8cccbbe8f7271dd9623e36fc043549c.png\" /></p><p></p><p>在这类组件测试中，测试环境会比较复杂，因为它要模拟系统的其余部分。</p><p></p><p>要全面了解契约测试的概念，建议研究下 Java Spring 契约测试的示例代码。此外，对于 Java 开发人员，这篇博文提供了一些在各个层面测试 Java 微服务的代码样例。</p><p></p><p></p><h2>微服务的端到端测试</h2><p></p><p></p><p>到目前为止，我们都是分块测试系统。单元测试用于分别测试微服务的各个部分，契约测试验证 API 兼容性，集成测试检查网络调用，组件测试用于验证子系统的行为。只有在自动化测试金字塔的最顶端，我们才是对整个系统进行测试。</p><p></p><p>端到端（E2E）测试用于确保系统可以满足用户需求并实现其业务目标。E2E 套件应该覆盖应用程序的所有微服务，并且使用与用户相同的界面——通常搭配 UI 和 API 测试。</p><p></p><p>应用程序的运行环境应尽量接近生产环境。在理想情况下，测试环境中应包含应用程序通常需要的所有第三方服务，但有时候，为了降低成本或防止滥用，也可以模拟。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/57f1fe232c692790f32f338fc6acd918.png\" /></p><p></p><p>端到端测试是模拟用户交互的自动化测试。只有外部第三方服务可以是模拟的。</p><p></p><p>从测试金字塔可以看出，E2E 测试数量最少，这很好，因为它们通常最难运行，也最难维护。只要专注于用户的操作过程及需求，我们就可以从少数几个 E2E 测试中获得很大的价值。</p><p></p><p></p><h2>小结</h2><p></p><p></p><p>范式变了，策略也要跟着变。在微服务架构下，测试比以往任何时候都重要，但我们需要调整技术来适应新的开发模型。系统不再是由单个团队管理。取而代之，每个微服务的所有者都必须完成好自己的部分，才能保证整个应用程序的正常运行。</p><p></p><p>有些组织可能会认为，单元、契约和组件测试已经足够了。其他的则认为需要端到端和集成测试，他们可能会选择组建一支 QA 团队，以推动跨团队的测试。</p><p></p><p>想要进一步了解微服务吗？可以阅读以下几篇文章：</p><p></p><p>什么是微服务架构？</p><p></p><p><a href=\"https://semaphoreci.com/blog/microservice-architecture\">https://semaphoreci.com/blog/microservice-architecture</a>\"</p><p></p><p>微服务架构的领域驱动设计原则</p><p></p><p><a href=\"https://semaphoreci.com/blog/domain-driven-design-microservices\">https://semaphoreci.com/blog/domain-driven-design-microservices</a>\"</p><p></p><p>微服务的发布管理</p><p></p><p><a href=\"https://semaphoreci.com/blog/release-management-microservices\">https://semaphoreci.com/blog/release-management-microservices</a>\"</p><p></p><p>转向微服务之前要了解的 12 种单体架构优化方法</p><p></p><p><a href=\"https://semaphoreci.com/blog/monolith-microservices\">https://semaphoreci.com/blog/monolith-microservices</a>\"</p><p></p><p>感谢阅读！</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://semaphoreci.com/blog/test-microservices\">https://semaphoreci.com/blog/test-microservices</a>\"</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140026&amp;idx=1&amp;sn=975eca537f138a3526aa4a50b58ab3fa&amp;scene=21#wechat_redirect\">对峙数年后，微软对 Java 的态度 180°大反转</a>\"</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140025&amp;idx=1&amp;sn=ca1cf244eb8a12c3561fad45e4300066&amp;scene=21#wechat_redirect\">奇葩事儿：删除用户做数据还无法恢复，只赔 3 万；微信键盘来了，体积 524MB；谷歌希望将效率提高 20%：暗示将裁员？｜ Q 资讯</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139876&amp;idx=1&amp;sn=b5479b58f06e714877092811902bf015&amp;chksm=bdb8d7778acf5e617885b343a0fa9932b961ec5ad16a2bca0b3db0770c4ab67d247b26a22dee&amp;scene=21#wechat_redirect\">“不搞职级、人人平等” 25 年后行不通了？Netflix 破天荒引入细分职级：气走老员工</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139040&amp;idx=1&amp;sn=1eee3c77db28fd14ef9a18d201dd80ce&amp;chksm=bdb8d3b38acf5aa5c63957fc7975fc1118319ae52a1697b388d358b88752daef0cae83953661&amp;scene=21#wechat_redirect\">缺少软件开发文化，大众汽车陷入困境，CEO 也被赶下了台</a>\"<a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138672&amp;idx=1&amp;sn=22a4495af1ff90c5590bc4e313a09230&amp;chksm=bdb8d2238acf5b354a48c9ff9c170235832de8bf23b998f34a7457cc9539a5d32d0045f5ee0b&amp;scene=21#wechat_redirect\"></a>\"</p><p></p><p></p><p></p>",
    "publish_time": "2022-09-13 20:22:42",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]