[
  {
    "title": "Java近期新闻： JReleaser 1.2、Spring Batch、PrimeFaces、Quarkus、JobRunr与Apache Beam",
    "url": "https://www.infoq.cn/article/lf8oLh7w0pphOigclNdG",
    "summary": "<p>最近，Java社区相对比较平静，本期的新闻包括JDK 19、JDK 20、Spring Batch 5.0.0-M5、Quarkus 2.11.3、JReleaser 1.2.0、PrimeFaces 12.0.0-M3、JobRunr 5.1.8、Apache Beam 2.14.0和Apache Johnzon 1.2.19。</p><p></p><h4>JDK 19</h4><p></p><p><a href=\"https://openjdk.org/projects/jdk/19/\">JDK 19</a>\"依然处于<a href=\"https://openjdk.java.net/jeps/3#rc\">发布候选</a>\"阶段，预计GA版本会在2022年9月20日发布。<a href=\"https://jdk.java.net/19/release-notes\">发布说明</a>\"包含了文档的链接，比如<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec//api/index.html\">完整的API规范</a>\"以及一个<a href=\"https://cr.openjdk.java.net/~iris/se/19/latestSpec/apidiffs/overview-summary.html\">标注的API规范</a>\"，后者对比了JDK 18（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-18%2B36\">Build 36</a>\"）和JDK 19（<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-19%2B36\">Build 36</a>\"）的差异。InfoQ会持续跟进，提供更详细的新闻。</p><p></p><h4>JDK 20</h4><p></p><p>JDK 20的<a href=\"https://jdk.java.net/20/\">早期访问构建</a>\"版本<a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-20%2B12\">Build 12</a>\"发布，它是对Build 11的<a href=\"https://github.com/openjdk/jdk/compare/jdk-20%2B11...jdk-20%2B12\">更新</a>\"，包括对各种<a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2020%20and%20%22resolved%20in%20build%22%20%3D%20b12%20order%20by%20component%2C%20subcomponent\">问题</a>\"的修复。关于该版本的更多细节，请参阅<a href=\"https://jdk.java.net/20/release-notes\">发布说明</a>\"。</p><p></p><p>对于<a href=\"https://openjdk.java.net/projects/jdk/19/\">JDK 19</a>\"和<a href=\"https://openjdk.java.net/projects/jdk/20/\">JDK 20</a>\"，鼓励开发者通过<a href=\"https://bugreport.java.com/bugreport/\">Java Bug数据库</a>\"报告缺陷。</p><p></p><h4>Spring框架</h4><p></p><p>经过前段时间的忙碌，最近Spring团队比较安静。</p><p></p><p>在通向<a href=\"https://spring.io/projects/spring-batch\">Spring Batch</a>\"&nbsp;5.0.0的道路上，<a href=\"https://spring.io/blog/2022/08/24/spring-batch-5-0-0-m5-is-available-now\">第五个里程碑版本</a>\"发布，其更新包括：删除<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/test/JobLauncherTestUtils.html\">JobLauncherTestUtils</a>\"中Job的自动装配，迁移至JUnit Jupiter以及文档的改进。这个发布版本还升级了依赖，包括Spring Framework 6.0.0-M5、Spring Data 2022.0.0-M5、Spring Integration 6.0.0-M4、Spring AMQP 3.0.0-M3、Spring for Apache Kafka 3.0.0-M5、Micrometer 1.10.0-M4和Hibernate 6.1.2.Final。最后，Spring Batch 5.0.0-M5还弃用了两项内容，分别是用于游标/分页的Hibernate&nbsp;<a href=\"https://docs.spring.io/spring-batch/docs/current/reference/html/readersAndWriters.html#itemReader\">ItemReader</a>\"和<a href=\"https://docs.spring.io/spring-batch/docs/current/reference/html/readersAndWriters.html#itemWriter\">ItemWriter</a>\"接口，取而代之的是基于Jakarta Persistence规范的接口，另外，因为发现在JUnit中存在两个提供相同功能的静态方法，<a href=\"https://docs.spring.io/spring-batch/docs/current/api/org/springframework/batch/test/AssertFile.html\">AssertFile</a>\"类也被弃用。关于该版本的更多信息，请参阅<a href=\"https://github.com/spring-projects/spring-batch/releases/tag/5.0.0-M5\">发布说明</a>\"。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat<a href=\"https://quarkus.io/blog/quarkus-2-11-3-final-released/\">发布了</a>\"Quarkus 2.11.3.Final，该版本对<a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=2108396\">CVE-2022-2466</a>\"进行了全面修复，该漏洞是在<a href=\"https://quarkus.io/guides/smallrye-graphql\">SmallRye GraphQL</a>\"服务器扩展中发现的，它会导致服务器请求无法正确终止。此外，还对mariadb-java-client&nbsp;3.0.7、postgresql&nbsp;42.4.1和42.4.2以及mysql-connector-java&nbsp;8.0.30进行了升级。关于该版本的更多信息，请参阅<a href=\"https://github.com/quarkusio/quarkus/releases/tag/2.11.3.Final\">发布说明</a>\"。</p><p></p><h4>JReleaser</h4><p></p><p><a href=\"https://jreleaser.org/\">JReleaser</a>\"&nbsp;1.2.0版本<a href=\"https://andresalmiray.com/jreleaser-1-2-0-has-been-released/\">发布</a>\"&nbsp;，它是一个简化项目发布的Java工具，该版本的特性包括：支持将<a href=\"https://flatpak.org/\">Flatpak</a>\"作为打包器；允许basedir作为一个命名模板；允许通过Twitter4J在Twitter上发布消息文件，在这个过程中每一行都会是一条单独的消息，并且会跳过空行；它会通过日志发现-add-launcher参数没有传入，进而提供了配置未使用的自定义启动器的方案。另外，还有很多的依赖升级，包括jsonschema&nbsp;4.26.0、github-api&nbsp;1.308、slf4j&nbsp;2.0.0、aws-java-sdk&nbsp;1.12.270 and 1.12.290和jsoup&nbsp;1.15.3。关于该版本的更多信息，请参阅<a href=\"https://github.com/jreleaser/jreleaser/releases/tag/v1.2.0\">发布说明</a>\"。</p><p></p><h4>PrimeFaces</h4><p></p><p>在通往<a href=\"https://www.primefaces.org/\">PrimeFaces</a>\"&nbsp;12.0.0的道路上，<a href=\"https://twitter.com/primefaces/status/1562367103772282880\">第三个候选版本</a>\"已经发布，其特性包括：修复了<a href=\"https://primefaces.github.io/primefaces/11_0_0/#/components/autocomplete\">AutoComplete</a>\"组件在<a href=\"https://myfaces.apache.org/\">Apache MyFaces</a>\"上无法运行的问题；新的showMinMaxRange属性，允许导航范围超过最小/最大日期，其默认值为true；<a href=\"https://primefaces.github.io/primefaces/11_0_0/#/components/datatable\">DataTable</a>\"组件提供了新的showSelectAll属性，在列的标题中会显示“select all checkbox”。更多细节可以在<a href=\"https://github.com/primefaces/primefaces/issues?q=is%3Aclosed+milestone%3A12.0.0-RC3\">问题列表</a>\"中找到。</p><p></p><h4>JobRunr</h4><p></p><p><a href=\"https://www.jobrunr.io/\">JobRunr</a>\"的创始人和主要开发者<a href=\"https://www.linkedin.com/in/ronalddehuysser/\">Ronald Dehuysser</a>\"发布了<a href=\"https://github.com/jobrunr/jobrunr/releases/tag/v5.1.8\">5.1.8版本</a>\"，这是一个在Java中执行后台进程的工具，该版本包含了为后台job服务器关闭指标的功能。</p><p></p><h4>Apache软件基金会</h4><p></p><p>Apache Beam 2.41.0版本<a href=\"https://www.mail-archive.com/announce@apache.org/msg07525.html\">发布</a>\"，它包含了大量的缺陷修正，并且为Python&nbsp;<a href=\"https://beam.apache.org/documentation/transforms/python/elementwise/runinference/\">RunInference</a>\"转换为Java提供了对<a href=\"https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/values/KV.html\">KV</a>\"类的支持。关于该版本的更多信息，请参阅<a href=\"https://beam.apache.org/blog/beam-2.41.0/\">发布说明</a>\"。关于Apache Beam的更深入介绍可以参阅InfoQ的<a href=\"https://www.infoq.cn/article/DNHzwEIkQyJgShdGHz6L\">技术文章</a>\"。</p><p></p><p><a href=\"https://johnzon.apache.org/\">Apache Johnzon</a>\"的1.2.19版本发布，该项目完整实现了JSR 353，即<a href=\"https://jcp.org/en/jsr/detail?id=353\">Java API for JSON Processing</a>\"（JSON-P），和JSR 367，即<a href=\"https://jcp.org/en/jsr/detail?id=367\">Java API for JSON Binding</a>\"（JSON-B）规范，<a href=\"https://twitter.com/rmannibucau/status/1561611201108484097\">发布</a>\"的特性包括：在<a href=\"https://johnzon.apache.org/apidocs/org/apache/johnzon/jsonschema/generator/PojoGenerator.html\">PojoGenerator</a>\"类中对枚举的基本支持；在onEnum回调中添加JSON-Schema；能够确保枚举使用JsonbProperty时，导入它；暴露PojoGenerator类中的toJavaName()方法给子类。关于该版本的更多信息，请参阅<a href=\"https://johnzon.apache.org/changelog.html\">发布说明</a>\"。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2022/08/java-news-roundup-aug22-2022/\">Java News Roundup: JReleaser 1.2, Spring Batch, PrimeFaces, Quarkus, JobRunr, Apache Beam</a>\"</p>",
    "publish_time": "2022-09-13 09:07:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Stack Overflow 2022报告：亚马逊云科技的软件开发“武器库”",
    "url": "https://www.infoq.cn/article/69cDiK84CkeW7CEZXg9j",
    "summary": "<p></p><p>前不久，备受期待的 Stack Overflow 2022 年度开发者调查报告终于出炉。作为软件开发行业最具专业性和影响力的开发者调研活动，Stack Overflow 收集了全球 180 个国家和地区的开发人员反馈，涵盖流行的操作系统、编程语言、框架和库、云平台、数据库、机器学习技术等多个细分主题。</p><p></p><p>Stack Overflow 在报告中表示，收回的 5 万 6 千份有效回复体现出了一些对塑造当今软件开发和实践的工具和环境的深刻见解（great insights）。这些结果也有助于我们在技术选型和开发环境选型时进行参考，因此我们摘取了部分亮点进行解读。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f0/f0af2106a2bc8e11805bbc200c7025fc.jpeg\" /></p><p></p><p></p><h2>云原生开发</h2><p></p><p></p><p>Stack Overflow 年度报告的“云平台”调查问题希望了解开发者在过去一年中主要在哪些云平台中进行开发工作。在针对专业开发者群体中，亚马逊云科技以 51.01% 的比例位列第一，其次是 Azure、Google Cloud 以及 Firebase。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/82/82d634a683fbcdbfbe8230e15a3bd65b.jpeg\" /></p><p></p><p></p><h3>从本地开发到云原生开发的演进</h3><p></p><p></p><p>在调查结果中，有的平台在 IDE 和云端开发环境上特别有优势，有的平台是基于云原生的平台即服务（PaaS），使软件开发人员可以无需担心底层基础架构就能轻松部署代码，有的是用于创建移动和 Web 应用程序的统一后端即服务 (BaaS) 平台。</p><p></p><p>处于第一位的是亚马逊云科技。亚马逊多年持续投入建设云开发环境，也有对应的一些产品。亚马逊云科技于 2017 年发布了 Cloud9 IDE，前身是一个著名的 WebIDE 开发平台。2019 年，亚马逊云科技发布了 Cloud Development Kit（CDK）云开发工具包，它是一项基础设施即代码服务，封装了亚马逊云服务的配置细节和粘合逻辑。另外，亚马逊还提供了基于云开发平台的 Serverless 架构、DevOps 一体化等诸多功能，实现生态的闭环。</p><p></p><p>从 Stack Overflow 的报告可以看出，基于云的开发平台，已经成为了各厂商的必争之地。虽然本地化开发目前还很普遍，但是云开发也有一些显著的好处。比如说在传统的软件开发方法中，开发者一般是在自己的电脑上进行开发和测试，然后在物理机或云上运行，但一些 CPU 和内存密集型的任务，在某些情况下编译或测试可能非常耗时且占用大量资源。然而大多数工程师的电脑有 CPU 和内存的限制，编译会浪费大量时间。开发环境上云之后，云服务就足以解决存储、计算资源上的弹性需求，云上按需计费也能节省边际成本。</p><p></p><p>另外，云上协同开发还可以让团队之间共享统一的预定义环境，不需要一而再地处理不同的平台、工具、版本和依赖项，一致的编译、测试环境让团队成员无需配置复杂环境即可上手，甚至可以突破时间、地域限制，让处于全球范围内、不同工作时间的开发团队使用统一的、定制的环境。云开发也意味着应用程序从开发、集成到测试、部署和生产都在使用一致的环境，有助于减少可能在生产中暴露出来的错误和其他问题的数量。</p><p></p><p>自前几年起，Kubernetes 和 Docker 开始流行，容器化技术让应用程序更加具有可移植性，这意味着它可以在任何云环境上运行，并且只需少量集成工作。而随着云原生技术的发展，原始定义现在可以扩展到包括一系列技术，而不是与容器严格相关，例如 Serverless 和流式传输等，能够让开发者更充分利用云计算模型，在云中设计、开发和运行工作负载也更加容易。</p><p></p><p></p><h3>Serverless 架构</h3><p></p><p></p><p>Serverless 是云原生技术发展的高级阶段。Serverless 最早的框架产品源于 2014 年亚马逊推出的 Amazon Lambda。Lambda 的推出开启了云计算的新时代，之后所有的大厂都在跟进，比如微软、谷歌、IBM 都先后推出自己的 Serverless 产品。在这之后，Serverless 也从愿景层面逐步走向落地，在企业里应用开来。</p><p></p><p>从最初认为 Serverless 是 FaaS（函数即服务），到 FaaS（函数即服务）和 BaaS（后端即服务）的集合，人们对 Serverless 的认知不断的变得清晰。对亚马逊云科技这样的云厂商而言，Serverless 不仅局限于计算服务，而是指一种端到端的架构。除了我们比较常提起的 Lambda 外，还覆盖了计算、存储、网络、容器、数据库等，集成多个方面的服务，才能快速地构建现代化应用。</p><p></p><p>开发人员在使用 Serverless 服务和架构时，只需要关注业务逻辑，不再需要部署、管理或扩展服务器。云服务本身可以快速、无缝地自动扩展，以适应流量峰值。</p><p></p><p>事件驱动型架构（EDA）是一个典型的 Serverless 架构，常见于使用微服务的现代应用程序，或者有解耦组件的任何应用程序。它以事件为媒介，实现组件或服务之间最大松耦合的方式。现在的企业，普遍采用了微服务架构，而结合微服务和事件驱动架构，能更好地解决关键业务的实时、可扩展等问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f5/f53d8727d4ba4515224221c2c31fc903.png\" /></p><p></p><p>事件驱动型架构有三个主要组成部分：事件发起者、事件路由器和事件使用者。事件源产生事件，并将事件发布至事件路由器。事件路由器进行事件筛选并推送给相应的事件使用者。事件使用者或者处理事件，或者受事件影响，并为之采取相应的操作。通过此架构，事件源和事件使用者解耦，从而使它们能够独立扩展、更新和部署。</p><p></p><p>使用事件驱动型架构的优势也是十分明显的，通过解耦，使服务之间相互独立，利于扩展和提高可用性。同时，使用事件路由器 Amazon EventBridge 或 Amazon Simple Notification Service（SNS）将帮助筛选并将事件推送给使用者，无需编写自定义代码，大幅提升开发的敏捷性。</p><p></p><p>这种架构对于成本的优化也是显著的，事件是按需发生的，这意味着我们无需为空闲资源付费。比如上图中的作为事件使用者的 Lambda 函数，只需要为 Lambda 处理事件时的函数请求数量和执行代码所花费的持续时间付费。</p><p></p><p>随着 Serverless 各方面的功能和性能的提升，其采用率也在持续增长。据 Datadog 2021 年发布的无服务器状态报告，开发人员正加速采用无服务器架构：2019 年之后 Amazon Lambda 的使用率显著增加，2021 年初，Amazon Lambda 函数的平均每天调用频率是两年前的 3.5 倍，且半数 Amazon Web Services 新用户已采用 Amazon Lambda。而据 Amazon Web Services 公布的数据显示，亚马逊已有数十万家客户在各种场景下用 Amazon Lambda 来构建他们的服务。</p><p></p><p></p><h3>低代码平台</h3><p></p><p></p><p>Serverless 是一种范式转变，可以减少服务器运维工作，如果再加上减少手动编码的方式，我们就能够更快地进行业务开发和交付。各云厂商近几年都在低代码开发平台上投入了不少力量，亚马逊也于 2017 年发布了 Amazon Amplify。</p><p></p><p>从云计算开始，技术发展在不断将底层平台进行抽象，低代码平台通过将底层平台云化，屏蔽复杂的使用规则，用 BaaS 层接口提供后端服务，让开发者将重心放到业务流程和界面定制上。也因此，低代码的核心部分之一是前端开发。Amazon Amplify 平台采用的是集成 UI 原型设计平台 Figma 的方式，允许设计师和前端开发人员在设计和开发活动上进行协作。例如，开发人员只需将新的组件设计从 Figma 拖放到 Amplify Studio 的应用程序中，设计好的 UI 会自动转换为 JavaScript 或 TypeScript，让开发人员可以完全控制应用程序的设计和功能。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c406b646228c773e751f67b40127475b.jpeg\" /></p><p></p><p>低代码开发平台的另一优势是加速全栈开发的速度。我们可以看到 Stack Overflow 的报告涉及的技术越来越多，也说明了随着应用程序的复杂性增加，我们开发人员需要在开发过程中处理越来越多的事情，包括框架和平台的选择、安全配置、数据库、CI/CD 部署等等。对于开发人员来说，全栈开发变得非常复杂，需要具备非常全面的技能。但通过低代码提供的堆栈环境，以及全生命周期管理能力，让开发人员可以以简单的方式管理从 UI 设计、代码开发到部署的端到端应用程序开发，进一步降低全栈开发难度。在 Amazon Amplify 中，它是通过 CLI 命令等方法实现快速地创建后端和数据库（在内部使用 Lamda、S3 和 DynamoDB），从而在短时间内完成一套全栈 Web 和移动应用程序。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/36/3615da0f26da877bd94f1cfdb7b62d9a.jpeg\" /></p><p></p><p>低代码还能减少对 AI 或机器学习专业人员的依赖，可以降低 AI 应用的失败率。在亚马逊的低代码平台中就提供了如 AI/ML、mapping 等服务。我们可以在构建的全栈应用程序时，轻松调用 Analytics 功能，收集事件数据分析用户操作，然后调用 AI/ML 服务“预测”用户的下一步操作。或者也可以根据自己的需求调用其它比如文字翻译、语音识别、图像处理等云服务。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/65/6582b37163cfe8ce8649e4fce4dc5b81.jpeg\" /></p><p></p><p></p><h2>机器学习</h2><p></p><p></p><p>在低代码平台中，对 AI/ML 服务的调用，也是在释放人工智能的力量。人工智能的应用现在越来越普遍，渗透到了企业的各种业务场景应用当中，发挥着重要且积极的影响。日常开发中，我们也会经常遇到需要应用 AI/ML 技术的地方，而云上的机器学习服务更加齐全，不仅提供了多样性的选择，而且还兼顾了易用性。</p><p></p><p>机器学习技术的普及也和云计算的发展密不可分。一方面，机器学习有着庞大的计算和数据存储需求，几乎机器学习的每一步训练与推断都需要庞大的云端集群来提供算力或存储资源支持。而云服务提供商凭借海量的集群资源，以及按需按消耗付费的计价模型，再加上这几年云服务持续的降低成本，让机器学习与人工智能已经变成了人人都用的服务。</p><p></p><p>另一方面，云服务厂商在机器学习的工具库上，提供了非常好的深度和广度，来满足用户的不同需求。机器学习本身是一个“Right tools for the right job”的事情，需要根据具体的业务和场景，选择最合适的工具。亚马逊云科技采取开放包容的工具选择策略，让云端可以和客户的整个环境做到良好的集成。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e9/e9af405082c411a95ad8d8c85cdf2b5e.jpeg\" /></p><p></p><p>从机器学习技术栈的 3 个层面分别阐述：</p><p></p><p>在底层机器学习框架方面，云厂商需要支持各种主流的机器学习基础框架和标准接口，如 TensorFlow、PyTorch、Apache MXNet、Gluon、Keras 等。这些框架也都出现在了今年 Stack Overflow 年度报告“受开发者欢迎的库”调查结果中。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9defe56a6f7d5527484cab4dd298eb1f.jpeg\" /></p><p></p><p>而亚马逊云科技不仅支持上述机器学习基础框架和接口，还针对 TensorFlow、PyTorch 和 MXNet 三个主流框架进行了专门的优化适配，并支持通过 Amazon Glue、Amazon Kinesis 等数据接口集成来最大限度方便框架的使用。这些设计使其可以方便地支持开发者以及数据科学家们运行流行机器学习框架以及运行使用多种框架。</p><p></p><p>在底层计算层也是如此，无论是 AI 芯片还是计算实例，云厂商也可以让用户根据不同的应用场景，根据自己的实际需求自由选择各种 GPU 实例、ARM 实例、机器学习专用推理芯片。</p><p></p><p>在上层 AI 服务层面，开发者可以根据自身需求，在云上有选择的使用各种 AI/ML 服务，比如文本分析、代码检查、聊天机器人、需求预测、文档分析、企业搜索、反欺诈、图像视频分析、个性化推荐、实时翻译、文本语言转换、转录，等等。为自己的系统应用补充所需要的智能化组件，通过简单的 API 调用即刻补足智能拼图缺失的一角。</p><p></p><p>在承上启下的中间层，像 <a href=\"https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db\">Amazon SageMaker</a>\" 这样的工具平台，提供了一项全托管端到端机器学习服务，这也是亚马逊云科技机器学习服务层面的核心产品，可帮助数据科学家、开发人员以及机器学习专家快速构建、训练并托管规模化机器学习模型。开发者只需要关心自己输入什么数据，自己想用什么框架和什么算法，其他的各种参数调优什么的脏活儿就让机器自己用机器学习来做，减轻了机器学习流行中数据清洗、建模等步骤的复杂性。</p><p></p><p>随着机器学习应用变得普遍，各种 MLOps 工具也变得越来越多，而且机器学习项目的开发工作流程仍然非常反复，所以对于开发人员来说，管理工作还具有挑战性。</p><p></p><p>例如，当尝试一种新算法或调整超参数时，开发人员和数据科学家通常在 Amazon SageMaker 上进行成千上万次实验，需要手动管理所有实验。随着时间的流逝，追踪性能最佳的模型和利用在实验过程得出的经验教训变得越来越困难。</p><p></p><p>2020 年， SageMaker Studio 正式发布，这是亚马逊云科技创建的一个全集成的 ML 开发环境——也是业界首创。它统一了 ML 开发所需的所有工具，将数百种机器学习功能，包含训练好的模型、设置好的容器镜像，都集成到基于 Web 的开发环境 Amazon SageMaker Studio 中。</p><p></p><p>开发人员可以通过单个窗格管理整个 ML 工作流，在可视化界面中编写代码、跟踪实验、可视化数据，以及针对 ML 工作流进行调试和监控，不需要切换来切换去，从而极大地提高了开发效率。</p><p></p><p>这种集成并简化后的开发环境对机器学习初学者也特别友好。以 Stack Overflow 报告最受开发者喜爱的 Hugging Face Transformers 为例，其官方网站默认使用 Amazon SageMaker 来训练和部署模型，提供了相应的<a href=\"https://xie.infoq.cn/article/fb833598f8919e89fd1168264\">入门指导</a>\"。Hugging Face 提供的深度学习容器（DLC）与 SageMaker 结合，可以让开发者跳过从头开始构建和优化训练环境的复杂过程，立即开始训练模型。在亚马逊云服务上，免费注册账户，然后用 Huggingface Sagemaker，只需简单几行代码就可以开始训练并部署 Hugging Face Transformers 模型。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c1/c1d717ed026bed33bbbc1c886b5b586d.jpeg\" /></p><p></p><p></p><h2>云数据库</h2><p></p><p></p><p>在 Stack Overflow 的报告中，还有一项特别有意思的调查项目，即“薪资待遇最好的技术”，其中在针对编程语言的统计中，使用 Clojure 语言的开发者收入最高；在针对框架和库的统计中，Apache Spark、Apache Kafka 和 Hadoop 排行最高，说明大数据类的工作收入较高；在针对数据库的统计中，DynamoDB 数据库开发者的薪水是最高的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/99/99201a2b2626b7e0d7e8cd1fdcf4b757.jpeg\" /></p><p></p><p>在这里就不得不介绍一下薪酬最高的开发数据库 DynamoDB 是何许人也，DynamoDB 是非关系型数据库的开山鼻祖，它起源于亚马逊于 2007 年发表的一篇划时代论文《Dynamo: Amazon’s Highly Available Key-value Store》。这篇论文影响了很多 NoSQL 数据库的设计，<a href=\"https://www.infoq.cn/article/aws-dynamodb-dive-in\">也最大程度地将 consistent hashing 这个概念从学术界引入了工业界</a>\"。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8a/8a6a0cc2f7795c9a6f5356740169e9de.jpeg\" /></p><p></p><p>Dynamo 论文推动了行业大规模变迁至非关系型数据库，并最终促成新一代的适用于互联网的云数据库 DynamoDB 的诞生。现在，DynamoDB 可处理每日超过 10 万亿请求和每秒超过 2000 万峰值请求，并且还具有详细的企业级特性，如支持 ACID 事务，使用户能够大规模构建业务关键型应用程序，从而被众多企业应用到核心业务中。今天有许多全球发展最快的企业，如 Lyft、Redfin、Disney、Zoom 等企业，都依靠 DynamoDB 的规模和性能来支持其关键任务负载。</p><p></p><p>在今年 7 月的 USENIX ATC’22 上，Amazon DynamoDB 团队再次发布了他们的新论文《 A Scalable, Predictably Performant, and Fully Managed NoSQL Database Service》，论文里包含了云数据库跨分区吞吐量的均匀分布是如何设计的，如何用多 Paxos 来保持副本同步的机制，MemDS 分布式缓存的设计方法等硬核内容。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/06/06fab638a25eaf2968b1c2f2367019cd.jpeg\" /></p><p></p><p>DynamoDB 的架构</p><p></p><p>更难得的是，这篇论文还涵盖了 DynamoDB 的架构设计，以及它如何不断演进以满足客户的需求，这种涉及演进的论文相对也比较少见。</p><p></p><p>过去 10 多年，该数据库的研发人员加入了包括二级索引支持、可扩展流式数据捕获、自适应容量等等功能。不断增加的功能，不仅涉及底层可用性、持久性、安全性和规模等，还包括易用性等。这些功能让用户不再需要配置集群，只需创建一个表存储数据，即可轻松实现无缝缩放。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/54/54a036ec338eeb54079dd19c477b809a.jpeg\" /></p><p></p><p>DynamoDB 的发展</p><p></p><p>从工程角度看，这应该是近年来大规模分布式系统最实用的论文之一，其中包含的那些云数据库设计方法，估计也会给业界带来一些启发。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>我们从 Stack Overflow 调查报告出发，介绍了当前的开发工具、开发环境热点技术方向。</p><p></p><p>出色的开发工具也是软件开发者的生产力放大器。现在软件开发几乎渗透到了经济的各个领域，甚至可以说未来每个公司都会是软件公司。而开发软件必须要有好用的开发工具，如果说软件是技术进步的助推器，那么开发工具是技术进步的二阶助推器: 助推器的助推器。</p><p></p><p>随着云原生时代的来临，以及组织代码规模的扩张，开发模式不断变得复杂，也促进一些大型企业，特别是云厂商提供更好的开发环境。同时云服务提供商通过将自己的服务，集成到流行的开发工具中，使得开发者能够使用自己熟悉的工具来管理云服务。对于云厂商来说，开发工具对于开发成本的优化，以及软件交付效率的提升，可以通过用户得到千百倍的放大，为用户带来巨大的经济价值，从而也能进一步促进云厂商自身的发展。</p><p></p><p>“云平台”、云数据库这些排行榜是云计算行业的一个缩影，Stack Overflow 开发者调查报告反馈出亚马逊云科技为开发者提供了称心应手的软件开发“武器库“，而这些开发工具收到了来自不同开发者的多方面的积极评价，这离不开亚马逊云科技对开发者的重视和对开发工具不断打磨与创新。当我们评估用什么云服务时，也不妨同时看看企业是否重视工具的打造，所提供的开发工具是否趁手，毕竟这两个之间是互相促进的，“双驱动”带来的效率提升会更加可观。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9e/9e8d5e25aac3673ef79f502e7d09cbdf.jpeg\" /></p><p></p><p>作为云计算领域的行业风向标活动，2022 亚马逊云科技中国峰会将于 10 月 13 日 -10 月 14 日于线上举办，与会者有机会与国内外尖端技术讲师、构建者、业界领袖面对面深入交流，全面了解亚马逊云科技在云开发、人工智能、机器学习、数据库、大数据分析、物联网、安全等方面最新的云计算解决方案。点击链接了解更多详情：<a href=\"https://summit.awsevents.cn/2022/signin?source=I4txnunRTQh30eQ4v/ulfA==&amp;tab=1&amp;type=2\">https://summit.awsevents.cn/2022/signin?source=I4txnunRTQh30eQ4v/ulfA==&amp;tab=1&amp;type=2</a>\"</p><p></p><p>参考链接：</p><p></p><p>参考链接：</p><p><a href=\"https://aws.amazon.com/cn/solutions/case-studies/redfin/\">https://aws.amazon.com/cn/solutions/case-studies/redfin/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/solutions/case-studies/lyft/\">https://aws.amazon.com/cn/solutions/case-studies/lyft/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/dynamodb/\">https://aws.amazon.com/cn/dynamodb/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/blogs/china/machine-learning-plugs-wings-for-digital-transformation/\">https://aws.amazon.com/cn/blogs/china/machine-learning-plugs-wings-for-digital-transformation/</a>\"</p><p><a href=\"https://aws.amazon.com/cn/amplify/studio/\">https://aws.amazon.com/cn/amplify/studio/</a>\"</p><p><a href=\"https://www.youtube.com/watch?v=T4MQrRDo20w\">https://www.youtube.com/watch?v=T4MQrRDo20w</a>\"</p><p><a href=\"https://www.cirrushq.com/wp-content/uploads/2022/03/AWS-UG-EDI-Amplify-Studio.pdf\">https://www.cirrushq.com/wp-content/uploads/2022/03/AWS-UG-EDI-Amplify-Studio.pdf</a>\"</p><p><a href=\"https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db\">https://xie.infoq.cn/article/a1b34421f3183d3bc1d8e59db</a>\"</p><p><a href=\"https://xie.infoq.cn/article/fb833598f8919e89fd1168264\">https://xie.infoq.cn/article/fb833598f8919e89fd1168264</a>\"</p><p>https://www.infoq.cn/article/aws-dynamodb-dive-in</p>",
    "publish_time": "2022-09-13 11:02:06",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "里程碑！PyTorch正式加入Linux基金会，社区治理这一核心将不会改变",
    "url": "https://www.infoq.cn/article/OYS7T01SgBBZvCqNT04E",
    "summary": "<p>当地时间9月12日，Linux基金会在其官网宣布，PyTorch已经正式加入Linux基金会。</p><p></p><h2>PyTorch正式加入Linux基金会</h2><p></p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf9c37347d63bf34453fc6de1bed5371.png\" /></p><p></p><p>&nbsp;</p><p>Linux基金会表示，其实很难用一篇文章来描述清楚PyTorch的加入对基金会的意义有多么重大，但还是希望尽可能将其表达出来。</p><p>&nbsp;</p><p>以下为基金会全文：</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/TblGFGRIjAKLu6JKYBqv\">PyTorch</a>\" 是当今世界上最重要和最成功的机器学习软件项目之一。我们很高兴与项目维护者、贡献者和社区合作，将PyTorch带入到一个中立的“家园”，在那里它可以继续强劲地增长并快速地创新。我们感谢Meta团队孵化出了PyTorch并让它成长为一个庞大的生态系统，更要感谢 Meta团队对于Linux 基金会的信任，正因为有了这样的信任才让PyTorch加入<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651130293&amp;idx=2&amp;sn=fd6dc3927e04a667860941633c52d7de&amp;chksm=bdb8f1e68acf78f00aafa670e4803a74f24c2a2e8f8eff59d50ed1948a0cb8e7922f57b3785f&amp;scene=27#wechat_redirect\">Linux</a>\"成为可能，才让这场史诗般的旅程得以呈现。</p><p>&nbsp;</p><p>人工智能、机器学习和深度学习对于当前和未来的技术创新至关重要。与人工智能、机器学习社区和它们生成的代码相关的一切都将飞速发展起来。<a href=\"https://archsummit.infoq.cn/2022/hangzhou/track/1272\">AI/ML</a>\"也是一个真正“开源优先”的生态系统。大多数流行的 AI 和 ML 工具和框架都是<a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651136062&amp;idx=4&amp;sn=14910cd2372b3c08e5b09a1225648b9e&amp;chksm=bdb8d86d8acf517bd272ece0155eca8e5714ff6e047a2dc194b4734099ea80c3d0186f28a629&amp;scene=27#wechat_redirect\">开源</a>\"的。社区十分重视透明度和开源精神。在开发让AI和ML落地的工具和解决方案时，开源社区正在并且未来也将发挥着主导作用，随着时间的推移，开源社区将使这些工具和解决方案变得更好</p><p>&nbsp;</p><p>&nbsp;基于上述所有原因，Linux 基金会明白，在人工智能和<a href=\"https://archsummit.infoq.cn/2022/hangzhou/track/1280\">机器学习</a>\"领域，开源是重中之重。Linux 基金会已经托管并与许多项目合作，这些项​​目要么直接为基础 AI/ML 项目（LF AI 和数据）做出贡献，要么为其用例做出贡献并与其平台集成。（例如，LF Networking、AGL、Delta Lake、RISC-V、CNCF、Hyperledger）。&nbsp;</p><p>&nbsp;</p><p>PyTorch正是扩展并建立在这些努力之上。显然，PyTorch 是用于开发、测试和部署 AI/ML 和深度学习应用程序的最重要的基础平台之一。如果你需要在 AI 中构建一些东西，如果你需要一个库或一个模块，那么 PyTorch 中很可能会为此提供一些东西。任何一款AI应用程序中，都可能有着PyTorch的身影。从提高疾病诊断和心脏病发作的准确性，到<a href=\"https://www.infoq.cn/article/UuQUfYXAdEuQt36MsD0e\">自动驾驶</a>\"汽车的机器学习框架，再到天文学家的图像质量评估工具，PyTorch 无处不在。</p><p></p><p>&nbsp;</p><p>PyTorch最初由Meta的AI团队孵化，在以社区为中心的管理之下，PyTorch现已发展成为一个由贡献者和用户组成的庞大社区。PyTorch 的精髓之处（以及它的维护者的功劳）在于，它的确是如今许多AI和ML项目的基础平台，它是一把真正的瑞士军刀。正如开发人员在 Linux 之上构建了我们今天所知的大量技术一样，许多AI/ML 社区也是在 <a href=\"https://www.infoq.cn/article/7Azz9NMpjuI4zmV4S4oC\">PyTorch </a>\"之上构建而成。PyTorch进一步支持了新兴技术和不断变化的用户需求。截至 2022 年 8 月，PyTorch 是世界上与 Linux 内核和 <a href=\"https://qcon.infoq.cn/2022/beijing/track/1291\">Kubernetes</a>\" 并列的五个增长最快的开源软件社区之一。从 2021 年 8 月到 2022 年 8 月，PyTorch 统计了超过 6.5万次提交.&nbsp;超过 2400 名贡献者以提交问题或PR或编写文档的方式参与了这项工作。这些数字使 PyTorch 成为历史上最成功的开源项目之一。&nbsp;</p><p>&nbsp;</p><p>像 PyTorch 这样有可能成为关键技术基础平台的项目，保持中立对它更有益处。中立性和真正的社区所有权使 Linux 和 Kubernetes 在变得更加成熟的同时继续加速和增长，从而超越预期。用户、维护者和社区开始将它们视为可以永久依赖和信任的公共资源的。通过创建一个中立的家园——PyTorch 基金会，我们共同为PyTorch打造了一个透明、社区治理和规模无可限量的未来。</p><p></p><h2>加入后，PyTorch不会有大的改变</h2><p></p><p></p><p>作为 Linux 基金会的一部分，PyTorch 及其社区将受益于我们的许多计划和支持社区，例如培训和认证计划（我们已经在进行中）、社区研究（例如我们的项目旅程报告），当然还有其他社区活动等。PyTorch 社区将在<a href=\"https://www.infoq.cn/article/8V7UcWWhXXeCg6xOsKvQ\"> Linux 基金会</a>\"内部和周围工作，PyTorch社区也有一个可以访问LFX 协作门户的入口，我们将为PyTorch社区提供指导并帮助 PyTorch 社区确定未来的领导者、寻找潜在的员工、并观察共享的社区动态。</p><p></p><p>PyTorch 通过良好的维护和开源社区管理达到了目前的状态。我们不会改变 PyTorch 的任何优点。事实上，我们迫不及待地想向 Meta 和 PyTorch 社区学习，以改善基金会其他项目的经验和成果。对于那些想要更深入地了解我们的 PyTorch 基金会计划的人，我邀请您加入 Soumith Chintala（PyTorch 的联合创始人）和 Ibrahim Haddad 博士（PyTorch 基金会的执行董事），在周四进行题为PyTorch 的现场讨论：开源 AI/ML 的基础。</p><p>&nbsp;</p><p>我们感谢 Meta 对“将火炬传递给我们”（双关语）的信任。与社区一起，我们可以构建（甚至更多）非常伟大的东西，并为支撑我们现在和未来生活的宝贵技术的全球遗产增添光彩。欢迎，PyTorch！我们等不及要开始了。</p><p></p><p>参考链接：</p><p></p><p>https://linuxfoundation.org/blog/welcoming-pytorch-to-the-linux-foundation/</p>",
    "publish_time": "2022-09-13 12:23:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "历时三年替换掉二十年老系统，这个团队选择“一次性到位” | 卓越技术团队访谈录",
    "url": "https://www.infoq.cn/article/SbPCPlTopJQsGAv1IPmB",
    "summary": "<p></p><p>作者 | Tina</p><p>采访嘉宾 | 沈勇毅、孔伟、苏彦春</p><p></p><p>作为传统 IT 铁三角的核心腹地，金融行业过去十年的“去 IOE”运动备受关注。这种在过去 30 年中被广泛使用的集中式架构逐渐难以适应金融业务的线上化、数字化、智能化需求，正在逐渐被替换。因为需要修改底层技术，涉及到很多代码的重写、技术架构的重组和迁移，去 IOE 基本上是一种“小步慢走”的过程，本身就是 5-10 年的工作。</p><p></p><p>金融行业的变革从银行开始，逐渐带动了保险行业。这几年保险行业的数字化转型走得特别快，一众头部保险公司都在自我改革以适应时代的改变。</p><p></p><p>金融企业的数字化转型，通常是规划长远、实施复杂的项目，需要有懂技术、有大型项目经验的人，做出既稳妥又大胆的决策，而一般的企业不可能无限制在技术上进行投入，那么在投入有限、人才缺乏、技术实力储备不足等刚性约束条件下，转型之路究竟该怎么走？绝大多数机构并没有清晰的答案。</p><p></p><p>作为一家中型金融机构，民生人寿保险也曾面临上述困难。2019 年的时候，民生开启了一场快节奏、深层次的数字化转型，将用了近二十年的架构，一举搬上了混合云架构上。原来需要 5-10 年时间的项目，也只花了 3 年就宣告完成。民生保险探索出来的这条数字化转型路径，或许也能给亟需变革的其他中小型企业带来一点启发。</p><p></p><p></p><h2>重构核心系统，一次性到位进行转型</h2><p></p><p></p><p>在 1955 年首届财富 500 强名单中，只有 12.2% 的公司在 2014 年仍然保持在该位置。虽然一些下滑是因为品牌重塑或并购，但其中大部分反映了许多曾经的大牌未能在现代社会中生存下来的事实。在技术不断进步的环境中，未以正确的方式接受变革并进行创新，这些衰亡的企业是带有警示意义的例子。</p><p></p><p>一般企业都是循序渐进的发展，但是新技术的革新，让企业的 IT 环境可能进行革命性的变化，没有壮士断腕的决心，可能真的无法适应业务的发展而被淘汰。</p><p></p><p>一边是当前企业都有变革的压力，另一边是金融企业里的特殊现状。</p><p></p><p>金融行业有自己的特性，使用的是一些成熟的技术或者在其它领域已经应用多年的技术。而现在，数字化转型普遍是将已有互联网的技术、流程、实践置于服务的构思和交付方式的核心。这也就是说，彻底、全面的转型意味着“不破不立”。</p><p></p><p>民生人寿保险面临的状况也是如此。在 2003 年成立的时候，受制于当时的技术环境，民生人寿保险采用了传统的 IOE 架构，以及单体应用。技术架构的层面发展到现在，已经变得陈旧，应用之间的耦合度也非常高，很难去适应现在快速业务的变化。</p><p></p><p>在过去二十年的时间里，民生保险在集中化的 Oracle 数据库中积累了大量数据，但各方面的指标口径没有进行统一，数据也缺少标准治理。</p><p></p><p>民生保险的转型目标是，用“民生保险”公众号和官网将 90% 常用的业务实现线上处理、用“掌上民生”实现保单销售全流程线上化，通过引入人工智能实现运营服务的自动化，打造了“业务中台”和“数据中台”双中台模式，以支撑公司转向以客户为中心的经营模式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/47/478eddce5733ac398d782aec3aa3c088.png\" /></p><p></p><p>图源：<a href=\"https://m.gelonghui.com/p/525770\">https://m.gelonghui.com/p/525770</a>\"</p><p></p><p></p><h2>技术选型是项目中最大的风险点</h2><p></p><p></p><p></p><blockquote>寿险行业的数字化转型在此之前并没有成熟的案例。</blockquote><p></p><p></p><p>作为求稳的金融企业之一，民生保险没有在老系统上进行“修修补补”，而是进行彻底变革。民生新一代的 IT 建设分为两大部分，一部分是建设新一代的业务核心系统，另一部分是重建技术架构。</p><p></p><p>在基础架构选型的时候，民生保险探索过多种路径，包括超融合，自己搭建 Kubernetes 集群支撑应用，基于 MySQL、PostgreSQL、CDH 用开源搭建大数据平台，但考虑到使用的效果和维护的成本，最终还是放弃了完全使用开源的实现方式。</p><p></p><p>原来使用的 Oracle 产品有自己的特色，能同时适用于交易场景和分析场景，所以在这一块儿上并没有一个对等的可取代它的软件。</p><p></p><p>现在，互联网的实现思路是将交易型的数据库和分析型的数据库拆解开来，再加上大数据平台去做海量数据的建模或者计算能力的支撑。基于此，民生选择了分布式数据库<a href=\"https://www.infoq.cn/article/YoxwIvkHZ07vijEi6W9M\"> TDSQL</a>\"、TBase 等来<a href=\"https://www.infoq.cn/article/AB_DU5f7OxCWerOKp2Th\">替换掉 </a>\"Oracle。</p><p></p><p>同时考虑到新一代的业务架构是基于分布式 Kubernetes 集群，适应未来 5 到 10 年的发展变化，核心应用比较倡导微服务网格化和基于云的研发应用一体化的模式，所以底层基础架构一开始定位为公有云服务。</p><p></p><p>但在把主流国内云厂商看了一遍之后，从数据资产的私有化来考虑，发现公有云的方式不完全满足现在金融行业的需求，于是民生保险跟腾讯深度合作，为大部分的数据和核心应用建立了一个私有云，再用公有云承载对外流量，以及实现活动场景下的弹性扩展预留。</p><p></p><p>新一代业务系统和新一代云数据中心都是采用的最新的技术，跨度很大，选择新技术也意味着接受挑战。针对复杂的技术和业务场景面临很多未知的情况，前期在做第一轮试验性“掌上民生”App 产品时候，怎么运行，怎么快速解决技术上的问题，没有一个可以用来参考的标准，还需要充分融合整个应用架构和云平台 PaaS 的能力，来寻找一个最佳的均衡点，所以这个项目中最大的风险也是来自于初期。</p><p></p><p>整体的架构设计和探索“花了大概 5、6 个月的时间才能定下来”，民生保险数据服务部副总沈勇毅表示，这也是整个项目开头最难的一个点。</p><p></p><p>“采用新技术总会有一定的风险，作为吃螃蟹的人，总归是要慢慢摸索”，沈勇毅介绍说。但经过了半年的并行期以后后面就很顺了，因为已经很清晰地知道自己的技术路线怎么走，业务转型的时候要考虑哪些问题，就相对来说按部就班地去做，只是看时间到底拉的多长。</p><p></p><p>传统金融机构的技术架构升级有着复杂的步骤，比如先建立一个数据中心，再建立第二个数据中心，逐步考虑兼容，是一个 5 到 10 年长远的发展过程。民生保险的数字化转型从 2019 年启动，采用比较先进的混合云基础架构和云原生的业务架构，一步到位地实现了两地三中心、同城双活、灾备，到投产上线、存量迁移，总共只花费 3 年时间，创造了一个行业里少见的案例。</p><p></p><p></p><h2>技术投入要讲究一个“均衡点”</h2><p></p><p></p><p></p><blockquote>CXO 控制着整个项目的风险系数。</blockquote><p></p><p></p><p>在企业的<a href=\"https://www.infoq.cn/article/PV03IOu8CgoNldNzGG7Z\">转型过程</a>\"中，技术只是一个应用，任何改变，如果没有考量到“人”的因素，必然无法达到真正的转型。</p><p></p><p>人的因素可以分为两个部分。</p><p></p><p>一方面是面向“消费者”。数字化转型的根本起源是“业务诉求”。因为人口众多，所以各行业都大量增加了线上业务，进行深加工，所以底层的数字化转型它其实不是一个技术层面的推动，它是一个业务层面的推动，是出于业务的需要。</p><p></p><p>民生保险在转型是将视频、图章、监管、报送等等这些系统业务进行线上化，线上业务还需要有数据的二次加工和分析。在具体业务场景上，推动业务层面去使用“新技术”，改变业务模式、运营模式、服务体系，这些都是面向消费者的事情。</p><p></p><p>另一方面，“组织内部的人”更是转型的成败关键。</p><p></p><p>技术和产品的问题总能够去解决，引入新技术不是最难的事情，这可以通过引入比如腾讯这样的云服务商作为合适的合作伙伴，借助于各行各业的经验支撑技术的转型。而业务上的问题，主要靠组织和管理层面。“一把手”董事长的决心和战略决定了“转型”的基调，然后管理层才能从公司层面明确建设目标，制定规划，内部各部门的协调和合作，从顶层向下推动整个公司转型。</p><p></p><p>在数字化转型中，CTO 或 CIO 也起着比较决定性的作用。一方面，作为“总设计师”，他需要根据企业的实际情况来去选择一个最佳的路径。</p><p></p><p>数字化转型的路径不止一种，基础好一点的可能循序渐进，每年可能动一点点，但是它的代价可能是花费的时间会很长很长。之前的基础差一点的，在技术大的变革时代，可能采取相对大胆激进的策略，能够在比较短的时间内能实现弯道超车，达到既定的目标，但是可能执行起来的整体风险也会比较高。一步到位还是逐步迭代，这些需要 CTO 或者 CIO 来做决策和选型。</p><p></p><p>“CTO 控制整个项目的风险系数，在不同的阶段去调整不同的风险”，作为民生保险信息化服务部门负责人，沈勇毅的角色也相当于 CTO 或者 CIO。另一方面，CTO 还需要靠确定整个组织架构，构建符合数字化的新的人才和体系。“民生这个项目的周期跨度 3 年，这也是我们有史以来最长的一个项目。参与的人数也很多，就我们自己民生和各个厂商的参与人数基本上全部加起来高峰的时候有 400-500 号人。”</p><p></p><p>在多厂商的管理上，合作能力的配合上，实施能力的管理上，包括民生自己内部多部门的管理和协调上，其实都有一些挑战。另外是人员能力，涉及到很多新技术引入，虽然很多新技术在互联网行业已经成熟，但对民生这样的一个金融企业来说，这个技术却是全新的。对民生保险来说，项目的实施需要很多懂技术，又有很多有大型项目经验的人员去推动。而且项目实施之后，技术怎么去沉淀，怎么去传承，怎么去保证确保所有的技术迭代和稳定的运转，这都是需要想办法解决的问题。这也是大多数转型中的中小企业需要面对的问题：作为一个甲方企业，不能无限制的在技术上去投入。</p><p></p><p>沈勇毅表示技术人员的投入也要讲究一个“均衡点”，民生的办法是借助于腾讯这样的厂商来接一部分基础云平台的部署和持续运维问题，同时也要清楚双方边界。但在应用层面还是要做到自主可控，培养自己的技术队伍。民生已经有专门的技术架构的团队，也是为了适应整个云的变化，近几年重构了这个团队，从原有的 IOE 的模式直接进行了转型，更多地去实现管理的职能或职责，做好资源分配和运用。</p><p></p><p></p><h2>切割二十年的老系统</h2><p></p><p></p><p>民生保险混合云有着自己的模式，基于国产自主生态的私有云、公有云、信创云混合的新一代基础设施。</p><p></p><p>民生将内部区域划分为几个大功能区，公有云更多是服务一些外网的业务，比如官微、官网、掌上民生。在项目实施过程中，开箱即用的公有云还承担着一个比较大的作用，就是在紧急的时候充当测试环境，毕竟私有云的搭建还包括购买服务器和网络等。</p><p></p><p>办公和核心放在了私有云上，这也是比较传统一些的 IT 交付模式。私有云基于腾讯云专有云全栈解决方案 TCE （Tencent Cloud Enterprise）打造，包括 70% 节点基于通用 x86 架构的私有云和 30% 节点基于全国产芯片为基础的私有云。腾讯专有云和公有云由同源同构的一套代码实现而来。腾讯专有云在金融行业落地时，还在网络、硬件、服务、网络安全、防护上，针对金融用户的属性做了深度定制。</p><p></p><p>作为腾讯云金融的主打技术产品之一，TCE 最早的实践案例可以追溯至微众银行，逐步扩展到交通、工业制造、传媒、零售、政府、泛互联网等行业，打造了建设银行、深证通、中国银联、永辉零售云、央视频等多个行业标杆。据腾讯介绍，TCE 本身历经数十次版本迭代，增强的功能和特性超过 500 项，涉及代码数百万行，也有完整的交付管理流程和自动化工具，从需求调研包括高低阶方案的设计，到基础设施包括云平台的实施，以及数据跟业务的投产迁移。</p><p></p><p>民生保险于今年 5 月 1 号开始切割，当时处于疫情全封闭的状态，数百名项目参与人员居家隔离，实现远程 “云上线”。关键线上业务还挺多，需要去做一些协同和管理。“大家都是各自在家里，去做了一个这么大的切换。这还是挺厉害的”，沈勇毅感慨。</p><p></p><p>项目切换过程中，大家的工作有一个“完整的清单”，每一个任务由谁负责，大家都要清楚自己在做什么，明白自己执行到了哪一个步骤，都需要非常明确和细致。在各个组织结构上分得很清楚，由“总控”去整体把控，底下有各个执行组、指令组，各个平台的支撑组、支持组，还有各模块的用户验证组，以及腾讯也有一支支持队伍，大家不断地相互之间去协调和通信，经历一个月的多轮预演，最后正式切换。</p><p></p><p>难度和风险最大的有两个，第一个技术选型，在第一次引入新技术试错的时候，第二个是最后一次性切割的时候。</p><p></p><p>“按照我们现在整个策略，迁移过程当中绝对不大会有一次性迁掉的那种模式，但是就算分阶段，分步骤慢慢去切割，到最后也有一次整个的最后切割。就像 5 月份‘云切割’就是最终的一个版本，最终的一个全量的扫尾切割。失败的可能性最大的就是存量扫尾切割这一块。”</p><p></p><p>“因为所有的历史的问题，历史的债，肯定需要在那个点上做一个切割和梳理。我们也是一个快 20 年的一个公司，那么积累的历史问题不会少。其实在最后一次迁移过程中，我们还是遇到了一些不一定需要临时去解决的问题，这些问题我们会放到后面慢慢再梳理。”</p><p></p><p>减少风险的办法，就是“最后一次切割之前，一定要把风险看得清楚，把问题理得清楚，再去做这件事情。”</p><p></p><p>如今，“新一代”的业务系统已经稳定运行数月，各方面能力得到了明显提升，也曾在切割之后支撑了民生有史以来并发量最高的一个业务节点。另外，云平台成本提供同样的计算资源的情况下，要比原来至少节省一半以上的成本。且从安全性上来说，应对一些重保也是会比原来要好很多。</p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>数字化发展和数字化转型已成为全球多个国家的战略。</p><p></p><p>可以说企业进行数字化转型不是可选项，而是必答题。企业数字化转型的动力也是现实的：在疫情时代，数字化协同能让企业能够去高效地运转下去；线上化和新渠道上的用户运营是企业活下去的关键动力；新技术能够更加地降本增效，提升服务体验。</p><p></p><p>民生保险的弹性、稳定的云原生方案，也是保险企业转型的一个典型样本。对比国内外保险行业，沈勇毅认为，无论是全球还是亚洲的同类企业，虽然他们在业务逻辑设计和敏捷方法论上更为先进，但国内企业借助敏捷加上分布式交付，以及云厂商的成熟运转模式，在引入新技术的速度上比国外企业要快不少。</p><p></p><p>服务过几千家金融企业的腾讯专家也表示，不管在保险行业还是在金融行业，甚至在一些现在比较特殊的制造行业来看，中国在各个业务场景，各个行业的业务场景上面是足够丰富的，也是领先于其它国家的。在使用所谓的互联网技术或者使用所谓的数字化转型技术上，几乎所有的行业都不落后于国外，甚至快于国外。</p><p></p><p>最重要的是，互联网企业在创新和创造的过程之后，能将这些技术变成了一种成熟的基础架构技术，赋能给金融行业、制造行业等，让这些技术应用得比国外更快、更强。</p><p></p><p>采访嘉宾：</p><p></p><p>沈勇毅，民生保险数据服务部副总经理</p><p></p><p>孔伟，腾讯云专有云产品中心首席产品架构师</p><p></p><p>苏彦春，腾讯金融云交付总监</p><p></p><p></p><h4>内容推荐</h4><p></p><p></p><p>本文选自《<a href=\"https://www.infoq.cn/minibook/EQzDrPI1dT9G8V6alV1I\">中国卓越技术团队访谈录</a>\"》（2022 年第三季），本期精选了阿里达摩院数据库、得物、华润云、民生保险、众安保险、字节跳动 AppInfra 等技术团队在技术落地、团队建设方面的实践经验及心得体会。</p><p></p><p>《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。</p><p></p><p>访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang_wechat，请注明来意及公司名称。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9f/9f66c137b5399abf731a2f0a1e31936c\" /></p><p></p><p></p><p></p><p></p><p></p><p>​​​​​​</p><p></p>",
    "publish_time": "2022-09-13 12:24:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "构建下一代万亿级云原生消息架构：Apache Pulsar 在 vivo 的探索与实践",
    "url": "https://www.infoq.cn/article/ZyNHQsXPD0N7VwHcUbTT",
    "summary": "<p></p><p></p><p>本文整理自 vivo 互联网大数据工程师陈建波与全利民在 Apache Pulsar Meetup 上的演讲《Apache Pulsar 在 vivo 的探索与实践》，介绍 vivo 在集群管理与监控上应用 Pulsar 的实践。</p><p></p><p>vivo 移动互联网为全球 4 亿 + 智能手机用户提供互联网产品与服务。其中，vivo 分布式消息中间件团队主要为 vivo 所有内外销实时计算业务提供高吞吐、低延时的数据接入、消息队列等服务，覆盖应用商店、短视频、广告等业务。业务集群已达每天十万亿级的数据规模。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d3087576321f59954c60f2595c77ed87.png\" /></p><p></p><p>图 1. vivo 分布式消息中间件系统架构</p><p></p><p>上图为系统的整体架构，其中数据接入层包括数据接入、数据采集服务，支持 SDK 直连；消息中间件由 Kafka 和 <a href=\"https://www.infoq.cn/article/z8NxTrFR8R1G11lkchyM\">Pulsar </a>\"共同承担，其中 Pulsar 的承载量达到千亿级别；数据处理部分使用 Flink、Spark 等组件。</p><p></p><p>目前，Kafka 采用多集群方式，根据不同的业务量级、重要性分别使用不同的集群提供服务，比如计费集群、搜索集群、日志集群。在 <a href=\"https://www.infoq.cn/article/ic2tSdHdZ8KKf4u9SsYp\">Kafka 集群</a>\"的内部，则采用物理隔离的方式，根据不同业务的重要性，将不同业务的 Topic 控制在不同的资源组内，避免业务之间相互影响。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/75/759c6e8ec108a2e30589ea63875b48fe.png\" /></p><p></p><p>图 2. Kafka 集群资源隔离</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/24/2461f1fee86083a7567332e36d8f111e.png\" /></p><p></p><p>图 3. Kafka 集群流量均衡</p><p></p><p>资源组内部则会针对 Topic 流量、分区分布、磁盘容量、机器机架等指标生成迁移计划进行流量均衡，以此增强 Kafka 可靠性。目前 Kafka 已在多集群部署、资源隔离、流量均衡三个方面保障了基本的稳定性和资源利用率，但是在此之外，系统仍存在一些问题。</p><p></p><p></p><h2>应对业务流量数十倍增长，引入 Apache Pulsar</h2><p></p><p></p><p>过去几年来，Kafka 集群承载的业务量迅速增长，流量上涨数十倍，带来诸多问题：</p><p></p><p>Topic 及 Topic 分区总量不断增加，集群性能受到影响：Kafka 高性能依赖于磁盘的顺序读写，磁盘上大量分区导致随机读写加重；业务流量增加迅速，存量集群变大，需要将老的业务进行资源组隔离迁移或者集群拆分。无论是资源组隔离还是集群的隔离的方式，由于集群不可以进行动态扩缩容，机器不能够进行灵活调配，都存在利用率不高、运维成本增加的问题；机器扩容慢，需要做长时间流量均衡，难以应对突发流量。集群规模越大，问题越突出；消费端性能扩展太依赖分区扩容，导致集群元数据疯狂增长；集群数量对应的机器基数大，硬件故障概率高，出现硬件故障时影响会直接传导到客户端，缺少中间层容错。</p><p></p><p>面对庞大的集群、流量和多样化的业务场景，综合考虑集群的稳定性和维护成本等因素，vivo 需要一个功能更丰富、适用更多场景、扩展能力更强的消息组件。</p><p></p><p><a href=\"https://www.infoq.cn/article/4P6SN4xzYtLtPgIRmzkU\">Pulsar </a>\"如何解决 vivo 存在的问题，可以首先看一下 Pulsar 的架构设计。Pulsar 采用计算存储层分离架构。计算层的 Broker 节点是对等且无状态的，可以快速扩展；存储层使用 BookKeeper 作为节点，同样节点对等。这种分离架构支持计算和存储层各自独立扩展。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/70/70b6f70c3c605bf365b0a5c5a8d62875.png\" /></p><p></p><p>图 4. Pulsar 存储计算分离</p><p></p><p>其次，Pulsar 的各个节点都是轻量化的，在出现故障和宕机时可以快速恢复。一般情况下可以通过快速上下线来解决某个节点机器的问题。同时 Broker 层可以作为 BookKeeper 层的容错层，可以防止故障直接传导至用户端。</p><p></p><p>Pulsar 扩容时无需长时间的数据迁移，且支持实时均衡。Broker 层抽象了 Bundle 概念，可以用有限的 Bundle 映射海量 Topic，Topic 可以随着 Bundle 迁移，通过动态迁移 Bundle 可以更好地应对流量突发场景。BookKeeper 分层分片的架构让数据分布均匀，在 Broker 层有一个选择机制，在扩容时可以将数据写入存储量小的节点，扩容时无需数据迁移，提供更好的流量高峰应对能力。Bookie 进行数据刷盘时会对批量数据自动进行数据排序，可以避免 Kafka 中的随机读写。</p><p></p><p>Pulsar 提供了四种消息模型：Exclusive、Failover、Shared 和 Key_Shared，其中 Shared 模型允许一个分区同时被多个消费实例订阅消费，并采用 Round Robin（轮询）方式将数据推送到各个消费实例。因此消费能力的扩展不会过于依赖分区扩容，慢消费的消费实例也可以在 Shared 模型中得到解决。Key_Shared 模型则是在 Shared 的基础上对应对顺序性有要求的场景，可以按照 Key 来消费。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/57cf72d884af0003c70c41178eda1c4c.png\" /></p><p></p><p>图 5. Pulsar 订阅模型</p><p></p><p>Pulsar 的设计架构带来了海量分区支撑、消费扩展、精准限流、流量均衡、快速扩缩容、故障恢复、分层存储、云原生容器部署、异地多活等特性和优势，可以帮助集群更好地实现高可用、高扩展，提高了更高的弹性。</p><p></p><p></p><h2> Apache Pulsar 集群管理实践</h2><p></p><p></p><p>下面我们从流量控制和数据管理方面，分享 vivo 在使用 Pulsar 过程中的集群管理经验。</p><p></p><p></p><h3>Bundle 的管理</h3><p></p><p></p><p>在集群流量控制层面，比较关键的一点就是 Bundle 的管理。Bundle 负责控制用户流量到 Broker 的具体分布。Broker 与 Topic 之间没有直接联系，而是在 Broker 之上抽象出 Bundle 概念，通过 Bundle 与 Topic 建立关系；Topic 通过名称计算哈希值，并散列分布到一致性哈希环中，而哈希环的每一段都是一个 Bundle。另外 Load Manager 根据 Bundle 的负载情况将后者分配到对应的 Broker 上，将 Bundle 数据存储在 ZooKeeper 中。由此以来就间接实现了 Topic 与 Broker 之间的联系（可参考近期 StreamNative 发布的 <a href=\"https://mp.weixin.qq.com/s?__biz=MzUyMjkzMjA1Ng==&amp;mid=2247491872&amp;idx=1&amp;sn=538df7ad042d43bc40d96cf78f1e8525&amp;scene=21#wechat_redirect\">Broker 负载均衡技术文章</a>\"）。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/29/29e6ca52b06e353dbefa4b7ca0c2fe73.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/21/21bb5c7ecf417384f0b9392de6554291.png\" /></p><p></p><p>图 6. Bundle 与 Topic 建立关系</p><p></p><p>这里需要注意：</p><p></p><p>Bundle 的个数影响均衡效果，因为通过一致性哈希来确认 Topic 应该落在哪个 Bundle 上， Topic 与 Bundle 会存在不均衡分配，某些 Bundle 分配的 Topic 可能较多或较少。Bundle 越多，每个 Bundle 承载的 Topic 越少，粒度越细。依赖于 Pulsar 的负载均衡算法，均衡效果更好；否则若 Bundle 太大，无论如何卸载都很难平衡负载；Bundle 数据和 Broker 映射元数据都维护在 ZooKeeper 中，需要做好 Bundle 数量的规划。</p><p></p><p>针对以上两点，我们根据 Broker 来设置 Bundle 数量设置最小最大值来控制，还可以对流量较大的 Topic 针对性扩大分区，让分区均匀分配到 Broker Bundle 上。</p><p></p><p>Pulsar 虽然提供了海量分区能力，但是过多的 Topic 或者分区产生的 lookup 也会对集群产生较大的压力。集群管理者需要提前规划 Bundle 和分区设置，杜绝滥用。</p><p></p><p>另外对 Bundle 的操作需要注意：</p><p></p><p>Pulsar 本身提供了卸载操作，可以解除 Bundle 和 Broker 的关联关系，将 Bundle 重新分配。线上流量较大时应卸载 Bundle 而不是整个命名空间，因为卸载后者会导致其上的全部 Bundle 与对应的生产者、消费者断开，重新进行 lookup。利用 Bundle split 对流量较大的 Bundle 进行拆分，增加命名空间的 Bundle 数量，降低影响。</p><p></p><p>总体而言，用户需要注意流量的均衡与集群的稳定性，在集群管理之初就做好 Bundle 的数量管理和相关测试，谨慎对待大批量 Bundle 卸载等运维操作。</p><p></p><p></p><h3>数据的管理</h3><p></p><p></p><p>接下来我们从数据的存储、过期、删除三个方面来分析。</p><p></p><p></p><h4>Ledger 翻转</h4><p></p><p></p><p>首先介绍数据写入 ledger 的过程。每一个 Topic 分区在一段时间内只创建一个 Ledger 维护分区写入的 Entry 的数据归属。Topic 分区写入的数据以 Entry 的形式，经过 Broker 写入 Netty 线程处理队列，线程依次根据 Entry 的 Ledger Id，对 Ledger 目录数取模，写入到目标磁盘 Ledger 目录，最终以 Entry Log 和 RocksDB 的索引方式存储。需要注意，Ledger 是一个分区在一段时间内写入数据的逻辑管理单位，维护了这段数据存储的 Bookie 位置。一个 Topic 分区在一段时间内写入的数据只被一个活跃 Ledger 管理，待该 Ledger 达到翻转条件后才会关闭 Ledger 并重新计算，创建新 Ledger 继续写入。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/22/2274eda6614ca7efe6fab8a4a0c2e86b.png\" /></p><p></p><p>图 7. Ledger 翻转示意</p><p></p><p>Ledger 翻转后，数据才会写入新的数据目录。在 Pulsar 中，在满足 Ledger 最小翻转时间以及以下条件之一后触发 Ledger 翻转：</p><p></p><p>已达到 Ledger 最大翻转时间；已达到 Ledger 的最大 Entry 数量；已达到 Ledger 的最大大小。</p><p></p><p>默认值：</p><p></p><p><code lang=\"makefile\">触发ledger翻转的最小时间：\nmanagedLedgerMinLedgerRolloverTimeMinutes=10\n\n触发ledger翻转的最长时间：\nmanagedLedgerMaxLedgerRolloverTimeMinutes=240\n\n触发ledger翻转的最大entry数：\nmanagedLedgerMaxEntriesPerLedger=50000\n\n触发ledger翻转的最大大小：\nmanagedLedgerMaxSizePerLedgerMbytes=2048\n</code></p><p></p><p>注意两个问题：</p><p></p><p>Ledger 过大：最小翻转时间是防止 Ledger 元数据过快增长的手段，但实践发现如果 Topic 分区流量较大，Ledger 的实际值可能远超上述设置的上限阈值。Ledger 只有在翻转后才会创建新的 Ledger，Ledger 过大会导致某段时间内写入某个磁盘的数据过多，产生磁盘存储不均衡的问题；针对 Ledger 为对象的一些操作也会受到影响，产生无法及时卸载数据到二级存储、数据卸载时间较长、还未卸载成功但 Ledger 已经过期等问题。Ledger 间不均衡：Ledger ID 以集群维度进行递增。在分区的维度，按照 Ledger ID 对 Ledger 存储目录数进行取模的方式无法对多磁盘进行均衡写入。但保持 Ledger 间的大小一致，在一定程度上会对多磁盘目录的写入均衡有比较大的改善。</p><p></p><p>总而言之，建议根据业务消息情况适当调整 Ledger 翻转参数和有针对性地增加大流量 Topic 分区数量，可以防止 Ledger 过大、大小不均衡的问题。</p><p></p><p></p><h4>数据过期</h4><p></p><p></p><p>数据过期主要分为四个阶段：</p><p></p><p>第一阶段：未被 Ack 的消息</p><p></p><p>Backlog 消息：该段数据不会被删除</p><p></p><p>第二阶段：已经 Ack 的消息</p><p></p><p>订阅主动 Ack 后，标记为非 backlog 消息，有多个订阅时以最慢的为准TTL：若某 Topic 没有活跃订阅，超过 TTL 存活时间的消息会被主动 Ack ，本质上是移动 cursor</p><p></p><p>第三阶段：消息保留时间检查</p><p></p><p>Retention：对已经 Ack 的消息的保留策略，按保留周期和保留大小设置来保留消息</p><p></p><p>第四阶段：消息删除</p><p></p><p>Deleted：超过 Retenion 范围的消息则被删除。超过 rentention 保留周期和保留大小的消息，系统会从当前已经 ack 消息的最新位置往前检查并获取已经过期的 ledger，将其标记删除。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/28/285e39c562f454cc709134f140e4f717.png\" /></p><p></p><p>图 8. 消息保留时间检查与消息删除</p><p></p><p>从上述的消息阶段演化来看，Pulsar 提供了较大的消息管理空间，但也略显复杂。建议集群维护者建立简单统一的规则处理数据保留策略，如可以设置 TTL = Retention 保留周期值。</p><p></p><p></p><h4>数据删除</h4><p></p><p></p><p>此处介绍数据的物理删除。Bookie 在处理数据写入过程时，会将同一段时间内的数据经过排序 flush 到同一个 Entry Log 文件中，将索引存放在 RocksDB 中。由于多个 Ledger 的数据可能会同时写入同一个 Entry Log，因此 Entry Log 便不能被简单直接的删除。对此 BookKeeper 会启动一个 GC（GarbageCollector） &nbsp;线程进行检查和物理删除操作。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3e/3ea6fc2305325524f5a512f32d60c06f.png\" /></p><p></p><p>图 9. 数据物理删除流程</p><p></p><p>Entry Log 维护元数据信息（ EntryLogMetadata），该元数据记录了 Ledger 列表、大小与剩余有效数据比例。</p><p></p><p>GC 清理线程在每个 gcWaitTime 时间间隔：</p><p></p><p>扫描 Entry Log 的元数据信息，对于已经没有有效数据的 entry log 直接进行删除。判断是否满足 compaction 条件，满足 compaction 条件后 GC 线程会读取每一个 Entry 判断其是否过期，一旦过期就会丢弃，否则会将数据写入新的 Entry Log。</p><p></p><p>Compaction 分为 minorCompaction 和 majorCompaction，二者区别在于阈值。默认情况下，minorCompaction 清理间隔 1 小时，阈值 0.2；majorCompaction 清理间隔 24 小时，阈值 0.8。阈值是 Entry Log File 中的剩余有效数据占比。</p><p></p><p><code lang=\"ini\">minorCompactionInterval=3600\nminorCompactionThreshold=0.2\nmajorCompactionThreshold=0.8\nmajorCompactionInterval=86400\n</code></p><p></p><p>在实际使用中，如果机器节点的磁盘较小且数据迟迟得不到删除，为了及时清除数据，应该按照业务流量和磁盘空间适当调整数据清理间隔时间、有效数据阈值，并配合 compaction 限速策略减小对集群的影响。</p><p></p><p></p><h2>Pulsar 监控实践</h2><p></p><p></p><p>vivo 的 Pulsar 指标监控链路架构如下：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bc/bc275ffbb77c4885169f5db2e1149733.png\" /></p><p></p><p>图 10. vivo 针对 Pulsar 监控指标搭建的监控架构</p><p></p><p>该架构中：</p><p></p><p>采用 Prometheus 采集 Pulsar 指标；应用 Prometheus 远程存储特性将格式化后的指标发送到 Kafka；Druid 消费 Kafka 数据后可以作为 Grafana 的数据源，配置 Grafana 面板查询指标。</p><p></p><p>为什么不使用 Prometheus 存储数据？因为有些数据较久远，一旦集群规模增加，监控指标数量级会很大。Prometheus 对资源依赖重，我们只采用了它的采集能力。</p><p></p><p>下图是常用的关键指标：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9ddadd1e715c4081c35548a7589057c8.png\" /></p><p></p><p>图 11. 关键监控指标</p><p></p><p>指标类型分为：</p><p></p><p>客户端指标：用来排查客户端出现的异常Broker 端指标：监控 topic 流量、调整 broker 间流量差距Bookie 端指标：排查读写延迟等问题</p><p></p><p>除了官方指标外，团队还开发了 Bundle 相关的一些指标：</p><p></p><p>分区数、流量等在 Bundle 的分布Broker 端记录读写延迟的 P95/P99 值基于请求对列实现 Broker 端网络负载指标等。</p><p></p><p></p><h2>问题优化与最佳实践</h2><p></p><p></p><p></p><h3>负载均衡参数</h3><p></p><p></p><p>负载均衡的目的是对资源平均分配，差异大会影响稳定性。对负载均衡设置的目标是节点流量偏差 20% 以内，每天均衡频次在 10 次以内，否则客户端会频繁断连、重连。优化后的参数如下：</p><p></p><p><code lang=\"ini\"># load shedding strategy, support OverloadShedder and ThresholdShedder, default is OverloadShedder\nloadBalancerLoadSheddingStrategy=org.apache.pulsar.Broker.loadbalance.impl.ThresholdShedder\n\n# enable/disable namespace Bundle auto split\nloadBalancerAutoBundleSplitEnabled=false\n\n# enable/disable automatic unloading of split Bundles\nloadBalancerAutoUnloadSplitBundlesEnabled=false\n\n#计算新资源使用量时的CPU使用权重（默认1.0）\nloadBalancerCPUResourceWeight=0.0\n\n#计算新的资源使用量时的堆内存使用权重（默认1.0）\nloadBalancerMemoryResourceWeight=0.0\n\n#计算新资源使用量时的直接内存使用权重（默认1.0）\nloadBalancerDirectMemoryResourceWeight=0.0 \n</code></p><p></p><p>下面三个参数改为零，是因为集群使用了相同的机型，团队更关注流量均衡，对内存和 CPU 不是特别关注。</p><p></p><p>以一个具体产品案例来看，其中有 1 个 Topic、30 个分区、180 个 Bundle：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fc/fc9415c2ec82d39a814348c5f2bdef43.png\" /></p><p></p><p>图 12. 1 个 Topic、30 个分区、180 个 Bundle 的每秒入流量</p><p></p><p>上图节点间流量差异较大，由 Bundle unload 导致。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9a/9a03efd91943b17f40f6faf0faf8739f.png\" /></p><p></p><p>图 13. 1 个 Topic、30 个分区、180 个 Bundle 下，Bundle 上 Topic 分区情况</p><p></p><p>上图可看出，有两个 Bundle 分配了四个分区，远超其他 Bundle。实践中出现以下问题：</p><p></p><p>均衡频次高，一天大概有 200 多次客户端连接频繁切换，流量波动大每个 Bundle 的分区数量分布差异大</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05bf257db4bba88ad52cf551a7574fef.png\" /></p><p></p><p>图 14. 1 个 Topic、30 个分区、180 个 Bundle 的入流量分布</p><p></p><p>优化过程中，关键在于将分区打散到不同 Bundle 上，但分区数量太少很难做到。Topic 通过哈希算法分配到 Bundle 上在前文已经介绍。此案例中，问题在于分区数量少。</p><p></p><p>于是团队将分区增加到 120 个，效果如下：</p><p></p><p>节点间流量差异小均衡频次降低，一天大概有 10 次左右客户端连接切换减少，流量波动较小每个 bundle 的分区数量分布差异降低</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6c/6c6c1576b0e5105e55d590be70a7e29b.png\" /></p><p></p><p>图 15. 1 个 Topic、120 个分区、180 个 Bundle 的每秒入流量</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d5/d5233a9938024724759ceb0e27c189ea.png\" /></p><p></p><p>图 16. 1 个 Topic、120 个分区、180 个 Bundle 下，Bundle 上 Topic 分区情况</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d9/d99bbc9a265d56b0f56bf3e3f7fd6016.png\" /></p><p></p><p>图 17. 1 个 Topic、120 个分区、180 个 Bundle 的入流量分布</p><p></p><p></p><h3>客户端发送性能</h3><p></p><p></p><p>在和上述业务相同的场景中，分区数量增加后，系统滚动重启后出现了流量下降情况：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7f/7f9647dc2159850d38faeab5736dc011.png\" /></p><p></p><p>图 18. 单个 Topic，30 个分区增加到 120 个，系统滚动重启后流量下降</p><p></p><p>客户端配置参数：</p><p></p><p>memoryLimitBytes=209715200 （默认为 0）maxPendingMessages=2000 &nbsp;（默认 1000）maxPendingMessagesAcrossPartitions=40000 （默认 50000）batchingMaxPublishDelayMicros=50 （默认 1 毫秒）batchingMaxMessages=2000 （默认 1000）batchingMaxBytes=5242880 （默认 128KB）</p><p></p><p>满足三个 batch 数据中的任何一个的情况下就会触发打包、发送。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1f/1fd734fd04ed74b505135c15ee90fa19.png\" /></p><p></p><p>图 19. 重启后 maxPendingMessages（队列长度）出现下降</p><p></p><p>这里 maxPendingMessages（队列长度）=min(maxPendingMessages, maxPendingMessagesAcrossPartitions/partitionNum) 。而分区数添加（30 -&gt; 120）后，需要重启客户端才对队列长度生效。重启后 maxPendingMessages 队列长度 从 40000/30 = 1333 变为 40000/120 = 333，出现了明显下降。</p><p></p><p>另外，测试发现 batchingMaxMessages 调小后性能提升 10 倍之多：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/72/72dee8d12cab8a6b3a9a4ef8899625ed.png\" /></p><p></p><p>图 20. 单个 Topic，30 个分区增加到 120 个，调整后性能提升</p><p></p><p>建议 batchingMaxPublishDelayMicros 不要过大，确保 batchingMaxMessages 比 maxPendingMessages 要大，否则等待 batchingMaxPublishDelayMicros 才会发送。</p><p></p><p></p><h3>宕机导致集群流量骤降</h3><p></p><p></p><p>某个分区队列满后会导致发送线程阻塞，影响所有分区的整体发送和集群稳定性：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/83/837567d0c85296b625630ee29fe86fd9.png\" /></p><p></p><p>图 21. 执行 Kill-9 一台 Broker 后，其他 Broker 流量下降</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/ea46c0e3279861e2b677f0b3acb3f54a.png\" /></p><p></p><p>图 22. 第四个分区已满，发送线程阻塞在 canEnqueRequest 上，等待时间长，其他未满分区的发送也被影响。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7bb1e6a8cfb60c32f9af6f5cef782acf.png\" /></p><p></p><p>图 23. 极端情况下，第四个分区已满，其他分区等待中。发送线程会在第四个分区阻塞等待，其他线程无法发送。</p><p></p><p>针对这一问题的优化思路，首先是能者多劳，让发送快的分区尽可能多发送；然后是将阻塞点从 ProducerImpl 移到 PartitionedProducerImpl；如果分区 ProducerImpl 出现队列已满阻塞较长时间，就将该分区排除。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/00/0070e2c99aa9d2b5ea7dbc3f7d3097b3.png\" /></p><p></p><p>图 24. 宕机导致集群流量骤降优化思路</p><p></p><p>实践中可分为可用 Producer 和不可用 Producer 两个列表。在 ① 中，两个列表都处于初始化状态并可用；在 ② 中，某个可用分区阻塞一段时间后可以等待一段时间；若不可用就移动到不可用列表中，如 ③ 所示；当分区可用比例达到阈值再挪回可用列表，如 ④ 所示。</p><p></p><p>经过优化后，宕机 Broker 流量可以快速转移到其他 Broker：</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/34/3428dbd6dc684f80b4dede68cbbe3905.png\" /></p><p></p><p>图 25. 优化后 Broker 流量分流并上涨</p><p></p><p>注：优化只支持 RoundRobinPartitionMessageRouterImpl 路由策略。</p><p></p><p>在单个 ProducerImpl 对应的 Broker 出现处理慢、网络慢等导致发送响应慢的情况，都可能会导致发送线程阻塞，业务发送消息的速度受限于最慢的 ProducerImpl 的速度。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>本文分享了 vivo 在 Pulsar 集群管理与监控的经验，并介绍 vivo 在负载均衡等方面的最佳实践。</p><p></p><p>由于服务端的问题很难通过监控指标进行分析，vivo 在未来计划实现生产端到消费端的全链路监控能力。大数据团队希望整合大数据组件，支撑 Flink、Spark、Druid 等核心下游组件打通落地。</p><p></p><p>同时，vivo 内部目前 Pulsar 与 Kafka 同时运行，团队将尝试基于 KoP 对存量 Kafka 万亿流量尝试迁移，降低 Kafka 迁移成本；并探索容器化落地，充分发挥 Pulsar 云原生优势。</p><p></p><p>作者简介：</p><p></p><p>全利民，vivo 大数据工程师，负责 vivo 分布式消息中间件建设陈建波，vivo 大数据工程师，曾任微服务应用架构师，负责 vivo 分布式消息中间件的建设</p><p></p><p>今日好文推荐</p><p></p><p><a href=\"https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651140025&amp;idx=1&amp;sn=ca1cf244eb8a12c3561fad45e4300066&amp;scene=21#wechat_redirect\">奇葩事儿：删除用户云数据还无法恢复，只赔 3 万；微信键盘来了，体积 524MB；谷歌希望将效率提高 20%：暗示将裁员？｜ Q资讯</a>\"​</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139876&amp;idx=1&amp;sn=b5479b58f06e714877092811902bf015&amp;chksm=bdb8d7778acf5e617885b343a0fa9932b961ec5ad16a2bca0b3db0770c4ab67d247b26a22dee&amp;scene=21#wechat_redirect\">“不搞职级、人人平等” 25 年后行不通了？Netflix 破天荒引入细分职级：气走老员工</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651139040&amp;idx=1&amp;sn=1eee3c77db28fd14ef9a18d201dd80ce&amp;chksm=bdb8d3b38acf5aa5c63957fc7975fc1118319ae52a1697b388d358b88752daef0cae83953661&amp;scene=21#wechat_redirect\">缺少软件开发文化，大众汽车陷入困境，CEO 也被赶下了台</a>\"</p><p></p><p><a href=\"http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651138876&amp;idx=1&amp;sn=6b41efee0d73ab9537025f0f2e547fc7&amp;chksm=bdb8d36f8acf5a79fac65237c89d8e72058bef5a792dfa15c238ed7f64e940cc4587f6984a2b&amp;scene=21#wechat_redirect\">我庆幸果断放弃了 SwiftUI：它还不够成熟</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif\" /></p><p></p>",
    "publish_time": "2022-09-13 13:26:53",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度百舸2.0升级发布：产业智能化升级需要怎样的基础设施？",
    "url": "https://www.infoq.cn/article/1XLRGUVLIylAkRG8Sf8Y",
    "summary": "<p>当今企业面临数字化转型和智能化升级的挑战，作为承载了庞大算力的云基础设施，成为企业打破这种挑战的重要支撑。</p><p></p><p>过去所说的算力，一般都是以 CPU 为主的传统算力。经过数十年发展，已经形成了庞大的市场规模。</p><p>随着<a href=\"https://www.infoq.cn/article/zjNolqefbu6PgizTmZhm\">产业智能化升级</a>\"的深化，大家再提算力的时候，注意力就会更多的放到以 GPU 等为主的智能算力上来。</p><p></p><p>在过去几年，智能算力高速增长，已经快占据到算力总量的一半，和传统算力平分秋色。</p><p></p><p>这给产业智能化提供了充足的算力支持。比如自动驾驶、生物医药、行业大模型、智算中心等行业和领域，走在了智能化升级的前沿。这些行业的快速发展，也将反过来拉动了智能算力规模的高速增长。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6f/6f73b132822f3a04d6ae18b1486a80bb.png\" /></p><p></p><p>算力和产业的相互影响，促进了双方都在快速发展，不断变化。这也说明需要构建新型智能计算基础设施，支持产业智能化的深化。</p><p></p><p>那智能算力的未来应该是什么样子，才能更好地满足产业智能化升级的需求呢？</p><p></p><p>百度智能云认为，随着 AI 应用场景更加丰富、超大模型不断的出现、云上 AI 任务的管理复杂性越来越高，芯片多元化、算力规模化、以及云原生化，将成为未来智能算力发展的重点方向。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/99/99222a5355d401029be5b23b6394ef7f.png\" /></p><p></p><p>为了建设 AI 原生的云计算基础设施，我们去年推出了百度百舸·AI 异构计算平台。基于产业智能化和智能算力发展大趋势，我们今年升级发布了 2.0 版本。</p><p></p><p>百度百舸 2.0 在 AI 计算、AI 存储、AI 容器等模块上，能力进行了增强，功能进行了丰富，同时全新发布 AI 加速套件。</p><p></p><p>AI 加速套件，通过存训推一体化的方式，对数据的读取和查询、训练、推理进行加速，进一步提升 AI 作业速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c3e3c13762d278de0a8c169a8566b1d.png\" /></p><p></p><p>首先我们来看 AI 相关的计算和网络部分。</p><p></p><p>为了提升集群通信效率，我们全新发布了弹性 RDMA 网卡。相比传统专用的 RDMA 网络，弹性 RDMA 网络和 VPC 网络进行了融合，使得用户的使用成本更低。相比传统的 TCP 网络，弹性 RDMA 的通信延时降低了 2-3 倍。同时，弹性 RDMA 还支持 GPU Direct RDMA，进一步提升 AI 集群训练速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/82af5c0d542e0658c6243ebebf96e67e.png\" /></p><p></p><p>百度持续投入 AI 的全栈能力建设，昆仑芯是其中重要的部分。</p><p></p><p>今天，我昆仑芯二代的云服务器也发布上市，为用户提供多元化的智能算力。昆仑芯二代采用了 XPU-R 架构，支持硬件级别的虚拟化，同时为用户快速地使用昆仑芯二代，我们提供了专属镜像。</p><p>针对典型 AI 负载，第二代昆仑芯的性能，相比一代提升了 2-3 倍，平均加速比是业界主流 GPU 的 1.5 倍。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf0397ecfdc7512121f2610cfe0aa404.png\" /></p><p></p><p>在 AI 存储部分，百度百舸 2.0 进行了全面升级，提升性能的同时降低使用成本。</p><p></p><p>我们全新发布了并行文件存储 PFS 的裸金属版本，支持 IB 网络，可将计算对数据的访问延迟降低至百 us 级别。</p><p></p><p>同时，对象存储 BOS 新增了原生层级 namespace，可以将元数据访问速度提升 4 倍以上。</p><p></p><p>在存储性能大幅度提升的同时，我们通过 Bucketlink 将 PFS 和 BOS 打通。这不仅提升了数据湖的访问性能，同时降低数据存储成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/256ec6a6be56f3d14ef424ab6d612104.png\" /></p><p></p><p>在 AI 加速部分，我们推出的存训推一体化加速方案，全面加速了数据湖存储访问、分布式训练和推理效率。</p><p></p><p>数据湖存储加速 RapidFS，这是一个分布式缓存系统，可以加速数据集访问，训练效率提升 5~10 倍。</p><p>分布式训练加速，能有效提升分布式训练的性能，在典型模型场景下吞吐提升 50%~150%。</p><p></p><p>在模型完成训练进行部署后，通过推理加速，提升 AI 应用的响应速度。在典型模型场景下时延降低 40%~60%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/7128aa6f977fddb139f836fee4e13af5.png\" /></p><p></p><p>在 AI 容器部分，百度百舸 2.0 在业界率先推出了双引擎 GPU 容器虚拟化方案，可以满足各类场景的要求，提升 GPU 资源利用率。</p><p></p><p>这个双引擎 GPU 容器虚拟化方案，包括内核态和用户态两种虚拟化方案。</p><p></p><p>内核态虚拟方案是我们今年全新发布的，能够为业务提供强隔离环境。</p><p></p><p>用户态虚拟方案，是百度内部大规模使用了多年的方案，支撑了各类 AI 业务的落地。今年我们对他进行了增强，进一步提升资源利用率。</p><p></p><p>更详细内容可以参考<a href=\"http://mp.weixin.qq.com/s?__biz=MzkxOTM4MTM3Ng==&amp;mid=2247484679&amp;idx=1&amp;sn=066458ed00d2ec842af15a4f0e7ea558&amp;chksm=c1a3b1e8f6d438fe9b58b302db494f98d8f280875d606e8756dff38fe5a5ce2c7cb3ce8adcb6&amp;scene=21#wechat_redirect\">《双引擎 GPU 容器虚拟化，用户态和内核态的技术解析和实践分享》。</a>\"</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f4/f4b67f1732596008a030ade50ffb5b32.png\" /></p><p></p><p>在完成各个模块的升级后，百度百舸 2.0 的优异性能，在测试结果中得到了充分展现。</p><p></p><p>在今年 6 月 30 日发布的 MLPerf Trainning v2.0 的榜单中，百度百舸和百度飞桨联合提交的 BERT Large 模型 GPU 训练性能结果，在同等 GPU 配置下排名第一，超越了高度定制优化且长期处于榜单领先位置的 NGC PyTorch 框架。</p><p></p><p>从图中可以看到，百度百舸和百度飞桨的组合方案比其他结果快 5%-11% 不等。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6047b02e67bd562c04280755240613a.png\" /></p><p></p><p>百度百舸在行业智能化升级的深化过程中发挥了重大作用。</p><p></p><p>百度百舸支持了文心大模型的落地。这是全球最大中文单体模型，2600 亿参数规模。</p><p></p><p>百度百舸提供了千卡规模、单集群 EFLOPS 级别的算力，配备了 1.6Tbps 的高速网络，提供百万 IOPS 的并行文件存储系统。</p><p></p><p>通过 AI 容器提供的容错、架构感知等手段，为文心大模型的训练提供了稳定的运行环境，满足长时间周期的业务需要。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/63/634740914ab805e2945f9cb718ddfb43.png\" /></p><p></p><p>在自动驾驶领域，百度百舸为用户提供了软硬一体的智能基础设施。</p><p></p><p>在高性能的智能基础设施基础上，百度智能云针对自动驾驶算法、通过显存卸载、算子融合、梯度融合等手段，可以将 Transformer 算法训练吞吐提升了 1.5 倍以上，加速了自动驾驶的研发进程。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1e/1eda78c8dec554dab0582ee94e6f58e1.png\" /></p><p></p><p>在生科医疗领域，百度百舸提供高性能生物计算的平台，作为高通量药物发现的引擎，可以满足 EB 级海量数据、千亿级参数的大模型训练，使得蛋白质结构的预测模型的迭代周期，从过去月级别提升至天级别。</p><p></p><p>其中，高性能网络为大规模的集群训练提供微秒级的通信时延。通过算力统一调度，满足不同场景的算力需求。同时，借助数据湖存储和对象存储之间打通后的能力，为用户降低数据存储成本一半以上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d0/d07dce6363593a20f37f680bf77d1ee3.png\" /></p><p></p><p>基于百度百舸的智算中心，能够提供普惠多元的 AI 算力，支持 AI 应用的大规模发展，做到产业的全场景覆盖，推动城市数字经济的高速发展。</p><p></p><p>最近，百度智能云 - 昆仑芯（盐城）智算中心落地汽车产业重镇盐城，可为盐城周边的智能经济发展提供庞大的 AI 算力和海量的数据处理能力，加速智能化升级。</p><p></p><p>该智算中心将成为当地科技创新的动力源泉，向长三角区域源源不断地输出最前沿的科研创新成果。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eaf4f422292e9f9ec9199a64336a2fa3.png\" /></p><p></p><p><a href=\"https://cloud.baidu.com/summit/summer_summit_2022/index.html\">点击视频回放链接，可以查看全部内容。</a>\"</p>",
    "publish_time": "2022-09-13 14:05:40",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一年 100% 云原生化，众安保险架构演进的探索与实践",
    "url": "https://www.infoq.cn/article/xAWCqCUkkWKqFQTdhhsQ",
    "summary": "<p>采访嘉宾 | 欧昀、鄢晶</p><p></p><p>金融行业的蓬勃发展，业务规模的不断扩张，用于支撑业务运行的系统和基础设施也日趋庞杂，强监管安全合规的属性又使得他在云原生的选择上比其他行业多了一丝谨慎，面临更多挑战。</p><p></p><p>众安保险从 2016 年就开始探索实践云原生相关技术，在服务治理、自动化运维等方面积累了大量的经验。为了深入了解众安在金融保险领域的探索和思考，近日，InfoQ 采访了众安保险技术团队，围绕金融保险云原生架构治理问题逐一展开探讨。</p><p></p><h3>众安云原生之路：从追随者到实践者</h3><p></p><p></p><p>2016 年，众安就开始逐步尝试云原生技术，届时众安已充分意识到云原生技术本身适用于任何行业，慢慢地众安对云原生的理解也从早期概念的追随到现在大规模落地的实践者甚至是布道者。这个模式的转换更多的是依据云原生的定义搭配众安自身的演进实现，同时结合业务实际，由浅至深，由点到面的过程。</p><p></p><p>早期云原生在定义过程中，主要是应用的容器化，以及面向服务架构，容器编排等等。随着云原生生态的逐渐成熟，众安现在更关注的是标准实践之后的深度治理，比如在不可变基础设施，微服务三要素等落地规范的定义下，如何最大化的实现云原生技术红利，并不断探索云原生标准的最佳实践等。</p><p></p><p>众安对云原生理解总结为一个词就是弹性。主要分为三个方面，分别对应弹性基础设施，弹性应用架构，以及弹性研发交付流程，也分别对应容器、微服务和持续交付相关技术。容器轻与快的特性能够让企业实现按需的编排使用，对于需要使用的资源实现快速的弹性伸缩。微服务应用架构则是作为部署与交付的介质，低耦合的设计能够充分发挥容器和持续交付的能力。此外借助 DevOps 实现的持续交付流程则能够使众安更快、更敏捷的去响应需求的变化。总的来说，云原生为众安提供了一套指导思想，让企业以更轻更快的方式去实现构建部署以及交付应用。</p><p></p><h3>众安架构演进：迈向云原生</h3><p></p><p></p><p>同其他互联网公司相似，众安的技术架构也是一直在演进与升级的，整体可以分为三个阶段。</p><p></p><p>第一阶段是在成立之初采用的传统单体架构，满足业务快速上线。第二阶段，随着互联网业务对新开通高并发、低延时的要求，众安开始进行微服务架构的升级，这个阶段又可以细分为闭源与开源两个过程，最初使用国内大厂闭源的技术组件，之后慢慢拥抱开源生态。第三阶段就是现阶段，采用基于 K8s 构建云原生的架构，包含了容器化的基础设施、微服务架构、服务治理、DevOps 体系建设等等。</p><p></p><p>众安在进行架构演进的过程中，首先会进行目标架构的规划，解决方案的规划也会成为目标架构演进过程中的目标路径。这就意味着方案规划需要符合长期的目标架构，同时在中短期也要能够解决当前或者即将面临的问题。另外众安将技术架构的关键能力聚焦在业务复杂度提升和数据量变高带来的海量数据、低延时高并发等互联网式的极端流量问题之上，这也要求众安停下来去审视当前的技术架构是否能够支撑业务形态的转变，以适应未来五到十年的变化为目标去进行架构规划。</p><p></p><h4>云原生架构建设思路</h4><p></p><p></p><p>众安在云原生架构上的建设思路，恰如众安对云原生的定义理解，也是分为三个层次，包含基础设施层，应用架构层，以及研发管理层。基础设施层次建设改造主要是指的是容器化的改造，包含容器服务，容器编排，以及如何将应用部署在容器当中等。其重点在于容器云平台的搭建，众安采用 K8s 并在其之上自研了一套自己的多集群统一管理容器云方案，实现了全公司全环境容器服务以及编排的统一管理。另外，通过镜像可视化编排、镜像插件等手段去标准化约束基础镜像，实现业务系统快速进行容器环境的适配。在此之上面向云原生设计并落地了新一代数字化保险系统称之为无界山 2.0。</p><p></p><p>在应用架构与研发管理层，众安主要采取架构标准化与微服务治理和自研 DevOps 体系的思路，我们在下文服务治理段落将进行详细讲解。关于标准化的约束，众安集成在流程与工具当中，形成一套事前自动生成、事中标准指导以及事后检查的机制。</p><p></p><p>在体系建设方面众安采用核心能力拥抱开源，服务能力进行自研的方式建设基础设施、应用架构和持续交付体系。在开源工具的选择上，众安会充分考虑一些 CNCF 认证的项目与规范，同时也会采取像社区共建、团队贡献、定制私有等方式，和社区保持长期稳定的一种参与关系。</p><p></p><p>此外众安在云原生安全方面也有着非常重要的考量，一方面会借助云上的安全产品去建设基本硬件级的安全防护能力。另一方面众安面向金融场景，围绕容器、应用、数据、业务方面进行安全能力自研孵化网络安全、应用安全、数据安全产品，形成面向不同行业和场景的安全合规、业务安全的风险管理解决方案。同时众安将安全能力和研发管理流程深度集成形成了现有的 DevSecOps 体系，这些都是众安在规划架构上的思考。</p><p></p><h4>强监管行业安全上云</h4><p></p><p></p><p>保险银行证券都是属于强监管的金融行业，上云对于他们来说既是挑战，也是机遇。最基础最关键的就是如何选择一个好的云服务商，根据行业的一些特性，可以从合规、安全、数据一致性等高要求来考虑。因此在架构升级上众安会主要从两个方面考虑。</p><p></p><p>首先在业务方面，传统的金融产品和服务，存在一定的门槛，效率低下，同质化严重，可能无法满足客户的特定需求，客户更多的需要线上化、个性化、场景化的金融产品和服务。</p><p></p><p>其次在技术层面，金融行业属于信息化程度相对比较高的一个行业，传统的金融 IT 架构存在较多问题，比如研发周期长，协作沟通问题，运维成本高、创新比较慢等等，还会遇到人才储备不足的难题。</p><p></p><p>结合目前数字转型在整个行业的深化，众安看到了越来越多的云原生技术在行业上的运用。众安开始逐步尝试云原生技术在生产实践中的运用，充分利用和发挥云的优势，同时做到灵活、低成本的方式构建弹性和可扩展的应用。在帮助研发的过程中，将研发的焦点，由资源为中心转向以应用为中心，利用弹性的概念去充分发挥云的优势，帮助提升产研的能力，支撑业务的创新。整体来说的话，众安认为云原生技术能够为金融行业，尤其是互联网金融行业带来巨大的红利，为众安构建新一代的数字化基础设施，以及帮助企业数字化转型带来强大的推力。</p><p></p><h4>最大挑战只有一个：技术升级不能影响业务</h4><p></p><p></p><p>技术升级最不缺的就是挑战，整个架构升级切换的过程，众安的技术专家表示，就像大家说的“开着飞机换引擎”，最主要的挑战就一个，技术升级的同时不能影响业务。在整个迁移的过程中，遇到了大家熟知的微服务问题，容器化，DevOps 等等，既不能影响生产业务，又不能影响日常开发的运维流程，挑战还是比较大的。众安主要分了两个阶段去尝试：</p><p></p><p>第一阶段，众安早期的业务形态，主要是围绕电商场景去开展，这个时期需要在很短的时间内做更多的生态，比如健康生态、汽车生态等等。早期的业务架构并不是很匹配未来的业务情况，因此早期有业务架构升级的需求，所以众安在做业务架构的同时，也将底层的技术架构做了升级，完成了早期云原生基础设施的转换。</p><p></p><p>第二阶段，有了云原生的基础，通过云原生的基础能力，众安对基础设施进行了底层的封装之后，确保上层应用运行环境的稳定，同时众安加强了 PaaS 层服务能力的建设，降低开发者对底层基础设施和公用组件的使用门槛和成本，这也可以帮助后续做到无感升级。同时为了降低日常运维的流程，众安还自研了 DevOps 产品，实现从构建到部署的自动化，并将标准化延伸业务交付。</p><p></p><h4>从探索容器到服务治理</h4><p></p><p></p><p>众安云原生的发展阶段也可以分为三个阶段：容器探索阶段、微服务化、服务网格治理。</p><p></p><p>前面提到，众安从 16 年就开始起步探索容器技术，以 Docker Swarm为技术核心建设了第一代容器管理和应用平台，在一些边缘应用上进行了小规模的试点应用。实践下来，在网络及其稳定性方面存在比较大的问题。</p><p></p><p>时间来到 18 年，这个时期众安以 K8s 为技术核心建设云原生基础设施，将微服务应用部署到容器环境。在容器微服务化阶段众安的迁移改造已经比较彻底，实现了业务应用100%容器化。</p><p></p><p>目前正处于第三服务网格服务治理阶段，当下众安主要以 Istio 和 Agent 为技术核心实现网格化的服务治理，对以 K8s 为主的云原生基础设施进行进一步的增强。</p><p></p><p>总的来说，阶段二的迁移最具挑战，迁移的过程耗时将近一年，无论是涉及到的系统规模，还是复杂度都是最高的。另外由于底层基础设施形态的转变，技术复杂度也比较高，众安通过蓝绿验证的方式，通过网关的能力进行流量的逐步切流，利用这种手段做到业务逐步迁移，保证了迁移过程中业务的连续性不中断，实现业务的无感迁移。</p><p></p><p>提及转向云原生收益之前先介绍一下众安的基建规模，众安这边的主机规模，按照 4C8G 这种机器的规格去计算的话大概是在一万加以上，应用规模是一千多个，技术人员的规模大概是在两千以上。众安技术架构在转向云原生之后，结合资源弹性编排带来的成本节省，以及 DevOps 体系建设和落地，有效提升了需求交付率，缩短了交付周期。从统计的数字上来看，21 年众安发布次数在 12 万次以上，相交于云原生之前增长了 22 倍，关于转向云原生，众安还是获得了非常明显的收益。</p><p></p><h4>目前的难题</h4><p></p><p></p><p>架构演进是一个持续的过程，企业会不断面临各种各样的问题与挑战，众安分享了其中一个多语言环境下架构治理问题。关于如何看待多语言，首先众安保险不希望开发语言成为公司吸纳各路人才的阻碍，不同的编程语言也会有他适合的一些应用场景，比如说人工智能 Python 会比较适合，云原生 Go 会比较适合，企业级的一些业务系统可能 Java 会比较适合。</p><p></p><p>在语言栈选择上众安秉承着开放的策略，但语言栈的开放带来的就是维护复杂度、治理困难的问题。为了实现统一架构的治理目标，将治理能力不断下沉到基础设施是众安认为唯一的标准答案。众安方案的抓手是流量劫持，从东西向流量和南北向流量这边分别去展开。对于南北向流量众安将治理的能力放在网关层，同时众安的目标也是建设 API、业务、安全的三合一网关；对于东西向流量众安则是依托服务网格技术，在全公司全场景覆盖，提供基础设施级的流量权限与可观测能力。</p><p></p><h3>众安架构服务治理方案</h3><p></p><p></p><p>随着众安技术伴随整个业务发展进入第九年，公司在业务形态和体量上都发生了巨大的变化，整个技术架构如何去支撑业务的线上运营与发展就就变成了非常有挑战的课题。</p><p></p><p>众安保险内部架构治理遵循公司统一架构目标，以技术架构、业务架构作为支撑点，主要分为三个方面。第一，基础设施层面众安要求百分百部署在云上，充分使用云服务提供的计算、存储、网络等能力；第二，在技术架构方面，众安基于云构建了技术中台，能够向业务系统提供统一的容器、中间件等 PaaS 能力；最后在应用层面，业务系统统一使用类 Spring Cloud 生态的微服务架构。</p><p></p><p>总的来说，目前众安已经形成了较为完善的云原生生态的建设，治理着超过上万服务的大规模集群。</p><p></p><h4>强监管的金融行业属性</h4><p></p><p></p><p>首先金融保险属于强监管的行业，安全合规是红线，金融保险架构治理也会有一些特殊的地方。因此众安在做基于架构标准的时候就会设定一些合规性的下限，在业务设计的过程中要帮助和指导大家去考虑合规性需求的扩展和一致性。其次，由于整个金融行业存在一些“历史包袱”，尤其是一些中小型金融企业，对于技术改造存在较大的风险和挑战。</p><p></p><p>所谓金融企业的“历史包袱”，可以从两个方面展开来讲。第一是业务上的挑战，第二是技术方面的挑战。大家可能知道，组织结构会决定技术的架构，众安早期遵循的一套架构叫做“胖前置，瘦核心“，这是因为众安前期强调的业务形态是前台的业务部门高效迭代的能力。在整个架构升级过程中，尤其上发展到现在业务稳步发展的阶段之后，就会更加关注业务的效率和质量，然后持续加大一些业务中台和技术中台的投入。最后在整个过程中不但有底层的业务架构的升级，以及匹配到技术架构的升级，整协同过程中组织架构的一些调整也会有冲击。还有一点可以补充的是，像传统的金融行业的业务系统，大家可能知道企业使用的像小型机，重量级的一些数据库，甚至闭源的厂商，都是比较普遍的。关于这个方面，金融企业上云也会存在一些阻力。</p><p></p><p>不过受访专家表示，众安也相信技术先进性会让之前的一些业务开展由不可能会变成可能，同时也在不断鼓励金融创新，鼓励技术先进性的探索也会成为众安架构治理的一个重要环节。此外，在服务治理的过程中也会发现新的一些架构和交互对于传统的业务流程和组织结构带来的一些冲击，众安也发现转变企业的文化，打破部门的一些壁垒，夯实数字化的一些群众基础也是非常重要的事情。</p><p></p><h4>三大企业架构治理方案</h4><p></p><p></p><p>众安在企业架构治理课题上具体来讲有以下几个方向：</p><p></p><p>首先是微服务治理，众安根据自身业务覆盖广、周期长的特性，使用开源体系落地实践的方案。以 Spring Boot 为基础，在此基础之上建设了可递进、可共建的统一微服务应用框架，为业务系统提供框架组件版本的统一管理能力，同时开放共建能力也可以让各事业线的技术团队参与到标准的制订以及演进过程当中。</p><p></p><p>众安采用无侵入为主、多语言的异构体系为辅的技术方案。尽量避免对业务代码产生侵入，升级也能够做到尽量减少对业务这块的一些感知与影响。简单来说就是 Istio 配合 Agent，或者称之为 Agent 加 Mesh 双治理的体系。众安应用服务技术体系，虽说是拥抱多语言，但实际上更多还是以 Java 占据绝对的比例。目前众安使用这两种技术体系共同完成不同业务场景的覆盖，这也是金融保险行业比较先进的治理方式。</p><p></p><p>再谈数据治理，众安作为国内较早开始数字化转型的企业之一，非常注重数据带来的价值，为此众安还成立了专门的数据治理组织。数据治理上众安保险主要关注两个方面，一是数据质量，二是数据安全，目前两个方面众安都是通过一些平台化的能力进行治理。</p><p></p><p>数据质量方面众安搭建了企业内部的数据质量平台，通过不断去维护运营过程中积累的像业务和数据的一些相关规则。比如说保险，保险是受强监管的，在业务处理的事前、事中、事后都要及时地对相关数据进行质量监控。另一方面，在数据安全上，众安自研了关于数据管理方面的平台，取名绿洲数据服务中心，通过系统对数据的一些流转和使用，进行相应的数据相关的一些权限和安全的控制。</p><p></p><p>最后是 DevOps 治理方面，或者叫研发过程的治理。这里众安是以一站式研发管理作为指导思想来建设一体化的 DevOps 平台，并且从文化、组织和工具层面对众安的研发一体化的体系进行落地。</p><p></p><p>众安整个 DevOps 体系的设计遵循了两个理念，一个是运维 N+1 的一个理念，一个称作“小工具大平台”的理念。什么意思呢？首先运维 N+1，指的是一个基础运维，N 个运维场景，也可以理解为是一个运维中台，N 个运维平台。</p><p></p><p>众安使用运维控制管道概念去提供基础的调度能力，去屏蔽底层比如容器调度、主机调度甚至文件调度，实现统一的命令和文件管道，同时上层工具平台遵循统一的数据和API标准。在此标准之上众安建设了像持续交付，可观测，数据治理包括 ITSM、IT 治理等众多的应用场景。“小工具大平台”则指的是众安运维体系模块化的设计，通过微前端等的一些技术手段，去实现模块的按需组合，并且按照研发角色例如开发运维测试等形成不同的工作视图。</p><p></p><h3>金融基建新挑战</h3><p></p><p></p><p>此外，信创基础设施作为当下较为火热的课题，众安在此方面亦有相关动作。金融安全关系国家命脉，在自助可控的重要性方面尤为突出。众安积极响应国家战略，在基础设施、核心系统方面的信创适配工作有着很大的投入并产生了不错的成果，面向行业推出了安全、运维、基础架构等领域的众多满足信创要求的产品。另外，众安保险具备金融、互联网双重行业特性。同时区别于传统公司，众安的基础架构体系 100% 构建于云上，是在云上进行大规模生产实践的典型案例。在与云商等产业机构联合共创之下，快速设计了有众安特色的信创云方案并进行尝试，目前已经有一定比例的科技投入。同时众安也非常愿意以科技赋能行业为目标持续输出相关产品与经验。</p><p></p><h3>写在最后</h3><p></p><p>中国信通院云大所云计算部副主任陈屹力曾提到，云原生是保险行业新一轮数字化升级的必经之路，众安在金融保险领域的成功实践也验证了这一点，尽管目前大多数企业还处于探索阶段，但在未来几年，金融保险行业将全面迎来云原生时代。</p><p></p><h4>嘉宾介绍：</h4><p></p><p>欧昀</p><p>众安保险首席技术专家、公司技术平台部负责人，曾任职阿里巴巴技术专家，15年以上互联网项目技术经验。主要负责保险业务中台和技术中台规划和落地，参与完成公司技术战略制定和落地，实现科技赋能保险。</p><p></p><p>鄢晶</p><p>众安保险高级技术专家，平台架构部技术负责人，在微服务，Devops，云原生技术领域有丰富的实践经验。主导了众安新一代智能运维平台的建设。</p><p></p><p></p><h4>内容推荐</h4><p></p><p></p><p>本文选自《<a href=\"https://www.infoq.cn/minibook/EQzDrPI1dT9G8V6alV1I\">中国卓越技术团队访谈录</a>\"》（2022 年第三季），本期精选了阿里达摩院数据库、得物、华润云、民生保险、众安保险、字节跳动 AppInfra 等技术团队在技术落地、团队建设方面的实践经验及心得体会。</p><p></p><p>《中国卓越技术团队访谈录》是 InfoQ 打造的重磅内容产品，以各个国内优秀企业的 IT 技术团队为线索策划系列采访，希望向外界传递杰出技术团队的做事方法 / 技术实践，让开发者了解他们的知识积累、技术演进、产品锤炼与团队文化等，并从中获得有价值的见解。</p><p></p><p>访谈录现开放长期报名通道，如果你身处传统企业经历了数字化转型变革，或者正在互联网公司进行创新技术的研发，并希望 InfoQ 可以关注和采访你所在的技术团队，可以添加微信：caifangfang_wechat，请注明来意及公司名称。</p>",
    "publish_time": "2022-09-13 14:37:51",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库内核杂谈（二十四）- Hologres，支持Hybrid serving/analytical Processing的数据引擎（2）",
    "url": "https://www.infoq.cn/article/65zC4wl1zoDko1GRvQFS",
    "summary": "<p>欢迎阅读新一期的<a href=\"https://www.infoq.cn/theme/46\">数据库内核杂谈</a>\"。新一期的杂谈特别安排在中秋节后，祝大家中秋快乐（主要还是忙得又拖更了）。本期的杂谈继续来学习蒋晓伟老师发表在VLDB2020上的文章：<a href=\"http://www.vldb.org/pvldb/vol13/p3272-jiang.pdf\">Alibaba Hologres: A Cloud-Native Service for Hybrid Serving/Analytical Processing</a>\"。这一期，着重介绍存储，执行的技术细节。</p><p>&nbsp;</p><p></p><h2>数据模型（Data Model）</h2><p></p><p>首先介绍Hologres的数据存储模型（data model）。对于每一张表，用户需要设置一个clustering-key和一个全局唯一的row locator（我觉得就可以理解为row key）。如果clustering-key本身就是唯一的，就会被默认用作row locator；如果不是，会有一个额外的唯一标识（uniquifier）和clustering-key组合成为row locator 。</p><p>&nbsp;</p><p>一个逻辑数据库（database）里面的所有tables都会按照某种规则组成多个table groups（后续写作TG）。这个规则可能是根据access pattern来定的。一个TG，还会被进一步被分拆（shard）到多个table group shards（后续写作TGS）。每个TGS，会保存一部分的base data（理解为表数据）和与之对应的所有的Indexes信息。每一部分的base data加上相关的indexes信息就被划为一个tablet。Tablet有两种存储模式，row tablet（行存）和column tablet（列存）。它们分别被用来针对点查询和分析型查询。一个tablet，取决于access pattern，可以被存为row tablet，或者column tablet，或者两者都存（可惜文中，并没有给出具体的case，什么时候会存储成什么？让用户来设置的话，感觉有点复杂）。</p><p>&nbsp;</p><p>Tablet里存储的数据需要一个唯一的key，所以对于base data tablet来说，上面讨论的row locator就能作为唯一的key。对于secondary indexes（二级索引）的tablets来说，如果这个index是唯一的，那index column本身就能成为唯一的key。否则，base table的row locator会被一起作用，作为唯一的key 。举个例子，假设一个table有2个二级索引，1个是唯一的key（k1-&gt;v1），另一个不唯一（k2-&gt;v2）。那么base table的key就是 ，唯一key的二级索引的key就是，而非唯一key的二级索引的key就是。</p><p>&nbsp;</p><p>文中也介绍了，为啥要把多个table组合成TGS。因为绝大部分的写入，会access一些相关的table，已经对应的indexes。把这些tables合成一个TGS，就可以把相关的多个写操作转换成一个atomic write，并且只有一个write log entry被记录到文件系统中，由此提升性能。此外，将经常需要被join的表组成TGS，也能避免join的时候需要重新shuffle数据（如果基于同一个row key进行hash的话）。</p><p>&nbsp;</p><p></p><h2>Table Group Shard（TGS）介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b271b8487d4c55f0df28dfc085a8eadc.png\" /></p><p>（TGS 介绍图片）</p><p>&nbsp;</p><p>TGS是Hologres里数据管理的基本单位。结合上面的TGS图片来讲解。一个TGS由一个write ahead logger（WAL）和多个tablet构成。所有的tablets，无论是row tablet，还是column tablet，都是以log-structured-merge-tree（LSM tree）形式存储：一个mem-table，和多level的不可变的shard-tables=。所有的shard-tables都保存在distributed file systems里面（这边用的是阿里的盘古分布式文件系统）。<a href=\"https://xie.infoq.cn/article/253f731e621992c7d3f032092\">LSM tree的工作方式</a>\"就不在这边赘述了。 每个tablet也会保留一个metadata文件来记录这些mem-table和shard-tables的状态，和RocksDB的工作方式类似。所有的数据都有版本记录（MVCC），且读操作和写操作是完全分离的。并且，系统设计里保证一个TGS只有一个writer可以写WAL，但允许多个reader同时读。</p><p>&nbsp;</p><p>写操作：Hologres支持两种类型的写操作：单TGS写和分布式批量写。这两种类型的写操作都可以被认为是原子的。单TGS写通过单个writer写WAL保证原子性，而分布式批量写通过两阶段事务保证。</p><p>&nbsp;</p><p>单TGS写：继续结合上图来看。1）WAL manager会给当前的write request分配一个LSN（现在的时间戳和一个递增数字），2）创建一个log entry（涵盖replay的所有数据）在log文件里。写操作等到log文件存储成功才commit。3）写操作会作用到tablet的mem-table里。4）当mem-table写满的时候，会触发LSM tree写到shard-tables里。level compaction是异步发生的。</p><p>&nbsp;</p><p>分布式批量写：通过两阶段提交事务来保证原子性。FE（Front-end）节点在接到写操作时，会锁住所有需要参与的TGS。然后，每个TGS会1）获得一个LSN，2）作用写操作到所有的mem-tables，3）如果需要，触发LSM tree写。参与的TGS在完成操作后会发结果vote给FE，FE会决定是否要commit还是abort。如果FE决定commit，每个TGS会commit log，否则，前面的操作都会被作废（典型的两阶段提交）。</p><p>&nbsp;</p><p>分布式TGS管理：文中也快速讨论了一下分布式的TGS管理，目前，TGS的writer和多个reader都是co-located在一个节点上，但Hologres在支持允许read-only replicas部署在一个remote节点上来进一步平衡读写负担。并且支持两种read-only replicas：1）完全synced replicas可以支持任何读操作，2）部分-synced replicas来支持数据只存在shard-tables里的数据。</p><p>&nbsp;</p><p></p><h2>Row Tablet介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/96/96cd1333be1584d6ddfabccbaa445f84.png\" /></p><p>（Row Tablet 介绍图片）</p><p>&nbsp;</p><p>Row tablet是针对高性能的点查询做优化支持的。结合上述图片来看Row tablet的结构：Row tablet的mem-table 结构是 Masstree，数据是按照key进行排序的。而写到文件中的shard-文件则被分为了数据block和index block。index block记录了每个data block的offset以及对应的starting key来加速读取。</p><p>&nbsp;</p><p>为了支持mult-version data，Value值存了三类信息：一是non-key的value columns的值； del_bit代表这行是否被删除了；和LSN version信息。</p><p>&nbsp;</p><p>读操作：每个读操作需要输入读key和LSN。结果的获取类似于读LSM-tree，通过读取mem-table和文件系统重的shard-table；只有有key重合的shard-table文件才会被扫描。</p><p>写操作：典型的LSM-tree，会specify column-values，del_bit和LSN。如果mem-table满了，会trigger flush到shard-table上。</p><p></p><p></p><h2>Column Tablet介绍</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cd872817c2aea22f120687b34b1153d5.png\" /></p><p>（Column Tablet 介绍图片）</p><p>&nbsp;</p><p>相对于row tablet, column tablet用来更好地支持某个column的scans。结合图片来介绍。和row tablet不同的地方在于，column tablet，除了维护一个column-store的LSM tree，还需要额外维护一个delete map（由于是column store的限制）。Column tablet的mem-table的存储格式是Apache Arrow（一种高效的columnar memory format）。数据会按照顺序被写进mem-table里面。在文件系统的shard-table里，数据依然是按照key来排序，但从逻辑上被划分为row groups。某一个column，它的值按照row group的划分，会存储到不同的物理data block上。一个column的data blocks会被连续的存储在一起来支持sequential scan。同时在，shard-file里，会保存index-block和meta block来加速读取，index-block存储了row相关的信息，而meta block，则存储了每个column的data block的相关信息，比如offset, value ranges, total row count等等。</p><p>&nbsp;</p><p>delete map本身其实是一个row tablet：key就是shard file或者mem-table的ID，然后value就是一个bitmap来表示这个shard-file里面，哪些records被删除了。</p><p>&nbsp;</p><p>读写操作本质都是对mem-table以及shard-file的flush操作，和row-table并没大区别。</p><p></p><p></p><h2>Hierachical cache</h2><p></p><p>文中也介绍了Hologres，为了进一步提升性能，采用了多阶段的caching来减少IO和计算cost：local disk cache, block cache 和 row cache。Local disk cache就是用来cache shard-files来避免频繁数据的IO读写操作。在这之上，内存为主的block cache用来存储shard-file里面的读取的blocks。在block cache上，我们还保留了一层内存机制的row cache来存储最近被查询过的row tablets，以加速读取。&nbsp;</p><p></p><p></p><h2>Query Execution Pattern</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/af/af00b4b64b10477d4e80071f64d27007.png\" /></p><p>（Query Execution 示例图）</p><p></p><p>结合图片来看Hologres在收到一个查询请求后，是如何一步一步执行的。1）在收到查询语句后，在FE节点上的query optimizer会生成一个DAG的执行计划；并且把这个计划按照shuffle boundaries（类似于map-reduce里面的map-reduce阶段）划分成多个阶段（fragments）。Fragments有三种，读，写fragments，以及数据处理fragments。每个fragments可以生成多个并行的instances来处理相应的数据。比如，对于每一个TGS，都可以起一个并行的reader或者writer fragment。</p><p>&nbsp;</p><p>FE节点会把这个执行计划发给coordinator节点，然后被coodinator节点分发到相应的worker节点上。读写fragments总是会被分派到host某个TGS的worker节点，数据处理节点可以被任意分配，来保持load balancing，并且也会考虑到数据传输的local性。在每个worker节点里，一个fragment可以进一步被拆分成多个work units（WU）来做具体的执行工作。WU是执行的基本单位。</p><p>&nbsp;</p><p></p><h2>Execution Context</h2><p></p><p>另一个值得一提的优化就是Hologres构建的execution context。因为Hologres需要支持多用户的并发查询需求。这会导致多个WU同时执行的时候会不可避免地进行context switch。而过多的context switch会造成性能瓶颈。为了解决这个问题，Hologres构建了一个user-space thread（就是协程吧），称为execution context（EC），用来记录WU的资源使用情况。调度EC不会牵涉到任何系统调用，所以EC之间的context switch就非常小。Hologres以EC为调度基本单位，计算资源也以EC的粒度被分配。EC在执行中，会跑在一个线程上。</p><p>&nbsp;</p><p></p><h2>Pull-based query execution</h2><p></p><p>Hologres采用了类似于Volcano模式的执行计划，异步的pull-based query execution。首先由coordinator会发送pull request到底层的WU，WU会继续发送pull request到下游WU里，直至到leaf WU，会开始读取mem-table或者shard-file里的数据。这个和大部分的执行引擎类似。</p><p>&nbsp;</p><p></p><h2>总结和一些思考</h2><p></p><p>读完整篇paper，最让我觉得最最创新的地方应该就是在Tablet中支持了row tablet和column tablet来同时优化<a href=\"https://xie.infoq.cn/article/a04f154de08ec69cbf5ff9795\">OLTP和OLAP workloads</a>\"。其他的<a href=\"https://www.infoq.cn/article/fd6mk3yGUEsfTm0D6QZW\">NewSQL</a>\"系统可能选择在更上层的架构中支持全部：比如通过CDC同步OLTP的数据到OLAP系统中。目前另一趋势就是updatable data structure比如<a href=\"https://hudi.apache.org/\">Apache Hudi</a>\"和<a href=\"https://iceberg.apache.org/\">Apache Iceberg</a>\"。目前工作的团队也在这方面探索，我也想借这个机会深入学习一下，以后写到内核杂谈和大家分享。感谢阅读！</p><p></p><p></p><h2>内核杂谈微信群和知识星球</h2><p></p><p>内核杂谈有个微信群，大家偶尔会讨论些数据库相关话题。但目前群人数超过200了，所以已经不能分享群名片加入了，可以添加我的微信（zhongxiangu）或者是内核杂谈编辑的微信（wyp_34358），备注：内核杂谈。</p><p>&nbsp;</p><p>除了数据库内核的专题blog，我还会push自己分享每天看到的有趣的IT新闻，放在我的知识星球里（免费的，为爱发电），欢迎加入。</p><p><img src=\"https://static001.geekbang.org/infoq/62/62e530824eee913af1a76fe28707a2b6.webp\" /></p><p></p>",
    "publish_time": "2022-09-13 14:43:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]