[
  {
    "title": "GitLab发布2023年全球DevSecOps报告，AI和ML从“有”变成“必须有”",
    "url": "https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7",
    "summary": "<p>GitLab的<a href=\"https://about.gitlab.com/blog/2023/09/12/gitlab-global-devsecops-ai-report/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s\">2023年全球DevSecOps AI报告</a>\"已发布，其中一个关键发现是<a href=\"https://en.wikipedia.org/wiki/Artificial_intelligence?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s\">AI</a>\"和<a href=\"https://www.infoq.com/introduction-machine-learning/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s\">ML</a>\"的使用正在从“有”发展到“必须有”。</p><p></p><p>报告显示，23%的组织已经在软件开发中使用AI，其中60%的组织每天都在使用AI。此外，65%的受访者表示，他们现在或将在未来三年内在测试中使用AI和ML。</p><p></p><p>83%的受访者表示，为了避免落后，在软件开发中使用AI至关重要。然而，也有约67%的受访者担心AI/ML所带来的影响，原因是AI/ML比人类更具成本效益优势，这会导致人类可从事的工作变少，并可能引入给他们带来麻烦的错误。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/7d/7dce13400a0b2380f6447c6bb01352bc.webp\" /></p><p></p><p>虽然AI能够帮助开发者写代码，但这只占开发者工作时间的四分之一，剩下的时间花在其他任务上，这意味着AI有机会被用在写代码以外的领域。62%的受访者使用AI在正式测试流程之外检查代码，53%的受访者使用机器人测试代码。这两个数字同比增长均超过10%。</p><p></p><p>报告还显示，除了AI和ML，自2022年以来，DevOps和DevSecOps方法的采用率正在上升，从47%上升到56%。此外，DevSecOps正在脱离孤立的状态——只有30%的受访者表示他们需要对安全完全负责——低于一年前的48%。38%的安全专业人员认为他们是跨职能安全团队的一员，这一比例在一年前为29%。但是，开发人员和安全专业人员在谁应该带头解决安全问题上仍然存在争议。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/97ed30248b89bb787ce40281796ab566.webp\" /></p><p></p><p>左移安全性检查的势头仍在，74%的受访者现在已经或计划在未来三年内在SDLC早期就进行测试，开发人员在编写代码阶段就发现漏洞（而不是在更后面）的情况显著增加。组织的首要投入重点仍然是云计算，但安全、治理和合规性现在是第二大关注点。</p><p></p><p>工具链复杂性仍然是一个问题，几乎三分之二的受访者希望简化他们使用的工具，因为大约一半的受访者所使用的工具链包含了六个或更多的工具。值得注意的是，这使得获得合规性和监控的整体视图，以及在工具链中获得洞见变得更加困难。</p><p></p><p>报告指出，提高开发者生产力、加快发布速度和提高业务敏捷性是扩展DevSecOps实践的关键原因。然而，只有15%的受访者认为去年的DevSecOps预算有所增加。DevSecOps平台继续受到关注，72%的受访者正在使用或将在明年使用，主要原因是为了提高效率、安全性和自动化。</p><p></p><p>GitLab的全球DevSecOps AI状态报告<a href=\"https://about.gitlab.com/developer-survey/#ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s\">可从其网站下载</a>\"。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/\">https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/</a>\"</p>",
    "publish_time": "2023-10-02 00:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "如何一步步优化你的负载均衡策略？",
    "url": "https://www.infoq.cn/article/BdK3Q9dAQPfTpFoX6RN9",
    "summary": "<p>发展到一定阶段后，Web应用程序就会增长到单服务器部署无法承受的地步。这时候企业要么提升可用性，要么提升可扩展性，甚至两者兼而有之。为此，他们会将应用程序部署在多台服务器上，并在服务器之前使用负载均衡器来分配传入的请求。大公司可能需要数千台运行其Web应用程序的服务器来处理负载。</p><p>&nbsp;</p><p>在这篇文章中，我们将重点关注单个负载均衡器将HTTP请求分发到一组服务器的各种可行方式。我们将从底层开始，逐步引出现代负载均衡算法。</p><p>&nbsp;</p><p></p><h2>问题可视化</h2><p></p><p>&nbsp;</p><p>我们先从头开始：单个负载均衡器将请求发送到单台服务器，请求以每秒1个请求（RPS）的速率发送，并且每个请求在服务器处理时都会逐渐缩小。对于很多网站来说，这种设置挺好用。现代服务器性能强大，可以处理大量请求。但是当它们的性能跟不上时会发生什么事情？</p><p>&nbsp;</p><p>从上面的模拟中我们可以看到，3RPS的速率导致一些请求被丢弃了。如果在处理一个请求时，另一个请求到达了服务器，服务器将丢弃后者。这将导致向用户显示的错误，这是我们要避免的事情。我们可以将另一台服务器添加到负载均衡器来解决这个问题。</p><p>&nbsp;</p><p>现在不再有丢弃的请求了！我们的负载均衡器在这里起到了作用，依次向每台服务器发送请求，这称为“循环法”负载均衡。它是最简单的负载均衡形式之一，当你的服务器都同样强大并且你的请求都同样昂贵时，这个机制很合适。</p><p>&nbsp;</p><p></p><h2>当循环法不好用的时候</h2><p></p><p>&nbsp;</p><p>在现实世界中，服务器同样强大而请求同样昂贵的情况很少见。即使你使用完全相同的服务器硬件，它们的性能也可能不同。应用程序可能必须为许多不同类型的请求提供服务，并且这些请求可能具有不同的性能特征。</p><p>&nbsp;</p><p>我们看看当我们改变请求成本时会发生什么事情。在以下模拟中，请求的成本并不相同。你可以看到一些请求比其他请求花费了更长的时间。</p><p>&nbsp;</p><p>虽然大多数请求都得到了成功处理，但我们确实放弃了其中一些请求。缓解这种情况的方法之一是引入一个“请求队列”。</p><p>&nbsp;</p><p>请求队列帮助我们应对不确定性，但这是一种权衡。我们将丢弃更少的请求，但代价是某些请求具有更高的延迟。如果你观看上面的模拟足够长的时间，你可能会注意到请求的颜色发生了微妙的变化。请求没有被送达的时间越长，它们的颜色变化的就越多。你还会注意到，由于请求成本差异，服务器开始表现出不均衡情况。队列会在运气不好的，必须连续服务多个昂贵请求的服务器上备份下来。如果队列已满，我们将丢弃请求。</p><p>&nbsp;</p><p>上述情况同样适用于性能不一样的服务器组。在下一个模拟中，我们还改变了每台服务器的性能，在视觉上用较深的灰色阴影表示。</p><p>&nbsp;</p><p>服务器被赋予一个随机的性能值，但很可能有些服务器的性能低于其他服务器，并且它们很快就会开始丢弃请求。与此同时，性能更强大的服务器大部分时间都处于闲置状态。这个场景展示了循环法的主要弱点：方差。</p><p>&nbsp;</p><p>然而，尽管存在缺陷，循环法仍然是nginx的默认HTTP负载均衡方法。</p><p>&nbsp;</p><p></p><h2>改进循环法</h2><p></p><p>&nbsp;</p><p>我们可以改进循环法来更好地应对方差。有一种称为“加权循环法”的算法，其中用一个权重来标记每台服务器，该权重决定了向每台服务器发送多少请求。</p><p>&nbsp;</p><p>在这个模拟中，我们使用每台服务器的已知性能值作为其权重，并在循环遍历它们时向更强大的服务器提供更多请求。</p><p>&nbsp;</p><p>虽然这种机制能比普通循环法更好地处理服务器性能的差异，但我们仍然需要应对请求方差。在实践中，让人类手动设定权重的做法很快就会失败的。将服务器性能用某个数字来表示是很难的事情，并且需要对真实工作负载进行仔细的负载测试。实践中很少这样做，因此加权循环法的另一种变体会使用一个代理指标动态计算权重：它就是延迟。</p><p>&nbsp;</p><p>按理说，如果一台服务器处理请求的性能是另一台服务器的3倍，那么它的速度可能就是另一台服务器的3倍，并且应该接收相当于另一台服务器3倍的请求数量。</p><p>&nbsp;</p><p>这次我向每台服务器添加了文本，显示最后3个请求的平均延迟。然后我们根据延迟的相对差异决定是否向每台服务器发送1、2或3个请求。结果与初始的加权循环模拟非常相似，但无需预先指定每台服务器的权重。该算法还能适应服务器性能随时间的变化。这称为“动态加权循环法”。</p><p>&nbsp;</p><p>我们来看看它如何处理服务器性能和请求成本都存在很大方差的复杂情况。以下模拟使用随机值，因此请随意刷新页面几次，查看它是否适应了新的情况。</p><p>&nbsp;</p><p></p><h2>循环法以外的选项</h2><p></p><p>&nbsp;</p><p>动态加权循环似乎能很好地处理服务器性能和请求成本的方差。但我们有没有更好、更简单的算法呢？答案是肯定的。</p><p>&nbsp;</p><p>这称为“最少连接”负载均衡法。</p><p>&nbsp;</p><p>因为负载均衡器位于服务器和用户之间，所以它可以准确地跟踪每台服务器有多少未完成的请求。然后当一个新的请求进来并且该确定将它发送到哪里时，负载均衡器已经知道哪些服务器要做的工作是最少的，并且会优先考虑这些服务器。</p><p>&nbsp;</p><p>无论存在多少方差，该算法都表现得非常好。它能准确掌握每台服务器正在做什么的信息，从而消除了不确定性。而且它的另一个好处是实施起来非常简单。由于这些原因，你会发现这个算法是AWS负载均衡器的默认HTTP负载均衡方法。它也是nginx中的一个选项，如果你从未更改过它的默认设置，这个算法非常值得一试。</p><p>&nbsp;</p><p>我们来看看这个算法在类似的复杂模拟中的实际效果。这里用的参数同上面为动态加权循环算法提供的参数是一样的。同样，这些参数在给定范围内是随机的，因此请刷新页面以查看新情况。</p><p>&nbsp;</p><p>虽然这个算法在简单性和性能之间取得了很好的均衡，但它无法避免丢弃请求的情况。但是你会注意到，这个算法只有在实际上没有更多可用队列空间的状况下才会丢弃请求。它能确保所有可用资源都被用上，这让它成为了大多数工作负载的绝佳默认选项。</p><p>&nbsp;</p><p></p><h2>延迟优化</h2><p></p><p>&nbsp;</p><p>到目前为止，我一直在回避讨论的一个关键部分：我们要优化什么指标。我之前一直把放弃请求当作是很糟糕的结果，并试图避免它们。这是一个不错的目标，但它并不是我们在HTTP负载均衡器中最想优化的指标。</p><p>&nbsp;</p><p>我们更关心的指标一般是延迟。这是从创建请求到处理请求的时间，以毫秒为单位。当我们讨论延迟时，通常会谈论不同的“百分位数”。例如，第50个百分位数（也称为“中位数”）定义为50%的请求低于该值（单位为毫秒），50%的请求高于该值。</p><p>&nbsp;</p><p>我用相同的参数运行了3次模拟，持续60秒，每秒都会进行各种测量。3次模拟的差异仅来源于所使用的负载均衡算法。我们来对比3个模拟的中值：</p><p><img src=\"https://uploader.shimo.im/f/ip6iAAU0xZqHEFX9.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>你可能没想到的是，循环法的延迟中值是最好的。如果我们不看其他数据点，得出的结论就会有问题。我们来看看第95个和第99个百分位数。</p><p><img src=\"https://uploader.shimo.im/f/TTRgpK0dzKcxG3Up.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>注意：每种负载均衡算法的不同百分位数之间没有颜色差异。更高的百分位数在图表上总是更高的。</p><p>&nbsp;</p><p>我们看到循环法在较高的百分位数中表现不佳。可是为什么循环法的中位数表现很好，但第95个和第99个百分位数很差呢？</p><p>&nbsp;</p><p>在循环法中不考虑每台服务器的状态，因此会有相当多的请求转到空闲服务器，于是第50个百分位的延迟就很低。另一方面，算法也很乐意将请求发送到过载的服务器上，因此第95和99个百分位数很差。</p><p>&nbsp;</p><p>我们可以看看直方图形式的完整数据：</p><p><img src=\"https://uploader.shimo.im/f/boAWP1iP5IrDLH8U.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>我为这些模拟调整了参数以避免丢弃任何请求，这样3种算法的数据点数量就是一样的。我们再次运行模拟，这次增加RPS值，目的是将所有算法推到它们可以处理的范围之外。以下是丢弃请求随时间积累的图表。</p><p><img src=\"https://uploader.shimo.im/f/0aQrwDSpEjmfkuQK.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>最少连接算法可以更好地处理过载，但这样做的代价是95%和99%的延迟略高。根据你的用例情况，这可能是一个值得接纳的权衡。</p><p>&nbsp;</p><p></p><h2>最后一个算法</h2><p></p><p>&nbsp;</p><p>如果我们真的想针对延迟做优化，我们需要一种将延迟考虑在内的算法。如果我们可以将动态加权循环算法与最少连接算法结合起来，那不是很好吗？我们可以得到加权循环法的延迟优势和最少连接法的弹性优势。</p><p>&nbsp;</p><p>事实证明，在我们之前就有人有了这样的想法。下面是对称为“峰值指数加权移动平均值”（或PEWMA）的算法的模拟。这是一个又长又复杂的名字，但坚持住，我稍后会详细解释它的工作原理。</p><p>&nbsp;</p><p>我为这个模拟设置了特定的参数，保证它表现出预期的行为。如果你仔细观察，你会注意到算法会在一段时间后停止向最左边的服务器发送请求。它这样做是因为它发现其他服务器都更快，并且不需要向最慢的服务器发送请求——这只会导致请求有更高的延迟。</p><p>&nbsp;</p><p>那么它是如何做到的呢？它将动态加权循环与最少连接法结合了起来，并加上了一点独创的魔法。</p><p>&nbsp;</p><p>对于每台服务器，该算法会跟踪最近N个请求的延迟。算法不是用这个数据来计算平均值，而是对值求和，但比例因子呈指数下降。这会产生一个值，其中延迟时间越长，它对总和的贡献就越小。最近的请求相比老的请求对计算的影响更大。</p><p>&nbsp;</p><p>然后将该值乘以服务器的开启连接数，我们用得出来的结果值来选择将下一个请求发送到哪台服务器上。这个值越低越好。</p><p>&nbsp;</p><p>那么它是如何做比较的呢？首先，我们来看一下第50、95和99个百分位数与之前的最少连接法数据的对比。</p><p>&nbsp;</p><p><img src=\"https://uploader.shimo.im/f/AyYg6RPU5Q7jMzWy.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>我们看到结果有了全方位的显著改善！新算法在较高的百分位数上优势更为明显，但中位数也一直有优势。下面我们来看直方图形式的相同数据。</p><p><img src=\"https://uploader.shimo.im/f/sjViCfSuWoj7765X.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>请求丢弃的情况如何？</p><p><img src=\"https://uploader.shimo.im/f/014k184cu2fHd3mw.PNG!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU4MDM4MjEsImZpbGVHVUlEIjoibG9xZU1wcGIxTElhSjhxbiIsImlhdCI6MTY5NTgwMzUyMSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.TwcgwujzewlzJ4lSO0a-i9wpwUT7fevVLGp3KAj6yrc\" /></p><p>它开始表现得更好，但随着时间的推移开始差于最少连接法，这是有道理的。PEWMA是机会主义的，因为它试图获得最佳延迟，这意味着它有时可能会让服务器负载不足。</p><p>&nbsp;</p><p>我想在这里补充一点，PEWMA有很多可以调整的参数。我为这篇文章编写的实现使用的配置似乎比较适合我的测试场景，但进一步调整参数可以获得比最少连接法更好的结果。这是PEWMA与最少连接法相比的一项劣势：额外的复杂性。</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>我在这篇文章上花了很长时间。我们很难在现实主义与简单易懂之间取得平衡，但我对最终成文还是很满意的。我希望读者能够通过本文理解这些复杂系统在理想和不太理想的情况下，实践的行为方式，这样可以帮助大家直观地了解它们在什么情况下最适用于你的工作负载。</p><p>&nbsp;</p><p>免责声明：你一定要牢记自己的负载才是永远的基准，不要把网上看来的建议视为福音。我在这里的模拟忽略了一些现实场景中的限制（服务器启动慢、网络延迟之类），而且为了展示每个算法的特定属性做了参数调整。它们并不是反映现实情况的基准测试。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://samwho.dev/load-balancing/\">https://samwho.dev/load-balancing/</a>\"</p>",
    "publish_time": "2023-10-02 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]