[
  {
    "title": "6种WebAssembly的优化手段",
    "url": "https://www.infoq.cn/article/owPkcmVjgx63g3FecIW7",
    "summary": "<p>简称为 Wasm 的 WebAssembly 是一种二进制格式，包括 Rust、C、JavaScript、Python、Ruby、.NET 在内等<a href=\"https://github.com/fermyon/wasm-languages\">诸多语言</a>\"都可通过 Wasm 执行。此外，Wasm 也可运行在各种硬件和操作系统之上，其<a href=\"https://www.w3.org/TR/wasm-core-1/\">规范</a>\"的设计快速且紧凑，以及重中之重的安全。</p><p></p><p>在2022年，最初仅为浏览器设计的 Wasm 已经在其他领域大放异彩，实践证明，Wasm 在嵌入式编程、插件、云、边缘计算等领域都非常有用。在这些用例中，性能都是极其重要的因素。快速加载可执行部分是性能中的一环，其中文件的大小往往对原始性能有直接的影响。</p><p></p><p>在本文中，我们将探讨六种优化 Wasm 性能及文件大小的方法。</p><p></p><h2>语言选择</h2><p></p><p></p><p>编程语言之间或多或少都些许区别，其中之一是语言执行时对运行时大小的需求。底层系统语言如 C 或 Rust 都算是轻量级，只需要很小的运行时开销。其他如 Swift 等语言对运行时的需求不小。Swift的二进制中包含了很多内置行为，因此文件也大多不会小。同理，Java 和 .NET 语言的二进制文件也往往很大。</p><p></p><p>为展示这其中区别，让我们看看一段“Hello World”程序在 Rust 和 Swift 中的表现。</p><p>Rust 中一段简单的“Hello World”如下：</p><p><code lang=\"rust\">fn main() {    println!(\"Hello, world!\");}</code></p><p></p><p>用&nbsp;cargo build —target wasm32-wasi&nbsp;命令编译后的二进制文件大小为2.0 M。这是未经优化的文件大小，后文中我们会再回到这点上。</p><p></p><p>同样的程序在 Swift 中如下：</p><p></p><p><code lang=\"swift\">print(\"Hello, World!\\n\")</code></p><p></p><p>通过&nbsp;<a href=\"https://swiftwasm.org/\">Swiftwasm</a>\"&nbsp;中的&nbsp;swiftc -target wasm32-unknown-wasi hello.swift -o hello.wasm&nbsp;命令编译至 Wasm 后，会产生9.1M 的镜像。可见 Swift 版本的程序相较 Rust 而言大了四倍有余。</p><p></p><p>因此，编程语言的选择会直接影响二进制文件的大小，并在一定程度上影响启动的时间。但对文件大小的优化并不是到此为止了，我们还有其他手段可以进一步优化二进制的大小。</p><p></p><h2>利用编译选项的优化</h2><p></p><p></p><p>部分编译器提供了内置的编译选项，以优化其所生成的二进制。C/C++ 的老手们对此并不陌生，而新生语言如 Rust 及 Zig 也提供优化选项。</p><p></p><p>在上文中简单的三行 Rust 程序中，我们通过默认编译命令cargocommand得到了2.0M 的二进制文件。但在加上编译选项之后，我们还可以进一步缩小文件大小。cargo build --target wasm32-wasi --release&nbsp;命令会输出1.9M 的二进制文件。因为 Rust 的 svelte 运行时存在，这种小型程序能优化掉东西并不多。但对于大型项目而言，--release&nbsp;选项可以显著减少文件大小。以&nbsp;<a href=\"https://bartholomew.fermyon.dev/\">Bartholomew CMS</a>\"&nbsp;项目为例，默认编译命令会生成84MB 的二进制文件，而启用&nbsp;--release&nbsp;选项的编译则会将文件大小缩减至7M，效果不可谓不明显。</p><p></p><p>Rust 中的&nbsp;--release&nbsp;选项能做的可不仅仅是缩小文件大小，它还能移除调试器和分析工具所用的符号，从而加快执行速度。在生产环境中的代码执行方面，这可是个非常有用的功能。运行完整84M 的 Bartholomew 需要数秒的执行时间，但优化后的7M 文件执行仅需要几毫秒。</p><p></p><h2>借助 wasm-opt 优化文件大小</h2><p></p><p></p><p>并不是所有编译器都提供优化的选项，即使是提供优化选项的编译器可能也不会有十分明显的优化效果。</p><p>Wasm 的优化工具可以分析 Wasm 二进制文件稳健性的同时，进一步优化文件大小，甚至还可优化 Wasm 可执行文件的性能特征。<a href=\"http://webassembly.github.io/binaryen/\">Binaryen</a>\"&nbsp;项目中提供了诸多 Wasm 可用的命令行工具，其中就包括 wasm-opt 优化器。</p><p></p><p>有9.1M大小的Swift程序珠玉在前，让我们看看用 wasm-opt 工具运行&nbsp;-O hello.wasm -o hello-optimized.wasm&nbsp;能带给我们什么。这条命令生成了一份优化后的二进制文件&nbsp;hello-optimized.wasm，大小仅有4.0M，缩小了50%有余。</p><p></p><p>wasm-opt 工具提供了多项对二进制的优化，从重复代码移除到代码整理不等。但这里说的“代码”是指 Wasm 指令，而非开发者编写的源码。因此，运行 wasm-opt 工具并不会修改 Swift 源码，仅仅是重写了 Wasm 二进制。这种方式不仅削减了文件大小，同时也优化了运行时性能。在作者的电脑上，优化后的“Hello World”程序执行速度比没经过优化的要快上两倍。</p><p></p><p>不仅如此，wasm-opt 工具甚至还能进一步优化已经经过优化的 Rust 代码。让前文中1.9M 的 Rust 二进制进一步压缩至1.6M。但在这种简单程序上的优化并没有给性能带来多少提升，无论是否进一步优化，运行时间均在十分之一秒左右。但或许更为大型的 Rust 二进制文件可以通过&nbsp;wasm-opt&nbsp;获得运行速度的改善。</p><p></p><h2>运行时很重要</h2><p></p><p></p><p>二进制格式 Wasm 非常灵活，可以通过&nbsp;<a href=\"https://github.com/wasm3/wasm3\">wasm3</a>\"&nbsp;这类解释器（如 ）按序读取并分块执行，而另外一些 Wasm 运行时，如&nbsp;<a href=\"https://wasmtime.dev/\">Wasmtime</a>\"，则是借助了 JIT（即时）编译技术，加快了执行的速度。</p><p></p><p>解释器的优势在”Hello World“这种简单程序、或运行于设备资源有限（如 Raspberry PI）的程序，因为它可以用更少的资源做更少的事。但对于 Bartholomew CMS 这类大型程序而言，JIT 形式的运行时拥有更多优势。这是因为 JIT 编译器会在启动以及执行早期进行额外工作，以优化程序的存内显示，而这种优化也会继续存在于程序的持续运行中。但因为 JIT 过程需要时间，所以对于只运行一小段时间的小型程序而言，反倒是一种性能的损失。</p><p></p><p>那么我们要如何选择呢？按照传统经验论的说法，如果是在比 Raspberry PI 资源还要有限的设备上运行，那么就用解释器，不然就还是选择支持 JIT 的运行时吧。</p><p>说起运行时，还有另一个技巧。</p><p></p><h2>提前（AOT）编译</h2><p></p><p></p><p>JIT 运行时会在启动时进行存内优化。但如果我们想在一次优化执行后，将其写回磁盘并在程序的下次运行时重复利用优化呢？这就是“提前（AOT）”编译了。</p><p></p><p>但 AOT 编译阶段所做的优化内容与之 wasm-opt 的优化有本质上的不同，这也是 AOT 编译的一大缺点。AOT 的优化因为考虑到了操作系统和处理器结构，所以优化后的 Wasm 二进制文件无法移植再移植到其他机器上。除此之外，优化后文件的格式也因运行时的不同而各异，也就是说，一个 AOT 编译的 Wasm 运行时程序无法再被其他 Wasm 运行时执行。</p><p></p><p>Wasmtime 运行时可将 wasm 模块编译为 AOT 格式，用&nbsp;wasmtime compile hello.wasm&nbsp;命令编译之前的 Swift 例子，会生成一个可被 Wasmtime 执行的新文件hello.cwasm。当然，对于“Hello World”这种小程序而言，AOT 编译效果并不明显。但在处理大型程序时，AOT 编译的性能会比解释器或 JIT 运行都要高。不过需要注意的是，多数 AOT 编译器所生成的二进制文件比其等效 Wasm 文件都要大，这是因为 Wasm 运行时中的很多自身元素都会被编译至二进制文件以提高性能。</p><p></p><p>什么时候该用 AOT 编译器呢？一个很具体的经验论是，只有在确定程序只会在同一套 Wasm 运行时、操作系统、架构配置下运行时再选择 AOT。此外，Wasm 模块应以正常的 Wasm 形式分发，并只在安装中或安装结束后再进行 AOT 编译。</p><p></p><h2>预初始化二进制</h2><p></p><p></p><p>第五种优化手段可以说是最神奇的一种。因为 Wasm 是基于堆栈的虚拟机，不仅可以随时停止，还能被写入到磁盘供后续恢复，当然这其中也有限制，但这些对本文的主题并不重要。Wasm 的这个功能有个蛮有趣的应用。</p><p></p><p>代码中时常会有一部分需要在每次启动时都运行，这部分代码做的事可能也很平常，像是设置变量默认值、创建数据结构实例等等。但每次运行程序时都必须执行同一套初始化逻辑，而每次运行的结果状态也不会有什么区别：变量被初始化为同样的值，数据结构被初始化为同样的状态。</p><p></p><p>如果我们能在第一次运行初始化的时候，将Wasm状态快照后写回磁盘，那么在后续程序执行的时候，我们就拥有了已经完成的状态，是不是就不用再运行初始化步骤了呢？</p><p></p><p>这个想法组成了&nbsp;<a href=\"https://github.com/bytecodealliance/wizer\">Wizer</a>\"&nbsp;项目，Wizer 提供对初始化代码块添加注释，让其在一次执行后被写入一个新的初始化后 Wasm 二进制文件。与 AOT 编译不同，这个新的二进制文件与别的 Wasm 二进制没什么区别，因此依旧是可移植的。</p><p></p><p>在用的时候可能会感觉 Wizer 有点不太稳定，但 .NET 这类系统可以从 Wizer 中受益良多。</p><p></p><h2>一起上</h2><p></p><p></p><p>根据我们在 Fermyon 的经验来看，优化对开发者工具和云运行时都很重要，但这二者的情况并不相同。</p><p>对开发者而言，编译器所能提供的优化工具中用得越多越好。比如在编译 Rust 代码时，我们总会带上&nbsp;--release&nbsp;选项。我们的开源工具&nbsp;<a href=\"https://github.com/fermyon/spin\">Spin</a>\"，允许开发者用多种语言构建 WebAssembly 微服务及网页应用，其中不乏有各种语言模板自己的优化内容。此外，在本地编译中包含 wasm-opt 也很有用，尤其是对于需要大量运行时的语言。开发过程中我们选择的运行时是支持 JIT 的，因为开发阶段 AOT 编译的价值不大。</p><p></p><p>服务器端就是另一个故事了。以我们基于SaaS的 Wasm 运行时平台为例，<a href=\"https://github.com/fermyon/spin\">Fermyon 云</a>\"&nbsp;仅接受 Wasm 二进制输入，但在部署到云集群后，这些二进制又变成了通过 AOT 编译过后的文件。因为我们非常清楚主机运行时的配置，所以这种方式很可靠。这些 Wasm 文件被部署到 Arm64 系统后可以相应地被 AOT 编译，我们不用担心这些文件在英特尔的架构上的执行情况。</p><p></p><p>至于 Wizer，我们其实只在&nbsp;<a href=\"https://www.fermyon.com/blog/webassembly-for-dotnet-developers-spin-sdk-intro\">.NET&nbsp;</a>\"上用过，Wizer 在这方面的优化非常好用。</p><p></p><h2>总结</h2><p></p><p></p><p>这6种优化 Wasm 性能及文件大小各有自己的优缺点，结合使用其中一些方法也可以增加效益。在生产的 Wasm 环境中应用这些手段也会有益处。</p><p></p><p>原文链接：<a href=\"https://www.infoq.com/articles/six-ways-optimize-webassembly/\">The Six Ways of Optimizing WebAssembly</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/pskeeKXTSbmQa2cauwBh\">WebAssembly 在工业领域的巨大机遇</a>\"</p><p><a href=\"https://www.infoq.cn/article/hipvRmYj1awjevsGI8Ps\">Docker 发布&nbsp;WebAssembly&nbsp;支持工具预览版</a>\"</p><p></p>",
    "publish_time": "2023-03-31 10:03:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Apache Doris 在美联物业的数据仓库应用实践",
    "url": "https://www.infoq.cn/article/kDZRv5SyOFyrRUIjPkAZ",
    "summary": "<p></p><blockquote>作者｜美联物业数仓负责人 谢帮桂</blockquote><p></p><p></p><p>传统行业面对数字化转型往往会遇到很多困难，比如缺乏数据管理体系、数据需求开发流程冗长、烟囱式开发、过于依赖纸质化办公等，美联物业也有遇到类似的问题。本文主要介绍美联物业基于 <a href=\"https://github.com/apache/doris\">Apache Doris</a>\" 在数据体系方面的建设，以及对数据仓库搭建经验进行的分享和介绍，旨在为数据量不大的传统企业提供一些数仓思路，实现数据驱动业务，低成本、高效的进行数仓改造。</p><p></p><p>美联物业属于香港美联集团成员，于 1973 年成立，并于 1995 年在香港联合交易所挂牌上市(香港联交所编号:1200)，2008 年美联工商铺于主板上市（香港联交所编号:459）， 成为拥有两家上市公司的地产代理企业。拥有 40 余载房地产销售行业经验，业务涵盖中、小型住宅、豪宅及工商铺，提供移民顾问、金融、测量、按揭转介等服务，业务遍布中国香港地区、中国澳门地区和中国内地等多个重要城市。</p><p></p><p>本文主要介绍关于美联物业在<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据</a>\"体系方面的建设，以及对数据仓库搭建经验进行的分享和介绍，旨在为数据量不大的传统企业提供一些数仓思路，实现数据驱动业务，低成本、高效的进行数仓改造。</p><p></p><p>考虑隐私政策，本文不涉及公司任何具体业务数据。</p><p></p><h1>业务背景</h1><p></p><p>美联物业早在十多年前就已深入各城市开展房地产中介业务，<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据体系</a>\"的建设和发展与大多数传统服务型公司类似，经历过几个阶段时期，如下图所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/07/07ebd25edcb6da342b89eb7a2de593d7.png\" /></p><p></p><p>我们的数据来源于大大小小的子业务系统和部门手工报表数据等，存在历史存量数据庞大，数据结构多样复杂，数据质量差等普遍性问题。此外，早期业务逻辑处理多数是使用<a href=\"https://www.infoq.cn/article/kDZRv5SyOFyrRUIjPkAZ\">关系型数据库 SQL Server </a>\"的存储过程来实现，当业务流程稍作变更，就需要投入大量精力排查存储过程并进行修改，使用及维护成本都比较高。</p><p></p><p>基于此背景，我们面临的挑战可以大致归纳为以下几点：</p><p></p><p>缺乏数据管理体系，统计口径统一，已有数据无法降本复用。多部门、多系统、多字段，命名随意、表违反范式结构混乱；对同一业务来源数据无法做到多份报表复用，反复在不同报表编写同一套计算逻辑。海量数据下性能不足，查询响应慢。历史大多数业务数据存储在关系型数据库中，分表分库已无法做到上亿数据秒级分析查询。数据需求开发流程冗长、烟囱式开发。每当业务部门提出一个数据需求，数据开发就需要在多个系统之间进行数据兼容编写存储过程，从而导致存储过程的可移植性和可读性都非常差。部门之间严重依赖文本文档处理工作，效率低下。由于长期的手工统计，用户已形成习惯，导致对信息系统的信任程度也比较低。</p><p></p><h1>早期架构</h1><p></p><p>针对上述的⼏个需求，我们在平台建设的初期选⽤了 Hadoop、Hive、<a href=\"https://www.infoq.cn/article/SlLsmcE3pW0qAZP6fTt9\">Spark </a>\"构建最初的离线数仓架构，也是比较普遍、常见的架构，运作原理不进行过多赘述。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/89/89b28408299b2c9ccff18d720aca0b2d.png\" /></p><p></p><p>我们数据体系主要服务对象以内部员工为主，如房产经纪人、后勤人员、行政人事、计算机部门，房产经纪在全国范围内分布广泛，也是我们的主要服务对象。当前数据体系还无需面向 C 端用户，因此在数据计算和资源方面的压力并不大，早期基于 Hadoop 的<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1496\">架构</a>\"可以满足一部分基本的需求。但是随着业务的不断发展、内部人员对于数据分析的复杂性、分析的效率也越来越高，该架构的弊端日益越发的明显，主要体现为以下几点：</p><p></p><p>过于笨重：传统公司的计算量和数据量并不大，使用 Hadoop 过于浪费。效率低下：T+1 的调度时效和脚本，动辄需要花费 1 小时的计算时间导入导出，效率低、影响数据的开发工作。维护成本高：组件过多，排查故障链路过长，运维成本也很高，且部门同事之间熟悉各个组件需要大量学习和沟通成本。</p><p></p><h1>新数仓架构</h1><p></p><p>基于上述业务需求及痛点，我们开始了架构升级，并希望在这次升级中实现几个目标：</p><p></p><p>初步建立数据管理体系，搭建<a href=\"https://www.infoq.cn/article/G-NGJllXC8zhCjpWhbl9\">数据仓库</a>\"。搭建报表平台和报表快速开发流程体系。实现数据需求能够快速反应和交付（1小时内），查询延迟不超过 10s。最小成本原则构建架构，支持滚动扩容。</p><p></p><h2>技术选型</h2><p></p><p>经过调研了解以及朋友推荐，我们了解到了 Apache Doris ，并很快与社区取得了联系，Apache Doris 的几大优势吸引了我们：</p><p></p><p>足够简单</p><p></p><p>美联物业及大部分传统公司的数据人员除了需要完成数据开发工作之外，还需要兼顾运维和架构规划的工作。因此我们选择数仓组件的第一原则就是\"简单\"，简单主要包括两个方面：</p><p></p><p>使用简单：Apache Doris 兼容<a href=\"https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH\"> MySQL </a>\"协议，支持标准 SQL，有利于开发效率和共识统一，此外，Doris 的 ETL 编写脚本主要使用 SQL进行开发，使用 MySQL 协议登陆使用，兼容多数 MySQL 语法，提供丰富的数据分析函数，省去了 UDF 开发工作。架构简单：Doris 的组件架构由 FE+BE 两类进程组成，不依赖其他系统，升级扩容非常方便，故障排查链路非常清晰，有利于运维成本的降低。</p><p></p><p>极速性能</p><p></p><p>Doris 依托于列式存储引擎、自动分区分桶、向量计算、多方面 Join 优化和物化视图等功能的实现，可以覆盖众多场景的查询优化，海量数据也能可以保证低延迟查询，实现分钟级或秒级响应。</p><p></p><p>极低成本</p><p></p><p>降本提效已经成为现如今企业发展的常态，免费的开源软件就比较满足我们的条件，另外基于 Doris 极简的架构、语言的兼容、丰富的生态等，为我们节省了不少的资源和人力的投入。并且 Doris 支持 PB 级别的存储和分析，对于存量历史数据较大、增量数据较少的公司来说，仅用 5-8 个节点就足以支撑上线使用。</p><p></p><p>社区活跃</p><p></p><p>截止目前，Apache Doris 已开源数年，并已支持全国超 1500 企业生产使用，其健壮性、稳定性不可否认。另外社区非常活跃，SelectDB 为社区组建了专职的技术支持团队，任何问题均能快速反馈，提供无偿技术支持，使用起来没有后顾之忧。</p><p></p><h2>运行架构</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/97/9716a60da7186661cbf4223ac97e4709.png\" /></p><p></p><p>在对 Apache Doris 进一步测试验证之后，我们完全摒弃了之前使用 Hadoop、Hive、Spark 体系建立的数仓，决定基于 Doris 对架构进行重构，以 Apache Doris 作为数仓主体进行开发：</p><p></p><p>数据集成：利用 DataX、Flink CDC 和 Apache Doris 的 Multi Catalog 功能等进行数据集成。数据管理：利用 Apache Dolphinscheduler 进行脚本开发的生命周期管理、多租户人员的权限管理、数据质量监察等。监控告警：采用 Grafana + Prometheus + Loki 进行监控告警，Doris 的各项监控指标可以在上面运行，解决了对组件资源和日志的监控问题。数据服务：使用帆软 Report 为用户提供数据查询和分析服务，帆软支持表单制作和数据填报等功能，支持自助取数和自助分析。</p><p></p><h3>数据模型</h3><p></p><p>1）纵向分域</p><p></p><p>房地产中介行业的大数据主题大致如下，一般会根据这些主题进行数仓建模。建模主题域核心围绕\"企业用户\"、\"客户\"、\"房源\"、\"组织\"等几个业务实体展开，进行维度表和事实表的创建。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b60c8aab544962e0a2f676553c33f680.png\" /></p><p></p><p>我们从前线到后勤，对业务数据总线进行了梳理，旨在整理业务实体和业务活动相关数据，如多个系统之间存在同一个业务实体，应统一为一个字段。梳理业务总线有助于掌握公司整体数据结构，便于维度建模等工作。</p><p></p><p>下图为我们简单的梳理部分房地产中介行业的业务总线：</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/50/5016e400bb8774a6c626b97f3113815f.png\" /></p><p></p><p>2）横向分层</p><p></p><p>数据分层是最常见的 5 层结构主要是利用 Apache Doris + Apache DolphinScheduler 进行层级数据之间 DAG 脚本调度。</p><p></p><p>存储策略： 我们在 8 点到 24 点之间采用增量策略，0 点到 8 点执行全量策略。采用增量 + 全量的方式是为了在ODS 表因为记录的历史状态字段变更或者 CDC 出现数据未完全同步的情况下，可以及时进行全量补数修正。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f6/f6b14413969c8745a0c793b5e5bfc238.png\" /></p><p></p><p>3）增量策略</p><p></p><p>where &gt;= \"业务时间-1天或-1小时\"</p><p></p><p>增量的 SQL 语句不使用 where=\"业务时间当天\"的原因是为了避免数据漂移情况发生，换言之，调度脚本之间存在时间差，如 23:58:00 执行了脚本，脚本的执行周期是 10 分钟/次，但是源库最后一条数据 23:59:00 才进来，这时候 where=\"业务时间当天\" 就会将该数据漏掉。</p><p></p><p>每次跑增量脚本前获取表中最大的主键 ID 存入辅助表，where &gt;= \"辅助表记录ID\"</p><p></p><p>如果 Doris 表使用的是 Unique Key 模型，且恰好为组合主键，当主键组合在源表发生了变化，这时候 where &gt;=\" 业务时间-1天\"会记录该变化，把主键发生变化的数据 Load 进来，从而造成数据重复。而使用这种自增策略可有效避免该情况发生，且自增策略只适用于源表自带业务自增主键的情况。</p><p></p><p>表分区</p><p></p><p>如面对日志表等基于时间的自增数据，且历史数据和状态基本不会变更，数据量非常大，全量或快照计算压力非常大的场景，这种场景需要对 Doris 表进行建表分区，每次增量进行分区替换操作即可，同时需要注意数据漂移情况。</p><p></p><p>4）全量策略</p><p></p><p>Truncate Table 清空表插入</p><p></p><p>先清空表格后再把源表数据全量导入，该方式适用于数据量较小的表格和凌晨没有用户使用系统的场景。</p><p></p><p>ALTER TABLE tbl1 REPLACE WITH TABLE tbl2 表替换</p><p></p><p>这种方式是一种原子操作，适合数据量大的全量表。每次执行脚本前先 Create 一张数据结构相同的临时表，把全量数据 Load 到临时表，再执行表替换操作，可以进行无缝衔接。</p><p></p><h1>应用实践</h1><p></p><p></p><h2>业务模型</h2><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/fefb5f5b46269f2f241f7b4d6bd374f9.png\" /></p><p></p><p>业务模型是分钟级调度 ETL初次部署建议配置：8 节点 2FE * 8BE 混合部署节点配置：32C * 60GB * 2TB SSD对于存量数据 TB 级、增量数据 GB 级的场景完全够用，如有需要可以进行滚动扩容。</p><p></p><h2>具体应用</h2><p></p><p>离线数据和日志数据集成利用 DataX 进行增量和全量调度，Datax 支持 CSV 格式和多种关系型数据库的Redear，而 Doris 在很早之前就提供了 DataX Doris writer 连接器。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/57/573ad9c887f008b491f0a0be85c9146d.png\" /></p><p></p><p>实时统计部分借助了<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1497\"> Flink</a>\" CDC 对源表进行实时同步，利用 Doris 的物化视图或者 Aggregate 模型表进行实时指标的汇总处理，因我们只有部分指标需要实时处理，不希望产生过多的数据库连接和 Flink Job，因此我们使用 Dinky 的多源合并和整库同步功能，也可以自己简单实现一个Flink DataStream 多源合并任务，只通过一个 Job 可对多个 CDC 源表进行维护。值得一提的是， Flink CDC 和 Apache Doris 新版本支持 Schema Change 实时同步，在成本允许的前提下，可完全使用 CDC 的方式对 ODS 层进行改造。</p><p></p><p><code lang=\"text\">EXECUTE CDCSOURCE demo_doris WITH (\n  'connector' = 'mysql-cdc',\n  'hostname' = '127.0.0.1',\n  'port' = '3306',\n  'username' = 'root',\n  'password' = '123456',\n  'checkpoint' = '10000',\n  'scan.startup.mode' = 'initial',\n  'parallelism' = '1',\n  'table-name' = 'ods.ods_*,ods.ods_*',\n  'sink.connector' = 'doris',\n  'sink.fenodes' = '127.0.0.1:8030',\n  'sink.username' = 'root',\n  'sink.password' = '123456',\n  'sink.doris.batch.size' = '1000',\n  'sink.sink.max-retries' = '1',\n  'sink.sink.batch.interval' = '60000',\n  'sink.sink.db' = 'test',\n  'sink.sink.properties.format' ='json',\n  'sink.sink.properties.read_json_by_line' ='true',\n  'sink.table.identifier' = '${schemaName}.${tableName}',\n  'sink.sink.label-prefix' = '${schemaName}_${tableName}_1'\n);\n</code></p><p></p><p>脚本语言采用 Shell + SQL 或纯 SQL 的形式，我们在 Apache DolphinScheduler 上进行脚本生命周期管理和发布，如 ODS 层，可以编写通用的 DataX Job 文件，通过传参的方式将 DataX Job 文件传参执行源表导入，无需在每一个源表编写不同的DataX Job ，支持统一配置参数和代码内容，维护起来非常方便。另外我们在 DolphinsSheduler 上对 Doris 的 ETL 脚本进行管理，还可以进行版本控制，能有效控制生产环境错误的发生，进行及时回滚。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4b81e46868e01c52c472a90b4ffdf3a7.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fc/fc19feec05bb61b0e1bcbe334ecf5553.png\" /></p><p></p><p>发布 ETL 脚本后导入数据，可直接在帆软 Report 进行页面制作，基于登陆账号来控制页面权限，如需控制行级别、字段级别权限，可以制作全局字典，利用 SQL 方式进行控制。Doris 完全支持对账号的库表权限控制，这一点和 <a href=\"https://www.infoq.cn/article/tJUA8Q3WJQvVHcazlcSY\">MySQL</a>\" 的设置完全一样，使用起来非常便捷。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea03cef94c612e5fed3ed86dc99dcea8.png\" /></p><p></p><p>除以上之外，在容灾恢复、集群监控、数据安全等方面也有应用，比如利用 Doris 备份实现容灾恢复、Grafana+Loki 对集群进行指标规则告警、Supervisor 对节点组件进行守护进程监控，开启 Doris 审计日志对执行 SQL 效率进行监控等，因篇幅限制，此处不进行详细说明。</p><p></p><h2>优化经验</h2><p></p><p>数据导入</p><p></p><p>我们使用 DataX 进行离线数据导入，DataX 采用的是 Stream Load 方式导入，该方式可以通过参数控制导入批次流量，DataX 导入不需要借助计算引擎，开箱即用的特点非常方便。另外，Stream Load 导入是同步返回结果的，其他导入方式一般是异步返回结果，针对我们的架构来说，在 Dolphinscheduler上执行异步导入数据会误以为该脚本已经执行成功，影响其正常运行。如采用其他异步导入方式，建议在 Shell 脚本中 执行 show load 再利用正则过滤状态进行判断。</p><p></p><p>数据模型</p><p></p><p>我们所有层级的表模型大部分采用 Unique Key 模型，该模型可有效保证数据脚本的结果幂等性，Unique Key 模型可以完美解决上游数据重复的问题，大家可以根据业务模式来选择不同的模型建表。</p><p></p><p>外部数据源读取</p><p></p><p>Catalog 方式可以使用 JDBC 外表连接，还可以对 Doris 生产集群数据进行读取，便于生产数据直接 Load 进测试服务器进行测试。另外，新版支持多数据源的 Catalog，可以基于 Catalog 对 ODS 层进行改造，无需使用 DataX 对ODS 层进行导入。</p><p></p><p>查询优化</p><p></p><p>尽量把非字符类型（如 int 类型、where 条件）中最常用的字段放在前排 36 个字节内，在点查表过程中可以快速过滤这些字段（毫秒级别），可以充分利用该特性进行数据表输出。</p><p></p><p>数据字典</p><p></p><p>利用 Doris 自带的 information_schema 元数据制作简单的数据字典，这在还未建立数据治理体系前非常重要，当部门人数较多的时候，沟通成本成为发展过程中最大的“拦路虎”，利用数据字典可快速对表格和字段的全局查找和释义，最低成本形成数仓人员的数据规范，减少人员沟通成本，提高开发效率。</p><p></p><h1>架构收益</h1><p></p><p>自动取数导数：数据仓库的明细表可以定时进行取数、导数，自助组合维度进行分析。效率提升：T+1 的离线时效从小时计降低至分钟级查询延迟降低：面对上亿行数据的表，利用 Doris 在索引和点查方面的能力，实现即席查询 1 秒内响应，复杂查询 5 秒内响应。运维成本降低：从数据集成到数据服务，只需维护少数组件就可以实现整体链路高效管理。数据管理体系：Doris 数仓的搭建，使得数据管理体系初步形成，数据资产得以规范化的沉淀。资源节省：只用了少数服务器，快速搭建起一套数据仓库，成功实现降本赋能。同时 Doris 超高的压缩比，将数据压缩了 70%，相较于 Hadoop 来说，存储资源的消耗大幅降低。</p><p></p><h1>总结与规划</h1><p></p><p>目前我们已经完成数仓建设的初期目标，未来我们有计划基于 Apache Doris 进行中台化的改造，同时 Apache Doris在用户画像和人群圈选场景的能力十分强悍，支持 Bitmap 等格式进行导入和转换，提供了丰富的 Bitmap 分析函数等，后续我们也将利用这部分能力进行客户群体分析，加快数字化转型。</p>",
    "publish_time": "2023-03-31 10:06:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从数据云的概念、应用场景聊我们为什么需要它",
    "url": "https://www.infoq.cn/article/Fu1EhxDGZluKyvvufOM4",
    "summary": "<p></p><h2>什么是数据云？</h2><p></p><p>在讲数据云的概念之前，我们先来了解一下<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1502\">企业数字化转型</a>\"的背景。</p><p>&nbsp;</p><p>企业在数字化早期，信息系统都是用烟囱式架构建设，孤立的系统需要花费大量精力和资源来维护和管理，从而使得数据在不同系统之间共享和交换变得非常困难。同时，孤立的系统也会存在数据处理速度慢的问题，企业无法以足够快的速度处理实时数据，也就无法实现<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1497\">数据智能</a>\"。另一些企业则可能会发现很难统一数据，以获得新的数据洞见或者使数据可供需要的人员即时访问和共享。</p><p>&nbsp;</p><p>即便使用现代数据工具，组织也无法轻松地将其与现有系统集成，并且会在扩缩和管理遗留 IT 基础架构时遇到困难。团队往往将大部分时间花在数据清洗上： 在正确的时间，将格式正确的数据，放到正确的位置上，因此很少或根本没有时间进行有意义的数据分析。</p><p>&nbsp;</p><p>现有技术无法解决现存的困难，就会催生新技术或新方法，于是数据云诞生了，数据云提供了一个基于云或者云原生的融合<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1523\">数据基础架构</a>\"，可实现企业数据的集成、存储、治理、建模、分析、挖掘和流通。利用融合数据基础架构的云特性，可以按需提供计算、存储、分析和建模功能，使企业能够利用其数据来推动其转型并创造价值。</p><p></p><h2>我们为什么需要它？</h2><p></p><p>&nbsp;</p><p>近几年，随着数字化转型的深入，企业的应用、数据和基础设施的结合越来越紧密，原本以资源为中心的传统云已经不能满足现阶段企业数字化转型的需求，而以数据为中心的数据云正在成为企业数字化基础设施建设的新方法。</p><p>&nbsp;</p><p>数据、应用和智能是数字化的三大核心生产资料，数据云在一个 PaaS 平台上提供包括数据仓库/数据湖、数据治理、数据智能与分析、数据交易与共享等在内的完整的数据解决方案以及应用生命周期管理能力。数据云可以通过构建统一的数据湖，消除数据碎片化并充分利用数据的全部潜力。数据云可以更轻松地统一、连接和提供数据，它提供具备弹性能力且可靠的交易数据库、分析<a href=\"https://www.infoq.cn/article/K30UQfJt7TqDVLDgjIK2\">数据库</a>\"、大数据平台和机器学习系统来推动创新、改善体验并更快地实现业务价值。</p><p>&nbsp;</p><p>数据云通常包括以下组件和功能：</p><p>&nbsp;</p><p>统一的元数据和数据存储：通常包含一个统一的数据湖，以存储从源系统收集的所有数据，包括结构化、非结构化或半结构化数据，从而降低复杂性并简化数据发现。</p><p>&nbsp;</p><p>敏捷的数据架构：数据云可以按需部署云数据库、ETL 引擎、流处理引擎、数据治理工具等数据服务。</p><p>&nbsp;</p><p>内置的 AI 和机器学习功能：智能功能（例如自助式分析、AI 和机器学习）可帮助企业节省时间和人力并支持创新。</p><p>&nbsp;</p><p>数据治理：提供完善的数据开发、数据治理、数据质量、数据标准等工具集，用于发掘数据的价值。</p><p>数据安全和基础设施安全：数据云需要提供安全的底层基础设施，包括计算、网络、存储安全，并在此基础上提供数据安全，包括数据分类分级、数据脱敏、数据安全审计等能力。</p><p></p><h2>数据云与云数据库的区别</h2><p></p><p>在谈论数据云的时候很容易和另外一个概念“<a href=\"https://www.infoq.cn/article/e9OECwQVphjLs0eXmr73\">云数据库</a>\"”相混淆，我们在此做一个区分。大数据和云计算的结合，最初主要是以云数据库或者云数据仓库这样的形态出现。云数据库通常指由私有云或者公有云厂商提供的数据库服务，用户只需要以服务的形式申请和使用，而无需关心底层的部署及运维，云厂商结合云计算底层能力解决了数据库的自动化、备份、可扩展性、可用性等运维需求。云原生数据库相较于云数据库，使用方式不变，基础架构则从传统的云计算技术变为云原生技术，从而更加轻量、敏捷、弹性和低成本。</p><p>&nbsp;</p><p>而数据云包含了云数据库能力，更加准确的说是数据库即服务的能力（DBPaaS）。数据云以最终实现数据的业务价值为导向，将各种数据库、分析工具、大数据平台、人工智能工具做了场景化的整合，以服务化的方式提供基础能力（例如云数据库），以及面向数据和企业场景的数据开发、数据流通、数据治理、数据安全防护等能力。</p><p></p><h2>数据云在各行业的应用场景</h2><p></p><p>数据云的主要目标是让<a href=\"https://archsummit.infoq.cn/2023/shanghai/track/1501\">数字化转型</a>\"变得更简单、更智能。我们知道企业数字化转型不是一蹴而就的，需要分步进行，我们可以将数字化转型分成信息化、数据资产化、数据业务化、数据生态化四个阶段，任何企业、任何行业想要全面数字化转型都要经过这四个阶段。</p><p>&nbsp;</p><p>企业在信息化阶段产生海量数据，在数据资产化阶段把信息化阶段产生的数据集中治理形成数据资产，在数据业务化阶段又需要第二阶段形成的数据资产来驱动业务本身，而到了数据生态化阶段，数据已经不再只服务于某个组织或者某个企业，而是作为生产要素开始在组织之间、企业之间流通，发挥出更大的价值。这四个阶段环环相扣，缺一不可，基于这四个阶段的底层技术支撑也需要同步升级。</p><p>&nbsp;</p><p>数据云就是能够解决这个四个阶段不同问题的新方法，数据云可以通过整个平台的计算、存储能力以及数据云产品架构的优化，为大数据服务提供高性能的存储和分析能力。同时，也基于整个数据云平台底层资源的复用和服务的有效调度，为大数据的存储和计算提供更高性价比的实现，加速各行各业的数字化转型，事实上，在星环科技的推动下，数据云已经在多个行业有落地。</p><p>&nbsp;</p><p>在政府行业，通过数据云可以帮助省级、市级大数据中心建设统一的数据共享交换平台，打通各部门信息系统、<a href=\"https://www.infoq.cn/minibook/VdiyYEfHjWVjyqEdppMj\">打破‘数据孤岛</a>\"’”建成对接国家平台，覆盖全市、统筹利用、统一接入的数据共享交换平台。 早在 2019 年星环科技基于自研数据云平台Transwarp Data Cloud （TDC ）为上海市大数据中心数据共享交换平台提供大数据支撑管理子系统，为汇集政务数据提供大数据存储和计算能力支撑，支持多个应用系统运行、用于数据存储和查询；数据范围包括49家市级委办局、16区县、四大库等各类数据。数据共享交换平台接入更多市政部门系统数据，一网通办平台可以做更多业务查询和处理。</p><p>&nbsp;</p><p>在银行行业，随着大数据技术的不断发展，各银行也开始投身到大数据应用实践中，而大数据平台是支撑银行业大数据应用的基础。为适应互联网时代银行业务和技术发展形势，大范围提升大数据应用、管控和服务能力，江苏省联社及各农商行积极开展大数据技术的探索研究。</p><p>&nbsp;</p><p>江苏农信在数据云的加持下，建设大数据 DAAS 应用平台，实现了各租户之间的资源、数据、应用、组件的完全隔离，为各农商行提供了一整套大数据基础平台和大数据应用解决方案，切实有效的提高了农商行大数据应用和分析能力。星环科技 TDC 为其提供强大的存储计算能力，加速农村金融机构数字化转型进程。</p><p>&nbsp;</p><p>在能源行业中，以中化集团为例，中化为响应国资委在《关于2019年进一步加强中央企业集团管控信息化工作有关事项的通知》中对央企提出的“大系统、大平台、大数据”信息化要求，同时为了推进集团“线上中化”的战略目标，助力集团各业务单位实现数字化转型。</p><p>&nbsp;</p><p>中化集团基于数据云构建分析Paas、数据Paas、应用Paas为一体的数据共享交换体系，通过数据接口、安全接口、资源接口、微服务接口对接业务，实现平台云+数据云+应用云三云融合。星环科技 TDC 为中化集团大数据平台提供一站式的大数据解决方案，能够充分整合和管理企业各个系统全生命周期数据，快速挖掘数据背后的价值，落地丰富的数据应用场景，形成数据驱动的闭环迭代生态，赋能业务，综合提升企业管理和运营能力。</p><p>&nbsp;</p><p>星环科技数据云平台 TDC，早在 2018 年发布 1.0 版本，是国内最早推出数据云产品和解决方案的企业，截至目前 TDC 已经为政府、银行、基金、能源等多个行业提供完整的数字化建设解决方案。</p><p></p><p>作者简介：</p><p>王天青，星环信息科技（上海）股份有限公司数据云负责人</p>",
    "publish_time": "2023-03-31 11:09:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]