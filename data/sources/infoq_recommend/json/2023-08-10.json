[
  {
    "title": "中欧财富数字化转型升级的过程是如何选择数据库的？",
    "url": "https://www.infoq.cn/article/9FMgIHyzeu91hlDNu4VE",
    "summary": "<p></p><p>&nbsp;嘉宾 ｜伍春兰 中欧财富技术总监</p><p>&nbsp;</p><p></p><blockquote>财富管理行业的数字化转型近些年主要面临着哪些环境因素的影响？整个过程存在哪些难点？对数据库的要求具体是什么？为什么要建设分布式数据体系？迁移之前做了哪些方面的准备？最终效果如何？作为国家首批五家基金投顾业务试点公司之一，中欧财富过去多年数字化转型的过程中对人才、技术、业务等做了哪些思考？本文，InfoQ 采访了中欧财富的技术总监伍春兰，试图寻求上述问题的答案。</blockquote><p></p><p></p><p>本文要点：</p><p></p><p>财富管理领域近几年受内外部环境的变化，对技术底座能力提出敏捷高效、及时创新等较高要求；数字化转型不是一个技术问题，涉及思维、组织、流程、平台四大层面；财富管理领域企业数字化转型主要面临人才，安全、基础架构（技术）三方面的挑战；人工智能技术在财富管理领域企业内部大规模落地还需要时间；在数据库选型之前，企业需要先定位清楚需求；数据库迁移前，旧有的 MySQL 体系主要遇到的问题是大表 DDL 耗时、分库分表耗费大量人力、单节点写入易出现瓶颈等问题，最后通过分布式数据库 TiDB 解决了上述问题；在评价数据库迁移前后的效果时注意运维、资源等隐形层面的成本；HTAP融合架构在性能、资源精准消耗等层面都起到了重要作用；</p><p></p><h2>中欧财富数字化转型升级的思路、难点及实践</h2><p></p><p></p><p>InfoQ：财务管理公司和基金公司这几年节奏明显变快，其背后的推动力到底是什么？财务管理行业的数字化转型存在哪些痛点？</p><p></p><p>伍春兰：最近几年，基金公司内外部环境都发生了比较大的变化。自 2013 年伴随着余额宝的兴起，整个互联网业务快速发展，这对市场带来了几个明显的变化：第一个变化是用户基本盘迅速扩大，要想服务好用户，技术迭代速度需要更快。举例来说，一些互联网属性的公司数据刷新较快，中欧财富为了达到这个效果，整个公司做了比较大的投入和配合，包括引入人工智能技术做一些自动化的事情；第二个变化是互联网业务比较有特点且信息较为透明，用户可以迅速看到市场上出现了哪些新的业务与渠道，这要求团队时刻保持敏捷和高效，包括与上下游业务的打通；第三个变化是业内开始出现新的营销形式，比如通过直播的方式进行营销，或者运营新的平台，比如抖音等，这需要企业打通内部的运营流程和数据，这对技术团队提出的要求同样是及时创新、敏捷高效。</p><p></p><p>综上，公司需要抓住机会，迅速做出决策，以应对这些变化。比如，打破原来的数据孤岛，形成统一的、智能的数据中台，基于这个中台可以更好地挖掘客户特性、绘制用户画像，从而让产品更好地满足客户需求；与上下游的机构和企业合作时需要具备强大的研发能力，包括模型、算法、定制化能力等都必须与互联网大厂的研发实力相匹配。</p><p></p><p>纵观内部和外部，难点主要在于：一是人才方面，并不是每一家金融企业都匹配了强大的且对技术趋势敏锐的研发团队；二是资源投入能力，比如产品层面的投入是否跟得上；三是数据安全，在适配互联网快节奏的业务更新和及时响应的前提下保证公司内部、与上下游企业合作全链路的数据安全是非常重要的；四是在旧有基础架构上做敏态升级，包括基础设施、运维、研发、产品等。</p><p></p><p>InfoQ：第二大变化中的“打通上下游”具体指什么？</p><p></p><p>伍春兰：数字化转型一是思维、二是组织、三是流程、四是平台。思维上，数字化转型不是某个部门的事情，过程中涉及组织及流程上的变化，需要保证大家思维统一；组织和流程上，数据打通就涉及跨部门共享，思维对齐的情况下还需要保证组织层面可以尽可能流程化，快速推动相关决策。比如新业务上线，可能涉及运营、产品、研发等多个部门，大家是否可以透明地了解整个执行链路，清楚了解公司的决策背景，只有每个部门都参与其中才能真正做到流程提效，而不仅是完成工作。平台上，数据打通之后能否真正用起来，数据质量需要达到什么程度都是平台要重点优化的事情。</p><p></p><p>InfoQ：针对人才，安全、基础架构三大难题，中欧财富是如何解决的？</p><p></p><p>伍春兰：在人才方面，中欧财富于 2014 年左右开始筹备，招聘的大多数员工背景偏互联网和核心金融机构方向，这些员工不仅了解金融的业务形态，同时具备较高的技术能力和敏锐度，整个架构起初就适配了互联网时代的特点；安全层面，除了符合国家相关监管规范的要求，中欧财富本身也做了大量探索，比如防 DDoS 攻击、流量清洗、内网监控、数据安全和审计等，这些能力经过过去三四年的发展逐渐建立起来，但要做到完全自动化还是比较困难的。基础架构层面，如前文言，初始架构已经适配了互联网时代的特点，在过去多年的演进中，中欧财富又针对不同的模块进行了优化，包括分布式数据库体系建立、私有云体系优化等。</p><p></p><p>InfoQ：您方便举例说明中欧财富通过数字化转型取得了哪些成果？</p><p></p><p>伍春兰：以投顾业务为例，首先该业务需要迅速理解客户需求，并基于数据驱动的逻辑做出快速、敏捷的反应，这对底层的数据能力要求较高；其次，作为国家首批五家基金投顾业务试点公司，中欧财富主要优势在于强大的自主研发能力。过去五年，中欧财富针对整个基础架构进行了升级，底层基建与行业技术演进的大趋势相匹配，实现了软件定义及弹性部署，降低了计算和运维成本。目前，公司业务全面部署在基于 K8s 的私有云上，可以很好地支持投顾等业务的发展。</p><p></p><p>InfoQ：如何看待人工智能技术在财富基金领域数字化转型中发挥的作用？</p><p></p><p>伍春兰：对于人工智能技术的落地，我认为大规模落地还是有难度的。虽然目前很多公司在这方面都有动作，但更多的是尝试，比如智能客服、敏感词审核等。在实际业务中，人工智能更多是在扮演辅助的角色，而不是代替很多人的劳动。</p><p></p><p>具体到金融领域，因为该领域强监管且对专业性要求较高，因此目前现有的、通用型的大模型可能无法很好匹配需求，未来可能会出现针对该领域的大模型，只是还需要一些时间。</p><p></p><h2>面向未来，中欧财富如何联手PingCAP打造分布式数据库体系？</h2><p></p><p></p><h3>迁移前的旧有数据库体系基于MySQL搭建</h3><p></p><p></p><p>InfoQ：中欧财富在与 PingCAP 的 TiDB 数据库合作之前，内部的数据体系是什么状态？</p><p></p><p>伍春兰：在此之前，中欧财富的数据库体系是基于 MySQL 搭建的。随着业务的逐渐发展，传统的数据体系遇到了一些问题，中欧财富开始思考是否存在一些新的工具、平台、产品可以更好地满足目前的诉求。</p><p>在技术层面，团队当时面临着三大比较明显的问题：一是大表的 DDL 操作，该操作一般通过 gh-ost 工具去实现，非常耗时，且会产生大量 binlog 影响下游的同步。如果遇到有分表逻辑的大表，整个 DDL 过程需要持续几天；二是分库分表，单表数据量增速非常快，时常需要进行分表处理。但开发资源有限，没有这么多人力可以投入到分表工作中；三是单节点写入，MySQL 传统的一主多从架构，主节点承担应用的写入。当有清算或跑批任务时，主节点会出现写入瓶颈。</p><p></p><h3>分布式数据库选型及迁移</h3><p></p><p></p><p>InfoQ：在分布式数据库选型层面，中欧财富主要看中哪些因素？</p><p></p><p>伍春兰：中欧财富在数据库选型层面主要看中整个架构的高可用性、去中心化、性能高且没有单点故障以及可以降低运维成本。以单点性能为例，虽然 MySQL 时代可以通过增加机器的方式来解决问题，但总体无法实现弹性扩展。经过对一些互联网公司数据库选型的调研，以及对市面上现有数据库产品的了解，最终团队抱着“试一试”的心态开始接触 TiDB。</p><p></p><p>选型确定后，研发团队对 TiDB 的稳定性、可用性、扩展性等进行了半年左右的测试，整个平台都放到了 TiDB 之上，包括核心业务，综合体验其对场景的适配情况。其实，数据库是一个非常复杂、庞大且核心的工程，且需要与时俱进。TiDB 在当时提出的存算分离等理念与场景能力特别匹配，且经过多方交流，其架构足以承担未来多年数据量的持续增长。</p><p></p><p>InfoQ：中欧财富的数据库迁移主要分了哪几步？</p><p></p><p>伍春兰：中欧财富从 2021 年开始进行调研、测试，2022 年开始部署、上线，并于今年进行深度测试并完成 30%的业务迁移，包括组合投顾系统、营销系统、产品系统、用户系统和交易系统，未来希望可以实现全量业务运行在 TiDB 之上。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/bd/bdde6e99f619f86a5f1eda3f7251530c.png\" /></p><p></p><p>回头来看整个过程，中欧财富的方法还是比较科学的。一是，企业需要对当前的情况有充分认知，清晰定位需求并匹配合适的产品；二是团队需要充分印证升级后的数据库整体架构，对未来演进有明确的方案；三是培养人才，中欧财富和 TiDB 团队做了大半年的密切交流，并在其社区中学习，对其技术能力、研发能力、现有市场、可预见的协同、定位、技术演进方向等都有了充分了解；四是准备备案，即双轮驱动。起初，业务在 TiDB 和旧的 MySQL 体系上同时运行，这种模式下运转了大半年之后，整个技术架构完成了较好适配（当然，TiDB 本身兼容 MySQL 协议），业务运转良好后开始进行正式迁移，双方团队一起完善新老架构的兼容及下游系统适配。迁移过程中，下游不会感知到上游的架构变化，团队做了充分的准备并严格按计划执行。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a4/a41c74250f404258fab6e816fa114c31.png\" /></p><p></p><p>生产 TiDB 集群配置如上图，为了应对复杂的业务场景，硬件层面都选择了超配。架构方面，计算层用了5台服务器，其中3台 TiDB-server 和 PD 混合部署，另外 2 台用于接收复杂 SQL 的请求（资源隔离）。每台 TiKV 服务器下挂三块盘，每一块盘都作为一个独立的 TiKV节点，所有 TiKV 一共有 3*3=9 个节点。集群架构可见下图。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e0/e03178253c902a164193c10b454f8854.png\" /></p><p></p><p></p><h3>迁移后的整体评价</h3><p></p><p></p><p>InfoQ：您对于数据库体系更换的整体评价是什么？</p><p></p><p>伍春兰：一是敏捷性，不需要在资源分配层面投入过多精力，可以更快推行创新业务；二是简化了公司架构，统一数据库架构之后降低了运维难度和升级换代的难度；三是 HTAP 架构下的一些计算任务的链路缩短，风险相对更加可控；最后是有利于未来的业务创新和增长。</p><p></p><p>具体到技术层面，TiCDC 简化了数据同步，TiCDC 可以将 TiDB 内的数据同步至 MySQL 和Kafka （canal - json 格式），大大降低了数据同步的改造工作；可观测性，配套的 dashboard 和 grafana 非常好用。测试阶段遇到问题或性能瓶颈，可以快速地定位出问题，加大测试的效率；服务器硬件故障，集群内服务器硬件故障导致宕机，没有影响任何业务；后续配件更换的停机流程也非常丝滑；Tiflash 优化模糊查询，业务有模糊查询的需求，通过 TiFlash 将行存数据转为列存，同时利用MMP对查询进行加速。</p><p></p><p>InfoQ：从运维角度来看，迁移前后的成本发生了哪些变化？</p><p></p><p>伍春兰：整体来看，运维层面还是节省了很多成本。举例来说，原有体系需要拆分出大量集群来运营数十个应用，现在只需要一个 TiDB 集群就可以解决问题，这种运营和计算资源（服务器等）成本是隐形的，因此整个迁移过程已经满足降本增效了。当然，很多企业可能足以承担这些成本，但运营效率也是不同的。更换之后，运营效率、架构敏捷度得到了极大提升，这在当前的业务场景下至关重要。</p><p></p><p>那么，为什么前几年企业不谈这些内容呢？在非互联网、非充分竞争的情况下，这些问题可能不是最关键的，靠人力驱动也可以搞定。但是，现在的市场环境下，效率在很多时候起决定性作用，这就逼得很多企业不得不对旧有的数据体系做出调整，而且企业不需要在纠结底层的选型和适配问题，资源全部池化，企业可以把所有精力投入到业务本身来获取最终的增长。</p><p></p><p>InfoQ：研发同学对于TiDB有哪些使用反馈？</p><p></p><p>伍春兰：从研发视角，首先我们对自己有清楚的认知才选择了 TiDB；其次，如上所言，运维难度和成本的降低是可以感受到的；再次，大厂倡导的分库分表技术肯定是成熟的，但对小企业来说，这带来的工作量是巨大的，在研发资源有限的情况下，这其中的成本不得不考虑；然后，业务需要及时、弹性，TiDB 的扩展能力让这一点成为可能；最后，TiDB 的 HTAP 融合架构解决了很多，以往的大批量数据计算任务对资源消耗极大且运行速度很慢，TiDB 在跑这类任务时资源隔离的情况下还能做到智能路由，资源隔离可以保证多个业务可放入一个集群，每个业务配置指定的 RU ，保证业务之间不会相互干扰。遇到突发流量，也可以控制爆炸半径，帮助精准判断资源消耗，而且性能非常好，这对业务发展非常重要。</p><p></p><h3>未来计划</h3><p></p><p></p><p>InfoQ：未来的迁移计划是什么？</p><p></p><p>伍春兰：整体规划是今年完成 70%-80%的业务迁移，目前已基本完成前期筹备工作。如果进展再快一些，今年底到明年初预计可以完成 90%的业务迁移，基本涵盖整个互联网所有的核心业务。希望在市场新的机会到来之前，整个底层平台能力准备充分。我相信，未来是有广阔前景的。</p><p></p><p>在技术层面，未来会尝试用 TiProxy&nbsp;替换 Haproxy 或 F5 ，能够保证集群无损升级，提供限流、熔断等高阶功能，未来可以抓取所有SQL，实现流量重放，提高测试效率；功能集成，将 Dashboard、TiUniManager、DM-web，甚至 TiCDC 的管控集中在一个平台，该平台还能提供备份管理、告警调整等辅助功能；巡检功能，很多时候要靠人去分析 Dashboard 和 Grafna 的 Performanceoverview 来判断集群情况。巡检功能可以省去人力开销，依托 AI 给出准确的集群运行报告，并附上相关优化建议。</p><p></p><p></p><h2>关于中欧财富：</h2><p></p><p></p><p>中欧财富成立于 2015 年 8 月 14 日，是中欧基金控股的销售子公司，持有中国证监会核准的基金销售业务牌照。旗下 APP 基本实现业内基金品种全覆盖，并为投资者提供基金交易、大数据选基、智慧定投、理财师咨询等专业便捷的投资工具及服务，致力为投资者及合作伙伴提供一站式互联网财富管理解决方案。中欧基金是中欧财富的股东，中欧财富与股东之间实行业务隔离。</p><p>&nbsp;</p><p>&nbsp;&nbsp;&nbsp;</p>",
    "publish_time": "2023-08-10 08:31:16",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "百度百舸平台的大模型训练最佳实践",
    "url": "https://www.infoq.cn/article/IZztkSiz8DGvvC6yNr9b",
    "summary": "<p>在《大模型时代的 AI 基础设施——百度 AI 大底座》系列云智公开课第八讲中，杨亮老师为我们介绍了百度百舸平台在大模型训练方面的实践。</p>\n<p>百舸异构计算平台是一个面向大模型的基础设施平台，是面向AI原生云时代打造的AI基础设施。杨亮老师在本次演讲中对百舸异构计算平台进行了全面介绍后，对大模型训练稳定性实践和大模型训推加速实践方面进行了详细解析。</p>\n<p>希望本期视频可以让各位了解更多大模型方面的技术干货 。</p>",
    "publish_time": "2023-08-10 13:57:05",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "TypeChat入门指南：从安装到对话流程设计",
    "url": "https://www.infoq.cn/article/247f4085df5daa8c1b1408533",
    "summary": "<p>大家好，我是星辰编程理财，这篇文章可以作为TypeChat的入门指南。</p><p></p><h3>一、介绍</h3><p></p><p>TypeChat是一款基于人工智能技术的对话系统，旨在帮助开发者构建智能机器人，并与用户进行自然语言对话。无论是应用于在线客服、智能助手还是其他领域，TypeChat都能提供强大的对话交互能力，为用户提供优质的用户体验。</p><p></p><h3>二、安装和设置</h3><p></p><p>在开始使用TypeChat之前，我们需要完成以下步骤来安装和设置环境：</p><p></p><h4>2.1 硬件和软件要求</h4><p></p><p>操作系统：Windows、Linux或macOSPython版本：3.6及以上内存：建议至少8GB存储空间：建议至少10GB</p><p></p><h4>2.2 下载和安装TypeChat</h4><p></p><p>可以通过以下步骤来下载和安装TypeChat：</p><p></p><p>在终端或命令行中执行以下命令来安装TypeChat：</p><p></p><p><code lang=\"shell\">pip install typechat\n</code></p><p></p><p>等待安装完成后，TypeChat就已经成功安装在你的环境中了。</p><p></p><h4>2.3 初始化和配置TypeChat环境</h4><p></p><p>在开始使用TypeChat之前，我们需要进行一些初始化和配置操作：</p><p></p><p>创建一个新的Python项目，并进入项目根目录。在项目根目录下创建一个名为typechat_config.json的配置文件，并填写以下内容：</p><p></p><p><code lang=\"json\">{\n  \"token\": \"YOUR_TYPECHAT_TOKEN\"\n}\n</code></p><p></p><p>请将YOUR_TYPECHAT_TOKEN替换为你的TypeChat访问令牌。</p><p></p><h4>2.4 连接到TypeChat的服务器</h4><p></p><p>在项目代码中，我们需要连接到TypeChat的服务器。在入口文件中添加以下代码：</p><p></p><p><code lang=\"python\">from typechat import TypeChat\n\n# 创建TypeChat实例\ntypechat = TypeChat()\n\n# 连接到服务器\ntypechat.connect()\n</code></p><p></p><p>至此，我们已经完成了TypeChat的安装和设置，可以开始创建和训练机器人了。</p><p></p><h3>三、基本概念和术语</h3><p></p><p>在使用TypeChat之前，我们需要了解一些基本概念和术语：</p><p></p><h4>3.1 用户</h4><p></p><p>用户是与机器人进行对话的实体，可以是网站访客、应用用户等。用户通过输入自然语言来表达自己的需求或问题。</p><p></p><h4>3.2 机器人</h4><p></p><p>机器人是由TypeChat创建的智能对话系统，用于与用户进行自然语言对话。机器人可以根据用户的输入和上下文信息，理解用户的意图，并给出相应的回答或建议。</p><p></p><h4>3.3 对话</h4><p></p><p>对话是用户与机器人之间的交互过程，包括用户的输入和机器人的响应。对话可以由多个轮次组成，其中用户和机器人交替发言。</p><p></p><h4>3.4 意图</h4><p></p><p>意图是用户在对话中的目的或意图，用于表达用户想要实现的目标。每个意图通常与特定的操作、查询或问题相关联。</p><p></p><h4>3.5 实体</h4><p></p><p>实体是对话中具有特定意义的内容，可以是日期、时间、地点等。实体有助于更好地理解用户的需求，并进行相应的处理。</p><p></p><h4>3.6 上下文</h4><p></p><p>上下文是对话过程中的环境信息，可以用来理解用户的上下文信息，并提供个性化的对话体验。通过上下文，机器人可以记住之前的对话内容，并根据用户之前的问题或回答做出更准确的响应。</p><p></p><h3>四、创建和训练机器人</h3><p></p><p>在TypeChat中，我们可以通过以下步骤来创建和训练机器人：</p><p></p><h4>4.1 创建机器人</h4><p></p><p>使用TypeChat提供的API，可以轻松地创建一个机器人实例：</p><p></p><p><code lang=\"python\"># 创建机器人\nrobot = typechat.create_robot(name=\"MyRobot\")\n</code></p><p></p><h4>4.2 设计对话流程</h4><p></p><p>在机器人中，我们需要设计对话流程，即定义用户的输入和机器人的响应。TypeChat提供了一种领域特定语言（Domain Specific Language，DSL）来定义对话流程。</p><p></p><p>可以使用@robot.flow装饰器来定义对话流程：</p><p></p><p><code lang=\"python\"># 定义对话流程\n@robot.flow\ndef qa_flow():\n    ask(\"你的名字是什么？\", \"name_question\")\n    response(\"name_question\", \"我叫TypeChat，很高兴认识你！\")\n</code></p><p></p><p>在上述代码中，我们定义了一个简单的问答对话流程。通过ask函数，机器人向用户提问，并将用户的回答存储在名为name_question的变量中。然后，通过response函数，机器人回答用户的问题。</p><p></p><h4>4.3 定义意图和实体</h4><p></p><p>在对话流程中，我们可以定义意图和实体，用于理解用户的意图和提取关键信息。</p><p></p><p>可以使用@robot.intent装饰器来定义意图，使用@robot.entity装饰器来定义实体。以下是一个示例：</p><p></p><p><code lang=\"python\"># 定义意图和实体\n@robot.intent\ndef order_pizza():\n    entity(\"pizza_type\", \"PizzaType\")\n\n@robot.entity\ndef pizza_type():\n    pattern(\"海鲜披萨\")\n    pattern(\"牛肉披萨\")\n    pattern(\"素食披萨\")\n</code></p><p></p><p>在上述代码中，我们定义了一个名为order_pizza的意图，用于处理用户订购披萨的请求。该意图依赖一个名为pizza_type的实体，用于提取用户所需的披萨种类。通过pattern函数，我们定义了一些常见的披萨种类。</p><p></p><h4>4.4 训练机器人模型</h4><p></p><p>完成对机器人的配置后，我们需要训练机器人模型，以便它能够理解用户的意图和提取实体。</p><p></p><p>使用以下代码来训练机器人模型：</p><p></p><p><code lang=\"python\"># 训练机器人模型\ntypechat.train()\n</code></p><p></p><p>训练过程可能需要一些时间，具体时间取决于训练数据的大小和机器的性能。</p><p></p><h4>4.5 评估和改进机器人模型</h4><p></p><p>训练完成后，我们可以使用TypeChat提供的评估工具来评估机器人模型的性能，并根据评估结果进行改进。</p><p></p><p><code lang=\"python\"># 评估机器人模型\nevaluation = typechat.evaluate()\nprint(evaluation)\n</code></p><p></p><p>评估结果包括准确率、召回率和F1分数等指标，用于衡量机器人模型的性能。</p><p></p><h3>五、与机器人对话</h3><p></p><p></p><h4>5.1 运行TypeChat客户端</h4><p></p><p>在与机器人对话之前，我们需要运行TypeChat客户端。使用以下代码来运行TypeChat客户端：</p><p></p><p><code lang=\"python\"># 运行TypeChat客户端\ntypechat.run_client()\n</code></p><p></p><h4>5.2 连接到机器人</h4><p></p><p>运行客户端后，我们可以通过连接到机器人来开始对话。在命令行中输入以下命令：</p><p></p><p><code lang=\"shell\">&gt;&gt; connect MyRobot\n</code></p><p></p><p>其中，MyRobot是我们之前创建的机器人的名称。</p><p></p><h4>5.3 开始对话</h4><p></p><p>连接成功后，我们可以与机器人开始对话了。在命令行中输入你的问题或需求，机器人将会根据对话流程给出相应的回答。</p><p></p><p><code lang=\"shell\">&gt;&gt; 你的名字是什么？\n</code></p><p></p><h4>5.4 处理用户输入</h4><p></p><p>在TypeChat客户端中，可以通过以下代码来处理用户输入并获取机器人的响应：</p><p></p><p><code lang=\"python\">input_text = \"你的名字是什么？\"\nresponse = typechat.process_input(input_text)\nprint(response)\n</code></p><p></p><p>以上代码将用户的输入传递给机器人，获取机器人的回答，并将其打印出来。</p><p></p><h4>5.5 判断意图和提取实体</h4><p></p><p>使用以下代码来判断用户的意图和提取实体：</p><p></p><p><code lang=\"python\">input_text = \"我想订一个海鲜披萨\"\nintent, entities = typechat.predict_intent(input_text)\nprint(intent)\nprint(entities)\n</code></p><p></p><p>以上代码将用户的输入传递给机器人，获取机器人预测的意图和提取的实体，并将它们打印出来。</p><p></p><h4>5.6 发送响应消息</h4><p></p><p>使用以下代码向用户发送机器人的响应消息：</p><p></p><p><code lang=\"python\">response_text = \"我叫TypeChat，很高兴认识你！\"\ntypechat.send_response(response_text)\n</code></p><p></p><p>以上代码将机器人的回答发送给用户。</p><p></p><h3>六、高级功能和技巧</h3><p></p><p>TypeChat提供了一些高级功能和技巧，以帮助开发者构建更智能、灵活的机器人：</p><p></p><h4>6.1 上下文管理</h4><p></p><p>通过管理上下文信息，机器人可以记住之前的对话内容，并根据用户之前的问题或回答做出更准确的响应。</p><p></p><h4>6.2 多轮对话处理</h4><p></p><p>处理多轮对话可以实现复杂的对话逻辑，包括用户的追问、澄清等。通过记录和分析对话历史，机器人可以更好地理解用户的需求。</p><p></p><h4>6.3 自定义动作和回调</h4><p></p><p>可以自定义机器人的动作和回调函数，实现更灵活的对话交互。例如，可以定义一个动作来查询数据库，并根据查询结果给出回答。</p><p></p><h4>6.4 模型调优和迁移学习</h4><p></p><p>通过调优和迁移学习，可以提升机器人模型的性能和适应性。可以使用更多的训练数据，调整模型参数，或者从预训练的模型中迁移学习。</p><p></p><h4>6.5 多语言支持</h4><p></p><p>TypeChat支持多种语言，可以根据需求选择适合的语言设置。可以使用不同的语言模型，或者自定义语言模型来满足特定的语言需求。</p><p></p><h4>6.6 安全和隐私considerations</h4><p></p><p>在使用TypeChat时，需要注意数据安全和隐私保护的问题。机器人收集的用户数据应当受到保护，并遵守相关法律法规和政策。</p><p></p><h3>七、最佳实践和案例研究</h3><p></p><p></p><h4>7.1 设计灵活且易于维护的对话流程</h4><p></p><p>在设计对话流程时，我们应该考虑到对话的灵活性和易于维护性。一个好的对话流程应该能够适应不同的用户需求，并且容易扩展和修改。</p><p></p><p>以下是一些设计对话流程的最佳实践：</p><p></p><p>使用模块化的方式组织对话流程，将不同的功能或场景划分为独立的模块。使用条件语句和循环语句来实现复杂的对话逻辑。尽量避免冗余的对话步骤，使对话流程更加简洁和高效。通过引入上下文来跟踪对话状态，以便在后续的对话中提供个性化的回答。</p><p></p><h4>7.2 使用合适的意图和实体定义</h4><p></p><p>意图和实体是理解用户意图和提取关键信息的重要组成部分。在定义意图和实体时，我们应该根据具体的对话场景和需求，选择合适的方式来定义。</p><p></p><p>以下是一些使用意图和实体的最佳实践：</p><p></p><p>定义清晰和具体的意图，以便更好地理解用户的需求。使用模式匹配、正则表达式或机器学习等方法来定义实体，以提高实体的提取准确性。根据实际需要，定义不同类型的实体，如日期、时间、地点等。</p><p></p><h4>7.3 组织和管理对话数据</h4><p></p><p>对话数据是训练机器人模型的重要资源，合理组织和管理对话数据可以提高模型的质量和效果。</p><p></p><p>以下是一些组织和管理对话数据的最佳实践：</p><p></p><p>收集丰富和多样的对话数据，包括不同的用户意图和实体。根据对话场景和目标，组织对话数据为合适的训练集、验证集和测试集。对对话数据进行清洗和预处理，去除噪声和不相关的信息。定期更新对话数据，以保持机器人模型的准确性和适应性。</p><p></p><h4>7.4 利用上下文提供个性化的对话体验</h4><p></p><p>上下文信息对于提供个性化的对话体验非常重要。通过利用上下文信息，机器人可以记住之前的对话内容，并根据用户之前的问题或回答做出更准确的响应。</p><p></p><p>以下是一些利用上下文提供个性化对话体验的最佳实践：</p><p></p><p>在对话流程中使用上下文变量来存储和检索用户的信息。根据用户之前的问题或回答，调整对话流程以提供更准确和有针对性的回答。当用户提问或回答不完整时，及时请求用户提供更多的信息以补充上下文。</p><p></p><h4>7.5 基于用户反馈持续改进机器人</h4><p></p><p>用户反馈对于改进机器人模型和提升用户体验非常重要。通过倾听用户的反馈，并根据反馈进行改进，可以不断优化机器人的性能。</p><p></p><p>以下是一些基于用户反馈持续改进机器人的最佳实践：</p><p></p><p>通过用户调查、用户测试等方式主动收集用户反馈。分析和总结用户反馈，识别机器人模型的问题和改进点。根据用户反馈，调整机器人的对话流程、意图和实体定义等。</p><p></p><h3>八、常见问题和解决方案</h3><p></p><p></p><h4>8.1 安装和配置问题</h4><p></p><p>在安装和配置TypeChat时，可能会遇到一些常见问题，如安装依赖、配置文件等。以下是一些常见问题和解决方案：</p><p></p><p>问题：安装TypeChat时出现依赖项错误。解决方案：确保已安装Python 3.6及以上版本，并使用正确的命令安装TypeChat。问题：无法找到TypeChat的配置文件。解决方案：请确保在正确的位置创建并命名配置文件，并正确填写相关信息。</p><p></p><h4>8.2 训练和优化问题</h4><p></p><p>在训练和优化机器人模型的过程中，可能会遇到一些问题，如模型训练时间长、模型效果不佳等。以下是一些常见问题和解决方案：</p><p></p><p>问题：模型训练时间过长。解决方案：可以尝试减小训练数据的规模，调整模型参数，或使用更高性能的机器来加快训练速度。问题：模型效果不佳，预测准确率较低。解决方案：可以尝试增加训练数据的多样性，优化模型架构，或使用迁移学习等方法来提升模型性能。</p><p></p><h4>8.3 对话处理问题</h4><p></p><p>在对话过程中，可能会遇到一些处理问题，如意图识别不准确、实体提取错误等。以下是一些常见问题和解决方案：</p><p></p><p>问题：机器人无法准确识别用户的意图。解决方案：可以通过收集更多的训练数据，优化意图定义和实体定义，或使用更复杂的模型来提升意图识别的准确性。问题：机器人无法正确提取用户的实体。解决方案：可以通过增加实体定义的模式、使用更强大的实体提取算法等方法，来提高实体提取的准确性。</p><p></p><h4>8.4 效果评估和改进问题</h4><p></p><p>在评估机器人模型的效果和改进性能时，可能会遇到一些问题，如评估指标不明确、改进方向不清晰等。以下是一些常见问题和解决方案：</p><p></p><p>问题：如何评估机器人模型的性能？解决方案：可以使用准确率、召回率、F1分数等指标来评估机器人模型的性能。还可以使用人工评估或用户调查等方法来获取更全面的评估结果。问题：如何确定模型改进的方向？解决方案：根据评估结果和用户反馈，分析模型的问题和改进点。可以通过调整模型架构、增加训练数据、优化意图和实体定义等方式来改进模型。</p><p></p><h3>九、总结</h3><p></p><p>本篇文章介绍了TypeChat的最佳实践和常见问题的解决方案。通过设计灵活且易于维护的对话流程、使用合适的意图和实体定义、组织和管理对话数据、利用上下文提供个性化的对话体验、基于用户反馈持续改进机器人，我们可以构建更智能、灵活的机器人，并提供优质的用户体验。</p><p></p><p>同时，我们也提供了一些常见问题的解决方案，包括安装和配置问题、训练和优化问题、对话处理问题、效果评估和改进问题。通过解决这些常见问题，我们可以进一步优化机器人的性能和提升用户的满意度。</p><p></p><p>希望本篇文章对您了解和使用TypeChat有所帮助。如果您有任何问题，请参考TypeChat官方文档或寻求相关技术支持。祝您在使用TypeChat的过程中取得好的成果！</p><p></p><p>参考文献：</p><p></p><p><a href=\"https://microsoft.github.io/TypeChat/docs/introduction/\">TypeChat官方文档</a>\"</p><p></p>",
    "publish_time": "2023-08-10 14:09:30",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "资深 Java 架构师曾波，确认担任QCon北京性能优化专题出品人",
    "url": "https://www.infoq.cn/article/dbDIJtJeat1ephRQvcpV",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0810&amp;utm_content=zengbo\">QCon 全球软件开发大会（北京站）</a>\"，资深 Java 架构师曾波将担任「性能优化」的专题出品人。在此次专题中，你将了解到后端、客户端、数据库、JVM 等多角度的性能优化最佳实践。</p><p></p><p><a href=\"https://qcon.infoq.cn/202309/beijing/track/1586?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0810&amp;utm_content=zengbo\">曾波</a>\"，《Java 性能优化实践：JVM 调优策略、工具与技巧》译者，资深 Java 架构师，毕业于四川大学计算机学院，16 年互联网从业经验，曾在微软、什么值得买、京东金融东家财富、博士电信传媒集团、国家电网任职。主持并参与多家公司的技术团队从建立到成熟的过程、主持实施重大技术决策和技术落地，对大规模复杂系统架构和技术管理有较丰富的实践经验。</p><p></p><p>相信曾波的到来，可以帮助提升此专题的质量，让你了解到性能优化是提高应用程序的响应速度、稳定性和整体性能的关键，对于提高用户体验、降低运营成本至关重要，以及涉及后端、客户端、数据库、JVM 等多角度的性能优化最佳实践。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-10 15:03:44",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI 推出网络爬虫 GPTBot，引发网站抵御潮：信息被爬走就很可能意味着永远无法删除",
    "url": "https://www.infoq.cn/article/IzPVkcZg0jeHGcD4xP7H",
    "summary": "<p></p><blockquote>不爬取你的页面数据，哪来几十亿美元的运营收入？</blockquote><p></p><p>&nbsp;</p><p>OpenAI在没有正式宣布的情况下，于本周发布了一项网站爬虫规范。</p><p>&nbsp;</p><p>网络爬虫通常用于扫描网站内容以训练其大型语言模型 (LLM)，OpenAI 在一篇新的博客文章中表示：“使用 GPTBot 用户代理抓取的网页可能会用于改进未来的模型”，特别是 GPT-4 和潜在的 GPT-5。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee18d156bc9e2c886716864ba6e41bae.jpeg\" /></p><p></p><p>&nbsp;</p><p>在此之前，OpenAI 刚提交了“GPT-5”商标申请。三周之后，该公司推出了新的爬虫以及使用规范。OpenAI在博文中表示，内容发布者和网站所有者可以据此拒绝为其提供素材。</p><p>&nbsp;</p><p></p><h2>网站需要加强防御</h2><p></p><p>&nbsp;</p><p>目前还不清楚 OpenAI 的爬虫在网上潜伏了多久，尽管有些人怀疑 OpenAI 可能已经有一个机器人在数月或数年时间里一直在秘密收集每个人的在线数据。现在该公司宣布了一种阻止 GPTBot 的方法，最新发布的技术文档描述了如何通过用户代理令牌和字符串来识别OpenAI的网络爬虫GPTBot。在发送至服务器进行网页请求的HTTP标头中，OpenAI公司的软件会明确使用这些令牌与字符串。</p><p>&nbsp;</p><p>因此，内容发布者可以在自己Web服务器的robots.txt文件中添加新条目，告知爬虫可以做什么、不能做什么。当然，这是假设GPTBot会老老实实遵守机器人排除协议，毕竟也有不少机器人会对规则熟视无睹。例如，以下robts.txt键/值对就会指示GPTBot远离root目录和网站上的其他全部内容。</p><p>&nbsp;</p><p>User-agent: GPTBot</p><p>Disallow: /</p><p>&nbsp;</p><p>&nbsp;</p><p>对此，搜索引擎优化顾问 Prasad Dhumal本周<a href=\"https://twitter.com/prasaddhumal_/status/1688517769158160384?s=20\">在 Twitter 上写道</a>\"：“最后，在吸收了所有受版权保护的内容来构建他们的专有产品之后，OpenAI 为你提供了一种方法来防止你的内容被用来进一步改进他们的产品。”</p><p>&nbsp;</p><p>另外，值得注意的是，一旦被大模型爬虫爬取，也意味着你的数据无法从公共数据集中删除。例如比较有名的公共数据集<a href=\"https://commoncrawl.org/\">Common Crawl</a>\"，常被用于训练OpenAI 的 ChatGPT、谷歌的 Bard 或 Meta 的 LLaMA ，专家表示，如果你的数据或内容被爬取进去，那意味着它永久成为了该训练集的一部分。但CommonCrawl 等服务确实允许类似的 robots.txt ，但网站所有者需要在数据被收集之前实施这些更改。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ef/ef6488efe02c951e1f36f98e55e6038c.jpeg\" /></p><p></p><p>&nbsp;</p><p>然而，OpenAI坚称开放网站数据收集入口，能够帮助该公司提高AI模型的实际质量，而且爬取的内容也不会涉及敏感信息。这话似乎可信，毕竟OpenAI和微软最近已经因此而官司缠身。</p><p>&nbsp;</p><p>这家机器学习超级实验室在文档中指出，“使用GPTBot用户代理爬取的网页，可能会被用于改进未来模型，且付费专区、已知涉及个人身份信息（PII）或包含违反我们政策的文本来源均会被过滤删除。”</p><p>&nbsp;</p><p>文档还提到，“允许GPTBot访问您的网站，可以帮助AI模型更加准确并提高其总体功能性与安全性。”</p><p>&nbsp;</p><p>这人人为我、我为人人的口号一讲，似乎帮OpenAI节约时间和成本，使其模型能力更强、风险更低是件利他又利己的大好事。</p><p>&nbsp;</p><p>可即便OpenAI承诺了自己在利用公共互联网数据训练大语言模型，仍有不少组织在努力限制自家信息通过网络被自动访问。毕竟AI软件厂商最喜欢借助网络上的各种信息为己所为，并借此建立起价值百万甚至数十亿美元的商业体系。所以部分企业已经采取行动，如果盈利一方不愿意拿出点分红，那他们就干脆关闭访问权限。</p><p>&nbsp;</p><p>例如，Reddit最近就修改了API条款，想更好地通过用户免费发布的内容获利。Twitter日前也起诉了四家身份不明的实体，拒绝抓取其网站数据用于AI训练的行为。</p><p>&nbsp;</p><p>一些网站已经在加强对GPTBot的防御，比如外媒<a href=\"https://www.theverge.com/robots.txt\">The Verge</a>\"就已经添加了 robots.txt 标志，以阻止 OpenAI 模型抓取内容以添加到其大模型中。substack博主Casey Newton也向他的读者<a href=\"https://www.platformer.news/p/its-time-to-change-how-we-cover-elon\">询问</a>\"是否应该阻止 OpenAI 收集他的内容。科幻杂志 Clarkesworld 的编辑 Neil Clarke<a href=\"https://twitter.com/clarkesworld/status/1688600561447268370?s=20\">在</a>\" Twitter上宣布将屏蔽 GPTBot。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/cef7e24ce8a70eccb2274ff51415f22a.jpeg\" /></p><p></p><p>&nbsp;</p><p></p><h2>建立合法路径才是正途！</h2><p></p><p>OpenAI没有立即回应，此次为什么要发布关于GPTBot的详细信息。但最近已经有多次针对该公司的诉讼，指控其未经客户许可而擅自使用可公开访问的数据/违反网站规定的许可条款。看来这两件事之间应该存在联系。</p><p>&nbsp;</p><p>除了隐私诉讼之外，OpenAI、微软和微软子公司GitHub去年11月还因涉嫌利用受许可证保护的源代码训练OpenAI的Codex模型，并因在GitHub Copilot代码辅助服务中照搬这些代码而面临起诉。另有多位作家在上个月提起类似诉讼，指控OpenAI在未经许可的情况下利用他们的作品训练ChatGPT。</p><p>&nbsp;</p><p>谷歌、DeepMind及其母公司Alphabet也未能幸免，同样因类似理由沦为被告。</p><p>&nbsp;</p><p>考虑到爬取公共数据并借此训练AI模型所带来的法律不确定性，OpenAI的竞争对手谷歌上个月提议重新设计爬虫协议的运作方式，尽量消弭愈演愈烈的数据归属权纠纷。</p><p>&nbsp;</p><p>专为医疗保健行业提供AI助手的Hyro公司联合创始人兼CEO Israel Krush在采访中表示，目前网络爬虫的运作方式主要存在两个核心问题。</p><p>&nbsp;</p><p>“首先就是默认发布者同意，对方如果不希望自己的网站成为爬取对象、信息被用于模型微调，只能主动选择拒绝。这个过程跟搜索引擎的运作方式存在很大区别，搜索引擎在爬取时只会引导用户访问内容发布网站的内容摘要。”</p><p>&nbsp;</p><p>“而在OpenAI和AI助手这边，内容本体成为产品的直接组成部分，这样问题的性质就完全不同了。发布者必须主动拒绝才能免受爬取也着实引起了巨大的不满。”</p><p>&nbsp;</p><p>Krush表示，将爬取到的内容集成至他人产品中、甚至受到篡改，则可能引发另一个潜在问题。</p><p>“第二个问题是，OpenAI在声明中称将排除「以使用个人身份信息（PII）闻名的相关网站」，这样的表述有点令人费解。”</p><p>&nbsp;</p><p>“以新闻出版商为例：他们的内容中肯定会存在某些身份识别信息。另外，即使那些似乎跟个人身份信息关系不大的网站，也或多或少涉及相关内容。而任何包含个人身份信息的内容都需要经过适当编辑。”</p><p>&nbsp;</p><p>Krush认为，模型的合规性问题和负责任立场需要匹配更强有力的保障措施，并强调他自己的公司就只会在获得明确许可时才爬取数据，且保证一切个人信息都得到妥善处理。</p><p>&nbsp;</p><p>他总结道，“OpenAI不该只关注那些被标记为包含个人身份信息的网站，而应当假设所有网站都可能涉及个人隐私，特别是各内容发布平台。他们应当采取积极主动的措施，确保爬取的信息不违反合规性要求。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://platform.openai.com/docs/gptbot\">https://platform.openai.com/docs/gptbot</a>\"</p><p><a href=\"https://twitter.com/prasaddhumal_/status/1688517769158160384?s=20\">https://twitter.com/prasaddhumal_/status/1688517769158160384?s=20</a>\"</p><p><a href=\"https://twitter.com/stealcase/status/1688604248974475264\">https://twitter.com/stealcase/status/1688604248974475264</a>\"</p><p><a href=\"https://www.theregister.com/2023/08/08/openai_scraping_software/?td=rt-9cp\">https://www.theregister.com/2023/08/08/openai_scraping_software/?td=rt-9cp</a>\"</p><p><a href=\"https://venturebeat.com/ai/capital-one-emphasizes-the-power-of-human-centered-design-at-vb-transform-2023/\">https://venturebeat.com/ai/capital-one-emphasizes-the-power-of-human-centered-design-at-vb-transform-2023/</a>\"</p>",
    "publish_time": "2023-08-10 15:35:47",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "生成的代码会出错、质量差？面对AI编程工具的老大难问题，华为这群人打算这样做",
    "url": "https://www.infoq.cn/article/ubciEs8NPH06CwlpEvtf",
    "summary": "<p>作者 ｜ 王亚伟、Pavel Petrochenko、Olga Lukianova</p><p>&nbsp;</p><p>2023年3月，GitHub推出了升级产品Copilot X，这是Copilot代码补全工具的新版本，并宣布正式接入GPT-4。同时，他们还推出了一系列诸如聊天、文档检索、代码合并等王炸特性。其中，以代码为中心的聊天式开发模式可以实现对选中的代码片段进行解释、单元测试和Bug修复等新颖功能。这种颠覆式的智能化开发体验确实让我们研发开发者工具同行们感到深深的困扰。</p><p>&nbsp;</p><p>以我最近与世界顶尖IDE公司JetBrains的技术专家K交流为例，他跟我分享了一个困扰他很久的问题：随着大语言模型变得越来越强大，一款支持多编程语言的IDE，是否还需要对每种编程语言实现对应的代码模型以及适配不同构建系统呢？</p><p>&nbsp;</p><p>这个问题的背景是他的团队正在打造一款多语言IDE内核来支持JetBrains的下一代IDE产品Fleet，而Fleet的定位是轻量级、智能化、分布式。然而，如果一款IDE内核同时支持多种编程语言和构建系统，那么它就很难做到轻量。于是，他提出一种可能的替代方案：用户本地只运行编辑器，用户代码作为纯文本输入到云端的大语言模型，由大语言模型完成各种补全、构建等操作。</p><p>&nbsp;</p><p>如果这个方案能够实现，那么就意味着已经存在了30年的架构将被彻底颠覆，各大IDE厂家的业务版图会被AI抢走，大家可能一下子都会陷入迷茫，不知道还有什么有意义的工作可做，这能不让人焦虑么？</p><p>&nbsp;</p><p>这位专家的问题听上去似乎很难回答，我们先不着急讨论。先科普下如果需要适配多语言、多构建系统，那么Fleet的内核要做什么事情？首先它需要对每种编程语言构造对应的代码模型 。代码模型的作用简单来说就是帮助Fleet理解所开发程序的所有编译和统计信息，包括项目依赖组件、源代码、编程语言的语法和语义。传统IDE的代码补全、语义高亮、浏览导航等特性都离不开它。</p><p>&nbsp;</p><p></p><h2>IDE智能化历史</h2><p></p><p>&nbsp;</p><p>1996年，第一代基于代码模型的代码补全技术发布于Visual Basic 5.0。可以说这是智能感知技术的前身，也是IDE智能化技术的鼻祖。2001年，首次发布的统一Visual Studio .NET集成开发环境把智能感知技术带到了一个新高度，支持的语言也进一步扩充。随后，Visual Studio的每一次版本迭代都展现了智能感知技术的进步。</p><p>&nbsp;</p><p>智能感知包含一系列的功能，包括代码补全/提示，快捷信息（QuickInfo），参数信息（Parameter Info），错误检测等。其中，代码补全和提示可以根据输入的关键字、类型、函数、变量名称等编译器可识别程序元素，主动补全剩余单词字符。智能感知的补全内容主要来自于代码模型，结果以单词或单符号为主。虽然只能补全单个符号，但这并不代表智能感知是落后的技术，相反，即使是放在大模型满天飞的今天，智能感知还是整个开发者内环体验的根基，是整个开发者工具领域最有技术含量的特性之一。</p><p>&nbsp;</p><p>说它有技术含量是因为它要解决的问题复杂且用户敏感。举例来说，智能感知系统通常在用户编码过程中被调用提供实时辅助，而此时的代码可能根本不在一个可编译的状态，传统编译器前端只能对完整代码进行解析，所以如何对不可编译代码进行语法语义分析是智能感知系统首先要解决的问题。第二点就是性能和稳定性，理想情况下智能感知要在50ms之内给出结果，并且稳定运行。第三点是结果的准确性。不管是参数帮助、快速信息还是错误提示，结果必须保持准确。</p><p>&nbsp;</p><p>时间来到了2018年，随着人工智能技术层面的应用持续发展，产业界意识到机器学习可以用来提升IDE智能化体验，IntelliCode、Codota、Kite和华为云的SmartAssist等一众基于预测机器学习模型（Predictive ML Model）的技术层出不穷。这类技术提供的代码智能补全的能力与传统智能感知类似，即开发者在编辑代码时，机器学习模型根据当前代码编辑的上下文特征生成API推荐列表并对其进行排序，供开发者选择。</p><p>&nbsp;</p><p>这类技术能对单符号至整行代码进行补全，补全效果（数量、质量）比智能感知有大幅提升。</p><p>&nbsp;</p><p>在2021年10月GitHub Copilot出现之前，事实上大语言模型（Large Language Model，LLM）已经展示出来其在自然语言和代码片段生成方面的强大能力。2022年底发布的ChatGPT是一个集大成者。作为一个烧掉了数百亿美元、背靠1,750亿参数大语言模型的产品，ChatGPT极致的<a href=\"https://cloud.tencent.com/product/nlp?from_column=20421&amp;from=20421\">自然语言处理</a>\"能力和高质量生成结果，使得人工智能的发展终于实现了阶跃式的突破。</p><p>&nbsp;</p><p>这一切的背后都是一种称为Transformer的深度学习模型。与循环神经网络（RNN）类似，Transformer模型可以处理自然语言等顺序输入数据，但与RNN不同的是，Transformer模型的架构允许它并行处理所有输入数据。自2017年谷歌大脑团队推出Transformer模型以来，它已经成为了自然语言处理的首选模型。</p><p>&nbsp;</p><p>有了Transformer模型之后我们离开发一个类似Copilot的产品还有多远呢？</p><p>&nbsp;</p><p>首先，我们需要大量高质量的源代码数据和GPU资源来训练模型，训练是为了让模型学习源代码数据中的程序固有的标准模式和结构。在训练过程中，模型摄取输入序列(例如表示部分代码片段的标记)，并根据上下文预测下一个最可能的标记。其次，训练过程需要对生成的代码准确率不断优化，通常使用无监督学习和最大似然估计等技术进行模型微调。随着时间的推移，生成的代码还需要不断通过用户反馈进行改进。当用户选择或修改代码建议时，这些改变就可以用于更新模型的参数。最后，需要开发云服务来部署模型并提供服务。虽然Copilot可以独立工作，但通常被集成到开发者的内环作业流，成为智能代码补全的搭档。</p><p>&nbsp;</p><p>从上述训练过程可以知道，基于LLM生成的代码来源于已有代码中固有的标准模式和结构数据，因此不可避免会遇到一些问题。事实上，业界对于Copilot这类工具普遍存在如下担忧：</p><p>1）错误或恶意代码：当面对新颖或不可预测的情况时，LLM倾向于猜测并给出错误的推荐，这些错误显著减慢开发速度，因为开发者需要花时间验证建议并删除任何不正确的部分。更糟的情况是导致未被发现的问题、不安全或恶意代码。</p><p>2）非最优代码：LLM生成的一些代码可以工作，但在性能或效率方面不是最优的。根据我们的实战，这类问题非常常见。LLM通常缺乏对算法或优化技术的深刻理解，它可能会生成计算成本高或效率低的代码，并且生成的代码可能并不总是遵循最佳编码实践或行业标准。</p><p>3）伦理考虑：使用LLM进行代码生成会引起伦理方面的关注，例如潜在的剽窃或侵犯知识产权。如何确保生成的代码不违反任何法律或道德界限成为一个至关重要的课题。</p><p>&nbsp;</p><p>下图是用<a href=\"https://codeium.com/playground\">Codeium</a>\"生成的一段代码，作用是连接字符串数组并以大写形式返回结果。这段代码初看起来语法功能都没问题，但却是一段不折不扣的低效代码 ：循环中使用‘+’连接字符串的效率十倍低于StringBuilder。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3e/3ef05bc123c8795180f0cae2792fb1f7.png\" /></p><p></p><p>&nbsp;</p><p>遗憾的是，上述3大痛点问题暂时没有特别有效的解决方案。</p><p>&nbsp;</p><p>所以回到开篇那位专家K的问题，答案显而易见：用LLM重构IDE架构，把所有开发者内环作业流的核心工作都交给LLM是不现实的。至少在可预见的未来，AI编程工具只能作为常规开发作业的辅助工具，成为开发者的编程副驾驶员，而代码模型、构建、调试系统对于一款IDE产品仍然是必须且至关重要的。</p><p>&nbsp;</p><p></p><h2>智能感知2.0</h2><p></p><p>那么，如果LLM短时间无法解决上述问题，特别是1）和2）两个影响开发效率的问题，有没有技术能与LLM一起工作来减轻上述问题产生的负面效果？作为一支为华为生态系统打造一流工具和服务的团队（<a href=\"https://www.huaweicloud.com/devcloud/\">CodeArts</a>\"），我们有一些探索和技术可以与大家分享：我们的思路是通过静态代码分析、人工神经网络和代码模型等手段来增强IDE中智能感知的能力，实现开发态的全方面的智能化融入，我们称之为智能感知2.0。智能感知2.0不仅仅提供代码生成的辅助，在一些问题场景中，当我们的工具感知到开发者需要帮助时，还可以提供诸如调试断点、热替换、搜索、浏览、检查提示等辅助。</p><p>&nbsp;</p><p>下面以代码生成为例介绍智能感知2.0是怎么工作的。比如我希望写一个函数，它返回一个空列表。于是给LLM一个输入：生成一个不接受参数并返回空列表的方法。LLM输出如下一段代码。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0b/0b67bd12b7a747137c65110b64ebf2cf.png\" /></p><p></p><p>&nbsp;</p><p>其中在第9行，Collections.emptyList()或new ArrayList&lt;&gt;()都是对的，但如果碰巧我需要的是一个Immutable列表，Collections.emptyList()就是最优推荐。此时LLM已经无能为力，但智能感知2.0可以对这个推荐进行替换。它虽然并不知道我需要的是Immutable列表，但当光标移动到第9行时，它能动态感知并理解上下文的语义——返回一个空列表，从而给我若干可能正确的推荐，Top1的推荐就是Collections.emptyList() （因为new ArrayList&lt;&gt;()已经被过滤）。</p><p>&nbsp;</p><p>智能感知2.0的代码生成技术跟前辈的主要区别是它更多关注结构化的原子建议(proposal)而非单个的符号(token)。在这个例子中，Collections.emptyList() 和new ArrayList&lt;&gt;() 就是两个独立的原子建议。如果基于单个符号进行推理，则完成上述代码片段需要由代码模型生成5-6个符号，并且在预测Collections符号的阶段，就需要知道之后预测的emptyList()，并生成语法上有效的代码。这除了会显著增加推理模型的特征数目之外，还要求我们时刻跟符号组合中的错误语法问题作斗争。此外，智能感知2.0使用了一些非常简单的模型来过滤掉不相关的原子建议，确保用户看到的是最可能的推荐和最短的建议列表。</p><p>&nbsp;</p><p></p><h2>推荐引擎</h2><p></p><p>&nbsp;</p><p>智能感知2.0的代码生成采用了我们全新设计的推荐引擎。该推荐引擎设计采用了顺序推荐系统（Sequential Recommender System，SRS）的思想：假如一个购物网站基于顺序推荐系统给用户提供购买建议，当用户购买了肥皂、洗发剂之后，它接下来可能会给用户推荐牙膏、毛巾等物品。它将（用户，物品）的交互序列作为输入，通过建模来描述嵌入在（用户，物品）交互序列中的复杂顺序依赖关系，来预测将来可能发生的交互中的（用户，物品）组合。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/24/24e91e841d89509f2caec1d3421a1ad8.jpeg\" /></p><p></p><p>消费品顺序推荐系统</p><p>&nbsp;</p><p>这个思想应用到代码生成中就是，通过已有代码中的原子建议的序列（已购买物品），比如“Socket”，“new PrintWriter()”，推测接下来的原子建议（未来可能购买的物品）。如下这个例子中，光标位置在“B”，光标之前是用户输入或LLM生成的代码，光标之后灰色代码是推荐引擎生成的补全或替换代码。至于是补全未知代码还是替换已有代码要取决于用户的场景：开发新代码还是修改/更正已有代码。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/519dfc55cb7360a74a2f67da1bbb17fd.png\" /></p><p></p><p>&nbsp;</p><p></p><h3>推荐引擎的架构</h3><p></p><p>&nbsp;</p><p>类似循环神经网络，它的设计初衷就是要求小而快，不能占用太多资源 - 因为它只能运行在用户本地环境。根据我们实测，它可以做到比某些LLM快100倍以上。该架构主要模块有：图卷积模块（Graph Convolution）和记忆单元模块（Memory Cell）。图卷积模块的一个作用是对代码上下文的抽象语义图（Abstract Semantic Graph，ASG）数据进行特征抽取处理，这里代码上下文即上图中白色代码部分，属于已经存在的代码。为什么要用抽象语义图而不是直接使用抽象语法书作为输入？因为抽象语义图包含更丰富的控制流图和程序依赖图的信息（包含共享子项），对结果准确性帮助很大。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ff/ff36496cecdb779bfb2d33e4644dea59.png\" /></p><p></p><p>智能感知2.0推荐引擎架构</p><p>&nbsp;</p><p>推荐引擎的工作流水线运行时就类似一个顺序推荐系统，抽象语义图的快照（snapshot）在每个时间步会被预测的建议而修改，图卷积模块、记忆单元模块分别对其空间结构和生长过程的动态时间状态进行评估。以抽象语义图作为主要数据结构贯穿整个推荐引擎工作流是整个架构的重大设计之一，也是“重原子建议轻符号”思想的主要技术承载。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/93/93ff656fded1e9ee0d71621f568f09b5.png\" /></p><p></p><p>抽象语义图（ASG）</p><p>&nbsp;</p><p>原子推荐来源于统计代码分析知识库，这是一个在项目初始化阶段由代码模型构建的数据库。生成器基于知识库生成符合语法和语义规则的原子建议，这些原子建议基于抽象语义图中时间上下文信息组合成最终结果，并融合进新的抽象语义图的快照中。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea3ab20ae472c144df3664ce9e22ad0c.png\" /></p><p></p><p>原子建议生成器</p><p></p><h2>“No Silver Bullet”</h2><p></p><p>&nbsp;</p><p>LLM问世之后，特别是GitHub Copilot、Copilot X这样的现象级产品出现以后，不单给我们带来了困扰，更把焦虑甚至恐惧带给了所有软件开发者。“我会被AI取代么？”这样的问题相信在很多人的脑海中浮现过，计算机程序员似乎正在成为被AI取代的高危职业之一。另外，又有报告认为，到2030年AI编程工具有望将软件开发者的生产力将提高10倍。然而，上述这些观点，基本都属于定性判断——基于个人的主观想象、见闻而非具体数据。</p><p>&nbsp;</p><p>那么，AI编程工具到底能否成为软件开发的“银弹“？我认为Frederick P.&nbsp;<a href=\"https://www.baike.com/wiki/%E6%B2%A1%E6%9C%89%E9%93%B6%E5%BC%B9\">Brooks的“没有银弹”的观点现在还是正确的，即使是高度智能化的开发工具也不是软件开发的“银弹”，因为</a>\"软件开发的困难不仅仅在于如何开发程序（How &amp; When），更在于理解要做什么以及其价值（What &amp; Why）。即使是开发程序本身（How &amp; When），如何运行好一个软件开发团队，让整个团队变得更高效，其中的分工、组织、协调等问题比编写代码本身更关键。</p><p>&nbsp;</p><p>智能化的工具可以全面提升个人的开发速率，这点是毋庸置疑的。工具的智能化体验也应该是全方位和立体的，各种技术能全面融入到代码开发的各个环节。我们团队致力于做一款优秀的智能化IDE，能让代码在指尖欢快的流淌，能让每个开发者心中的一团锦绣呼之欲出。.</p><p>&nbsp;&nbsp;</p><p>作者简介：王亚伟，华为云开发工具和效率领域首席专家，华为软件开发生产线CodeArts首席技术总监，当前领导一支国际化软件专家团队负责华为云CodeArts IDE系列产品的研发和华为云开发者生态能力建设。加入华为前，曾任微软开发者事业部资深开发经理，在微软全球多个国家地区工作 13 年。近20年的云和开发工具的行业经验让他具备从底层技术、产品规划到开发者生态建设洞察的能力。王亚伟先生发表和被授予 20 多项软件开发技术相关的发明专利。</p><p>&nbsp;</p><p>Pavel Petrochenko，华为俄罗斯<a href=\"https://hr.huawei.com/orgarchive/index.html#/?orgcode=072284\">新西伯利亚软件开发工具云技术实验室</a>\"主任，首席架构师，</p><p>20 年开发者工具构建经验，曾是一家&nbsp;IDE 和语言工具初创公司的创始人兼首席技术官。Eclipse DLTK Committer，Eclipse Nebula Committer，Apache Harmony&nbsp;Contributor。</p><p>&nbsp;</p><p>Olga Lukianova，华为俄罗斯<a href=\"https://hr.huawei.com/orgarchive/index.html#/?orgcode=072284\">圣彼得堡软件开发工具云技术实验室</a>\"主任，首席架构师，2006年入职JetBrains圣彼得堡，历任软件工程师，首席软件工程师、Resharper项目负责人，精通Compilers，Parsers，Code Analysis等技术。</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/d4613NRodWJEAXqRblEu\">被逼出来的自主可控，从华为自研看国产 IDE 的未来和商业模式</a>\"</p>",
    "publish_time": "2023-08-10 15:44:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "springboot+activiti+vue+mysql轻松搞定审批！（源码）",
    "url": "https://www.infoq.cn/article/04a5ce9315606779a577dbe56",
    "summary": "<p>目前市场上有很多开源平台没有整合工作流，即使有，也是价格不菲的商业版，来看这篇文章的估计也了解了行情，肯定不便宜。我这个快速开发平台在系统基础功能（用户管理，部门管理…）上整合了工作流，你可以直接用来开发ERP，OA，CRM等企业级应用，不用再担心如何再去花大量的时间集成工作流进来。目前是单独把这一套给抽取出来了，做成了可插拔的，可以非常方便的整合到你的程序中。下面我们来一起看看吧。</p><p>一、项目技术栈</p><p>springboot+vue+activiti集成了activiti在线编辑器，快速开发平台，可插拔工作流服务。</p><p>二、项目介绍</p><p>本项目拥有用户管理，部门管理，代码生成，系统监管，报表，大屏展示，业务审批等功能。功能太强大，只能粗矿的介绍，所见即所得，体验一下吧。</p><p>三、工作流</p><p>1.流程模型绘制</p><p>进入流程模型菜单，创建流程模型，这里涉及到网关流转，需要设置流转条件，我们这里是三十岁以上的走下面分支，三十岁以下的走上面的分支。点击分支线，设置流转条件即可。${age&lt;=30}。保存后我们在列表中点击发布即可。</p><p><img src=\"https://static001.geekbang.org/infoq/5c/5cb6d1c01c21079b99b39ab57469a419.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ce/cec88384cb85dca70c9a7c860f789a3d.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c3133385f03f6bfcf0451cad5079068.png\" /></p><p>2.流程配置</p><p>发布后，就到了已发布模型列表，在启用之前，我们需要先对进行节点设置和关联具体单据。</p><p><img src=\"https://static001.geekbang.org/infoq/34/3408ed5c845147eef8b11de8b846b659.png\" /></p><p>审批人员可以根据角色，直接指定人，部门，部门负责人，发起人部门负责人来进行配置，基本上满足所有的流转需求，并且可以设置表单变量。</p><p><img src=\"https://static001.geekbang.org/infoq/28/28019e354a47e5b48a53bad956d7afa1.png\" /></p><p>设置流程表单，目前就做了一个请假的测试表单，并且可以对相应角色授权，做到自定义权限。</p><p><img src=\"https://static001.geekbang.org/infoq/b1/b1e95f85dfa96108cdf79a29f83456c7.png\" /></p><p>设置完后启动即可。</p><p>3.流程提交</p><p>填写请假表单</p><p><img src=\"https://static001.geekbang.org/infoq/b8/b833c1e5206a577d1ffeaec1ba16e79b.png\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/922fdb9190efe6cb99b4d57856bfc948.png\" /></p><p>提交单据，优先级分为普通，重要，紧急。消息通知可以选择站内通知，短信，邮件。</p><p><img src=\"https://static001.geekbang.org/infoq/a2/a23ffe0091869b5fa33d53a9b893e671.png\" /></p><p>提交之后可以撤回单据。</p><p><img src=\"https://static001.geekbang.org/infoq/ec/eca6fb3613463bedd784d67feb533e1b.png\" /></p><p>查看流程流转进度情况。</p><p><img src=\"https://static001.geekbang.org/infoq/be/be4173aec5a0a7a41f3ee084305b8c32.png\" /></p><p>也可以挂起，删除流程。</p><p><img src=\"https://static001.geekbang.org/infoq/29/2965e2d2609c69234a0c1a9c9a3fb237.png\" /></p><p>4.流程审批</p><p>办理人审批列表，可以处理单据（驳回或者通过），也可以委托他人待办。</p><p><img src=\"https://static001.geekbang.org/infoq/f0/f020ddabebc56b51541b957c2b75ad65.png\" /></p><p>审批通过。</p><p><img src=\"https://static001.geekbang.org/infoq/a6/a6c88b7977923e4cf62a821a8dc35dd9.png\" /></p><p>委托他人待代。</p><p><img src=\"https://static001.geekbang.org/infoq/8c/8c644c872dd128b4706149856710f57c.png\" /></p><p>审批通过后进入已办列表。</p><p><img src=\"https://static001.geekbang.org/infoq/1e/1ebbbb6a77f88a254855f44dbd33b48c.png\" /></p><p>年龄大于30岁，进入下面分支流转。</p><p><img src=\"https://static001.geekbang.org/infoq/66/663cda9bd3cde46d47c7d6ecbe21982f.png\" /></p><p>审批通过。</p><p><img src=\"https://static001.geekbang.org/infoq/72/72eeca73176f3499794e6b2cf4947004.png\" /></p><p>5.待办信息推送</p><p>站内消息推送。</p><p><img src=\"https://static001.geekbang.org/infoq/02/023049a6b30e3f7b7fe001371d05896c.png\" /></p><p>总结</p><p>上面只是展示了平台的审批流功能，还有其他很多功能没展示出来，自己也写了一些非常好用的组件，做到系统敏捷快速开发，大大减少开发时间和成本，目前正在对接移动端审批。之前由于没有时间去部署线上测试环境，考虑近期部署，目前可以单独找我，远程演示，有需要源码的联系我，私信。</p><p>鸣谢：</p><p>咖啡兔activiti实战https://kafeitu.me/</p>",
    "publish_time": "2023-08-10 10:06:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "零代码应用实例",
    "url": "https://www.infoq.cn/article/IljpS4ch9SelIOQs5y2b",
    "summary": "<p>明道云迄今已经发布过《各行业零代码应用案例集锦》，也发表了我们服务各行业标杆客户的客户故事。不少客户表示：案例看过无数，但还是缺少了一些真实上手的感觉，有限的文字难以充分表达客户的使用效果和案例中的精妙设计。</p><p></p><p>为此，明道云正式推出《零代码应用实例》（No Code, True Case）系列内容。它将收录明道云团队为真实客户做过的 POC 应用或脱敏后的交付项目，你可以免费下载安装这些应用，亲自上手体验。</p><p></p><p>作为首卷《零代码应用实例》，我们优先把绝大部分企业都需要的人事、财务费控、销售管理应用实例收录其中。此外还有建材行业的复杂报价系统、软件行业的项目管理，以及内外协同的工单中心，展示明道云在不同行业的需求满足度和使用灵活性。后续，我们将继续增添更多具备行业代表性和参考价值的应用实例。</p><p></p><p>事不宜迟，点击下载，即可领取《零代码应用实例》。</p><p></p><h3>目录：</h3><p></p><p>导语全人事管理销售漏斗管理复杂报价系统软件项目管理内外协同的工单中心RPIC：一个简明的信息架构方法关于明道云</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6be649677a7a2a0f4820310058a76441.png\" /></p><p>扫/码/下/载</p>",
    "publish_time": "2023-08-10 17:30:38",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "AIGC风口下，一窥智能技术在金融行业的应用与实践｜直播报名预约",
    "url": "https://www.infoq.cn/article/i1tjSZxTysysWJHs4F1v",
    "summary": "<p>一直以来，金融行业都是前沿技术应用的先行者。从信息化、数字化到智能化，技术的迭代与革新在金融丰富的业务场景中创造着巨大价值。</p><p></p><p>经过多年的探索与实践，以AI为代表的智能化技术已经渗透于<a href=\"https://www.infoq.cn/article/tXdg1xI1YWGYG6iGg4rj\">金融</a>\"产品设计、市场营销、风险控制、客户服务和其他业务运营场景中。并且，随着应用深度和广度的不断拓展，越来越多的金融机构展开了智能金融的规模化应用，从单一场景向多场景延展，从单领域创新向生态连接演变。</p><p></p><p>面对<a href=\"https://www.infoq.cn/article/4LKYBOU859NxLSk2klif\">AIGC</a>\"这波热浪，金融行业显然也不会置身事外。但作为一个在安全合规层面有着严苛要求的行业，相关技术在商业落地中每一个细微的问题都值得反复推敲和推演——比如“AI幻觉”的问题如何解决，如何让AI分析过程更具有可解释性等等。</p><p></p><p>基于这一背景，在8月23日由InfoQ与TGO鲲鹏会联合出品的《<a href=\"https://www.infoq.cn/theme/192\">超级连麦.数智大脑</a>\"》中，我们将邀请金融行业资深专家，围绕智能技术如何与金融场景结合，背后涉及什么样的技术升级以及AIGC等智能化技术落地过程有何挑战又如何顺利推进等话题，分享其在各自领域内的洞见和实践，为金融业的智能化创新实践找到更优的解题思路。</p><p></p><p><a href=\"https://live.infoq.cn/room/1848\">点击链接</a>\"率先报名预约（留下你关心的问题，讲师将在直播中解答）：<a href=\"https://live.infoq.cn/room/1848\">https://live.infoq.cn/room/1848</a>\"</p><p></p><h3>直播时间</h3><p></p><p>8&nbsp;月&nbsp;23&nbsp;日（周三）19:30-22:00</p><p></p><h3>联合出品</h3><p></p><p>InfoQ x TGO 鲲鹏会 x 极客时间企业版</p><p></p><h3>直播主题</h3><p></p><p>智能技术在金融行业的应用与实践</p><p></p><h3>直播亮点</h3><p></p><p>分享银行/证券/保险等金融机构智能化实践进程探讨智能技术如何与金融场景充分结合剖析金融智能化背后的技术升级挑战探寻智能技术在金融场景落地的路径和方法脑暴AIGC技术如何影响和助力金融智能化创新</p><p></p><h3>直播议程（拟）</h3><p></p><p>19:30-20:00 &nbsp;议题分享 -银行智能化运营实践20:00-20:30 议题分享 -华盛证券智能风控探索与实践（黄曙光 华盛证券技术VP）20:30-21:00  议题分享 - 保险智能化运营探索及背后的技术架构升级实践（周建华 太保寿险首席架构师）21:00-21:40 连麦对话 - AIGC技术如何影响和助力金融智能化创新</p>",
    "publish_time": "2023-08-10 11:59:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]