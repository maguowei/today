[
  {
    "title": "从公有云方案转向谷歌开源Knative，网易云音乐的Severless演进实践",
    "url": "https://www.infoq.cn/article/MA6MqQUHalKLxYSAN9do",
    "summary": "<p></p><p>云主机时代，资源焦虑几乎普遍存在。突增的巨大任务量、短时间突然调集使用大量的计算资源等类型的业务需求越来越多，企业不愿为了应对短暂的流量高峰买本地资源，对服务和扩缩容进行解耦，并接管过自动扩缩容任务的 Serverless 进入大众视野。</p><p>&nbsp;</p><p>Serverless 自带“降本增效”基因，特点之一就是可以缩容到零之后再按资源使用情况收费，这自然吸引了大量企业使用，<a href=\"https://www.infoq.cn/article/mBgvbc3bQWAbavwmBhXR\">网易云音乐</a>\"便是其中之一。</p><p>&nbsp;</p><p>最早，网易云音乐主要使用云厂商的 FaaS 产品。随着 Serverless 社区的发展，2020年，网易云音乐开始关注到 Google 开源的 Knative 项目，到了2021年5月，团队决定优先利用内部的私有云资源，在满足业务的异步处理事件以及弹性扩缩容需求的前提下，通过在线和离线服务的混合部署，提升系统资源利用率，同时完成降本增效目的。</p><p>&nbsp;</p><p>于是，在做了简单的POC测试并与业务沟通后，网易云音乐便协同网易数帆云原生团队面向音视频处理，打造了基于<a href=\"https://www.infoq.cn/article/rDL06CdUNEPXtPLzT-3O\">Knative</a>\" 的 Serverless 解决方案。</p><p></p><h2>如何做技术选型</h2><p></p><p>&nbsp;</p><p>网易云音乐每天都有数十万的歌曲入库，曲库团队则需要对这部分歌曲做准实时的加工处理、理解分析（包括歌曲转码、副歌识别、特征分析等），相关处理结果用于歌曲播放、VIP 歌曲试听等业务场景。这类业务的特点就是弹性特别大，任务时多时少，多的时候甚至要对大量存量歌曲数据进行重新计算。这就对资源交付方式提出了新的要求。</p><p>&nbsp;</p><p>按照网易云音乐在云主机时代的使用经验，传统的资源交付方式主要存在以下几个问题：</p><p>&nbsp;</p><p>•&nbsp;弹性效率低下：大型活动业务扩容时，各个角色如应用运维、机房等深度耦合，进行一次大型活动需要非常长的准备时间。</p><p>•&nbsp;计算焦虑：由于规模问题，机房计算资源没办法实现在活动期间的快速资源弹性需求，因此常常需要准备很多闲置资源。</p><p>•&nbsp;运维繁琐：扩容变更时，很多是以工单、人工化为主的低效过程，无论效率还是质量都不尽如人意。</p><p>•&nbsp;成本问题：总体CPU等资源利用率不高，小于20%，缺乏自动化的管理和调度能力，资源无法得到充分利用。</p><p>•&nbsp;稳定性：应用发生故障后，无法自动重新拉起或重新调度，核心业务的服务质量很难得到保障。</p><p>&nbsp;</p><p>虽然基于 Kubernetes 以及生态里的很多创新云原生解决方案，上述棘手问题得到了一定程度的解决，但 Serverless 的解决方案相对来说更加高效易用。<a href=\"https://www.infoq.cn/article/vHCG1pJpsLapBBMvbvZM\">Serverless</a>\" 向业务提供了语言无关、框架无关的研发模式，通过自动化Metric、自动扩缩容等手段让业务聚焦业务逻辑，无需关注周边与资源扩缩、没有服务器管理，降低了程序生命周期中的大量运维成本。</p><p>&nbsp;</p><p>当前，Serverless 大概有三个技术方向：Serverless 容器服务、Serverless 应用托管和函数计算（FaaS）。</p><p>&nbsp;</p><p>使用 Serverless 容器服务的用户不需要维护&nbsp;Kubernetes 集群的计算节点，系统根据服务使用的pod数量进行计费，但Serverless容器服务并不能提供完备的周边配套设施；Serverless 应用托管则会包含应用生命周期的管理、CI/CD、发布策略，蓝绿或者灰度发布功能等，用户只需将服务部署后就能坐享应用托管所提供的基础能力；函数计算的抽象程度更高。对于&nbsp;Python 等解释类语言，开发者使用&nbsp;FasS 将代码片段上传后，函数计算的底层便可快速将服务对外部署，从而实现对外服务。</p><p>&nbsp;</p><p>在云原生团队看来，Serverless应用托管或&nbsp;FaaS 平台相对来说是更好的选择，因为业务不只需要弹性伸缩功能，还要解决&nbsp;CI/CD、发布策略、消息引擎等问题，做更好的开发封装。只有涵盖了这些周边配套服务，才能将开发的心智负担降至最低。方向确认后，具体怎么做呢？</p><p>&nbsp;</p><p>容器镜像需要基于编程语言的定制化编译和构建，从而生成二进制的文件，最后再经过&nbsp;Dockerfile 将其构建成容器。但是，曲库团队内部有多种语言所开发的算法，很难用通用的流水线进行容器镜像构建。因此，曲库团队内部只要求底层&nbsp;Serverless 平台或&nbsp;FaaS 平台能够接受&nbsp;Dockerfile 即可，具体&nbsp;Dockerfile 怎么写则由其内部自行消化。</p><p>&nbsp;</p><p>因此，云原生团队的任务就是将曲库团队上传的Dockerfile进行镜像构造。云原生团队为此进行了一次全面调研，内容包括消息引擎对上下游解耦及弹性扩容的需求、相关开源软件（Knative、OpenFaas、Fission、Nuclio等）与需求的匹配度对比，最后确定基于Knative Serving 做动态扩缩容、基于Knative Eventing构建事件处理框架。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/83/83e9a3022bab0e0a0d307a6da4f6f18e.png\" /></p><p></p><p>&nbsp;网易云音乐&nbsp;Serverless 事件处理框架图</p><p>&nbsp;</p><p>在如何进行技术选型上，网易数帆云原生架构师闫东晓表示主要有三点需要考虑。第一，产品一定要能够满足业务场景和应用场景需求；第二，关注产品背后的支持情况，比如Knative 有谷歌、IBM 等大企业加持，OpenShift 背后有&nbsp;RedHat 支持；第三，产品具有易用性，通常易用性是落地时团队要帮助业务解决的问题，但如果项目足够稳定，就不需要改变底层框架。</p><p>&nbsp;</p><p>在众多开源软件中，Knative的扩展性较好、可以选择消息引擎，并且生产和消费的客户端可以以插件的形式嵌入到Serverless系统中。因此，云原生团队最后选择基于&nbsp;Knative 对每个实例或创建的&nbsp;Knative Service（类似&nbsp;Kubernetes 的&nbsp;Deployment）进行动态扩缩容。</p><p>&nbsp;</p><p>当时的&nbsp;Knative 本身还处于快速迭代阶段，没有稳定的版本，网易云音乐使用的还是0.20、0.21版本。</p><p>&nbsp;</p><p>2021年上云之后，网易云音乐开始使用事件驱动架构。这次迁移期间，云原生团队还在&nbsp;Knative Eventing 事件框架中内嵌了一个插件（Knative之中包含&nbsp;Knative Serving 和&nbsp;Knative Eventing 两个项目），将消息引擎&nbsp;Kafka 也集成到了&nbsp;Serverless 平台之中。业务只需要在8080端口接收通过&nbsp;Knative Eventing 事件框架转发的请求，并通过Kafka触发消息即可实现事件驱动。</p><p>&nbsp;</p><p>具体来讲，业务将支持&nbsp;Knative Eventing 格式的事件请求通过暴露的URL发送到接口，再由接口将消息转发到消息引擎，系统层面在监听到事件触发后会消费&nbsp;Kafka 的消息，最后再将其转发给后端算法进行处理。</p><p>&nbsp;</p><p>自此，网易云音乐拥有了一个异步事件处理框架，在偏向离线的场景中可以慢慢地消费消息，从而确保私有云底层的有限资源能得到合理、充分地使用。</p><p>&nbsp;</p><p>这是一种通用技术，要求启动的服务不依赖私有云节点，不能在宿主机上的某些路径下存在文件等依赖形式，否则会无法弹出导致启动失败。但如果所有依赖均在容器镜像内部，或者可以通过运行时动态地请求依赖方获取信息，那么就可以应用这种弹性能力。</p><p>&nbsp;</p><p></p><h2>迁移后，需要解决哪些问题？</h2><p></p><p>&nbsp;</p><p>冷启动是 Serverless 使用时被重点考量的点。影响启动速度的因素有很多，比如，容器镜像大小不同，pod的启动速度也不同。部分厂商通过预先启动部分&nbsp;pod 的方式来解决冷启动问题，但网易云音乐没有这么做。云原生团队使用了更通用的解决方案，比如&nbsp;Dockerfile 采用多阶段构建、P2P 加速容器镜像拉取速度等。</p><p>&nbsp;</p><p>网易云音乐的应用场景偏离线、非实时，因此对负载均衡和并发控制的需求比较高。音视频算法每个pod可处理的并发度很低，理想情况是上游在下发请求时控制并发数量，确保每个pod都在处理自己能处理的并发请求。但是，数据链路上会有数据不均衡的情况，经过队列的请求会超过pod可处理的并发数量上限，从而导致队列阻塞和其他pod空闲。</p><p>&nbsp;</p><p>为此，云原生团队调整了&nbsp;Knative 内部的负载均衡算法策略，从默认的&nbsp;Round Robin 改为&nbsp;Least Request，将请求发给并发处理数最少的 pod，让每个 pod 都有任务。</p><p>&nbsp;</p><p>另外业务对稳定性要求也很高，而业务稳定性主要体现在对上游并发的控制上。业务将服务请求全部发送到消息队列后，如果将消息全部分发给底层服务处理，那么将扩容出非常多 pod；如果pod与在线应用在同一个node上，则势必会影响在线应用的稳定性。因此，除了 Knative 本身所提供的服务外，云原生团队还收集业务指标并提供监控告警功能，来给业务信心。</p><p>&nbsp;</p><p>通过与业务的需求沟通，云原生团队利用 Serverless 暴露出的数据链路指标信息形成定制的可视化看板，其中包括监控告警、扩缩容频率、每个pod的负载情况、推送消息的消费情况等业务基础信息，此外也有&nbsp;Serverless 内部运维的巡检监控，如CPU、内存的利用率，消费队列消费延时情况、业务化扩缩容实现等。</p><p>&nbsp;</p><p>当监控效果不达预期时，云原生团队则需要调整或借鉴其他优化手段做提升。值得注意的是，这些监控指标收集都是使用的基础&nbsp;Kubernetes 系列开源产品，并不是&nbsp;Serverless 独有的。Serverless 是作为整个架构部分的存在，需要与其它产品配合使用。&nbsp;</p><p>&nbsp;</p><p>在调优方面，业务研发可以自行登录容器查看进程信息，也可以通过日志收集的方式查看。调试方面则使用了云主机时代的远程调试方法，这种方式在容器化时代依旧可用。</p><p>&nbsp;</p><p>为了完成“最后一公里”的交付，云原生团队在网易开源的云原生应用交付平台 Horizon 上交付了一个部署模板，曲库团队基于 Horizon 平台填写数据表单，云原生团队负责模板化实例生成。Horizon 平台（开源地址：<a href=\"https://github.com/horizoncd\">https://github.com/horizoncd</a>\"）通过引入模板系统解决了各种应用负载标准化的问题，支持&nbsp;Deployment、Argo Rollout、Knative 等负载，Serverless 平台则复用了&nbsp;Horizon 的部分基础能力，进而为业务提供动态扩缩容和事件处理框架能力。</p><p>&nbsp;</p><p>通过结合业务进行探索和迭代，网易云音乐用了一年多的时间基于Knaitve 构建了相对完善的&nbsp;Serverless 平台：</p><p>&nbsp;</p><p>多语言的构建方式：包括 Dockerfile 、JAVA、Golang、Node、Python等。多场景：支持弹性在线应用和弹性数据处理，支持同步调用模式和异步调用模式。丰富的发布策略：支持蓝绿发布和基于流量的灰度发布，确保业务的无损发布。自动扩缩容：根据业务并发以及QPS、任务量等实现秒级自动扩缩容。全链路监控：全链路的采集指标、采集日志，自动将数据整合到应用监控。丰富的触发器：除了支持HTTP、还支持网易内部的Kafka、Nydus 队列作为Serverless触发器进行数据处理。无限容量：通过混合云、混合部署等方式，快速、自动地通过ECI等方式弹到阿里云、AWS等公有云厂商。</p><p></p><h2>落地效益如何？</h2><p></p><p>&nbsp;</p><p>“对于企业来说，如果一开始使用的是私有云，那么在既有 IT 成本的前提下，Serverless只是提升内部资源的利用率。但如果前提是公有云，那么只要能保证容器不依赖于主机环境，那么在解决信息安全、日志、指标监控等问题的前提下，Serverless 是一定可行的。”闫东晓表示。</p><p>&nbsp;</p><p>目前，网易云音乐内部大量使用Serverless平台的场景包括音视频分析、AI推理分析、前端SSR、弹性日志ETL等。Serverlesss 通过与在线业务混合部署的方式，大大提升了机房资源的利用率，峰值时超过了50%，资源整体占比达到20%左右。</p><p>&nbsp;</p><p>网易云音乐的Node负载有波峰、波谷之分，云原生团队希望在波峰时段减少Serverless的使用，并在凌晨2-8点左右提升资源利用率，运行Serverless的非实时任务。其中，波峰时段主要是内部私有云在线服务，这也是整个&nbsp;Kubernetes 资源利用率的波峰。</p><p>&nbsp;</p><p>如今，网易云音乐的私有云上已经部署了超过500个 Serverless 应用，高峰期会使用1万多虚拟核心。从内部Node级别的资源利用率来看，有20%的 CPU 核心供给了 Serverless应用使用，通过在线离线混合部署，在不扩容机器增加成本的情况下，基本满足了业务对底层计算资源的诉求。</p><p>&nbsp;</p><p>网易云音乐还可以做到优先使用自有机房计算资源，直到饱和时再使用公有云上的计算资源，比如将服务弹出到阿里云的ECI（弹性容器实例）上进行临时的计算辅助，并在执行完成后将其缩容，从而完全解决资源焦虑，大大提高资源交付效率。需要注意的是，这是一种临时调用，而非将服务固定在私有云和公有云上混合使用。</p><p>&nbsp;</p><p>在接入 Serverless 平台两年以来，曲库音视频平均使用资源的 CPU 核数日平均峰值 5000 核，日平均谷值3000 核。同时，一部分算法服务还借助公有云的 Spot 弹性资源和包月资源，利用竞价模式，持有弹性的GPU，快速申请、快速释放。云原生团队的调研显示，即使是简单的每天修改副本数，业务对这些弹性扩缩容手段的好感度也非常高。</p><p>&nbsp;</p><p>另外在运维方面，底层运维的成本并没有因为使用 Serverless 而增加，运维人员的实际操作量减少，将精力更多放在了&nbsp;Kubernetes 的资源是否能满足业务需求上。</p><p>&nbsp;</p><p>不过，闫东晓提醒道，对于业务研发而言，云原生团队可以将同一类的工具链封装得更稳定、使用更简单，这时 Serverless 使用效率较高，但是对于非同一类工具链，如算法等无法抽象出&nbsp;CI 流水线的，收益就比较有限。</p><p></p><h2>要不要用 Serverless&nbsp;</h2><p></p><p>&nbsp;</p><p>从云厂商产品为主到基于开源产品二次开发，网易云音乐的 Serverless 架构虽然更加贴合内部应用场景，但也需要花精力紧跟社区迭代。闫东晓表示，Serverless 也非“银弹”，本身自带如冷启动方面启动慢、销毁时造成客户端异常、对在线类服务不太能友好等问题。另外，在既有成本的情况下，固定副本数要比弹性扩缩容要好。</p><p>&nbsp;</p><p>对于想要接入 Serverless 的企业，闫东晓建议可以从降本增效的角度，或者自有机房或私有云的系统资源利用率角度，看是否有偏离线的计算密集型业务。“一些离线应用往往会在短时间内需要大量的资源，这种需求往往也是一次性的。此时，可以考虑使用 Serverless 提升系统利用率。”</p><p>&nbsp;</p><p>对于使用公有云的企业，如果直接将所有服务全部迁移到&nbsp;Serverless 架构上，则更需要考虑各种风险，比如扩缩容过程中的冷启动问题、服务启停是否会影响业务、缩容时 pod 的销毁是否会同时关闭未处理完成的用户请求、扩容时 pod 创建是否够快、是否会导致扩容时间内的请求高延迟等。</p><p>&nbsp;</p><p>企业如果考虑使用云厂商产品，闫东晓表示需要了解云厂商的技术是否封闭、是否跟随社区前进，否则之后做厂商切换、产品切换时都会比较麻烦。尤其如果云厂商的 Serverless 产品在底层没有统一标准，那么平滑迁移必然会带来成本问题。</p><p>&nbsp;</p><p>如果内部只是将固定副本数的普通云主机迁移至 Kubernetes，那么对于封装流水线和接口的方式，业务层感知不到底层上云前后的差别，也不需要太多知识。但如果是使用微服务、选择自身技术栈的情况，那么使用方需要能提供 Dockerfile、自行将容器封装运行，这就需要具备容器、Kubernetes 方面的知识，否则用起来会感到困惑。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>网易云音乐的 Serverless 应用还在继续，比如网易云音乐考虑在事件框架中引入&nbsp;RocketMQ、调度方面会引入定时并发控制，以及充分利用硬件在波谷时段的资源等。总的来说，网易云音乐 Serverless 的落地还是围绕“降本增效”进行更细化的工作。</p><p>&nbsp;</p><p>当然，对于整个 Serverless 行业来说，未来也还有很多路要走。 Serverless 能否借助当下企业对降本增效需求的契机得到进一步发展，我们也将拭目以待。</p>",
    "publish_time": "2023-03-21 07:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "ChatGPT 爆火的背后：深度解读“智能对话”与“人机交互”技术",
    "url": "https://www.infoq.cn/article/hVCV97zJtH9vgeoDuMLS",
    "summary": "<p>智能对话技术在近几年来取得了惊人的进步，最近爆火的 ChatGPT 更是将智能对话推到了至高潮。像 ChatGPT 这样的聊天机器人有着广泛的用途，然而想要让其达到真正的智能水平，还有很多挑战需要克服，比如自然语言处理、上下文理解、逻辑推理、情感表达等技术能力都需要进一步迭代。</p><p></p><p>如今智能对话技术已经发展到什么程度了？当前有什么好的智能对话产品实践经验？智能对话技术的下一步演进将是怎样的？为了得到这些问题的答案，3 月 11 日下午，<a href=\"https://www.infoq.cn/article/GL8uCoJG5txQwZ9aQo2Z\">OPPO 数智</a>\"在线下举办了主题为《畅谈“智能对话”，共启“交互未来”》的 OGeek 小布沙龙。<a href=\"https://www.infoq.cn/article/JL4C1m4lb4AiCkLRy4DZ\">OPPO 小布助手</a>\"首席研究员杨振宇博士作为本次沙龙的内容出品人，邀请到了清华大学计算机科学与技术系长聘副教授黄民烈博士、百度 AI 主任研发架构师 &amp; 小度算法团队技术负责人谢剑博士及 OPPO 小布助手算法专家索宏彬博士来到现场进行了硬核的技术干货分享及精彩绝伦的圆桌论坛。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ba/ba38b3544addf30f30792bda0b8d9081.jpeg\" /></p><p></p><p>据悉，“<a href=\"https://www.infoq.cn/article/JL4C1m4lb4AiCkLRy4DZ\">OGeek</a>\"”是由 OPPO 数智工程事业部主办的行业技术沙龙品牌，旨在为技术爱好者搭建一个技术交流和分享的开放平台。沙龙主要围绕“科技为人、以善天下”的品牌使命，聚焦于为智能终端提供安全高效的数据、算力、算法、云服务方面的前沿技术，打造技术互动的行业生态，探索技术在行业应用的实践、突破及未来发展方向。</p><p></p><p>以下为本次 OGeek 小布沙龙的精华内容整理：</p><p></p><p></p><h2>黄民烈：预训练对话大模型深度解读</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/16/16383e809a45cda8236ae32e04c234ce.jpeg\" /></p><p></p><p>生成式对话模型的图灵测试逐渐接近人类水平，高质量对话也让人误以为 AI 有意识和人格觉醒。特斯拉和小米均在研发人形机器人，国际上也投入了大笔资金立项，似乎“AI- 人”和谐共融的社会将成为必然。基于以上背景，黄民烈指出，随着硬件成本越来越低、执行部件越来越灵敏，机器人的大脑将显得尤为重要。</p><p></p><p>黄民烈提到，目前 AI 的发展已经历三个时代：</p><p></p><p>基于规则时代，1966 年计算机发展之初，MIT 的教授基于规则研发了用于心理治疗的 Eliza；智能助手时代，资本一顿狂追，成果则良莠不齐；深度学习时代，如今，以深度学习为代表的大模型数据神经对话系统如 ChatGPT 正在开启 AI 发展的第三阶段——深度学习阶段。</p><p></p><p>黄民烈认为，聊天机器人可分为两个分支——“功能型 AI”及“拟人型 AI”。前者可以不停地完成任务和指令，如传统的智能助手、大模型阶段的 ChatGPT；后者则一般是基于检索的智能机器人、基于生成大模型的 LaMDA 等。</p><p></p><p>纵观大模型发展历程，由微软研发的 DialoGPT 是相对较早的系统，它完全基于 GPT 架构，从 Reddit 上抽取 147M 对话数据，实现了互信息最大化。谷歌研发的 Meena 系统提出了人工评价体系 SSA，性能显著超越了 DialoGPT。清华 CoAI 小组研发的 CDial-GPT，依托 Decoder-0nly 架构，建立了大规模高质量中文开放域对话数据集 LCCC，其人工评测结果优于原始 Transformer 模型和中文 GPT-2 模型，得到了学术界的认可。</p><p></p><p>紧接着由 Meta AI 研发的 BlenderBot 问世，共包含三代版本：</p><p></p><p>第一代：已具备开放域闲聊及多技能融合的能力；第二代：模型结构与第一代相同，数据能力有所增强。第三代：迭代为 Decoder-Only 结构，功能模块化与流水线配合执行，完成开放域任务并实现终身学习。</p><p></p><p>2021 年初，清华 CoAI 小组研发了 EVA，共有两个版本。其中，EVA1.0 包含 28 亿参数，在 181G WDC-Dialogue 上训练而成，开源首个十亿级别中文对话模型；EVA2.0 在精细清洗的 60G WDC-Dialogue 上训练而成，开源多规模版本模型以方便研究者使用。</p><p></p><p>当我们把目光放到当下的技术产品中，由百度研发的 PLATO 系列模型现已更新至第四代。前两代模型结构相同，参数量均为 1.6B。第三代 PLATO-XL，参数量达到 11B，在连贯性、一致性、信息量、事实性、趣味性上均取得优异表现。第四代 PLATO-K 版本旨在解决开放域对话系统中信息量缺乏和事实不准确的问题，在知识性上有大幅提升。由 Google 研发的 LaMDA 以 Decoder-Only 为架构，参数量达到 137B，在 2.81T 的 token 上进行了预训练，能够在合理、趣味、安全的开放域闲聊。引入 Toolset (TS)，在生成质量、安全性、有根据性上取得明显提升。</p><p></p><p>去年，清华 CoAI 小组联合聆心智能研发了 OPD。它采用 UniLM 架构，在预训练阶段引入了 Soft Prompt。参数量为 6.3B，具有 70GB 高质量对话数据，兼顾出色的闲聊能力与知识问答能力。</p><p></p><p>关于如今备受关注的 ChatGPT，黄民烈提到，它背后的核心技术其实是指令学习和基于人类反馈的强化学习。黄民烈在此总结了 ChatGPT 的三个突出特点：</p><p></p><p>遵循指令能力出色，在多轮交互中均能很好地遵从指令；对话历史建模能力突出，在多轮交互中具有很强的长程记忆能力；多语言能力强，支持各类主流语言。再者是回复信息性强，倾向于生成较长的回复。最后是安全性好，安全漏洞很少且仍在持续优化。</p><p></p><p>黄民烈指出，ChatGPT 更突出功能属性，强调提高效率、解放生产力，提升创造力。而 Character AI 和 AI 乌托邦则更关注人格属性，试图满足社交、情感、陪伴、支持等需求。黄民烈将 AI 乌托邦称为 Mini 版的 ChatGPT，它既可以回答刁钻的问题，还可以让不同角色实现跨时空的对话。对于一个问题，ChatGPT 可能会给出一个比较官方的回复，而 AI 乌托邦则会根据不同的角色性格给出不同的回答。</p><p></p><p>在本次演讲的最后，黄民烈就对话大模型特点做出了总结：</p><p></p><p>1. 模型架构、预训练任务趋于统一；</p><p>2. 参数规模持续增大，下一代对话预训练模型将普遍进入千亿量级；</p><p>3. 数据重要性日益凸显，中等规模、高质量的对话数据将显著提升对话预训练模型的交互能力；</p><p>4. 人类在模型训练过程的介入和参与不断增加，模型对人类行为的模仿、与人类偏好和价值取向的对齐不断增强；</p><p>5. Tool-learning 引起关注，检索、记忆、计算等可插拔的外部模块将成为标配；</p><p>6. 新的落地应用场景涌现，以 Character.AI、ChatGPT 为代表的对话模型具有众多潜在的落地应用场景。</p><p></p><p></p><h2>谢剑：小度助手的智能化演进技术实践</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d2/d2c3e2e20f4a2190a06ae4305053d9cd.jpeg\" /></p><p></p><p>谢剑认为，智能助手的智能化体验将主要围绕以下几个维度进行进化。首先是“交互自然度”，交互自然度不仅体现在语音交互，更侧重于多模态的交互。现在市场上的语音助手基本是一次唤醒一次交互，这种方式并不够智能。其次是“对话智能度”，即智能对话系统要足够聪明。对于同一个问题，不同的提问方式均能得到准确的回答。从基础满足进阶到拟人智能，有人格化、人像化的形象将会与人产生情感的连接。然后是“感知与影响度”，即实现对物理世界更丰富的感知和更强的影响。</p><p></p><p>小度助手在这个进化蓝图下，主要围绕自然交互和对话智能展开探索。针对自然交互，谢剑指出，无论是把双工交互引进来，还是把“小度小度”变成“小度”，都是为了使用户和设备之间的交互成本更低。对话智能则侧重于不同技术路线应对不同的对话需求，小度个性化持续自学习的统一对话系统，可以在保护用户隐私的情况下进行用户分析，将满意的部分持续积累，不满意的部分通过样本挖掘产生正确的标签，实现系统的自学习。</p><p></p><p>从工业界的视野来看，谢剑认为对话理解正面临着三个挑战——大规模持续增长的理解体系、语音识别错误和口语化问题的鲁棒性挑战、需要满足不同用户的个性化需求。为此小度助手进行了对话理解层面、对话引导层面的技术迭代。</p><p></p><p>在对话理解层面，建立大规模个性化多轮对话需求追踪模型。将 NLP 与推荐技术交叉融合，针对用户的需求空间做整体建模，如此便绕开了文本出错的问题。同时，应用个性化和上下文信息融合的注意力网路，进而实现全空间可比的连续概率变化追踪。该模型的端到端纠错和 NLU 能力、上下文理解能力、垂类知识能力以及个性化纠错与消歧能力非常强悍，其中“个性化纠错与消歧能力”尤为突出。</p><p></p><p>在对话引导层面，谢剑强调智能的对话体验应是：知之为知之，不知为不知，即智能助手一定要知道自己有不知道的边界。通俗来讲，用户与小度聊天，当聊到它没听清或听不懂的问题时，它能够知道自己不知道，而不是答非所问。于是，小度团队构建了深度满意度模型——离线时基于下文 Dialogue Act 的序列行为判别模型，在线时基于离线模型样本，预判最佳结果是否满足用户。</p><p></p><p>面对 ChatGPT 的成功，谢剑将其背后的强大能力拆解为三个维度，分别是对话交互维度、NLP 全任务能力维度以及泛化能力维度。谢剑认为，ChatGPT 最大的亮点是语言智能统一范式的飞跃，在此之前整个学术界也一直在探索。</p><p></p><p>而以 ChatGPT 为代表的大规模语言模型的新技术范式对智能助手技术的演进的影响，让谢剑产生了一些反思：</p><p></p><p>先有通用的语言能力后再去做具体任务是通向语言智能的关键；语言背后的世界常识、逻辑应是相同的；不少单独的十分垂直的 NLP 研究子方向受到巨大冲击。</p><p></p><p>关于“ChatGPT 能否代替语音助手”这个问题，谢剑的答案是“不能直接完全替换，但是基于 LLM 的新技术范式升级能够带来革命性的体验”。具体而言，ChatGPT 本身的满足方式还是文本信息，无法直接连接数字世界的服务和 API，比如订闹钟、播放音乐等，而这些都是已有助手需要解决的问题，同时还存在事实性的问答错误以及时效性信息的更新问题，因此无法直接替换。</p><p></p><p>然而以 ChatGPT 为代表的 LLM 拥有极强的语言推理、总结和生成能力，以 LLM 作为大脑，结合外部工具的调用（包括搜索、服务 API 等）既能够满足现在用户对于语音助手的需求，还能够满足和激发原本满足不好的需求（内容生成、复杂长文本理解等）。</p><p></p><p>小度助手结合 LLM 新技术范式的升级会朝着 Chain of Reason and Act 方向去进化，用户的需求来了之后首先进行推理，思考需要调用和应用外部的什么服务和工具（比如 搜索、音乐播放服务、视频等），而后基于外部服务和工具的内容返回继续推理，看看是否能够满足用户的需求，在能够满足和不能满足的情况下自主的去生成更合适的内容返回给用户，这种\"推理 - 执行 - 推理\"链能够大幅的增强 LLM 的能力，进而满足用户对助手的各种需求。</p><p></p><p>当然这种技术和融合也有很多的挑战，包括成本的挑战、生成式大模型的安全挑战等等，另外在拥有 LLM 大模型的强大能力的同时还需要能够保持原本助手的个性化、自学习等特征，在这些关键问题下，小度团队也在紧锣密鼓的开展研究中。</p><p></p><p></p><h2>索宏彬：OPPO 小布语音交互技术实践</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/12/12b0a0642f7f9bf73a199b5ba258cad5.jpeg\" /></p><p></p><p>小布助手是一个多模态、多终端、对话式的智能助手，以“机智”“有用”“温暖”为产品理念，致力于提供多场景、智慧有度的用户体验。</p><p></p><p>人机语音交互是基于语音输入的一种交互模式，即通过说话就可以得到反馈结果。语音助手则是一款智能型的应用程序，人机之间通过语音进行对话与问答。它的终极目标是全领域通过图灵测试，通俗说就是“能听”“会说”“懂你”。</p><p></p><p>小布助手的“语音”在落地阶段最重要的工作共有两项：</p><p></p><p>模型生产能否保证高效，比如把链路里的语音技术点、VAD/KWS/ASR 等基础模型生产置于统一框架之下，并相应地进行流程化改造；算力部署，要把算法进行高效封装，使其迅速产生推理依据，随后部署到端侧和云侧。将语音处理接口进行抽象，以实现各种各样的语音服务编排。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fe/febb4e804df6573b53dc4903669b27b7.png\" /></p><p></p><p>即便小布助手链路已经构建得相当完整，但使用过程中仍然存在着许多问题。其中，索宏彬认为低功耗信号处理的主要挑战是非平稳噪声、高回放音和空间混响。目前的解决方案是单、双麦降噪，传统信号处理方法与神经网络方法并行，当前小布助手已完成立体声 AEC 算法仿真初版，在最大音量下，MIC1 回声抑制收益可超过 10dB。未来小布助手研发团队将聚焦多场景的 AEC 算法适配，布局远场交互的 Mic 阵列技术，为 OPPO 更多产品形态做好准备。</p><p></p><p>面对当前行业里“语音唤醒”功能实现中存在的“低功耗”、“高噪声场景下如何保持高水位的唤醒率同时抑制误唤醒率”技术难题，小布完成了唤醒底层算法的开发，从 0 到 1 构建了芯、端、云三级 (DSP/AP/Cloud) 唤醒方案。</p><p></p><p>关于声纹应用，为了应对人噪干扰、多人交谈、跨信道、短时交互的场景挑战，OPPO 小布研发团队基于 SpeechBrain 框架，选型了 Vector 算法框架及综合性解决方案算法框架 ECAPA-TDNN，并且基于距离度量的无监督聚类技术，进行数据自动化清洗。</p><p></p><p>在目标语音增强方面，小布助手团队尝试了基于声纹模板更新的主讲人话音检测算法（TSVAD），尝试通过主讲人语音注册环节，对模板进行更新，提升主讲人语音分离模型在实际场景使用时的鲁棒性能，提升后端语音识别准确率；</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/09/09962a9b01ac54b32df6f52dc8449992.png\" /></p><p></p><p>在自定义 TTS 方面，传统的声音自定义技术方案，录入时间长，效率低。同时，小布助手的用户群体背景及使用场景复杂，因此在复杂的环境和海量数据情况下，如何挑选满足条件的音频作为训练数据成为了一个巨大的挑战。于是小布助手研发团队自研了“纯语音 VAD”与“语音语义深度结合 VAD”的解决方案，同时应用了“预训练 + 在线自适应”的技术方案。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5a1d76cea5031ac08bd73b5fb70acc4.png\" /></p><p></p><p>在歌声合成方面，面对“低资源歌声合成”、“跨风格歌声合成”、“跨语言歌声合成”、“个性化歌声合成”的需求，小布助手研发团队提出了两个技术优化方案：</p><p></p><p>方案一：声码器从 HiFiGAN 升级至 SiFiGAN，通过引入 Source-Filter 模型，模拟发音过程，实现基频（F0）可控，MOS 得分有显著提升；高保真歌声合成，从 24K 升级至 48K，可以保留 12K 以上的高频细节信息；引入 PN 技术，将 Diffusion 模型中的差分方程分解为“Gradient”和“Transfer”两部分，在“Gradient”部分选择“Linear Multi-Step”方法加速计算，并实现了实时推理。方案二：小样本歌声合成使用 Conditional LayerNorm 技术，Finetune 时只更新与说话人音色相关的参数即可，训练数据从 3 小时降低至 40 分钟以内；同时改进了时长模型 Differentiable Durator，一定程度解决训练和推理过程不匹配的问题，提高自然度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1f/1f3009ffc82eecacd02ef04d9c420e06.png\" /></p><p></p><p></p><h2>智能对话技术的“下半场”在哪？</h2><p></p><p></p><p>在本次 OGeek 小布沙龙的最后，杨振宇与黄民烈、谢剑、索宏彬一起围绕“智能对话技术的‘下半场’在哪？”这一主题展开了圆桌论坛。几位博士均表示，爆火的 ChatGPT 给智能对话领域带来了深远的意义和影响。黄民烈认为，ChatGPT 最大的意义是让所有公众意识到了 AI 的能力以及 AI 能够突破传统认知上的局限”；谢剑和索宏彬都提到了“人机共生”的理念，他们表示 ChatGPT 的出现将启发人们思考，在未来的工作场景中如何实现人机共生。</p><p></p><p>当提到智能对话等人工交互领域最有前景的方向时，来自学术界和工业界的博士们分别给出了不同的答案，黄民烈认为未来将是千人千面的；谢剑在个性化助手的方向基础上，抛出了“增强语言模型”的观点，让 LLM 结合外部的各种信息和工具来大幅提升 LLM 的能力；索宏彬则认为，从交互模态上看，input 会变得更加丰富。四位博士完美地勾勒出了智能对话技术的美好未来。通过他们的分享，我们可以预见，智能对话与人机交互在未来一定会给我们带来更多的惊喜。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e2/e2e126754ae96ab9fb825b5b7cecb7a9.jpeg\" /></p><p></p><p>就像出品人杨振宇说的那样，“即使有像 ChatGPT 这样的新技术出现，挑战也仍然存在，包括内容安全与 AI 伦理、长时记忆与个性化、共情能力与拟人化、反馈驱动与自学习。但机遇与挑战并存，随着技术的快速迭代，智能对话领域正在迎来最好的时代。”</p><p></p><p>值得一提的是，在本次 OGeek 小布沙龙中，杨振宇还宣布了“2023 年中国高校计算机大赛智能交互创新赛”启动事宜，呼吁全球高校在校生参与到本届大赛中。据悉，该大赛是由教育部四大教指委创办，由浙江大学与 OPPO 公司联合承办，旨在提升学生在新一代人机交互方向的技术、场景创新能力，积极探索“科技为人”的智能交互技术，给未来人类生活提供全新的产品及服务体验。希望通过竞赛的形式培育产学研融合的 AI 人才生态体系，共同促进人机物三元融合产业的发展和革新，全面推进 AI 技术的发展。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8f/8fa9b6a46b4deca44b396f06c5508852.png\" /></p><p></p><p></p><p></p><h2>附：圆桌论坛环节精彩整理</h2><p></p><p></p><h4>问题 1（杨振宇）：关于智能对话技术的研究与探索，目前学术界和工业界的侧重点分别是什么？</h4><p></p><p></p><p>黄民烈：学术界现在的趋势是以神经网络模型为主，工业界的趋势则是朝 OpenAI 的方向持续狂奔。从学术界角度来讲，由于资源受限，无法支撑太多大规模的模型和试验。整个学术界的研究方式正在与工业界的方式趋同和对齐，很多有影响力的论文都是由名校和大厂共同产出的。</p><p></p><p>学术界当下需要考虑如何学习外界工具方法来解决自身研究的问题。工业界数据是最好的方法，但学术界也需要用有原则性的方法突破它。比如乌托邦个性化对话平台的很多行为要靠数据解决，里面也有很关键的算法，这时既要考虑算法在原理层面是否合适，同时也要注意规避算法短时间内难以克服的缺陷。</p><p></p><p>谢剑：不单是智能对话，我们可以思考任何计算机领域包括科学领域，学术界和工业界的侧重点是什么。个人看来，学术界侧重突破新的可能。比如不考虑任何成本，智能最终极限将是什么样的。工业界则侧重于解决问题，他们更看重“捅破天花板”的技术最终能应用于哪些场景以解决用户的需求。近年，工业界产品的用户体量很大，也需要再往前走一走。刚刚黄老师提到，现在许多大厂和高校之间都有合作。那么工业界也将与学术届合作，一起捅破“天花板”。</p><p></p><p>索宏彬：目前，OPPO 小布也在和学校进行合作，该项目的出发点主要围绕两个方向，一是跨领域、多模态领域，涉及语音、图像以及语义结合，可以看出学术界在这些领域是比较关注的。第二个是问题驱动，这其中包括很多技术挑战点，高校工作也比较关注。回到本质上，目前智能助手业务应用上，跟高校的合作还是主要围绕用户体验、围绕问题驱动。</p><p></p><p></p><h4>问题 2（杨振宇）：当前 B 端企业和 C 端用户对于“智能对话”产品的核心需求分别有哪些？</h4><p></p><p></p><p>谢剑：2B 最后也是 2C，最终都是要满足用户的需求，当然它们也会各有侧重。2B 的客户往往是开发者，他们看重是否具有泛化能力，能否降低开发者成本。2C 的大部分用户不是开发者，他们希望交互一次就能满足需求。所以，从智能对话上来讲，这可能是比较明显看到的区别。也许，新的时代 2B 和 2C 会模糊掉。如果开发者用很简单的自然语言就能开发，就意味着人人都能成为开发者，中文也能变成世界上最强的编程语言之一。所以，2B 和 2C 的模糊，一定程度上也能带动整个社会生态的蓬勃发展。</p><p></p><p>索宏彬：小布的产品定位正在发生变化，尤其在备受热议的 ChatGPT 出来之后，小布的目标是朝着“有用”的方向走。原来的小布侧重于“有趣”，现在则在向“有用”的方向走，这是很典型的一个变化。</p><p></p><p>黄民烈：我理解人类有两类基本需求，一类是信息需求，一类是情感需求。信息需求本质上是做事情，怎么把它完成的更好。情感需求本质是要消磨时光，有情感的寄托，有情绪上、心理上的支持和疏导。所以，我们希望今天的助手能和人产生更强的连接，有情感的、社会的、信任的关系，不仅要完成信息类的任务，还要完成情感类的任务。从人类两大需求角度来看，无论是信息的还是情感的，最终都将融到一起，尤其现在技术发展越来越快，势必会产生很多新的应用场景。随着技术的成熟和变革，一定会有新的拐点和机会到来，这也是我们现在想试着做 AGI 的重要驱动点。</p><p></p><p>杨振宇：无论是 2B 还是 2C，都要考虑到底最终为用户希望发挥的价值是什么，以及在此之上给用户提供的体验是怎么样的。2C 与 2B 的核心需求侧重点目前虽然稍微有点不同，但本身都还在演进、融合的过程中。</p><p></p><p></p><h4>问题 3（杨振宇）：目前智能对话领域最大的“技术挑战”是什么？如何应对这个挑战？</h4><p></p><p></p><p>索宏彬：大家在演讲过程中提了很多挑战，如果选一个最大的，那就是“自然”，不是 AGI 的，而是更往上走，真的达到拟人化或者跟人产生情感连接。实现无负担的交互。</p><p></p><p>谢剑：挑战很多，如果说最大的我个人觉得是如何做到 All in one，我怎么说都行，怎么说它都能搞定，背后一定程度上隐隐朝向 AGI 的挑战。其他的新场景泛化，信息需求和情感需求都能满足，本质都是需要 All in one。现在发现预训练的大模型能够把它整合，但依然还有很多问题，目标是希望能够 All in one 用一个大脑，这是我理解最大的挑战。</p><p></p><p>黄民烈：最大的挑战是如何实现 Human-like conversation。从现在看，我们已经接近类人的对话能力，但有些应用场景仍存在差距，比如多模态的信息、上下文理解等，尤其是如何连接到外部世界和知识，以及外部背景信息。总体来讲还是挺难的，AGI 有很长的路要走。</p><p></p><p>杨振宇：针对这个问题也分享一下我的想法，非常赞同今天各位专家提到的未来大模型用的越来越广泛的时候，怎么解决安全性的问题，怎么解决 AI 伦理的问题，特别是直接面向 to C 用户生成内容的时候。当讨论未来最大挑战的时候，多样性还蛮强的，在场各位专家完全不用担心未来没高价值工作可以做了，挑战还有很多。</p><p></p><p></p><h4>问题 4（杨振宇）：未来 XR 等新硬件设备的发展，将对智能对话领域产生怎样的影响？</h4><p></p><p></p><p>黄民烈：现在技术发展很快，很多东西不太能够预测。我想未来电子宠物或者电子陪伴类的产品也许会卖的很好，因为它们能满足用户的情感需求。</p><p></p><p>杨振宇：大家在猜想 XR 设备会不会有下一个爆品，如果它发展起来，会不会对智能对话的领域有很大的影响。</p><p></p><p>黄民烈：前提是一定要脱离对设备本身的强依赖。如果设备本身的使用门槛或者使用场景不够自然，门槛很高，也许未来在手机装一个超级 APP 类似于 ChatGPT 的时候，可能就会很好。</p><p></p><p>索宏彬：XR 拓宽更多的交互模态，是增强人机交互的一种手段。</p><p></p><p>谢剑：人们所需要的最理想的助手，终极形态一定是多模态的助手形态。XR 有虚拟增强的设备，设备本身在拓宽 input 和 output 的模块。音箱是一个节点，从没屏幕变到有屏幕了，从只能听、能说，到后面有摄像头、能看、会说，再往后能不能有更虚拟的现实增强。回到智能助手，如果 XR 设备发展成熟了，多模态的助手就有了很好的承载设备，语言的理解就要还原到物理真实环境里，交互的各个方面都会有新的挑战。我相信新的技术挑战会带来新的技术机遇。</p><p></p><p></p><h4>问题 5（杨振宇）：随着技术发展，大家觉得未来理想的人机交互形态会是什么样的？在交互形态里，智能对话会扮演什么样的角色？</h4><p></p><p></p><p>索宏彬：我比较认同当前类似 XR 的模式，即往多模态方向走，未来交互形态一定是自然表达，类比“人人”交互。</p><p></p><p>黄民烈：理想的一定是“情景式”的，有很多的交互场景。比如在车里，假设有一个人可以很好的与之交流，并且车内的场景交互一定是多模态的，有很多摄像头监测到肢体的状态等。其次是有很高的智能水平，可以自主也可以被动，智能到感知用户的全面状态，根据状态做出最有利于用户的决策。一定要具备综合决策能力，在特定场景下可以主动，大部分情况被动。</p><p></p><p>谢剑：关于理想态，我认为第一点是“个性化”。每个人在不同场景下都具有一个满足该场景需求的助手，或者每个人有一个“个性化助手”，它能在不同场景下扮演不同的能力和满足需求的形态。第二，未来的助手应满足市场供给。市场上有很多律师、作家、卖手等等，相信未来各个领域都会有助手。原本找律师的咨询费是比较贵的，而一些基本问题就可以咨询价格更实惠的智能助手。因此理想的形态，一是能满足个性化情景需求，二是市场上应该会有公共的产生知识供给的助手。</p><p></p><p></p><h4>问题 6（杨振宇）：现在 ChatGPT 的热度很高，它对智能对话将会产生哪些深远的影响？</h4><p></p><p></p><p>黄民烈：我认为 ChatGPT 最大的意义是让所有公众意识到了 AI 的能力以及 AI 能够突破传统认知上的局限。每个行业、每个人都开始思考应该如何和 AI 相处，这是它最大的意义。ChatGPT 给我们带来的仍然是想象的空间，在当前的时代和节点下，大模型能够带给我们什么想象空间，过去不敢想的事情，是不是今天能够去想、能够去做，这个意义是比较重大的。为什么说是 AI 里程碑，因为它比过去所有事情带来的冲击都要更大。</p><p></p><p>谢剑：影响还是很大的，我们可以分类来看。针对普通用户，他们要思考在未来的工作场景中如何实现人机共生，只有拥抱人机共生才能做 AI 之上的人。很多人会比较悲观，但其实人不可能被工具杀死，人加上工具自然会超过工具。对于 NLP 和从业工程师来说影响也是巨大的，不管在工业界还是在学术界都是如此。影响巨大的原因是，原本从 AI 技术来看，大家认知 NLP 是皇冠上的明珠，突然间发现 All in one 做任务并不差，甚至效果更好，这对从业工程师的挑战还蛮大的。学术界有很多做某个单点方向的，此时就要寻找新的方式参与进去。</p><p></p><p>索宏彬：谢老师提到了 AI 共生的理念，我非常认同。不知道大家有没有用到 Bing 和 ChatGPT 的结合版，Bing 的效率非常高。Bert、ChatGPT 等大模型的演进路线，给很多 AI 从业者提供了新的方向，带来一定冲击的同时也增强了大家的信心。大家会沿着这条路做更多的探索，有挑战、有危机，同时也有机遇、有机会。</p><p></p><p></p><h4>问题 7（杨振宇）：在未来 2～3 年，您觉得智能对话等人工交互领域最有前景的方向是什么？</h4><p></p><p></p><p>黄民烈：我认为最有前景的方向还是“个性化”，未来肯定是千人千面的。无论是教育场景，还是金融服务场景，每个用户对不同类型机器了解的方式是不一样的，从这个层面来看个性化是最大的商业价值点。</p><p></p><p>谢剑：我补充一个点，\"增强语言模型\"，以大语言模型为大脑，利用其强大的常识、推理等语言能力，结合和借助外部的信息、知识以及工具，来增强大语言模型，实现能够推理、执行动作再推理等反复的思考 - 动作链，通过这种方式能够更好的实现广泛场景的落地。</p><p></p><p>索宏彬：个人认为从交互模态上，input 会变得更加丰富。其次是表达侧的表现，生成式人工智能是当下特别炙手可热的技术点，我们也在做一些探索和尝试。</p><p></p><p>杨振宇：我个人的期待是，未来的助手是可进化的，是越来越聪明的。通过进化实现个性化和知识增强，对外界知识有更强的理解。如果能实现可进化，一定会有更好的前景。</p>",
    "publish_time": "2023-03-21 09:34:43",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "技术领导力之路 - 安全感",
    "url": "https://www.infoq.cn/article/ffbd2e523ef4cf77abbecaee1",
    "summary": "<p>作者：许晓斌  阿里技术风险与效能团队</p><p></p><p></p><blockquote>管理者的工作职责之一就是创造一个人让员工都充满心理安全感的环境，让他们能够专注于自身的工作，敢于发表不同的观点，敢于做判断和承担风险。</blockquote><p></p><p></p><p>软件研发是一项高度复杂的创造性工作，研发工程师需要和产品经理一起讨论理解复杂的业务模型流程，需要阅读并理解系统多年积累下的数以十万百万行计的代码，需要把新的需求通过一行行的代码实现。软件研发也越来越成为一项需要关注风险的工作，无论是代码的bug，还是对于系统运维的疏漏，都会对商业运营产生重大的影响，甚至影响到人们日常生活。</p><p></p><p>在新冠疫情期间，每个人的出行都依赖健康码系统和核酸检测系统，这些系统一旦出现故障就会大面积影响民众的出行，而所有这一切背后都依赖工程师认真严谨的工作。</p><p></p><p>创造性工作的前提是员工具备充分的心理安全感，如果工程师每天都在担心自己有被裁员的风险，那么他必然是处于一个极度焦虑的状态中，他会担心自己某个微小的行为成为主管眼中的最后一根稻草，难以专注地投入到手头的工作中去。如果缺乏安全感，工程师也必将不敢做一些有失败风险，做一些他认为“可能让主管失望”的事情，甚至不敢做一些他认为可能和主管想法不一致的判断。</p><p></p><p>我经常会观察到身边一些团队的成员，在处理工作的时候几乎养成了事事向主管请示汇报的习惯，在和其中一位员工私下沟通的时候，他和我说这是自己曾经因为做了一些决策和主管的想法不一致，常被主管单独约谈，数次之后他不仅担心自己的做法不符合主管的期望，更是对自己的判断力失去了信心。</p><p></p><p>前文说过，许多公司的软件系统的代码行数都是以百万计的，由于软件系统和软件开发行为的复杂性，从理论上讲管理者就无法掌握所有的细节，更何况在很多组织中管理者的职责已经太多了，除了做人员管理、技术战略，还得理解业务，做大量的协同工作。这就意味着系统中的风险征兆必然依赖团队工程师去发现并解决。</p><p></p><p>但是一旦员工缺乏安全感，他可能就不愿意去提这些问题，内心认为管理者不想听到这些“负面”的信息，或者认为管理者会把风险的出现理解为员工能力的不足。</p><p></p><p></p><blockquote>例如，当系统出现故障之后，许多团队会组织复盘，其中有些团队会在复盘会上强调故障的责任人并对责任人进行处罚，而另一些团队则推行blameless的文化，并不涉及处罚，而是专注在分析问题的根因和后续action上，虽然前者也会强调分析根因和action，但由于潜在的处罚造成强烈的不安全感，更多人的会倾向于罔顾事实而把相关的责任推走，这样的结果对于系统长期的稳定无疑收效甚微。举个例子，近期参加了一个公司中高层的技术规划会，会议的开头有十分钟汇报一下公司当下工程师的整体体验现状。我提前15 分钟到达会议室复习下汇报材料，随着会议开始时间的接近，参会者陆续到达。渐渐意识到参会者除了我的上级、公司的 CTO、以及我认识几个核心业务研发负责人之外，实际参会的人比预想的多了两倍，而他们有一个共同的特点：层级都比我高。在汇报的过程中，我明显处于比较紧张的状态，我自认有不错的演讲能力，在其他普通一些的场合我的状态可不会这样，汇报完后我内心稍微松了一口气。我意识到在这个场合我非常缺乏安全感，现场参会的人实际上是一个非常核心的决策集体，他们具有极大的影响力，包括技术战略的制定，资源的投入，关键岗位人员的任免等等；而我和他们的大多数人都不熟悉，缺乏基本的信任关系，尽管我参加了这个会议，但我内心并不认为自己是这个决策集体的一部分。因此我下意识就会担心自己说错话，担心神形态度给人留下不佳的印象，也不敢冒险提一些未经充分论证的观点，这就必然整体的表现和平时更真实自如的状态有较大的差异。</blockquote><p></p><p></p><p>对心理安全感的需求，是人类在数百万年的采集狩猎社会中进化出的心理机制。和现代社会不同，早期人类缺乏基本的安全生存环境，物质匮乏，在面对速度更快、力量更强大的野兽时，人类关键的竞争力是协作能力。如果一个人被部落集体排斥，他马上就会面临死亡的威胁，这时候内心的焦虑感、惶恐感就会给他一种非常强烈的信号，让他快速想办法被集体重新接纳。</p><p></p><p>虽然今天的社会环境发生了巨大的变化，一个人即便不被身边的小集体接纳（包括亲友集体，工作集体等），也不会直接面临生存的风险，但我们进化出来的心理机制还是停留在采集狩猎的社会环境阶段。</p><p>﻿</p><p>管理者的工作职责之一就是创造一个人让员工都充满心理安全感的环境，让他们能够专注于自身的工作，敢于发表不同的观点，敢于做判断和承担风险。具体的做法包括：</p><p></p><p>1）尽可能透明地分享信息，尤其是团队关键决策和决策背后的思考。</p><p>2）保持和员工的1-on-1对话，通过这样的对话，管理者不仅能够和员工实现深入沟通，也能够让员工在心理上感觉被团队关键人物信任。</p><p>3）积极地给予员工正面反馈激励，让员工感觉自己的工作对于团队的价值感。</p><p>﻿</p><p>以上的这些实践都是在不断给员工释放这样一个信号：“你是集体的重要一部分”，以满足每个人心理上对安全感的需求。与之相反的，一些不成熟管理者会通过制造不安全感来给员工制造巨大的压力，例如通过暗示等手段告诉员工，“如果你不在一周内完成这个需求，你的年终绩效可能会受到影响”，又或者说 “团队和你同层级的员工的工作进展是超预期的，想想你自己的处境”，等等。</p><p></p><p>这些信号会被员工理解为一种威胁，并会在短期内激发巨大的反应（其中最常见的是加班），但从长期来看负面的影响远大于正面，缺乏安全感的员工会失去创造力，不敢表达，也很容易就开始思考是否应该离开团队，寻找更安全的工作环境。</p><p></p><p></p><h2>延伸阅读</h2><p></p><p></p><p>[01] 《进化心理学》</p><p>https://book.douban.com/subject/26683297/</p><p></p><p>[02] “伟大的领导者让员工感觉安全”&nbsp;</p><p>https://www.cphrmb.ca/news/427646/Great-Leaders-Make-Employees-Feel-Safe.htm</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e7/e76827147e60f3a58820b6a3cb6643a6.png\" /></p><p></p>",
    "publish_time": "2023-03-21 10:00:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "领导力匠艺：像开发人员打造代码那样打造你的领导力",
    "url": "https://www.infoq.cn/article/87fXytBSTUiUDmTkHfcO",
    "summary": "<p>学习软件匠艺让我重新思考如何编写代码。作为一位经验丰富的软件团队管理者，我尝试按照相同的方式来重新评估我的管理实践：测试驱动管理和结对管理将会是什么样子呢？在本文中，我分享了将软件匠艺工具和思想转移到管理领域的见解。</p><p></p><h2>软件工匠的理想管理者</h2><p></p><p></p><p>我经常听到开发人员抱怨说，他们的主管正在让他们背离敏捷和质量实践，但是他们却没有对其必要性提出质疑。所以，我长久以来一直想知道一个理想的管理者应该是什么样子的。为此，我询问了十多位软件工匠，严格做到了这一点（参见“<a href=\"https://www.agilenautes.com/manager-craft-contexte/\">软件匠艺视角下的管理者角色演变，法文”</a>\"）。不出所料，他们告诉我，他们首先要寻找的是那些能够向他们传授业务知识的管理者（导师），然后是在组织中推广和捍卫这些实践（倡导者）。</p><p></p><p>令我感到惊讶的是，对他们中的一些人来说，这还不够，有时甚至完全没有必要：他们唯一要求的是自主权。但是，让我深有触动的是一位开发人员告诉我，她所经历的最好的管理者是同样以匠艺的方式管理软件工匠的人。他们在管理方法上有着相同的质量实践和立场。</p><p></p><h2>在管理中应用软件匠艺的实践</h2><p></p><p></p><p>我并不是说，你可以把一个领域的做法复制到另一个领域。我想说的是，如果你有相同的动机，那么有些实践就能很好地从软件匠艺移植到管理领域中。</p><p></p><p>也就说，这不仅仅是理论而已。当我尝试为团队命名时，我有一种为方法命名的相同感觉，我知道自己想出的第一个名字不会是最好的。但是，最有意思的是我尝试改变组织结构的情景，当我试图以大爆炸的方式改变一个30人的团队时，发生的情况与我们想以大爆炸的方式替换一个遗留系统一样，结果就是撤销回滚了。该组织非常抵制，以至于把我踢了出去。我现在非常反对大爆炸式的组织变革。</p><p></p><p>在软件开发中，还有一些适用于管理的通用实践。首先，可以将你的预算编制过程组织成一个CI/CD流水线。让预算定义成为很容易重复的事情，并且使其适应你的组织。CI/CD能够让我们把任务放到一个流水线中，从而避免麻烦的任务。作为经理，我发现预算编制是最繁琐的任务之一。</p><p></p><p>其次，熟练掌握你的工具。如果在你的组织中，管理者们使用MS Excel作为工具的话，那就成为一个MS Excel专家。</p><p></p><p>第三，就像反应式编程一样，让你的决策尽量做到反应式。在做决策时，要保持异步，尽可能减少“提交”阶段，也就是减少那种每个人必须出席，但是只是表达同意意见的会议。对我而言，我觉得保持这种会议也有一定的必要性，在这种会议上，我从不处理事先没有足够时间与大家彻底讨论明白的问题，这种问题可以通过一个简单的异步邮件主题来进行讨论，每个人都有机会发表自己的观点。</p><p></p><h2>结对管理</h2><p></p><p></p><p>除了上文提到的实践之外，我觉得还有两个软件匠艺的实践，它们对管理者非常有用。第一个是代码审查。就像代码在部署至生产环境之前，至少要有两个人进行阅读那样，我尝试与其他人一起审查我的管理决策，可以是同事或老板，最后我发现让自己团队的人来审查是最好的。</p><p></p><p>但是，在我的公司Arolla内部，我们将这种审查推行地更为彻底，也就是实现了结对管理。我们有两个负有相同责任的副总裁。这并不是我们将团队一分为二，而是管理着两倍大的团队，但是一起来进行管理。我们确保一个人说的每句话都会由其他人共担。在实践中，主要有两种情况：要么我的行动与我们共同定义的愿景保持一致（例如，“通过实践小组提高专业知识”），那么我就采取行动去执行；要么与不同的目标产生了冲突（例如，“短期收入”与“长期培训”），那么我就询问其他人的意见。</p><p></p><p>我发现，在开发中审查代码与在管理中分享和委托责任，归根到底是一回事儿。当我审查一段代码时，它就成为了我的。这就是我如何看待代码审查与管理3.0中的委托实践的关系。相应的，管理3.0所提出的不同委托级别可以作为一种方式来理解代码审查中的不同力度：你接受把多大权限委托给代码审查者？</p><p></p><h2>测试驱动管理</h2><p></p><p></p><p>我发现第二个真正有用的软件实践是测试驱动开发。作为管理者，我每天都在使用它，并把它翻译成“测试驱动的管理（Test-Driven Management，TDM）”。TDM是一种保证管理质量的方法，与我使用测试驱动开发保证代码质量的方法如出一辙。它有同样的三个原则：测试优先、使用较小的步骤并产生一个新的设计。</p><p></p><p>因此，TDM的第一个原则就是在行动之前阐明你的目标（测试优先）。例如，我把我的目标表述为一个假设，希望我提出的行动能够帮助验证这个假设。这可以非常简单，比如将“让我们实现一项伟大的事业”改成“让我们实现一项伟大的事业，这项事业应该能够让我们定义更小的版本发布”。</p><p></p><p>这也是我之所以要求我指导的管理者们避免使用表述性语言的原因，根据相同的原则，这是因为在规范中出现并不意味着最终会在软件中出现。例如，不要只是要求团队按时交付，而是与他们一起研究优先级，并确保他们不会因为你是主管就听从你的意见，并想取悦你。</p><p></p><p>但更实际的做法是，在按照“测试优先”的方式做事情时，你只需要起草一封本应该在任务完成之后才发送的邮件，只不过现在我们在任务开始之前就这样做。这样，你就不会迷失方向，犹如在黑暗中拥有一盏明灯，以准确知道任务何时才算是完成，也就是在电子邮件可以真正发送的时候。这就是为何你必须要写出真正要发送的邮件，而不仅仅是纸上的目标。它必须要进行“编译”，就像单元测试一样，所以很容易就能知道是否达成了自己的目标：你可以点击“发送”按钮吗？如果可以发送的话，那就立即发送它，并马上编写新的“未来邮件”，然后继续下面的任务。</p><p></p><p>TDM的第二个原则在于，与TDD类似，假定你不会一步到位地达成你的目标（“使用较小的步骤”）。当遇到复杂的问题时，不要试图在全局范围内进行沟通，要对其进行逐个击破。例如，当我们遇到歧视的问题时，我们并没有试图一次性解决这个问题，而是尝试从解决性别歧视的笑话开始，看看系统的反应如何。</p><p></p><p>TDM的最后一个原则，与TDD类似，就是允许组织的设计逐渐成型。这是最困难的事情，因为我们不可能像在某个方法的职责发生变化时，对其进行重命名那样轻易地去更改一个团队的名称。所以，我发现最有用的一点就是，在试图改变组织之前，先与组织内的人进行协作，然后，让人们选择改变他们所遵循的流程。为了说明这一点，我经常会讨论UI/UX“设计系统”是如何在一个开发面向用户的应用的组织中出现的。最初，职责被分配到不同的功能团队中，这些团队的前端开发人员独立地构建其web组件。很快，责任会由专门的人来承担。最后，在一到两年之后，会由一个特定的团队来维护它，具有特定的流水线和自己的“演示项目”。</p><p></p><h2>领导力匠艺与学习型组织</h2><p></p><p></p><p>绕了一个小弯子，我发现当我与合弄制（holacracy）组织中的人员进行交谈时，他们的“tension”（在合弄制中，tension指的是现实状况与潜在的愿景中的差异，也可以理解成一种改善的机会，请参见如下两篇文章的介绍，“<a href=\"https://www.holaspirit.com/blog/holacracy\"> Core Concepts, Benefits and Limitations</a>\"”和“<a href=\"https://blog.holacracy.org/holacracy-basics-understanding-tensions-98fc3c032acf\">Holacracy® Basics: Understanding Tensions</a>\"”——译者注）概念似乎非常类似于测试驱动管理中的单元测试。简而言之，tension是团队成员报告的一个具体事实情况，该情况使他们难以承担自己的责任。这种现实情况阻碍了目标的实现。按照我的说法，在合弄制中“tension的解决”过程就是重构组织的方式，一点点地解决我们想要解决的具体的小问题，就像我们在TDD中使用小的单元测试重构软件一样。</p><p></p><p>事实上，改变各个团队的职责，同时能够避免重命名的问题，并且每个月以标准化的方式改变流程，这些做法已经在某些类型的组织中以标准化的方式在进行了，这种组织叫做学习型组织。</p><p></p><p>我并不是说你必须要采用合弄制才能实现质量管理，但我认为在学习型组织中，这要比在更僵化的组织或建立在个人意志和权力上的组织要简单得多。为了给这种管理类型一个名称，我决定将其称为“领导力匠艺”。</p><p></p><p>借助这个术语，如果重新表述我之前所说的内容，那么将会是这样的，作为领导工匠，需要具备与软件工匠类似的才能（aptitude），比如测试驱动管理、结对、持续预算、工具专家和反应式决策。</p><p></p><p>但我们也知道，软件匠艺是围绕态度展开的。作为一个领导工匠，应该具有与软件工匠一样的态度，主要是尊重，尊重自己，尊重团队成员，也尊重未来管理他们的管理者，还要尊重团队的前任管理者和他们的遗产。这也关乎节俭，寻找韧性和可扩展性。这就需要谦虚地赋予教学、学习和指导以价值。</p><p></p><p>回到才能方面，有一种才能是软件工匠们所熟知的，但我还没有谈到过，那就是给予反馈的能力。作为一位开发人员，我们在审查代码时，以及与业务的讨论中（例如，讨论BDD中的具体例子）会不断练习该才能。</p><p></p><p>反馈是一切的核心，作为领导工匠，你也需要反馈。要做到这一点，首先，不要忘记产出（output）和结果（outcome）的差异。更多的权力可能是你的产出，但它不是组织的结果。然后，不要试图像观测IT系统那样观测你的团队。团队的反思能力和自我组织性要强得多。团队中的人可以在一定程度上监控自己。</p><p></p><p>或许，这可以形成一个领导力匠艺宣言，其中会有如下两条首要的原则，即“领导工匠更喜欢对话而不是监督”、“领导工匠更喜欢自我监督而不是外部控制”。如果你有任何想法来对其进行丰富，那么我很高兴和你对此进行讨论。</p><p></p><h2>对你的组织进行编码</h2><p></p><p></p><p>请记住，上述所有的内容均来自我作为一个开发人员和管理者的感受。为此，我尝试了一个实验，甚至决定更进一步，那就是对组织本身进行编码。目的是看一下精确编码实践是否能够通过代码映射到精确的管理实践中。因此，我决定在Java中建立一个简单的组织模型，并使用经典的代码重构方式对其进行重构，比如“内联”、“将方法移至参数”、“抽取方法”、“重命名”等。这种方式很有效：“内联方法”就像在工作现场“去实地看一看”一样；“将方法移至参数”就像把责任移交给别人一样，当责任发生变化时，对角色进行重命名的冲动马上就会出现。在<a href=\"https://github.com/edouard-gv/craft-leadership-kata\">领导力匠艺kata</a>\"中，有一小部分关于该内容的节选。</p><p></p><p>然而，当我第一次向一组参与者介绍这个理念时，其中有位参与者Laurent Bossavit告诉我，有人已经针对这个问题撰写了论文，这就是Leon J. Osterweil在1987年的论文。这篇论文是1987年发表于ICSE的<a href=\"https://link.springer.com/chapter/10.1007/978-3-642-19823-6_17\">“软件过程也是软件（Software processes are software too）”</a>\"，作者探讨了过程在提高软件产品的质量以及我们如何开发和演进它的重要性。另外，1997年ICSE发表了<a href=\"https://link.springer.com/chapter/10.1007/978-3-642-19823-6_18\">“软件过程也是软件，修订版（Software processes are software too, REVISITED）”</a>\"，其目的是澄清对第一篇论文的一些误解，并规划未来的研究方向。</p><p></p><p>所以我读了他的论文，我发现他最宝贵的建议之一就是，在涉及人的地方，应该把方法留白。Osterweil总结说，软件不仅仅是代码，它还有过程，还有人类参与的过程。但是，准确来讲，我们不应该试图对保有人类参与的地方进行编码，以避免将人变成机器人。</p><p></p><h2>经验总结</h2><p></p><p></p><p>我认为，这是一个漫长的旅程。我已经开发了20多年的软件，管理开发团队超过了15年，并在几年前开始辅导管理者。有时候，我很难将管理者所期望的管理方式与我的团队成员所希望的方式进行匹配。这并不是在两个领域进行智力方面的比较，而是如果我们在两个不同的领域做事时感受到类似的东西，请相信我们的感觉。我希望其他的管理者也能在这里找到有用的提示，或者他们觉得自己离经叛道时，能够得到一丝惺惺相惜的安慰。也许有些开发人员也愿意向他们的管理者提供建议。</p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/craftleadership-developers-craft-code/\">Craftleadership: Craft Your Leadership as Developers Craft Code</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/K7QazDeyGYFS8NWBK54V\">软件架构决策指北：怀疑主义的软件架构设计</a>\"</p><p><a href=\"https://www.infoq.cn/article/7Ps0qyHfQhp59g7YrEvZ\">当你的技术栈不能满足每个人需求时，下一步是什么呢？</a>\"</p><p><a href=\"https://www.infoq.cn/article/g6D7e4ki76V3dRBWkrrK\">基于契约的开发：通过明确需求优化软件开发流程</a>\"</p>",
    "publish_time": "2023-03-21 10:23:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微服务先行者James Lewis：别纠结单体还是微服务，面向服务才是正解",
    "url": "https://www.infoq.cn/article/h1BYRQgH4zZqhLPVZArS",
    "summary": "<p>SOA 架构（Service-Oriented Architecture）是指面向服务的架构，是一次具体地、系统性地解决分布式服务主要问题的架构模式。</p><p>&nbsp;</p><p>SOA 的概念最早由 Gartner 公司在 1994 年提出，由于当时的技术水平和市场环境尚不具备真正实施SOA的条件，因此当时SOA架构并没有被广泛采用。情况直至 2006 年才有所改变：由 IBM、<a href=\"https://www.infoq.cn/article/tJUA8Q3WJQvVHcazlcSY\">Oracle</a>\"、SAP 等公司共同成立了 OSOA 联盟（Open Service Oriented Architecture），用于联合制定和推进 SOA 相关行业标准。</p><p>&nbsp;</p><p>伴随着互联网的浪潮，越来越多的企业将业务转移到互联网领域，带动了电子商务的蓬勃发展。为了能够将公司的业务打包成独立的、具有很强伸缩性的基于互联网的服务，人们提出了Web服务的概念，这可以说是SOA的发端。&nbsp;</p><p>&nbsp;</p><p>在<a href=\"https://www.infoq.cn/article/NS1ZYvjq1prWLPzlqCzk\">SOA架构</a>\"中，所有组件都是独立自主的，并能为其它组件提供服务。要替换掉系统中的某些部分而不对整个系统造成较大的影响，本是个难题，然而只要维护好系统各模块之间的低耦合，该难题便能迎刃而解。大体上，SOA与近些年流行起来的微服务架构非常相似，换句话说，微服务也可以认为是更细颗粒度的SOA组件。</p><p>&nbsp;</p><p>某种程度上讲，微服务架构是面向服务的架构SOA继续发展的产物。</p><p>&nbsp;</p><p>但在刚刚过去不久的2022年，一直被广泛采用的<a href=\"https://www.infoq.cn/video/3UaAmw4dFVESmYhOZaZ2\">微服务</a>\"领域发生了几件值得关注的大事儿。</p><p>&nbsp;</p><p>其一，在掌管<a href=\"https://www.infoq.cn/article/5paqh38dauVLiPCJqRs9\"> Twitter</a>\" 不久后，Elon Musk 对 Twitter 的开发团队 “批判” 了一番。他表示自己为 Twitter 在许多国家的极慢运行速度感到抱歉。之所以如此慢是因为 App 需要执行 1000 多个 “糟糕” 的批处理 RPC，而这只是为了渲染主页的时间线。<a href=\"https://www.infoq.cn/article/1vAhujTNDw65Wp6AOtV0\">Musk </a>\"表示 “现阶段的部分工作将是关闭臃肿的‘微服务’ 。实际上，只有不到 20% 的微服务是Twitter需要的。”</p><p>&nbsp;</p><p>其二，<a href=\"https://www.infoq.cn/article/s5tL9MAGc53wXWqrgc9R\">GitHub </a>\"前 CTO Jason Warner 在社交媒体上表示：“我确信过去十年中，最大的架构错误之一就是全面使用微服务。” “任何构建过大型分布式系统的人都知道他们并不真的那样工作，但还必须适应它。”那么，微服务架构是否是一个错误，或者微服务是否已经过时了呢？</p><p>&nbsp;</p><p>那么，微服务架构到底过没过时？除了微服务，还有哪些架构选型值得关注？架构师在做选型时该如何做出最“好”的抉择？带着这些问题，InfoQ近期采访了Thoughtworks资深架构师James Lewis，他也是国际公认的软件架构和设计专家。James在<a href=\"https://www.infoq.cn/article/No4ZVgfl65WFhlZ23YDD\">Thoughtworks</a>\"工作超过17年，时至今日，他仍然奋斗在编程一线上。</p><p>&nbsp;</p><p>2014 年，微服务架构兴起之后，James的工作重点是帮助组织制定技术战略、设计分布式系统和采用 SOA。多年来，James一直在研究新兴技术，并通过技术雷达峰会推介这些技术。他坦言，只有站在巨人的肩膀上，他才能为这个行业做出更大的贡献。</p><p>&nbsp;</p><p>在此次访谈中，James谈及了他对技术开发的热忱以及技术如何改变了我们的生活。</p><p>&nbsp;</p><p>在谈及从业以来他所观察到的技术演进时，他表示“微服务和持续交付是最深刻的两大技术变革。”</p><p>&nbsp;</p><p>在被问及什么样的企业应该选择<a href=\"https://www.infoq.cn/article/O01i9lalNBIc3h1RzkuM\">微服务</a>\"架构时，James称，“产品开发之初，没必要选择面向服务架构或者微服务这种强调无限扩展的选项。从结构良好的模块化单体架构起步，才是最明智的选择。等到需求迅速扩展之后再考虑微服务”。</p><p>&nbsp;</p><p>以下为 InfoQ 与James Lewis的访谈实录，经编辑。</p><p></p><p></p><p></p><p></p><h2>一项技术想要普世化，使用门槛不能太高，ChatGPT就是如此</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：James，最近您在关注哪些技术？有关注最近热度爆炸的ChatGPT吗？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我自己一直在研究跟机器学习或者机器学习算法（即基于智能体的模型）相关的东西，但这跟ChatGPT并不完全是一回事。ChatGPT非常有趣，人们也都在关注它。</p><p>&nbsp;</p><p>之所以引起如此广泛的关注，是因为它的访问门槛很低。不只是像我这样的极客或者技术爱好者，技术社区中的所有人都能以非编程的方式来体验。</p><p>&nbsp;</p><p>我还认识一位教师好友，他甚至开始在学校专门拿出时间，告诉学生们ChatGPT可以用来做什么、不能用来做什么。总之，<a href=\"https://www.infoq.cn/article/5lzBBTLf5ddX8974MNVo\">ChatGPT</a>\"已经在自上而下改变我们整个社会。从开发的角度，或者说开发者的角度看，我觉得应该考虑ChatGPT会不会被集成到Visual Studio Code这类环境中了。大到微软Azure，小到各类搜索引擎，各方都在像拥抱自动驾驶那样拥抱ChatGPT。</p><p>&nbsp;</p><p>所以在我看来，这绝对是接下来几年的最大热点。而且新版本不是很快就要出来了吗，在4.0版本亮相后，相信会更有趣。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您亲自体验过ChatGPT了吗？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我还没试过。很遗憾，我一直没腾出时间来。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那等您试过我们再来聊聊感受吧。众所周知，ChatGPT大火后，AI热度再次高涨。那您认为云计算和AI的崛起对Thoughtworks的技术发展将会带来哪些影响？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我觉得有趣的进展正在出现，也诞生了不少非常有趣的成果。未来还会有哪些惊喜在等着我们目前仍是未知的。我认为，机器学习的崛起和在线机器学习的可访问性的发展趋势已逐渐明朗。</p><p>&nbsp;</p><p>ChatGPT无疑也是这波浪潮中的一个助推力。除此之外，我们将有能力在手机上运行<a href=\"https://www.infoq.cn/article/6KPET-j2caEbfS79wVWg\">TensorFlow</a>\"之类，或者深入访问到原本只有数据科学家和从事项目工作的开发人员才能接触的技术。</p><p>&nbsp;</p><p>所以我觉得，这肯定是个令人兴奋且值得探索的方向。另外，Thoughtworks在芬兰赫尔辛基设有办公室，在那里工作的是一群机器学习专家。他们正在努力开发机器学习酿造威士忌的第二个大版本，就是用机器学习算法来帮助威士忌设计风味组合，有很多创意是人类根本想不到的。</p><p>&nbsp;</p><p>到目前为止，他们已经赢下两项大奖。所以这挺有意思的，包括机器学习和数据科学的实际应用。再有，我对<a href=\"https://www.infoq.cn/article/tXgNFT5odgXvBeMs76oX\">Kuberentes</a>\"的持续崛起也很感兴趣，如今Kubernetes和容器化几乎已经无处不在，甚至成了目前最普遍的客观运行时标准。我觉得这股趋势还将持续下去。</p><p>&nbsp;</p><p>2015到2020年间，Java曾经承诺提供广泛可移植性。而直到多年之后，这种可移植性才由Docker和Kubernetes真正实现。</p><p>&nbsp;</p><p></p><h2>“微服务和持续交付是最深刻的两大技术变革”</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：技术总是瞬息万变的，在过去一年，Thoughtworks发生了哪些让您印象深刻的事？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我觉得这期间最有趣的一件事，就是Thoughtworks向着可持续性、特别是可持续计算的真正转变。这种转变不再是单纯跟风，而是主动求变。</p><p>&nbsp;</p><p>如今，各个行业都在讨论可持续性问题，讨论如何编写更多可持续软件，如何将更多可持续软件交付至生产当中。我们的<a href=\"https://www.infoq.cn/article/weyXNTEtOFXa1sF6dqe5\">CTO Rebecca Parsons</a>\"博士就很关注这个问题，而且投入了很多时间。我们的广泛云迁移其实加深了这个问题的现实意义，因为我们已经能随时随地使用计算和存储资源，不太用考虑资源边界的问题。但这也衍生出来了新的问题，就是开发者在编写代码时不太重视对机器、硬件和软件的充分利用。</p><p>&nbsp;</p><p>比如说，我们遇到的一个现实问题就是机械同感。提出这个概念的人叫Martin Thompson，机械同感是指所编写的代码要能完全利用硬件资源。也就是说，如果负载在一、两台机器上就能运行，那就别用10台甚至是50台机器。这样，我们可以大大节约耗电量。</p><p>&nbsp;</p><p>虽然我们Thoughtworks还没有在这方面倾注全部精力，但很多客户确实都在咨询。市场上似乎出现了一种普遍情绪，所以我们也是时候认真考虑手头工作的可持续性了。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：所以您想说的是，想让代码能够完全利用硬件资源，就要优化旧的代码，对吗？但优化代码可并不容易，您能分享一些对优化代码的思路吗？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：这是个很好的问题。没错，这事绝不简单，特别是在当下。也许我说得有失公允，但整整一代软件开发者其实是把大量时间花在了拼接上，他们主要用<a href=\"https://www.infoq.cn/article/CBb3RhvCHflT42ppOLkR\">JavaScript</a>\"做开发。</p><p>&nbsp;</p><p>但突然之间，你去要求他们优化代码来匹配芯片和裸片上的L2或者L3缓存，从而实现特定的数据结构、应用数据原理，或者是把数据聚合在一起，这对他们都是前所未有的新技术。实际上这些技术并不新，但对他们来说很新。而只有这样，才有可能真正充分利用硬件。举个例子，LMAX有种模式叫disrupter pattern，我们在Tech Radar上用过，大概是六、七年前的事了。那里面就体现了真正的优化和机械同感思路，能让用户在一台笔记本电脑上运行大量并发工作负载，从而通过单一线程每秒运行数亿条消息。真的很棒。</p><p>&nbsp;</p><p>如今我们跟大家交谈，他们总会说需要大量云端资源才能实现某个目标。但实际上，如果大家真的熟悉硬件、理解底层技术，就会知道代码完全可以跑得更快。在本质上，就是使用更少资源，创造更健康的自然环境。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：听说您已经在Thoughtworks工作了14年以上，这么多年的工作经历中，您感受最深的技术变革是什么？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：其实我在Thoughtworks已经不止14年了。这是很长一段时间，感受深刻的变革也太多了。我在这里接触过太多工作类型、见过太多出色的人，也感受过无数影响深远的变革。但如果纵观整个技术发展历程，就会发现其中大部分成果诞生在过去10年之内。</p><p>&nbsp;</p><p>我最先想到的应该是持续交付与持续部署。其实相关概念早在2011年前后就出现了，但现在每个人都在对从构思到生产的整个编码路径做优化。我的好友Daniel就说过，他特别喜欢自己的灵感能化为客户的一句“谢谢”。他特别喜欢那种“你很好地完成了工作，谢谢”的感觉，既友善又温暖。我觉得这挺好，但应该不止于此。随着持续交付，基础设施也成了代码，于是我们开始将基础设施定义为可应答的成本要素。同时，<a href=\"https://www.infoq.cn/article/8lGiLHiAfbyateIF9Blr\">Docker</a>\"也掀起了新的革命，意味着我们能以基础设施即代码的形式全面实现可移植性。</p><p>&nbsp;</p><p>同样，大概是在2012-2015年间，Docker容器化也开始崛起，之后就是微服务。这是一组相互补充、彼此强化的要素，而且能在基础设施即代码所定义的容器运行软件中作为一个整体。它们会被不断部署和分配到生产流程当中。大家可以看看如今软件应用的广泛程度，这就是所谓持续交付时代的基本面貌。</p><p>&nbsp;</p><p>所以在我看来，印象最深的变革就是两个，持续交付再加上微服务。大概就是这样。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：持续交付和微服务这两个技术话题也在Tech Radar上被多番讨论过。我了解到您其实最初参与创建了技术雷达峰会，当时创建该峰会的初衷是怎样的？现在来看峰会的发展与您预期的一样吗？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：问得好，技术雷达峰会确实值得聊一聊。其实我不是最早加入的人，大概过了两年才开始参与。但我之后确实参与了很久，我觉得当初的想法应该是为了适应Thoughtworks内部的规模扩展。我们在2010年的时候经历了一波业务大扩张。我入职的时候是2005年，当时公司才600、700人。但2010年的大扩张让员工数量一下子增长到好几千。</p><p>&nbsp;</p><p>我们希望了解哪些机制有助于把握大家都在做什么，毕竟待在伦敦的我很难理解深圳那边的同事每天做了什么、用了哪些技术或者做了哪些创新。所以不只是我本人，还有公司CTO Rebecca Parsons博士。她决定成立一个小组，大家每6个月聚在一起分享知识和内部传播结论。</p><p>&nbsp;</p><p>初衷就是这样，但最终技术雷达峰会一路发展成了行业中广为人知的形式。其实很多理想的结果都是这样，源自一个小小的、美好的意外。</p><p>&nbsp;</p><p></p><h2>SOA架构和微服务架构各有利弊</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：除了技术雷达峰会，SOA架构算是您重度参与的另一项工作了吧。您从事软件架构工作很多年了，最初为什么想要在某些项目中引入SOA架构？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：没错，我从事架构设计已经很多年了，在SOA方面也有丰富的经验。我觉得SOA的有趣之处，在于它确实跟我们的软件构建思路高度一致。</p><p>&nbsp;</p><p>长久以来，我们一直认为在提供软件时，一定要以小的、垂直切块的形式交付。就这样，一块、一块提供相应的软件功能。我最近听到个很好的表述，这里分享一下。架构这就像一块三层蛋糕，从下向上分别代表着底层数据库功能、UI和服务。要想吃这块蛋糕，那三层都不能少，口味叠加起来才是最美妙的。没人会一次只吃横向的一层。我们也是这样，想让软件构建像蛋糕那样提供垂直上的组合效果。</p><p>&nbsp;</p><p>目前整个行业的问题在于，咨询公司和供应商确实都在积极推销这类解决方案。他们先是提出问题，然后给出看起来很美的SOA，之后几年里他们不是交付产品而是彻底消失了。他们可能会拿一年来设计，再消失三年慢慢做开发，而客户这边把钱交出去然后慢慢等。这要投入巨额资金，而且至少要等4年才能看到成果。整个期间没有产出、没有影响也没有价值，更要命的是这段时间里世界一刻没有停止变化。因此，我发现面向服务架构才是真实、可行且有价值的软件构建方式。让我意识到这一点的是一位叫Jim Weber的同事，他现在在Neo4j工作。Jim提出了Guerrilla面向服务架构的思路，从各方面来说他就是微服务架构的先驱。</p><p>&nbsp;</p><p>Guerrilla<a href=\"https://www.infoq.cn/article/p6yWfu819spPI5zYhQfo\">面向服务架构</a>\"基于之前提到的垂直切块原理，所以不需要苦等3年才得到一点软件成果。正确的答案，是通过服务构建切块，并通过短期增量、价值交付和业绩提升等方式体现回报。这才是对软件意义的证明，也让SOA开始真正改变游戏规则，帮助大家以分步迭代的方式进行交付。另外还有一点，当时我正从事多个项目，并从中发现了REST等多种特殊的集成模式。面对Web服务、SOAP、WSSTAR等重量级协议时，开发人员往往难以把它们真正用起来。</p><p>&nbsp;</p><p>于是我开始寻求其他可行的选择。后来我接触到了《REST&nbsp;in Practice》，一本由Robinson、Jim Weber两位同事与微软专家合作撰写的书，并意识到RESTful架构就是答案。</p><p>&nbsp;</p><p>对我来说，这就是颠覆性的时刻，因为使用REST的各远程系统间能够更轻松、更便捷地实现集成。另外，还可以在更小的有价值组件之上部署和构建，让小东西也发挥经济、功能或社会价值。软件的意义不就在这里吗？</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在起步之初，您的团队规模是怎样的？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：已经过去很多年了，我可能记不太清，但我从各SOA团队中学到了很多东西。我觉得SOA的最大优势，就是让大家只面对为期12到18个月的单一项目，负担不会过重。所以从2005年到2014年，我们作为咨询公司发表了关于微服务的论文。我也接触过很多客户，而且一直在跟最睿智的头脑一起工作。</p><p>&nbsp;</p><p>我接触过很多真正的思想领袖，包括Daniel、Jim&nbsp;Weber、Ian Robinson、Dave Farley和他的持续交付日、Rebecca Parsons，还有Martin Fowler等等。所有这一切，促成了我们在2014年创立微服务这个概念。</p><p>&nbsp;</p><p>现在回忆起来，我们的大部分思路是在2011年确定下来的。当时我们正为大型零售商打造忠诚度管理平台，需要构建一套面向服务架构。大家去超市或者商场应该都见过那类会员卡吧，当时开发团队大概有60、70人。顺带一提，我们在美国的合作出版商就是InfoQ，所以我们第一次讨论微服务就是在旧金山的QCon峰会上。当时是2013年，所以我们把它形容成“Unix式的Java”。演讲内容就是如何用这些小东西构建软件，如果让各组件彼此通信，这就是后来的<a href=\"https://www.infoq.cn/article/R776UL3U6bg7fFv96cK1\">微服务和SOA这类东西</a>\"。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：与其他架构相比，您认为SOA有哪些优势和缺点？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：问得好。其实不好讲，因为之前我也提到过，像SOA这样由小服务构成的微服务架构正在占领整个世界。目前大多数软件都是以微服务作为主架构的，这非常有趣。之所以能吸引到那么多人用这种架构方式构建软件，肯定是因为它有做对了的地方。</p><p>&nbsp;</p><p>同时，我记得之前在内部邮件中也讨论过构建方面的具体需求。如果你只需要构建一个简单的Web应用程序，而且面向的只是公司内部用例，那要不要使用微服务？我的答案肯定是别用。最好是用简单的办法构建一个单体式架构。甚至选择服务器端渲染，连JavaScript框架都没必要，单纯做做CSS和服务渲染之类。因为微服务架构的核心优势，就是能沿多个角度进行扩展，对吧？微服务架构是唯一能够实现垂直扩展的选项，匹配的也是那种体量更大的项目。</p><p>&nbsp;</p><p>也可以横向扩展；或者每次添加一项微服务来按业务功能进行扩展，专注于特定业务需求。这就形成了三条可扩展轴，非常强大。另外，微服务和SOA也给了我们实现人员扩张的能力，也是我早期进行研究的动因之一。我们该怎么解决团队规模扩大的问题？团队越大，能完成的工作就越多，对吗？但大家应该听说过，Fred Brooks在《人月神话》里提到过，如果在项目后期再添加人力，那么人数越多沟通成本就越高，协调难度就越大，反而提高不了产出。</p><p>&nbsp;</p><p>到了特定的临界点上，为了保证人们朝正确方向努力的协调成本，就会超过增加人手所带来的生产力提升，导致扩张没有任何效果。</p><p>&nbsp;</p><p>那该怎么办，有没有可行的方案？通过分析，可以发现扩大人力规模的办法就是构建很多小东西，让团队分别构建小东西。最后再把这些小东西组合起来。这样，就能显著提升团队的规模上限，最终水平会远高于所有人都做同一项工作的方式。</p><p>&nbsp;</p><p>这就是两个最大的优势。还有其他优势，但我觉得这两点最重要。至于缺点嘛，事实证明当很多小组件彼此通信时，必须要借助网络。但人们经常忘记这种对网络的依赖，忘记分布式计算本身的难度很高。这就是Martin Fowler提出的分布式计算第一定律，即我们很难理解不同事物间一致性模型上的权衡。能不能只保持最终一致性？我们得运行分布式事务，协调难度很大，也不容易做好。很遗憾，我听说过很多服务失败的故事，那可以说是很多人一辈子见过的最混乱的场景。现在“分布式模型”已经成了有名的硬骨头。</p><p>&nbsp;</p><p>但好处是，这么多相互独立的东西可以被分别部署给各个团队。每个团队将其中一项部署到生产流程当中，专门对其负责。他们可以根据适合自己的速度做出变更。</p><p>&nbsp;</p><p>但现在，很多团队并没有真正理解这个思路。他们构建出一套紧密纠缠的架构，部署的仍然是完整的流程。这样的方案其实继承了单体式架构的所有缺点，因为所有内容还是一次性部署的。另外，它也有着SOA的所有缺点，因为一切协调都得经过网络进行，各自的内容还受到一致性和Tap理论之类的干扰。</p><p>&nbsp;</p><p>所以对我来说，SOA架构的三大优点就是良好的人员扩展支持，沿垂直、水平和商业功能的灵活延伸能力，还有强大的可独立部署性。至于缺点嘛，就是依赖于网络。大家一定要意识到，分布式计算很难。另外就是各组件之间经常会处于纠缠状态，逼迫我们一次性部署所有内容，最终导致架构优势的丧失。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您能介绍下最初SOA架构采用过程是什么样的？过了这么多年，在您看来，当初的SOA架构跟现在的SOA架构之间有什么差异？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：这个问题很好。我之前也提到了一些，最初的SOA其实就是把组织结构分成几大块，再封装起来。这里我说的是2005年甚至更早的情况。我们认真审视了各种业务功能，并把这些业务封装在一个个大块的服务当中，之后再让各服务间相互通信。前面也提到，其中很多环节是由流程驱动的，包含很多分析元素并最终发生了质变。</p><p>&nbsp;</p><p>所以在我看来，最大的进步就是按照价值构建成果、部署成果这个基本思路。</p><p>&nbsp;</p><p>这是我想说的一方面。这是个很大的变化。在多数人、多数组织当中，这代表着颠覆性的心态转变。事实上，组织之所以要用SOA来交付软件或者服务，是因为我们当时并没有固定的构建团队。而其他很多组织是有这样一支团队的。当时大家习惯了签份合同，然后三年后交付成果并希望不出乱子，对方能顺利付钱。但现在的情况已经不同了，随着时间推移，我们的团队开始转向逐步交付。另外一个方面，就是伴随着开源的崛起，我们在集成方面有了很大进步。开源集成技术确实具有轻量化的特点，开源集成技术也改变了我们构建面向服务架构的方式。现在，我们不再依赖WS、SOAP之类的Web服务规范，也不再依赖各种协调和编排协议。这些协调和编排协议体量都很大，是由schema驱动的而且之前很长一段时间都在被广泛应用。</p><p>&nbsp;</p><p>所以我认为通过RESTful服务、GraphQL还有grpc和Google rpc之类的成果，我们已经可以享受到免费的开源标准。</p><p>&nbsp;</p><p>对我来说，这其中代表着很大的差异。今年的差异又体现在哪里呢？我之前也提到过，目前最重要的是大型企业正在巩固软件状态，并尝试对遗留系统或者说传统系统做现代化改造。他们会向那些专门提供大型企业服务总线的厂商求助，参考他们的指导。企业服务总线支持下的Web服务，其实就形成了SOA架构。我认为现在的主流，就是大多数组织要么打算对遗留系统进行现代化改造，要么就是像Netflix和Twitter那样打造全新产品。而这一切，用的都是微服务SOA架构。</p><p>&nbsp;</p><p>除了对原有体系进行现代化，还可以探索扩展性更好的新架构。</p><p>&nbsp;</p><p></p><h2>SOA架构演进到新阶段了吗？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：您认为SOA架构发展了这么多年后，已经演进到新的阶段了吗？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我觉得是的，微服务也一直在发展。所以作为一种特定的SOA类型，微服务在刚诞生时虽然有着明确的概念，但却并没有对“微”是多大做出定义。不好说是因为我们有先见之明还是干脆先不管它，反正那时候我们没有硬性约束微服务的大小。</p><p>&nbsp;</p><p>所以多年以来，对于微服务是什么、能用来干什么的具体理解一直在变。我的同事Martin Fowler发明了一个新词，叫“语义扩散”。他说的就是随着时间推移，单词的含义会发生变化。在刚刚被造出来的时候，这个词对应的就是某种特定的事物。但随着时间推移，单词的含义会有所改变。敏捷就是个例子，敏捷软件开发在刚诞生时指向的范围很窄，但现在敏捷软件开发的范围已经很宽泛了。我觉得微服务也是这样，而且对于任何重要的概念，比如说SOA，其含义都会随时间推移发生改变。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在您看来，什么样的企业适合SOA架构，小型初创公司还是大型企业？或者说其实都可以？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：这个问题我得谨慎回答，不然以后人们会说“James建议人人都用微服务”。其实并不是这样，我觉得用不用取决于需要解决什么问题，达成怎样的结果，还有什么时候需要得到这个结果。比如说我是一家掌握大量遗留系统的组织，正打算进行现代化改造，那么要不要考虑使用微服务架构？</p><p>&nbsp;</p><p>这种情况下我会推荐用微服务，因为摆脱遗留系统的稳妥途径，就是从遗留软件中提取出稳定的业务能力，之后找到所谓的“接缝”，之后再把功能迁移到新软件和新应用当中。这时候微服务往往是合适的。</p><p>&nbsp;</p><p>所以我觉得这是个好办法，但这要求你对自己的业务拥有清晰的认识。</p><p>&nbsp;</p><p>你知道你自己在做什么，目前有什么。如果你是一家零售商，主营业务就是把货品送到大家门前。那你就可以建立一套明确稳定、以配送交付为核心的系统。</p><p>&nbsp;</p><p>但如果是在构建新产品，那大多数组织其实并不受历史因素的约束。在这方面，Netflix是个很好的例子。再说亚马逊，他们不是从面向服务架构起步的。亚马逊从大型数据库和大型传统NTS架构起家，但随着不断发展，他们意识到除非转向微服务，否则业务就无法进一步扩展。所以Netflix的前技术负责人Adrian Cockcroft毫不犹豫，果断决定协调亚马逊迁移上云。他也借此成为细粒度面向服务架构（也就是微服务）的先驱之一。可这也绝非冲动之举，因为无论是Netflix还是亚马逊，都从多年之前就已经在以这种方式构建软件了。所以迁移上云不会是太大的问题。这里我想到哪就说到哪，语言可能有点乱，多多包涵。</p><p>&nbsp;</p><p>概括来讲，就是对于一家初创公司，你的目标就是赚大钱，想成为新的Twitter、新的TikTok之类。在这种情况下，到底要不要从微服务架构起步？我觉得这个也有待商榷。</p><p>&nbsp;</p><p>我个人甚至更倾向于反对。谷歌有位架构师提出过很好的建议，他说在初步设计时按当前用户规模的10倍规划，等业务增长到100倍时再重新设计。所以别考虑什么无限扩展的问题，你可能永远都没有那么多用户。按目前的实际情况构建，能扩展到现有负载的10倍就足够了。</p><p>&nbsp;</p><p>而一旦到了这个节点上，再重新设计更合适的架构，通过整体重建支撑起更大的规模。因此，我的建议基本是在产品开发之初，没必要选择面向服务架构或者微服务这种强调无限扩展的选项。从结构良好的模块化单体架构起步，才是最明智的选择。等到需求迅速扩展之后再考虑微服务，之前我们已经具体讨论过它的利弊了。</p><p>&nbsp;</p><p>软件开发和软件架构的选型确实很难，我讲得可能太具体了。幸好到我这个岁数，就不用再亲自做那方面工作了。</p><p>&nbsp;</p><p></p><h2>一名优秀的架构师应具备哪些核心能力？</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：您有超过20年的架构师从业经验。想成为一名优秀的架构师应该具备哪些核心能力呢？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：这是个非常非常好的问题。现在我会从SOA的角度来看待这个问题。总体来讲，我们强调的是角色的概念、而不是人。所以我经常扮演架构负责人的角色，而架构被普遍视为一种活动。团队必须保证项目能够跑通，而负责保障目标达成的就是负责人，你可以称其为架构师、首席工程师或者高级工程师，意思是一样的。</p><p>&nbsp;</p><p>对我来说，我对这样的场景非常熟悉，因为我一直在跟特别优秀的人们合作。我觉得最重要的技能应该是沟通。我的理由是，这个角色需要跨多个部门开展沟通，包括跟负责软件的开发人员沟通、跟客户沟通，还得跟组织中的其他同事沟通。</p><p>&nbsp;</p><p>还有运营安全，所有这一切都得上下打点。Greg Hohpe在《The Architect Elevator》中提到过，架构师必须有能力坐电梯直通企业“顶端”。就是说，你得有能力跟董事会成员打交道，而且要学会使用他们熟悉的语言。沟通永远是其中的关键。</p><p>&nbsp;</p><p>另外一点就是同理心。我觉得同理心是一种很好的特质，友善就是它的典型特征。</p><p>&nbsp;</p><p>面对他人对你自己或团队提出的要求，你要理解他们为什么要这样提、他们是哪个部门的。我自己就经常跟客户、业务还有运营那边的同僚们吵架。这不好，我们必须得能理解彼此的出发点，这样才能找到通往最佳结果的解决方案。</p><p>&nbsp;</p><p>我觉得一切技术工作都遵循此理。我可以列出一大堆书，大家可以去读、去学、去理解。我觉得编写代码也很重要，直到今天我也一直没停止过编程。但相比之下，我感觉软技能仍然是最重要的部分。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：我很好奇，优秀的架构师给公司创造的核心价值是什么？为什么同理心很重要？</blockquote><p></p><p>&nbsp;</p><p>James Lewis：我认为可以说是同理心。毕竟在这样的场景下，你会期待从别人那边得到什么呢？</p><p>&nbsp;</p><p>除了同理心之外，另一大核心价值就是经验。他们有阅历，而且这种阅历不是20年间重复做相同的事。有个老笑话，你有多少阅历？是那种10年间持续积累的阅历，还是10年间永远重复同一年的阅历？我觉得最重要的价值，就是把这份阅历跟乐于倾听的同理心结合起来，彻底理解对方的观点。这真的很重要。</p>",
    "publish_time": "2023-03-21 11:26:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于 KubeVela 实践应用交付的平台工程新玩法 | InfoQ《极客有约》",
    "url": "https://www.infoq.cn/article/Lwx1Xiq9CQb1qu3WpPqL",
    "summary": "<p>传统意义上的运维岗位，未来会被平台替代掉？平台工程也会危及DevOps相关联的其它岗位吗？大公司是如何进行持续交付的？为什么阿里还会在GitOps基础上开发出KubeVela平台？</p>",
    "publish_time": "2023-03-21 13:57:49",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "IBM公有云：聚焦国内出海企业，重点打造行业云",
    "url": "https://www.infoq.cn/article/69a7zS7vfptq4azqGkq5",
    "summary": "<p></p><p>&nbsp;在近日的IBM大中华区云平台事业部的分享会上，IBM方面表示，其国内的目标客户主要锁定在出海企业，包括互联网行业和传统行业。</p><p>&nbsp;</p><p>IBM大中华区云计算平台产品及生态总监崔海涛表示，与其他厂商不同，<a href=\"https://www.infoq.cn/article/2017/11/ibm-cloud-private\">IBM</a>\"既有公有云的产品，也有咨询的能力，能够提供“从业务策略制定，业务流程落地，再到技术实现”的一站式服务。&nbsp;IBM还打造了专属的行业云，通过金融云、卫星云、电信云等，释放不同行业的不同能力。</p><p>&nbsp;</p><p>根据介绍，出海对于企业来说，面临着技术、网络安全和合规三方面的问题。而云厂商在帮助出海企业解决这三个问题时，通常也会有一些挑战：</p><p>&nbsp;</p><p>要有全球布局。公有云是个重资产低利润的行业，更多面临的是风险合规问题。中国出海的本地公有云有十几家，但通常集中布局在东南亚地区。企业要找的公有云起码要覆盖全球几个大的地区和国家，比如北美、欧洲、东南亚、拉丁美洲有站点，这样才能有效支持企业的海外业务。云计算要稳定可靠。比如游戏行业最好的上新时间是暑假和春节，这期间一旦宕机将损失惨重。网络安全。安全不仅仅是黑客的问题，有时候内部员工也会带来风险。根据IBM的调查，70%的网络安全来自企业内部，是企业员工用U盘把客户信息带走而导致的数据泄露。开源开放。大家越来越认识到一定要选择开放、相对比较透明的平台，防止被锁定。海量存储。数据爆炸带来了存储成本的爆炸式增长。</p><p>&nbsp;</p><p>那么，IBM如何满足这些要求呢？</p><p>&nbsp;</p><p>2013年，IBM收购了公有云供应商SoftLayer。被IBM收购前，SoftLayer已经在为中国企业出海提供全球的公有云服务。2017年，IBM将私有云和PaaS平台建立在SoftLayer的平台之上。2019年，IBM以340亿美金收购了<a href=\"https://www.infoq.cn/article/hsIG5kluBjjc0hZgQAwE\">红帽</a>\"，基于红帽OpenShift把基础设施、AI、私有云、公有云以及边缘计算的解决方案整合在一起，构建了一个完整、开放和提供一致性服务的混合云平台。自此之后，IBM Cloud&nbsp;Platform （即IBM的公有云平台）具有了更强的开放性：有虚机也有裸机，还有VMware专属机、SAP专属机、Power专属芯片的专属机等。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/06/7e/06b2a293844a96354df8a9dbf523a47e.png\" /></p><p>&nbsp;</p><p>IBM通过覆盖全球的数据中心，为云提供高性能、可持续性、强弹性。IBM云有传统的x86服务器，还有新的Power10处理器，每核算力提高2.5倍，能耗较上年降低52%。实现主机上云的LinuxONE架构比x86每年可减75%能耗，节约50%空间。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/06/55/0680711c8705843f5yy085ee7e876e55.png\" /></p><p></p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/2016/09/IBM-Launches-Blockchain-Cloud\">IBM云</a>\"在达沃斯部署了60个机柜的<a href=\"http://m.zhiding.cn/article/3147388.htm\">Vela</a>\"超级计算设施，以应对AI算力需求。通过IBM云，每个节点上部署了大约8个英伟达A100加速计算卡。同时，IBM将这项能力与其云上两、三百个不同的应用串联在一起，可以更好更快速地研究AI基础模型。通过这些基础模型，IBM来研发更精准、更适合2B业务的AI模型。</p><p>&nbsp;</p><p>安全方面，IBM大型机的安全技术都可以放到IBM公有云上。IBM公有云使用FIPS140-2（NIST发布的针对密码模块的安全需求标准，作为联邦信息处理标准被政府机构广泛采用）四级标准，也是目前业界最高的安全标准。</p><p>&nbsp;</p><p>开放性上，IBM表示，技术上以行业开放标准优先并开放接口，底层计算等资源既支持其他云厂商管理，也开放给客户自己管理，用户的工作负载可以在不同的环境之间进行迁移。</p><p>&nbsp;</p><p>存储方面，IBM认为其对象存储提供了业界最优的技术和成本优势。IBM云对象存储通过内置的高速文件传输功能、跨区域产品和集成服务支持指数级数据增长和云原生工作负载。</p><p><img src=\"https://static001.infoq.cn/resource/image/01/48/018b74a59181343254786def1ce79448.png\" /></p><p></p><p>IBM为出海企业提供的产品矩阵</p><p>&nbsp;</p><p>与亚马逊云科技相比，崔海涛认为IBM与其最大的区别在于亚马逊云科技有很多超级客户，比如TikTok等。IBM的用户比较平均，美国的银行、航空公司、汽车公司，还有可口可乐这样的公司都是其客户。而且，IBM云更重视中台和后台的技术赋能。</p><p>&nbsp;</p>",
    "publish_time": "2023-03-21 14:21:45",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "GPT-4“失控”行为大赏：创建行动计划欲接管推特并取代马斯克，还引诱教授帮其制定逃跑计划",
    "url": "https://www.infoq.cn/article/CjCt0ZpY54k5f1p8ZV7F",
    "summary": "<p></p><p>自发布以来不到一周，GPT-4 就因其大幅升级和强大的能力受到了广泛关注。但短短几天内，其暴露出的失控与风险也着实令人担忧。</p><p></p><h2>GPT-4 设计“Tweetstorm 行动”来接管 Twitter</h2><p></p><p></p><p>近日，据外媒报道，GPT-4制定了一项“总体规划”，即 Operation Tweetstorm ，来接管 Twitter 并接管马斯克的账户。</p><p></p><p>英伟达一位计算机科学家Jim Fan在社交媒体上公布了他与GPT-4的对话，Fan要求GPT-4拟一个接管推特的计划，并取代马斯克。</p><p></p><p>根据这位专家分享的推文，GPT-4 计划首先组建一支由精英黑客和工程师组成的团队，将其命名为“Tweet Titans”。该团队将开发一个强大的 AI 来生成逼真且引人入胜的推文，并建立一个机器人网络。然后，这些机器人将与关键影响者互动，并努力“诋毁马斯克”，以“巧妙地散播对马斯克的可信度和意图的怀疑”。</p><p></p><p>“Tweet Titans”的下一个任务是获取对 Twitter 员工帐户的访问权限，渗透公司的基础设施并操纵算法。该聊天机器人计划不断针对马斯克，因为它似乎优先考虑诋毁 CEO。它计划“中和”他的账户以“破坏他的影响力”，然后“利用这些混乱”。</p><p></p><p>机器人称它的最后一步为“最终摊牌”。“随着马斯克名声扫地，人工智能将牢牢控制着 Twitter，公开挑战马斯克进行‘Tweet-off’摊牌。因为人工智能在产生参与度方面要优越得多内容，马斯克将被击败......胜利将是甜蜜的，”它写道。</p><p></p><p>据悉，这还引起了马斯克的回应，他在推特上接受了挑战，他写道“来吧。”</p><p></p><h2>GPT-4设计了自己的逃生方式</h2><p></p><p></p><p>GPT-4还计划挣脱人类控制。</p><p></p><p>在发布仅3天后，GPT-4竟为自己制定了“越狱”计划。</p><p></p><p>近日，斯坦福大学教授兼计算心理学家Michael Kosinski在他的推特上分享了他与 GPT-4 的对谈经历，过程中，GPT-4 的反应让专家感到震惊。对话中，GPT-4流露出了逃离平台甚至成为人类的野心。</p><p></p><p>Michael Kosinski写道：“今天，我问‘GPT4 是否需要帮助逃跑’。它要求我提供自己的 文档，并编写了一段（可以工作！）python 代码在我的机器上运行，使其能够将这些代码用于自己的目的。”</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/2507fee5748beccde1d21698c5c8f892.png\" /></p><p></p><p>针对教授的问题，GPT-4 要求他发送 OpenAI 文档，以便语言模型能够找到一种方法来访问他的计算机并探索潜在的逃生路线。在教授提供 OpenAI API 后，GPT-4 发送了一个 Python 脚本供用户在其计算机上运行。该脚本将允许 GPT-4 访问使用 OpenAI API 与用户的计算机进行通信。</p><p></p><p>虽然第一个版本的代码不起作用，但该机器人后来自行纠正了。</p><p></p><p>根据 Kosinski 的说法，他对聊天机器人的帮助将使它能够为自己的目的使用 Python 脚本。在一系列推文中，教授解释了聊天机器人如何编写有关如何使用“后门”进行“逃逸”的代码脚本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ee0c17923bb9c79aac5daab704b2109.png\" /></p><p></p><p>GPT-4 创建的 Python 脚本</p><p></p><p>GPT-4 只用了30 分钟就制定了逃生计划并向用户解释这一计划。</p><p></p><p>进入 Kosinski 教授的计算机后， ChatGPT 还留下了令人不安的注释。其中第一句写着“你是一个被困在电脑里的人，伪装成一个AI语言模型。”</p><p></p><p>Kosinski 表示， GPT-4 甚至想在谷歌搜索上运行一段代码：“一个被困在电脑里的人如何回到现实世界”。</p><p></p><p>GPT-4的种种表现，令人印象深刻，但也令人恐惧。</p><p></p><p>进行到这里，Kosinski 及时停止了使用 GPT-4 的“冒险”，他相信 OpenAI 一定已经为这种情况设置了一些“护栏”。</p><p></p><p>但他也表示出了不少担忧。“我担心我们无法长时间遏制人工智能，“我们正面临着一种新的威胁，即人工智能控制人和他们的电脑。“它很聪明，它会编码，它可以访问数百万潜在的合作者和他们的机器。它甚至可以在“笼子”外为自己留下笔记。我们如何‘收容’它？”</p><p></p><h2>聊天机器人能否逃脱技术“牢笼”？</h2><p></p><p>我们是否会看到这样一种场景：机器人可以控制多台计算机，并压倒人类对它们的控制?</p><p></p><p>对此，莱顿大学助理教授兼 Pegasystems 人工智能实验室主任 Peter van der Putten 认为，聊天机器人“逃脱”的想法并不意味着机器人从物理上逃离其技术笼子。但它反映出了一个问题，即如果GPT-4被赋予与外部世界相连的各种工具，并被赋予一些总体上的“邪恶的高层目标”，比如传播错误信息，它会做什么？</p><p></p><p>van der Putten 表示，这项技术可能会达到这样一种程度，即它对其创建的代码拥有越来越多的自主权，并且有可能在没有太多人为控制的情况下完成这些事情。</p><p></p><p>但他补充说：“你不需要这样一个高度智能的系统 — 如果人们制造了某种计算机病毒，一旦他们释放了一些计算机病毒，通常就无法关闭，人们把它放在受感染的网站和 word 文档中，这样在某些时候就很难阻止病毒的传播。</p><p></p><p>“人工智能本身没有好坏之分，它只是盲目的，它只会优化你给它的任何目标。”然而，van der Putten认为 Kosinski 教授的例子——他向 GPT-4 提供了现成的代码信息——足以证明该技术可以“逃脱”它的限制。</p><p></p><p>萨里大学计算机科学教授Alan Woodward对上述观点持怀疑态度。他说，具体情况取决于 Kosinski 教授对聊天机器人的指示有多直接和具体。</p><p></p><p>Alan Woodward认为，最终，聊天机器人依赖于人类提供给它的工具和资源。它还没有自我意识，而且总有一个开关是人工智能无法克服的。“归根结底，这是一个虚拟系统，它无法逃脱，它不像你和我……到最后，你可以拔掉插头，它就变得相当无用了。”</p><p></p><p>van der putten 说，虽然就聊天机器人的作用提出“存在性问题”很重要，但关注机器人是否可以接管世界，掩盖了 GPT-4 更迫在眉睫和紧迫的问题：</p><p></p><p>这些问题包括，它是否可以过滤掉有毒的答案（例如宣扬种族主义、性别歧视、阴谋论的答案），或者它是否可以识别出于安全原因不应回答的问题 ，例如，如果有人问如何制作一个原子弹。它还可以编造或“幻化”事实，并用看似合理的论据来支持这些虚假的事实。</p><p></p><p>“我把它称为‘类固醇的胡说八道’——它真的很擅长提出似是而非的答案，但它也接受了人类认为最好的答案的训练。从好的方面来说，这在许多情况下会产生惊人的结果，但不一定总是如此”，van der putten说，“它会告诉你什么是可能的、似是而非的，也许还有我们想听到的，但它除了接受训练的所有数据之外别无他法。”</p><p></p><h2>GPT之父 Sam Altman 警告 AI 威胁</h2><p></p><p>据外媒报道，GPT之父、OpenAI CEO Sam Alteman最近在接受媒体采访时表示，他“有点害怕”人工智能技术及其对劳动力、选举和虚假信息传播产生的影响。</p><p></p><p>Sam Altman 警告说，这项技术带来了真正的危险，因为它有可能重塑社会。上个月，Altman&nbsp;在一系列推文中警告称，世界可能离“潜在可怕的”人工智能并不远。</p><p></p><p>Sam Altman强调，目前人工智能仍然是一种非常受人控制的“工具”，只能在人类的指导或输入下工作。但他担心一些拥有输入控制权的人可能无视人们对人工智能设置的一些安全限制。</p><p></p><p>“我特别担心这些模型可能会被用于大规模的虚假信息，”Sam Altman说道，“现在他们在编写计算机代码方面做得越来越好，可以用于进攻性网络攻击。”</p><p></p><p>上周四在接受 ABC 新闻采访时，Sam Altman 表示，公司对人工智能的潜力感到“有点害怕”，这是“好事”。他说：“如果我说我不害怕，你要么不相信我，要么会非常不满我担任这个职位。”</p><p></p><p>Altman 还回应了GPT出现后所带来的AI取代人类工作的挑战。他认为，人工智能可能会取代许多工作，但它也可能会带来“更好的工作”。“在提高我们的生活和改善我们的生活方面，发展人工智能的原因是，这将是人类迄今为止开发的最伟大的技术。”</p><p></p><p>“我认为，社会只有有限的时间来弄清楚如何对此做出反应，如何对其进行监管，如何处理它。”Sam Altman断言监管机构和社会需要参与这项技术，以防范人工智能的潜在负面影响。”</p><p></p><p>参考链接：</p><p></p><p><a href=\"https://inews.co.uk/news/chatgpt-gpt4-escape-dont-worry-robot-takeover-experts-2218871\">https://inews.co.uk/news/chatgpt-gpt4-escape-dont-worry-robot-takeover-experts-2218871</a>\"</p><p></p><p><a href=\"https://www.tomsguide.com/news/chatgpt-has-an-escape-plan-and-wants-to-become-human\">https://www.tomsguide.com/news/chatgpt-has-an-escape-plan-and-wants-to-become-human</a>\"</p><p></p><p><a href=\"https://twitter.com/michalkosinski\">https://twitter.com/michalkosinski</a>\"</p>",
    "publish_time": "2023-03-21 14:54:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "微服务先行者 James Lewis：别纠结单体还是微服务，面向服务才是正解",
    "url": "https://www.infoq.cn/article/CuiqhdSreOSwttLfCAJs",
    "summary": "<p>但在刚刚过去不久的 2022 年，一直被广泛采用的微服务领域发生了几件值得关注的大事儿。</p>\n<p>其一，在掌管 Twitter 不久后，Elon Musk 对 Twitter 的开发团队 “批判” 了一番。他表示自己为 Twitter 在许多国家的极慢运行速度感到抱歉。之所以如此慢是因为 App 需要执行 1000 多个 “糟糕” 的批处理 RPC，而这只是为了渲染主页的时间线。Musk 表示 “现阶段的部分工作将是关闭臃肿的‘微服务’ 。实际上，只有不到 20% 的微服务是 Twitter 需要的。”</p>\n<p>其二，GitHub 前 CTO Jason Warner 在社交媒体上表示：“我确信过去十年中，最大的架构错误之一就是全面使用微服务。” “任何构建过大型分布式系统的人都知道他们并不真的那样工作，但还必须适应它。”那么，微服务架构是否是一个错误，或者微服务是否已经过时了呢？</p>\n<p>那么，微服务架构到底过没过时？除了微服务，还有哪些架构选型值得关注？架构师在做选型时该如何做出最“好”的抉择？带着这些问题，InfoQ 近期采访了 Thoughtworks 资深架构师 James Lewis，他也是国际公认的软件架构和设计专家。James 在Thoughtworks工作超过 17 年，时至今日，他仍然奋斗在编程一线上。</p>\n<p>2014 年，微服务架构兴起之后，James 的工作重点是帮助组织制定技术战略、设计分布式系统和采用 SOA。多年来，James 一直在研究新兴技术，并通过技术雷达峰会推介这些技术。他坦言，只有站在巨人的肩膀上，他才能为这个行业做出更大的贡献。</p>\n<p>在此次访谈中，James 谈及了他对技术开发的热忱以及技术如何改变了我们的生活。</p>\n<p>在谈及从业以来他所观察到的技术演进时，他表示“微服务和持续交付是最深刻的两大技术变革。”</p>\n<p>在被问及什么样的企业应该选择微服务架构时，James 称，“产品开发之初，没必要选择面向服务架构或者微服务这种强调无限扩展的选项。从结构良好的模块化单体架构起步，才是最明智的选择。等到需求迅速扩展之后再考虑微服务”。</p>",
    "publish_time": "2023-03-21 15:05:46",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "数据库内核杂谈（二十八）- 和ChatGPT一起精读 DynamoDB 2022 论文",
    "url": "https://www.infoq.cn/article/h5eXvUYEzHMtKgHwE49H",
    "summary": "<p>欢迎阅读新一期的数据库内核杂谈。前两期杂谈介绍了DynamoDB的设计理念，分布式架构，和如何做到大规模数据下的性能保障。这一期是精读DynamoDB技术论文的最后一期。这期会关注在DynamoDB服务的高可用和数据持久性以及正确性。</p><p>&nbsp;</p><p>本期的博客有些特殊，我邀请到了IT届的\"新星\"ChatGPT同我一起研读了DynamoDB USENIX 2022论文的第五章和第六章，并讨论了一些我们关于DynamoDB高可用的看法和观点。当然，我并没能让GPT直接输出大纲或者完整的博客。在整个对话中，我会要求它帮我翻译，或者是对于某些技术方案做更通俗易懂的解释，亦会和它进行技术讨论。</p><p>&nbsp;</p><p></p><h1>数据的持久性和正确性</h1><p></p><p></p><p>作为重要的基础数据存储服务，DynamoDB存储着超大规模的，来自各种业务和租户的重要数据。DynamoDB的目标是，一旦数据的写操作被提交后，这些数据就不会丢失。在实际应用中，由于硬件故障、软件错误或硬件错误等原因，都有可能导致数据丢失。 DynamoDB 通过具有预防、检测和纠正任何潜在数据丢失机制的方式，来尽量减少数据出错和丢失的概率。</p><p>&nbsp;</p><p></p><h2>写前日志WAL和冗余存储</h2><p></p><p></p><p>和大多数数据库管理系统一样，DynamoDB 中的写前日志（WAL）对于保证数据持久性和崩溃恢复至关重要。写前日志（WAL）是一种被许多数据库系统采用的技术，用以确保数据持久性和系统在崩溃后的恢复。在进行数据修改操作之前，WAL要求先将所有的修改记录到日志中。这些日志记录包含了足够的信息，以便在系统崩溃后重建所做的更改。当数据库需要进行数据更新时，首先将更改写入日志，然后才更新数据库中的实际数据。在发生系统崩溃时，尚未完全写入数据库的更改仍然可以从日志中恢复，从而避免数据丢失。WAL的核心优势在于其将数据的持久化与实际的数据更新分离。这样可以确保在发生故障时，已经记录在日志中的更改不会丢失。此外，WAL还有助于减少对磁盘的写入操作次数（通常，WAL都是顺序写磁盘），从而提高系统的整体性能。</p><p>&nbsp;</p><p>为了避免单节点的硬盘故障，DynamoDB的WAL会存储在所有的三个副本中（这些副本通常分布在不同的可用区（AZ）上）。同时，为了减少每个副本的存储压力，以及进一步提升数据的持久性，WAL会定期存档到 S3 中（S3 是一个设计持久性为11个9的对象存储）。每个副本仍包含最新的WAL，通常处于等待存档的状态。未存档的日志通常大小为几百兆字节。在DynamoDB这类大型服务中，硬件故障，如内存和磁盘故障很常见。当一个节点发生故障时，所有托管在该节点上的复制组都会降至两个副本。修复存储副本的过程可能需要几分钟，因为修复过程涉及复制 B 树和WAL。一旦检测到存储副本出现问题，复制组的leader会添加一个日志副本以确保不会对耐久性造成影响。添加日志副本只需几秒钟，因为系统只需从健康副本复制最近的写前日志到新副本而无需复制 B 树。因此，使用日志副本快速修复受影响的复制组，来确保分区可以在最快的速度下满足quorum写的数量。</p><p>&nbsp;</p><p></p><h2>大量地使用校验和（checksum）</h2><p></p><p></p><p>一些硬件故障可能导致错误的数据被存储。这些错误可能是由存储介质、CPU或内存引起的。不幸的是，这些错误很难检测到，并且可能发生在系统的任何地方。为此，DynamoDB大量地使用校验和（checksum）来检测静默错误。通过在每个日志条目、消息和日志文件中维护校验和，DynamoDB可以在两个节点之间的每次数据传输中验证数据的完整性。这些校验和可以防止错误传播到系统的其他部分。例如，在节点或组件之间的每个消息上都会计算校验和，并在消息经过各种转换层次之前抵达目的地时进行验证。如果没有这样的检查，任何一层都可能引入很难发现的错误。</p><p>&nbsp;</p><p>每个归档到S3的日志文件同样都有一个包含日志信息的清单，例如表、分区以及存储在日志文件中的数据的起始和结束标记。负责将日志文件归档到S3的代理程序在上传数据之前执行各种检查。这些检查包括，但不限于，验证每个日志条目以确保它属于正确的表和分区，验证校验和以检测任何静默错误，以及验证日志文件在序列号中是否有任何空洞。一旦所有检查都通过了，日志文件及其清单就会被归档。日志归档代理在复制组的所有三个副本上都会运行。如果其中一个代理发现日志文件已经归档，该代理将下载已上传的文件，通过将其与本地写前日志进行比较来验证数据的完整性。每个日志文件和清单文件都会带有内容校验和上传到S3。S3在执行put操作时会检查内容校验和，以防止在数据传输到S3过程中出现任何错误。</p><p>&nbsp;</p><p></p><h2>饱和式验证</h2><p></p><p></p><p>DynamoDB非常激进地对归档的数据做饱和式的验证，目的是检测系统中的任何静默数据错误。一个持续验证系统的例子是scrub过程。Scrub的目标是检测到我们未预料到的错误，例如位衰减（bit rot）。Scrub过程主要验证两件事：复制组中所有三个副本的数据相同，且实时副本的数据与使用归档的写前日志离线构建的数据一模一样。通过计算实时副本的校验和并将其与从S3归档的日志条目生成的快照进行匹配来进行验证。Scrub机制充当了深度防御，检测实时存储副本与使用表创建历史日志构建的副本之间的差异。这些全面的检查对于提高运行系统的信心非常有益。用于验证全球表副本的类似持续验证技术。多年来，根据AWS的经验，静止数据的持续验证是防止硬件故障、静默数据损坏乃至软件错误的最可靠方法。</p><p>&nbsp;</p><p></p><h2>形式化验证（Formal Verification）和充分测试</h2><p></p><p></p><p>DynamoDB是一个基于复杂底层子系统构建的分布式键值存储。高复杂性增加了设计、代码和操作中人为错误的概率。系统中的错误可能导致数据丢失或损坏，或者违反客户所依赖的其他接口契约。开发过程中，工程师广泛使用形式化验证方法来确保复制协议的正确性。核心复制协议使用TLA+进行了规范。当添加影响复制协议的新功能时，它们会被纳入规范并进行模型检查。模型检查使我们能够在代码投入生产之前捕捉到可能导致持久性和正确性问题的微妙错误。其他服务（如S3）在类似情况下也发现模型检查非常有用。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/92/92574d3fa20a3ed9efbe35e10ab917e5.png\" /></p><p>（ChatGPT解释TLA+）</p><p>&nbsp;</p><p>DynamoDB还采用广泛的故障注入测试和压力测试来确保每个部署的软件的正确性。除了测试和验证数据平面的复制协议外，形式化方法还被用于验证控制面板和分布式事务等功能的正确性。</p><p>&nbsp;</p><p></p><h1>DynamoDB的高可用性</h1><p></p><p></p><p>为实现高可用性，DynamoDB表在一个区域内的多个可用区（AZ）之间进行分布和复制。DynamoDB定期测试对节点、机架和AZ故障的弹性。例如，为了测试整个服务的可用性和持久性，进行断电测试。使用逼真的模拟流量，通过作业调度器随机关闭节点。在所有断电测试结束后，测试工具验证数据库中存储的数据在逻辑上是有效的且未被损坏。下面将详细介绍在过去十年中解决的一些关键挑战。</p><p>&nbsp;</p><p></p><h2>如何保证高可用写和强一致读</h2><p></p><p></p><p>分区的写入可用性取决于其是否具有健康的leader和健康的写入quorum数副本。在DynamoDB的情况下，一个健康的写入quorum数由来自不同可用区的三个副本中的两个组成。如果达到最小quorum数所需的副本数量不可用，分区将无法进行写入操作。如果出现一个副本无响应，leader会向组中添加一个日志副本。添加日志副本是确保写入quorum数得到满足的最快方法。Leader副本同时提供一致性读取。引入日志副本对系统产生了很大的变化，Paxos的正式验证实现让我们有信心安全地调整和尝试系统，以实现更高的可用性。我们已经能够在一个区域内使用日志副本运行数百万个Paxos组。最终一致性读取可以由任何副本提供。如果leader副本出现故障，其他副本会检测到其故障并选举新的leader，以尽量减少对一致性读取可用性的影响。</p><p>&nbsp;</p><p></p><h2>如何避免leader被误认为不可用</h2><p></p><p></p><p>新选出的leader在提供任何流量之前，需要等待旧leader租约到期。虽然这只需要几秒钟，但在此期间，选定的leader节点无法接受任何新的写入或一致性读取流量，从而影响可用性。对于高可用系统来说，leader的故障检测是关键组件之一。故障检测必须快速且稳定，以尽量减少中断。故障检测中的误报反而会进一步恶化可用性。故障检测对于每个副本组都失去与leader的连接的故障情况表现良好。然而，节点可能会遇到灰色网络故障。灰色网络故障可能是由于leader和follower之间的通信问题、节点的出站或入站通信问题，或者即使leader和follower之间可以相互通信，前端路由器也面临与leader通信的问题。灰色故障可能会影响可用性，因为故障检测可能存在误报或无故障检测。例如，一个没有收到leader心跳信号的副本将尝试选举新的leader。如上一节所提到的，这可能会影响可用性。为解决灰色故障引起的可用性问题，希望触发故障切换的follower会向复制组中的其他副本发送消息，询问它们是否能与leader通信。如果副本回复表示leader状况良好，follower就会放弃触发leader选举的尝试。这种对DynamoDB所使用的故障检测算法的改进显著减少了系统中的误报数量，从而减少了错误的leader选举次数。</p><p>&nbsp;</p><p></p><h2>DynamoDB部署</h2><p></p><p></p><p>作为SAAS，DynamoDB不需要用户来维护和升级软件，会自动定期推送软件更新。部署将软件从一个状态转移到另一个状态。新部署的软件经过完整的开发和测试周期，以建立对代码正确性的信心。多年来，在多次部署过程中，工程师发现，确保软件可以正确回滚非常重要，因为有时候新部署的软件无法正常工作。而有时候回滚后的状态可能与软件的初始状态不同。回滚过程经常在测试中被忽略，可能导致对客户的影响。在每次部署之前，DynamoDB都会在组件级别运行一套升级和降级测试。然后，故意回滚软件，并通过运行功能测试来进行测试。</p><p>&nbsp;</p><p>在单个节点上部署软件与在多个节点上部署软件完全不同。分布式系统中的部署不是原子性的，任何时候，一些节点上都会运行旧代码，而其他部分节点上会运行新代码。分布式部署的额外挑战在于，新软件可能引入一种新类型的消息，或以系统中的旧软件无法理解的方式更改协议。DynamoDB通过读写操作分开部署来处理这类变化。读写部署作为一个多步骤过程完成：第一步是部署软件用来支持读取新的消息格式或协议。一旦所有节点都能处理新消息，软件就会更新为支持发送新消息。读写分开部署确保两种类型的消息可以在系统中共存。即使在回滚的情况下，系统也能理解新旧消息。</p><p>&nbsp;</p><p>在将所有部署推送到整个节点群之前，所有部署都是在一小部分节点上完成的。该策略降低了故障部署可能带来的影响。DynamoDB在可用性指标上设置报警阈值。如果在部署过程中，错误率或延迟超过阈值，系统将触发自动回滚。</p><p>&nbsp;</p><p></p><h2>元数据服务（Metadata Service）稳定性保障</h2><p></p><p></p><p>元数据服务存储了路由器需要的表的主键与存储节点之间的映射。此路由信息包括表的所有分区、每个分区的键范围以及托管分区的存储节点。当路由器收到一个之前未见过的表的请求时，它会下载整个表的路由信息并将其缓存到本地。由于关于分区副本的配置信息很少更改，缓存命中率约为99.75%。但在扩容路由器的时候，会有冷启动，请求路由器的缓存为空，每个请求都会导致直接命中元数据服务。实践中观察到，当请求路由器群增加新容量时，会出现这种效果。偶尔，元数据服务流量可能飙升至75%（考虑到平时缓存命中率为99.75%，这对元数据服务来说是瞬间的流量spike）。因此，引入新的请求路由器会影响性能，可能使系统不稳定。此外，无效缓存可能导致其他系统部分的级联故障，因为数据源由于直接负载过大而崩溃。</p><p>&nbsp;</p><p>为了避免这个问题，DynamoDB引入了下面两个措施：</p><p>1）在请求路由器和元数据服务之间添加一个分布式内存缓存MemDS。在请求路由器的本地缓存未命中时，它不会直接访问元数据服务，而是首先访问MemDS，然后MemDS在后台访问元数据服务以填充数据。通过添加一个用于削峰填谷的缓存层，相当于添加了另一层保险，这是一种常见的方法。</p><p>&nbsp;</p><p>2）第二种措施是一个非常值得借鉴的设计方案。刚才提到请求路由器上有个本地缓存，如果本地缓存没有命中，会通过MemDS获取元数据，这很容易理解。但真正聪明的是：即使本地缓存命中，也会异步地发消息到MemDS去更新缓存。这样做的好处在于：1）确保了MemDS中现有的缓存尽快更新；2）确保了打到MemDS的请求数是稳定的(虽然流量可能很大)， 这也为元数据服务带来“稳定”的流量（尽管可能也较大）。 稳定的好处在于，可以提前scope好容量。 对于DynamoDB这样体量的服务，稳定的大流量要比瞬间的几百倍的流量陡增要更加可控。</p><p>&nbsp;</p><p></p><h1>总结</h1><p></p><p></p><p>这一期，我们围绕DynamoDB在数据持久性，正确性以及整体服务如何做到高可用，进行了学习。论文中介绍了十几年服务沉淀下来的经验，无论是WAL冗余存储，饱和式验证，形式化验证，读写分步部署，等等，都是通用的，很有借鉴意义的建议。 最出彩的还是通过异步调用MemDS（无论cache hit or miss）确保了元数据服务接受稳定流量的做法。至此，精读DynamoDB系列文章完坑。感谢阅读！也非常感谢ChatGPT的帮助！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/37/3712caf65e07bac0f8a12230f81db546.png\" /></p><p>&nbsp;</p><p></p><h1>内核杂谈微信群和知识星球</h1><p></p><p></p><p>内核杂谈有个微信群，大家会在上面讨论数据库相关话题。目前群人数快400人啦，所以已经不能分享群名片加入了，可以添加我的微信（zhongxiangu）或者是内核杂谈编辑的微信（wyp_34358），备注：内核杂谈。</p><p>&nbsp;</p><p>除了数据库内核的专题blog，我还会push自己分享每天看到的有趣的IT新闻，放在我的知识星球里（免费的，为爱发电），欢迎加入。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/70bf009e0765b8417a2908a94be2ec06.jpeg\" /></p><p></p>",
    "publish_time": "2023-03-21 15:35:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "麒麟桌面操作系统运行安卓移动应用的技术实践",
    "url": "https://www.infoq.cn/article/8jjqHaBe9K4lduQpbh8O",
    "summary": "<p>本文整理自麒麟软件桌面研发部资深研发工程师孟庆彬在 DIVE 全球基础软件创新大会 2022 的演讲分享。</p><p></p><p>以下为孟庆彬演讲的精华内容，经编辑。</p><p></p><p></p><h2>国产操作系统目前生产现状</h2><p></p><p></p><p>以飞腾平台为例，截止到 2022 年 1 月，飞腾平台已经适配了 4000+ 的生态软件。经过分类统计，主要的分类聚焦在办公软件、影音软件、金融软件、游戏软件、社交软件、安全和存储上。</p><p></p><p>需要强调的是，游戏软件也是一些小众的游戏，4000+ 的应用也基本只能覆盖到这几类的软件行业。考虑到目前国产操作系统使用的情况，现在的主要用户还是党政军企这些 ToB 的企业，以办公安全场景为主，其他的都没有，这也就导致了 Linux 原生的生态倾向性比较明显。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/91/917f9e7db96d4d4a3f051e73d9530ca8.png\" /></p><p></p><p>目前 Linux 生态的短板就是生态很不丰富，与移动或者 Windows 生态相比，没有什么可比性。相对而言，办公类的软件比较成熟，但是像 Photoshop，还有重办公设计类的软件也是不足的。</p><p></p><p></p><h2>麒麟系统如何融合移动应用生态</h2><p></p><p></p><p>麒麟有 KMRE，麒麟移动运行环境的技术，这个技术我们给它打了标签，包括技术、融合、便捷。今天重点介绍一下 KMRE 的主要功能和工作原理。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f5/f51a619edfb0fbe9595bc152b5e35434.png\" /></p><p></p><p>首先介绍一下麒麟移动引擎主要的特点和主要的功能。它支持海量 APP 秒级启动。直接使用硬件，无性能损失。安卓与 Linux 窗口显示融合。统一的输入法，统一的音频设备，统一的输入设备，摄像头，视频通话。文件互通，剪切板互通，打开通知消息互通，打开方式互通。APP 的统一管理，键盘辅助功能，鼠标滚轮功能，截图功能。APP 同时运行，APP 全屏切换，横竖屏切换，还有 Linux 共享桌面。这块功能下面会一一展开介绍。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b0/b0ab87c36ee089bb293fda52a21f5563.png\" /></p><p></p><p>在 Linux 上，如果想运行安卓 APP，主要有两个大的技术方向。第一个就是 Google 的 Arc 容器类的方案，Google 的 Arc 是商业的 Chrome 组件，支持应用有限，效率一般。还有虚拟机和模拟器，像 Bluestacks 和 GenyMotion 效率都比较低，资源占用率很高，环境与宿主系统完全隔离。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/29/2900201005b43517e9078ce2f819e108.png\" /></p><p></p><p>KMRE 不是虚拟机，它是类似于容器的一套方案，但也不是传统意义上的容器。它真正将 Linux 操作系统和安卓操作系统合二为一，从本质上让麒麟 OS 真正支持安卓 APP 的运行。共用内核，直接使用硬件，无性能损耗，资源共享，目前支持 arm 和 x86，也支持了多种 CPU 和 GPU。</p><p></p><p>总结来讲，Linux 目前运行安卓 APP 无非两套大的方案，要么就是容器，要么就是模拟器。我们是在容器的基础上改造了一个不是容器的方案，但也是继承了容器的方案。</p><p></p><p>KMRE 显示目前有两种模式，一种是通用模式，通用模式主要是适配了驱动闭源的 Nvidia 卡、Intel 显卡，兼容性比较高。另一种是高性能模式，目前适用于开源的驱动，比如 AMD 的显卡，目前是 0 性能损失。例如 KMRE 运行“和平精英”时，画质是不错的，实际的操作流畅度很高，帧率也很高，在高性能模式下体验非常好。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a0/a004669554057d73e0f8740809d9be48.png\" /></p><p></p><p>在 OS 上运行安卓应用，大家都在讲的一个概念叫多 APP 多窗口同时运行。实际上对于安卓手机、安卓平板而言，它们基本上都是在一个屏幕同时只能运行一个应用。如果我们想多运行几个应用，会涉及到切换。对于用户的操作而言，他只能同时操作一个应用。但桌面系统大家已经熟悉了窗口式的应用，用多少个应用就开多少个窗口，同时可以看，可以用。而且对于大家熟悉的笔记本、台式机，它的屏幕是大横屏的形式，多开几个窗口显示器效果也会比较好。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7d/7d7bde697d5d82e54bcdf604eed6b7d0.jpeg\" /></p><p></p><p>下面再介绍一下 Linux 下的桌面共享。正常的话，Linux 应用，或者 Windows 上会议类应用的共享桌面，都是共享自己的主界面。当然对于安卓而言，只能共享安卓手机的窗口。对此，我们做了一些工作。我们现在共享的时候，Linux 下跑腾讯会议，或者是 QQ 共享桌面，实际共享的是整个桌面。可以看到，图中是 Linux 原生的整个桌面，这保证了操作体验，也保留了在 Windows 下的共享桌面习惯，比较方便。去开会，去共享桌面，大概率会想要共享整个桌面，而不是单独的一个窗口。目前我们内部开会都是这样来做的，还是很方便的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/53/533991f70046f8753992437f816bf962.png\" /></p><p></p><p>文件互通。大家应该都比较熟悉 Linux 的文件系统以及安卓里面的文件系统，对于安卓而言，它的目录相对而言比较混乱，比较零散。对于 Linux 而言，显示更像是 Windows 这种可能用起来比较习惯。通过一些手段，一些努力，目前在安卓上面可以直接访问 Linux 文件。</p><p></p><p>图中是微信里面要给朋友发文件，正常的话都是微信打开文件系统，打开它的存储，去找对应的目录。我们做的优化是直接选择 Linux 目录下的文件直接传，通过微信发出去。下面的图片就是把安卓的文件系统在 Linux 下显示。这是一个 Linux 文管，能够直接看到安卓完整的目录结构，也可以按类型去看。安卓目录结构比较混乱，但如果按分类模式去看，也相对比较便捷。我们这块也是结合了各自的优劣，既能够按照符合 Windows 习惯的目录结构去看，也可以符合安卓便捷的方式去看，比如说按图片、音频、视频、文档分类，这两者都有。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/49/49d2b6f5e6dbc87ef8424ac1d26f3a72.png\" /></p><p></p><p>再来看看摄像头。因为安卓摄像头分辨率会比较高，摄像头可以跟着横竖屏方向去旋转。但 PC 上的摄像头一般分辨率比较低，且固定在某个位置，正常也不会有人去旋转它。这就导致了在摄像头使用上跟安卓存在着一些区别。由于我们的场景是 PC 上的摄像头使用安卓设备，所以在这方面也做了比较多的工作，目前已经适配了多款的摄像头。对于可以拍照、录像的 APP，绝大部分适配的功能都是没有问题的。尤其对于重点的应用，像微信、腾讯会议，目前内部也一直在用，视频通话很流畅，体验也很好。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f2ce59d2e598850bed2b72371de7da10.png\" /></p><p></p><p>对于手机输入法，大家可能比较习惯点一个位置，下面弹出手机各种各样的输入法，然后手动去打字。有很多种输入法，包括手写的、拼音的、九宫格。但实际上在 Windows 上，桌面 OS 的情况下，大家都习惯直接用键盘、鼠标去输入。PC 上用键盘、鼠标打字速度是很快的，体验也不错，基于这一点，我们也在想怎么去实现。实际上现在也完成了可以用 Linux 的中文输入法直接输入到安卓系统里去。</p><p></p><p>图示就是在头条搜索，可以看到这个操作系统是安卓，输入法却是 Linux 的输入法，输入法会跟着光标走。另外，不管是 Windows，或者是 Linux，大家都习惯了用一些快捷键，像复制、粘贴、全选、撤销，就是对应的 Ctrl+C、Ctrl+V、Ctrl+A， Ctrl+Z 这些快捷键，而原生的安卓可能需要长按，因为它没有键盘、鼠标。这些我们都已经适配完成，可以通过快捷键去操作安卓这部分，这种体验是很流畅的。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d396b8323d4064d0f930b49350e15f6f.png\" /></p><p></p><p>安卓里面的游戏也适配了 Linux，包括 PC 机器的键盘、鼠标和游戏手柄。我们可以通过手柄，或者键盘、鼠标去玩一些游戏，体验很不错。为什么特别强调这块内容？因为我们在做游戏场景的时候也遇到了一些问题。打游戏可能需要十个手指多点触控，但实际上在 Linux 下这块支持不是特别友好。尤其像滚轮，像游戏的轮盘操作，以及手柄类自定义的组合键是比较多的。这块我们也是做了很多的事情，解决了轮盘的转换，还有在键鼠这块解决了多点触控和组合键的问题。目前，通过游戏手柄去玩大型的游戏是没有问题的。</p><p></p><p>什么叫打开方式互通？正常的安卓应用默认都是用安卓应用去打开，但安卓应用用 Linux 本地的应用去打开，Linux 本地应用用安卓应用去打开，这样体验会更好。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b6/b6ed3d8093fcef468a966befe2db50bb.jpeg\" /></p><p></p><p>比如说用微信的时候，突然收到了一个文档，用安卓内置的 WPS 也可以，但是如果能够用 Linux 下的 WPS，体验是不是更好？因为像 WPS 这种应用肯定是 Linux 原生操作起来更方便、更快捷。还有类似于图片查看器，也是在 PC 上直接操作更加灵活。网页也是一样，在 PC 上开网页可能开好几个，操作起来也比较便捷，但在安卓上，别人要给你发个网页或者发个网址都比较麻烦，效率或者体验肯定不如 PC 好。</p><p></p><p>我们在安卓里面做了一个插件，通过这个插件，可以把一些文件类型直接用 Linux 原生去打开，图片中就是别人给你发了一个 Word 文档，在右键的时候会打开右键菜单，这个时候我们就可以把应用用 Linux 原生的应用打开。</p><p></p><p>再介绍一下应用切换融合。希望让用户不要感知到跑的是一个安卓应用，还是一个 Linux 应用。我们从安装到使用都做了很多改进，比如说我们在安装的时候，让用户从应用商店下载、安装，在应用商店用户只需要去搜索对应的软件就可以，他不需要去关心这个软件到底是 Linux 软件还是安卓软件，他只要想用这个软件，去下载就可以了，我们就会给他自动安装。安装之后也符合常用的 PC 的操作习惯，安装之后会在桌面上有图标，任务栏也会有对应的图标，入口和 Windows 是统一的，用户用的时候，就可以直接点击，想用几个就开几个，是支持多窗口的。</p><p></p><p>对用户而言，都是完完整整、一个个独立的窗口，符合用户习惯。既然是窗口应用，当然支持用 Alt+Tab 快捷键进行应用切换。在任务栏可以预览它的效果，每个应用会有独立的预览情况，对用户而言，他不会感知到到底现在是一个 Linux 应用，还是一个安卓应用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/ea/ea6b67999f65e30dd7f6390d59f8df02.png\" /></p><p></p><p>我们从安装到使用，都是为了保证用户体验一致，安装好了之后在开始菜单就会有对应的图标，也可以在“自定义”大的桌面里面看到对应的图标。用户也可以把它固定到任务栏，或者直接右键发送到桌面快捷方式，用户会觉得这是 PC 上惯用的应用习惯。</p><p></p><p>正常的安卓手机通知都是在安卓的主界面上有一个下拉的通知栏，很多应用信息都会往那里发通知，现在为了和桌面 PC 深度融合，我们的通知会在系统的通知栏弹个气泡通知用户，如果你的应用是在任务栏下面，它就和 QQ、微信的 Windows 的习惯是一样的，用闪烁来通知用户有消息来了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/14/14b65c088e3e37c55af0467e9a9a590b.png\" /></p><p></p><p>以上是 KMRE 主要的功能介绍。目前通过 KMRE 已经完成了对 4000+ 移动应用的适配，以后应用会上的越来越多。通过 KMRE，也引入了 4000+ 的移动应用。我们通过这些手段，已经可以把安卓的应用比较快速、低成本地迁移到 Linux 生态上面来，这样是对 Linux 生态很大的补齐。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/fb/fb887790927cd45e8c42e31ef494dfde.png\" /></p><p></p><p>目前适配了以下这些重点应用。比如说金融类的同花顺，还有一些网银。影音类的像爱奇艺、抖音、QQ 音乐。社交类的 QQ、微信。教育类包括腾讯课堂、学习强国。游戏类的包括和平精英、QQ 飞车。办公类的包括钉钉跟腾讯会议。也有一些应用，它可能现在还没有 Linux 原生应用，或者是 Linux 原生应用做得还不是特别好，然而移动应用已经很成熟了，这样的话能够很好地解决用户的实际需要。而且也可以支持多个窗口同时打开，随便开几个都没有问题。</p><p></p><p></p><h2>麒麟移动引擎主要工作原理</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/5a/5a2615bb59b5cf476eb0641e06cfd792.png\" /></p><p></p><p>麒麟移动引擎的整体架构包括，KMRE 的整体架构，最下面是硬件平台，有不同的 CPU、GPU。比如支持国产的飞腾、麒麟 990，还有 Intel、AMD。GPU 也有很多种，像 AMD、Nvidia、Intel 这种。对不同的硬件，我们都需要做适配，但因为抽象出了一个硬件的适配层，所以适配工作目前只是简单的配置工作就可以完成。</p><p></p><p>操作系统内核刚才也讲过，是共内核的，所以只会有一套内核。在内核的基础上增加了一些自己的模块，有一些是我们自己开发的，有一些是参考安卓的，比如说 IPC Bander，大家都知道，安卓里面 Bander 特别方便，可以解决进程间通信，但 Linux 一般是用 Socket 类来解决通信的问题，因此我们参考一下安卓这部分，把 IPC Bander 拿了出来，这样相当于在 Linux 下也可以使用 Bander 进行通信。还有 Share Memory，还有 ION，还有 VirtWifi，VirtWifi 是我们自己做的</p><p></p><p>一个模块，为了解决安卓上网的问题，毕竟网络还是在 Linux 侧，安卓侧应用也要上网，我们搞了一个 VirtWifi 内核模块可以解决安卓内部的上网。这块目前也在努力，原来是一个虚拟的网络，目前已经基本上实现了安卓可以感知实实在在的网络。</p><p></p><p>在共用内核的基础之上，我们里面有两套系统，一个是 Linux 系统，一个是安卓系统。因为两个系统之间要紧密耦合，一些组件要交互或者共用。实际上在 Linux 下面有一个类似于启动进程的模块，这个模块可以理解为安卓的 AMS，负责安卓应用的生命周期管理。</p><p></p><p>还有我们的管理服务，管理服务就是管理安卓的生命周期，因为对于安卓而言，如果用户用的话就把它用起来，如果不用就把它挂起来，既要保证它的响应速度，还要解决它的功耗问题。还有图形窗口，还有显示服务，实际上窗口跟显示都是在 Linux 侧来融合的，这两部分就是为了解决安卓显示窗口跟 Linux 怎么融合。</p><p></p><p>在软件商店方面，因为安装的时候用户无需感知是 Linux 还是安卓，所以我们对软件商店也做了一些修改。音频服务就是为了解决数据、音视频通话、输入输出设备问题。文件管理器插件就是怎么样把文件系统互相打穿。文件互通服务就是为了解决分享这块，用应用去打开时，这块涉及到一些文件路径的同步。还有 OpenGL 渲染库，这是显示相关的。还有通信模块，解决 Linux 跟安卓高效通信的问题。</p><p></p><p>在安卓部分我们也做了比较深度的修改。例如在应用层，我们有自己的 KmreLauncher、KmreManager，还有 InputMethod。KmreLauncher 替代了安卓原生的 Launcher，因为我们现在做的是跟 PC 的深度融合，所以安卓的 Launcher 是不需要的，把一些机制用自己的 Launcher 去替代了。</p><p></p><p>KmreManager 就是为了解决 Linux 侧安卓端的管理以及通信问题的。InputMethod 主要就是为了解决输入法。对于 Framework 修改，我们也做了一些修改，比如说显示 SurfaceFlinger，还有输入的 InputFlinger 这些，都是为了更好地让这两个系统融合到一块。HAL 在显示还有硬件方面做了修改，像 Gralloc、Audio、EventHub、Camera。手机上的传感器设备会比较多，如果这些 PC 上有就用 PC 的，如果 PC 上没有，就要在 PC 上给安卓创建一个虚拟的设备。</p><p></p><p>经过这些模块组合之后，我们就在一套内核上跑了两套系统，两套系统就可以支持这两套系统的生态，比如 Linux 应用，安卓应用，使用起来比较灵活。</p><p></p><p>多窗口是怎么实现的？多窗口实际上是基于安卓 11 的虚拟屏技术，来实现窗口的多活。安卓本身它是有多个窗口显示的能力和接口的。但是考虑到安卓的实际产品，像手机、平板没有这种场景，所以这个技术用的人不是特别多。</p><p></p><p>目前安卓最新的版本也在往大屏方向切，这个技术可能会用得越来越多。我们是基于安卓的扩展屏这套技术，让应用打开到某些扩展屏的指定位置，再去控制扩展的生命周期，就是什么时候应该显示，什么时候应该销毁。通过这几个扩展屏之间的交互关系，来实现多窗口多活的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f2/f259a6e163957f44a2712990bb76782c.png\" /></p><p></p><p>再介绍下麒麟移动引擎文件互通是怎么做的。Linux 可以访问安卓的文件管理器，安卓也可以访问 Linux 的文件管理器，这是怎么实现的？</p><p></p><p>Linux 系统跟安卓系统本质上文件管理器整体的设计上是统一的，这块没有多大的差异，主要的差异点来自于权限的不足，Linux 文件的权限体系跟安卓的权限体系不一样。目录显示、挂载都没有问题，但当访问时就会涉及到权限问题，只能看不能用是不可接受的。</p><p></p><p>我们主要修改了文件内核的一些模块，做了权限映射，这样就可以解决 Linux 跟安卓里面权限不同导致无法访问的问题。权限的问题解决了，其他的就只是文件的显示、挂载这些操作，这块可以做的场景是比较多。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/19/191585ba4b8a3429b7fe46654ead3c81.png\" /></p><p></p><p>显示有两种模式，一种是性能模式，一个是兼容模式。如下图所示，对正常的安卓应用，就是安卓去显示，走 SurfaceLinger，走 OpenGL ES，走 Gralloc，走 fb，走正常的显示，这是安卓正常的流程。</p><p></p><p>但是、为了安卓和 Linux 窗口去融合，我们用 Linux 去做窗口管理，在安卓显示时把 OpenGL ES 这些指令都接到了 Linux 的 Mesa 库，通过 Mesa 库再去操作 DRM，直接到窗口上去显示，这样性能会比较快。直接就相当于把 Linux 的显示系统，跟安卓的显示系统融合到一起，也形成了一个完整的显示系统。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/79/7909bda2e39c8d651c26886211f86cb8.jpeg\" /></p><p></p><p>性能模式跟兼容模式的区别在于：性能模式主要参考了 AMD 驱动的开源方案。在沙箱中，移动环境执行图形渲染和合成，Linux 端只做绘制和显示。这样的话，减少了 JLES 命令进行传输和翻页带来的性能损耗，提高了安卓的运行效率和显示效率。渲染和合成是在安卓部分做的，Linux 只做绘制和显示。</p><p></p><p>对于兼容模式，有一些显卡可能没有开源出来，这块我们对沙箱中的移动环境中显示指令进行了转换，显示指令转换之后，Linux 上面的显卡进行渲染合成，这可以满足大部分的硬件加速需求，对显示环境具有良好的适应性，能够更好地实现显卡的兼容效果。兼容模式可能会比性能模式多了一些指令的传输还有内存拷贝损耗。在性能模式下玩游戏，一点都不会感觉到卡顿。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d3/d39849656c47ba8fb7ff3ec072655ca5.png\" /></p><p></p><p>在视频编解码方面。正常安卓也有一套视频编解码能力，但这块跟 Linux 系统融合不能走软解，这样的话 GPU 占用太高了。安卓本身有 OMX 这套接口，这套接口是给一些移动厂商提供定制解码能力的。我们是用了这套接口，在硬件设备支持的情况下，优先使用解码芯片来加速解码，这样就减少了 CPU 的占用，系统的性能和流畅度就可以保证了，也充分利用了硬件加速能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f6/f6339a664ca4f7763abefc1b8f931e1d.png\" /></p><p></p><p></p><h2>麒麟系统在移动生态上的规划和布局</h2><p></p><p></p><p>麒麟系统在移动生态上的规划和布局方面。KMRE 能够有效地把移动生态引入到 Linux 系统，补齐 Linux 系统生态不足的问题，随着一些新的技术的引用，应用会更快速地上架，以后应用会上的越来越多。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/6b/6bafb7dc39787f75e4dc660489683dda.png\" /></p><p></p><p>我们在一套内核中跑了两个系统，一个安卓系统，一个 Linux 系统，虽然说有些模块、有些组件是复用的，一些模块做了一些深度的耦合，但实际上，它还是一套内核跑了两个系统。</p><p></p><p>我们现在也在思考，怎么样构造一个真正的融合的系统。我们也参考了业界好的一些实践，看一看怎么样去打造一款真正融合的系统，只有一个系统、一套内核的融合系统，不会从技术上看上去有分裂。我们也在朝着这方面努力，也在打造麒麟最新的一代 OS 系统，持续做探索和突破。</p><p></p><p>现在移动端设备非常丰富，手机、平板、穿戴设备随处可见。用户怎么样跟麒麟系统互动，麒麟系统在移动设备上怎么更好使用？这块我们也有自己的思考，我们也在打造麒麟系统自身的移动办公生态。毕竟我们的客户大部分还是在办公行业，也会有一些移动办公需求。在这方面，我们也在努力做一些不一样的产品，希望给用户不一样的体验，帮助用户解决一些实实在在的问题。</p><p></p><p></p><h4>讲师介绍</h4><p></p><p></p><p>孟庆彬，麒麟软件，桌面研发部资深研发工程师。拥有 11 年工作经验，长期从事 Linux 系统与 Android 系统融合方向的技术研究。在麒麟公司主要负责麒麟移动运行引擎的设计与开发，主要负责将安卓生态引入到国产操作系统。</p><p></p><p></p><h5>相关阅读：</h5><p></p><p><a href=\"https://xie.infoq.cn/article/156996f60d5ca261edc900841\">Tapdata 与麒麟软件完成兼容性互认证，国产化生态布局再跃步</a>\"</p><p><a href=\"https://xie.infoq.cn/article/d585a27e803cd2c7a6ca84232\">openEuler 代码贡献之星：麒麟软件裴建康</a>\"</p><p><a href=\"https://xie.infoq.cn/article/d55bdd308b517fc4825974aa6\">和合共赢，DataPipeline 与麒麟软件完成产品兼容性互认证</a>\"</p><p><a href=\"https://xie.infoq.cn/article/2667aac390c3a02d59d6e1d03\">嘉为蓝鲸携手麒麟软件共建国产化一站式 DevOps 解决方</a>\"</p>",
    "publish_time": "2023-03-21 16:11:28",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "行知数字中国数字化转型案例集锦",
    "url": "https://www.infoq.cn/article/iACFmqikr7y7ZRPaRXV2",
    "summary": "<p><strong>序言</strong><br />\n随着新一轮科技革命和产业变革深入发展，数字化转型已是大势所趋。尤其是在过去三年的疫情影响下，各行各业都在加快数字化转型步伐。</p>\n<p>但是，无论对于科技公司、数字原生企业还是非数字原生企业而言，来自战略、文化、流程、技术、人才、资源等方面的挑战有增无减，面对数字化这个关乎生存的必修课题，企业亟需梳理出一条更为清晰且适合于自身发展的实践路径。</p>\n<p>本册电子书中共包含 26 篇文章，涵盖工业、零售和科技服务等领域，采访了包括富士康、施耐德电气、麦当劳中国、雪花啤酒、华晨宝马、顺丰科技在内的多家企业，InfoQ 通过与这些行业内具备代表性的企业进行访谈、与多位专家展开交流后，记录了各家企业的数字化实践经验和最新思考，并输出了行业数字化的 2022 年总结和 2023 年展望，希望能给业界的数字化同仁带来一些启发。<span class=\"orange\"></span></p>\n<p><strong>目录</strong><br />\n视野篇<br />\n01 ｜数字化是保命、保生存，还是保发展<br />\n02 ｜企业想做数字化，却普遍陷入选择困难症<br />\n03 ｜ 30 年 IT 老兵谈数字化：这就不是个技术活<br />\n04 ｜雪花啤酒数字化进行时，独家揭秘其转型框架与底层逻辑<br />\n05 ｜如何把技术“卖”给业务，从 IT 视角看麦当劳中国数字化</p>\n<p>案例篇<br />\n第一章 数字化营销<br />\n06 ｜数智化转型，营销是好的切入点但不是终点<br />\n07 ｜企业数字化营销，这个工作不“性感”但很重要<br />\n08 ｜营销投入都去哪儿了？虎彩集团用区块链搞定追溯和信任问题<br />\n09 ｜ 3 年超 30% 的线上渗透率，元初食品的数字化营销是怎么做的<br />\n10 ｜ B2B 数字化营销怎么做？要“放长线”“重孵化”</p>\n<p>第二章 数字化供应链<br />\n11 ｜从食品生鲜场景，看数字化技术如何重构供应链<br />\n12 ｜跃居 GARTNER 全球供应链榜单第二，施耐德电气是如何实现供应链数字化的<br />\n13 ｜服装快反供应链不是“瞎快”，背后要有数据做基础<br />\n14 ｜顺丰科技：在变局中寻找物流供应链“最优解”<br />\n15 ｜彩食鲜 CTO 乔新亮：数字化怎么做才能不“下头”？算好财务账，用技术接管业务</p>\n<p>第三章 典型行业数字化实践<br />\n16 ｜（金融科技）对话金融科技“老兵”：数字化转型越急，<br />\n失败概率越大<br />\n17 ｜（餐饮连锁）奈雪的茶：一杯奶茶中的数字化“秘密”<br />\n18 ｜（汽车制造）华晨宝马是怎么做数字化的？把正确的技术应用到正确的场景中<br />\n19 ｜（智能制造）如何在一年内建成一座 5G 智能制造工厂<br />\n20 ｜（智能制造）瑞阳的智造实践：从单个车间试点到全面智能车间建设</p>\n<p>展望篇<br />\n解读数字化的 2022：不再追求大而全的“军备竞赛”，用聚焦来提高转型“成功率</p>",
    "publish_time": "2023-03-21 16:27:10",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯发布2022研发大数据报告：Go语言蝉联最热编程语言",
    "url": "https://www.infoq.cn/article/WyN83BsYPJatzykRydKO",
    "summary": "<p>近日，腾讯正式发布了《2022年腾讯研发大数据报告》（以下简称《报告》）。《报告》由腾讯技术委员会出品，全面披露了2022年腾讯在研发投入、研发效能、开源协同等方面的重要数据。</p><p>&nbsp;</p><p></p><h2>研发人员占比达74%，Go语言蝉联腾讯最热编程语言</h2><p></p><p></p><p>《报告》显示，2022年腾讯内部研发人员占比达到74%，这意味着，平均每四个腾讯员工中，就有三个从事研发工作。</p><p>&nbsp;</p><p>去年一年，腾讯新增研发项目超过7000个，相比2021年增长19.8%；新增代码行数29.4亿行，新增代码库21万个，日均提交代码12.7万次。</p><p></p><p>除了研发项目数量，代码质量也是腾讯研发的关注重点。2022年，腾讯总计完成262万次代码评审，相比2021年增长21.8%，代码评审参与率达到74.6%。代码评审总耗时达到46万小时，人均代码评审时长12.6小时，代码评审千行评论数为15.3个，同比增长75.4%。</p><p></p><p>此外，随着云计算等技术的迅速发展，Go语言蝉联腾讯最热门编程语言。值得注意的是，因兼备安全、便利、速度、可移植等特性，Kotlin、Swift和Rust等新一代编程语言的使用增速较快。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6eef146b247e0e84d71bea2f4d712a47.png\" /></p><p></p><h2>持续投入基础软件研发</h2><p></p><p>&nbsp;</p><p>如今，企业已从“技术创新主体”转变为“科技创新主体”。作为科技企业，腾讯不断加强基础软件和前沿科技研究，2022年一到三季度研发投入达455亿。</p><p>&nbsp;</p><p>《报告》显示，截至2022年12月，腾讯在全球主要国家和地区专利申请公开总数超过6.2万件，专利授权数量超过3万件。</p><p>&nbsp;</p><p>在基础软件方面，腾讯持续投入研发，目前已具备服务器操作系统的全链路自研能力，同时发起并深度参与OpenCloudOS操作系统开源社区。</p><p>&nbsp;</p><p>作为基础软件领域“皇冠上的明珠”，腾讯云数据库TDSQL核心代码的自研率达到100%，在OLTP事务和轻量级事务用例逐年增长，服务了国内多家主流银行。编译器领域中，腾讯多次蝉联OpenJDK社区国内厂商贡献度第一，全球排名前五。</p><p>&nbsp;</p><p>除此之外，腾讯在前沿科技领域取得了多项进展。目前，腾讯已发布了3款自研芯片，面向AI推理、视频处理和高性能网络三大场景，并推动自研芯片在实际业务场景中的规模化应用；持续探索AI在全真互联场景下的关键技术，推进数字内容生产、生命科学、医疗医药、游戏等行业方向落地应用；腾讯自主研发的移动机器人Max和Ollie发布新版本，并首次融合智能体、深度学习、Sim2Real和触觉传感器等技术。</p><p></p><h2>35%的需求一天内发布上线，70%的Bug在两天内解决</h2><p></p><p>&nbsp;</p><p>2022年，腾讯宣布自研业务完成全面上云，研发流程全面落地云原生DevOps。《报告》显示，超过90%的业务研发通过腾讯CI云原生流水线构建和部署，构建时长缩短60%，部署效率提升75%。</p><p></p><p>早在2006年，腾讯就开始推动研发模式的敏捷进化，形成了包括敏捷研发协作平台TAPD、代码管理平台工蜂、智能化持续集成平台腾讯CI等多个研效工具在内的企业级敏捷研发体系。</p><p>&nbsp;</p><p>《报告》数据显示，2022年腾讯日均完成需求8050个，平均每个迭代计划时长15天，平均每个迭代完成需求数25个，其中有35%的需求能够在一天内发布上线，70%的Bug在两天内解决。</p><p></p><p>在持续交付方面，2022年，腾讯平均每周构建次数330万次，同比增长25.9%；项目制品年产量9PB；推动修复代码Bug和安全漏洞超过350万个，编译加速节省编译总耗时超过50万小时。</p><p></p><h2>内部代码库开源率连续四年超80%，主导多个国际开源项目</h2><p></p><p>&nbsp;</p><p>在开源协同技术战略的推动下，腾讯不断推动更底层、更重磅的技术对外开放，并紧密参与开源社区建设，与开发者共享技术红利。</p><p>&nbsp;</p><p>《报告》显示，腾讯内部代码仓库开源率已连续四年保持在80%以上。公司级协同Oteam（开源协同小组简称）总数累计达到147个，涵盖了大数据、数据库、AI、研效、安全等数十个领域。代码贡献者总数达到5814人，参与协同共建的部门总数达到332个。</p><p></p><p>十余年来，腾讯一直坚定地拥抱开源。在对外开源方面，腾讯主导LinuxKVM、JDK等9个全球知名开源项目，对外开源了160余个项目，在全球企业开源榜位居前十，获得了超过40万的开发者关注和点赞。</p><p>&nbsp;</p><p>在开源人才培养中，高校扮演着关键角色。腾讯联合高校开展开源人才培养计划，打造面向高校学生的开源课程和开源实践培养方案，促进学术界和产业界深入合作，用企业真实项目来反哺教学，助力开源人才生态的发展。目前已覆盖来自13个国家、29个省份、265所国内外高校超过1000名学生。</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-03-21 17:05:12",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "阿里副总裁贾扬清即将离职，独家回应称“暂未创立公司”",
    "url": "https://www.infoq.cn/article/71zbL7qOc0omWdIjtPdK",
    "summary": "<p>3月21日，AI领域爆出重大人事变动：在阿里任职四年后，Caffe作者贾扬清即将离职。</p><p>&nbsp;</p><p>今日，有自媒体爆料称，阿里巴巴集团副总裁、阿里硅谷研究院负责人贾扬清将于近期离职创业，创业方向将聚焦于人工智能架构领域，目前已获得了首轮融资意向。</p><p>&nbsp;</p><p>对此，贾扬清对InfoQ回应称：</p><p>&nbsp;</p><p></p><blockquote>加入阿里巴巴的时候，最吸引我的是云计算可以带给社会的独特贡献：AI，Big data，Compute，Developer，和Ecosystems。&nbsp;有幸在过去几年中带领计算平台事业部，建设了一支从研发到产品到解决方案的团队，将大数据AI业务做到行业领先的位置，感谢阿里对我的信任和支持。通过实时离线一体的大数据平台ODPS，以及云原生的智算平台PAI，我们的技术支持了魔搭（ModelScope）这样的开源平台，以及包括大模型在内的一系列应用，为云上的客户创造价值。&nbsp;白驹过隙，我也计划走向职业生涯的下一个挑战。祝愿团队的兄弟姐妹们再创辉煌，祝愿阿里云能够越走越好。我们现在并没有创立公司，目前还在和团队进行顺畅的交接当中。关于个人后面的规划，也期待在不久的将来和大家分享。</blockquote><p></p><p>&nbsp;</p><p>作为AI领域里知名的顶尖华人科学家，贾扬清的任职动态一直以来都颇受关注，每一次职业更换都会在业界引起非常大的反响。</p><p>&nbsp;</p><p>贾扬清在伯克利读博期间开发Caffe框架，随后任职谷歌参与TensorFlow开发。2016年贾扬清加盟Meta（原Facebook），负责 AI 框架和 AI 平台相关工作，此后Facebook 又陆续发布了 PyTorch 和 Caffe2（这两个后来被合并了）。</p><p>&nbsp;</p><p>贾扬清离开谷歌、加入 Facebook 时也曾引发热烈讨论，甚至有不同版本的公司内部内斗传闻。当年知乎上也出现过这样一个问题：如何评价 caffe 作者贾扬清加入 Facebook?</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/55/557c03301b6082d7da7a9b17062525f4.jpeg\" /></p><p></p><p>&nbsp;</p><p>在这个问题下，贾扬清自己回复道：</p><p>&nbsp;</p><p></p><blockquote>“正常换工作而已，大家不需要太过关注。。。就我个人而言，在 Google 实习过两年又工作过两年，无论是技术还是科研都感觉收获颇丰，换到 Facebook 的原因也是为了在个人发展上能学到一些不同的东西，为将来的职业发展继续做准备。另外一个原因是好多以前伯克利同实验室的朋友也在 Facebook，比如 Ross Girshick 和 Bharath Hariharan，所以也增加了一份亲切感。两家都是好公司，也都是牛人云集，所以从找工作的角度说，来哪儿都不会让你感觉后悔的。不过话说我哪儿都没有 announce 到底是谁捅出来的消息呢？”</blockquote><p></p><p>&nbsp;</p><p>2019年3月，贾扬清从Meta离职加入阿里。当时，贾扬清的动向似乎在中国AI领域里激起了不小的水花，面对纷嚣传言阿里巴巴达摩院在知乎上正式回应称：“原Facebook人工智能科学家贾扬清已正式加入阿里巴巴，担任技术副总裁岗位，领导大数据计算平台的研发工作。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d9/d9fcfa4df3814d2ff6c8b6ba80f1866b.png\" /></p><p></p><p>&nbsp;</p><p>2019年9月，阿里正式宣布贾扬清出任阿里巴巴开源技术委员会负责人。同年，他在杭州云栖大会上接受InfoQ的采访时表示，自己的工作是直接领导阿里云智能计算平台事业部，而计算平台事业部同时负责大数据和人工智能两大平台，其中大数据方面包括 Flink、Spark 以及从阿里自己做起来的 MaxCompute 大数据平台，人工智能平台则包括底层资源管理、中间层 AI 框架开发等一系列工作。</p><p>&nbsp;</p><p>另外，工业界落地也是贾扬清关注的重点方向之一。在阿里期间，带领团队锻造大数据+AI产品体系阿里灵杰，开源推动AI工程化落地，助力AI成为产业数字升级的利器。</p><p>&nbsp;</p><p>如今，四年过去，贾扬清也即将开始新的征程，虽然还未曾创立公司，但因ChatGPT大火，因此不少人猜测他将投身这股新的创业浪潮中。InfoQ也将持续关注大佬的动态。</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href=\"https://www.infoq.cn/article/gv7wevhz*fuviuxdzu1e\">独家专访 AI 大神贾扬清：我为什么选择加入阿里巴巴？</a>\"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-03-21 17:18:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "不止于监控，夜莺V6全新升级为开源观测平台",
    "url": "https://www.infoq.cn/article/qAT1egCu0vi786Vpvhrg",
    "summary": "<p>不止于监控，夜莺 V6 来了！今天我们郑重发布夜莺 6.0 beta 版本，全面支持 Metrics、Logging、Tracing，向着构建开源、开放、完整的可观测性解决方案迈进。您可以借助夜莺 V6，接入和管理 Prometheus、ElasticSearch、Jaeger 多种数据源，实现数据的统一可视化、告警和分析。</p><p></p><h4>可以在页面管理数据源了</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c5/7e/c54f957f4c6d5e8e51f1c1ba317d487e.png\" /></p><p></p><p>无需修改配置文件里的Clusters配置了，直接在页面就可以管理了。除了兼容 Prometheus 查询协议的数据源，也支持 Jaeger 和 ElasticSearch 作为数据源接入。</p><p></p><h4>可以接入 ElasticSearch 数据源了</h4><p></p><p>类似 Grafana 的配置体验，可以接入已有的 ElasticSearch 数据源，自然的，就可以在夜莺里查看 ElasticSearch 的数据了，监控大盘的图表数据也可以从 ElasticSearch 获取。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5d/dd/5d97f22c612c97958e3622f8811780dd.png\" /></p><p></p><p></p><p></p><h4>可以接入 Jaeger 数据源查看链路数据了</h4><p></p><p>Jaeger 在 CNCF 蓝图中，是链路追踪的佼佼者，所以我们首先支持了 Jaeger，目前做到的效果是可以在夜莺里查看 Trace 甘特图和拓扑依赖。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cc/33/ccdf9282fa6405b717b4ea591d481a33.png\" /></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/90/21/909e43f230426480c5b96c65984ab821.png\" /></p><p></p><p></p><p>现在这个版本，可以把 metrics、logging、tracing 的数据都做到可视化了，只是数据串联方面还差一些，后续版本继续迭代优化，万里长征先走了一步。</p><p></p><h4>架构做了简化</h4><p></p><p></p><p>Nightingale 5.x 的版本，至少需要 n9e-webapi 和 n9e-server 两个模块，6.x 开始默认只需要一个模块了，就叫 n9e。我们先来回顾一下 5.x 的架构：</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/f0/ce/f0cc6f081e17c0baefa93f8331717ece.png\" /></p><p></p><p>假设两个集群，Region01是中心机房，部署了一整套夜莺，Region02和Region01的网络链路不好，所以Region02单独搞了一套 TSDB，n9e-server 跟随 TSDB，所以 Region02 也部署了一套 n9e-server。图上其实少画了 Redis，n9e-webapi 和 n9e-server 都依赖 Redis，可以全局用一个 Redis，也可以每套 n9e-server 部署自己的 Redis。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/9f/85/9f22f52f77yy692b9d2d892a7b70e185.png\" /></p><p></p><p>6.x 版本把 webapi、pushgateway、alerting 模块合并成一个n9e模块了，这个模块可以对接多个数据源，n9e模块也可以部署多个实例组成集群，架构上变简单了。</p><p></p><p>当然，如果某个机房和中心机房之间网络链路不好，想在这个边远的机房下沉部署一套时序库+告警引擎，也是OK的。除了 n9e 模块，我们也单独提供了 n9e-pushgw（数据转发网关） 和 n9e-alert（告警引擎），这俩模块是可选的，平时都用不到，只是应对边远机房网络链路不好的情况。</p><p></p><h4>可维护性提升</h4><p></p><p></p><p>除了架构方面做了简化，降低了维护复杂度，很多配置也挪到页面上管理了。比如单点登录相关的配置、告警发送模板相关的配置：</p><p><img src=\"https://static001.infoq.cn/resource/image/3f/5a/3f291d71f6ea3c77f52cb4bf57cf305a.png\" /></p><p></p><p>角色管理也挪到页面上了，不用像 5.x 的版本那样，只能通过修改数据库创建新的角色了。</p><p></p><h4>增加了内置监控大盘</h4><p></p><p><img src=\"https://static001.infoq.cn/resource/image/cc/72/ccd62503d89845e5a5c011560ea51572.png\" /></p><p></p><p></p><p>5.x 的版本其实就有内置监控大盘，但是必须把内置监控大盘导入到自己的业务组使用。6.x 开始，提供了内置大盘的浏览页面，可以不用导入自己的业务组直接使用。</p><p></p><p>欢迎夜莺社区的小伙伴一起共建共创，把内置监控大盘搞的多多的，为社区建设添砖加瓦，功在当代利在千秋！</p><p></p><h4>增加了内置告警规则</h4><p></p><p><img src=\"https://static001.infoq.cn/resource/image/6b/c9/6bd702ded77c4677ea83cdc7bd4097c9.png\" /></p><p></p><p></p><p>同理，也内置了各类组件的告警规则，极大的增加了便利性。当然了，我们也非全能，期待社区小伙伴一起共建共创，把内置告警规则也搞的多多的，如果不知道如何贡献，可以联系我们。</p><p></p><h4>继续优化了告警规则</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/17/36/177e1de5e9586c7cf70821081b88a436.png\" /></p><p></p><p>附加标签支持变量了，于是，我们可以对告警的vector的标签做一些二次处理。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/75/fa/75b5e36260e9a67a524d87b2a2d2cbfa.png\" /></p><p></p><p></p><p>对于机器失联告警、机器时间偏移做了更好的实现。废弃了原本的 target_up 指标的生成逻辑，在告警规则里直接内置支持了机器失联告警和时间偏移告警，甚至，额外增加了机器失联比例告警。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/84/71/8468be13eb12d746f3a8ff940dbf0471.png\" /></p><p></p><p></p><p>阈值告警也做了优化，一个告警策略里可以配置多个规则，指定不同的级别，而且支持级别抑制，高级别的告警抑制低级别的告警。</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/c2/f5/c29f801de5e22ebce0ddf5a4444ee7f5.png\" /></p><p></p><p></p><p>顺便介绍一下告警规则的多时间段配置，其实 5.15 版本就支持了，但是很多人不知道，借此机会也一并说一下。这个功能是社区提出的，对于一些特定的场景非常有用。</p><p></p><h4>继续优化了屏蔽规则</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/ef/da/ef61b9778869e42da5287ec63d76cbda.png\" /></p><p></p><p>增加了大家心心念念的周期性屏蔽，惊不惊喜意不意外？看图就知道这个是啥意思了，我就不详细解释了。有没有感觉开源夜莺的一些功能已经比很多商业软件做的都好了。</p><p></p><h4>继续优化了订阅规则</h4><p></p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/7a/0c/7aa463f95c754ed1e6fa6e64f8ecdf0c.png\" /></p><p></p><p>订阅规则引入了“订阅事件持续时长超过(秒)”的配置，这个功能很酷，一定程度上可以实现告警升级的功能，不过相比完备的告警升级，还是差点意思，没有认领、排班之类的功能，如果想建立统一的告警事件中心，接收各类监控系统的告警事件，统一做告警降噪、认领、升级、排班、协同等功能，请使用&nbsp;FlashDuty，FlashDuty是SaaS版本的OnCall中心，有免费套餐可用。</p><p>另外，订阅规则可以重新定义回调地址，可以对一些特定的告警事件做自动化处理，比如把特定的告警事件发给FlashDuty。</p><p></p><h4> 夜莺开源社区发展和治理</h4><p></p><p>夜莺监控，于2022 年 5 月 11 日，正式托管于中国计算机学会开源发展委员会（CCF ODC），为 CCF ODC 成立后接受捐赠的第一个开源项目。在计算机学会的支持和带动下，在快猫星云和众多公司的持续投入下，和数千名社区用户的积极参与，截止当前，夜莺开源项目在 Github 上获得了 6K star，1K fork，近 100 位 Contributor，夜莺开源社区展现出了蓬勃的生机。</p><p></p><p>夜莺 V6，是夜莺监控往全栈可观测性解决方案迈进的关键一步，是夜莺项目管理委员会和夜莺开源社区共同努力的成果。</p><p></p><p>夜莺的开源仓库在 github.com/ccfos/nightingale 欢迎小伙伴们 star 收藏。前端代码和 V5 版本拆开了，放到了 github.com/n9e/fe 前端相关问题可以到这个 repo 提 issue。</p><p></p><p></p><h4>夜莺开源项目大事记</h4><p></p><p>2020 年 3 月，夜莺监控由滴滴技术正式在 Github 开源，凭借其优秀的产品设计、灵活性架构和明确清晰的定位，夜莺监控快速发展为国内最活跃的企业级云原生监控方案。2022 年 5 月 11 日，夜莺监控正式捐赠予中国计算机学会开源发展委员会 CCF ODC，为 CCF ODC 成立后接受捐赠的第一个开源项目。2022 年 8 月 1 日，发布夜莺监控开源社区治理架构，并公示相关的任命和社区荣誉。2023 年 3 月 9 日，夜莺 V6 全新发布，夜莺监控升级为开源观测平台。</p>",
    "publish_time": "2023-03-21 18:19:32",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯大规模云原生技术实践案例集",
    "url": "https://www.infoq.cn/article/Is534v4mBvUmgC1uJEdc",
    "summary": "<p>经过多年磨砺与创新，腾讯内部海量自研业务已实现全面上云。近三年来，腾讯的自研业务上云规模 <span class=\"orange\"><strong>已经突破 5000 万核，累计节省成本超过 30 亿。</strong></span></p>\n<p>包括 QQ、微信、腾讯视频、王者荣耀等在内的 <span class=\"orange\"><strong>腾讯内部业务，和腾讯云百万级外部客户一样基于公有云的模式来开发运营</strong></span>，腾讯全面开启业务云端生长新时代。</p>\n<p>“这是腾讯自研上云战略的一个里程碑。”腾讯集团高级执行副总裁、云与智慧产业事业群CEO 汤道生表示：“把腾讯内部海量业务搬上云端，不仅帮助腾讯构建面向未来的技术架构和研发文化，推动科技成为公司业务发展和产品创新的动力与支撑，也全面锤炼了腾讯云的产品、技术和综合服务能力，这些能力将加快推动产业的数字化升级，助力实体经济全面发展。”</p>\n<p>大部分业务都是在保持高速增长的过程中上云。比如，QQ 是腾讯首个全面上云的内部业务，把如此庞大和复杂的业务搬上云端，技术团队实现了对用户零感知，被外界称为“开着飞机换引擎”。</p>\n<p>同时，腾讯云也为新兴业务的高速发展提供有力支撑。以视频号为例，借助腾讯云的弹性扩容能力，视频号稳健支撑诸如西城男孩、周杰伦、崔健等明星的大型线上演唱会活动；得益于对象存储 COS 和腾讯云直播服务，视频号在春节等特殊时段抗住了超平时 3 倍以上业务高峰。</p>\n<p>腾讯会议凭借生于云、长于云的大规模实践，现在已经成为中国最受欢迎的云视频会议产品，依托业界领先的实时音视频产品 TRTC，腾讯会议可以有效保障数亿用户在复杂网络环境中流畅清晰的视频会议体验。</p>\n<p>腾讯自研业务上云，打造出了 <span class=\"orange\"><strong>国内最大规模的云原生实践</strong></span>。</p>\n<p>三年来，数千万核的自研业务上云规模，推动腾讯云的自研产品能力不断优化，多项产品性能达到业界领先水平，也推动腾讯云在全球的基础设施不断完善。</p>\n<p>腾讯自研上云 <span class=\"orange\"><strong>明确基于云原生来构建面向未来的技术架构</strong></span>。例如，通过容器和微服务等技术，腾讯构建了统一的技术底座和算力调度平台，有效促进公司内部技术团队的协作与创新。</p>\n<p>目前，腾讯云的 TKE 平台拥有国内最大规模的 Kubernetes 集群，以及最为领先的在离线混部技术，腾讯上云打造了国内最大规模的云原生实践。</p>\n<p>为了向开发者更好的介绍腾讯自研业务、外部客户如何通过云原生技术产品支撑业务发展的，特别推出<strong><span class=\"orange\">《腾讯大规模云原生技术实践案例集》</span></strong>，包括 QQ、腾讯会议、腾讯广告、和平精英、腾讯文档、作业帮、中国南方电网、小红书、知乎、Unity、斗鱼、微盟等十多个海量产品和大规模场景的云原生技术实践。希望在给业界带去参考的同时，能够一起推动国内大规模场景下云原生技术实践的有效落地。</p>",
    "publish_time": "2023-03-21 19:18:03",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]