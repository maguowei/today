[
  {
    "title": "AWS Cloudshell 现在可以访问 Docker Engine",
    "url": "https://www.infoq.cn/article/Ae7AKOrhPULADSxkhpy5",
    "summary": "<p>最近，亚马逊云科技宣布 AWS CloudShell 为用户提供对 Docker Engine 的访问能力。通过这一集成，可以在本地对容器进行原型化，并在将其部署到 AWS 之前将其推送到注册中心。</p><p></p><p>AWS CloudShell 是一个基于 Web 的 Shell，用于通过命令行访问 AWS 环境中的资源。可以通过 AWS Console 访问，并使用相同的凭据进行预身份验证，允许用户执行 AWS CLI 命令来完成临时或重复的任务。除了 AWS CLI 之外，它还包含了各种常见的开发和运维工具，用于进行快速原型设计和实验。Docker Engine 是其预安装工具列表中最新添加的一个。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/67/67ad39e4c9054f8d966d8915f54b9567.png\" /></p><p></p><p>在 AWS CloudShell 中运行 Docker 命令（来源：AWS CloudShell 教程）</p><p></p><p>AWS CloudShell 于 2020 年底推出，受到开发者社区的欢迎，为 AWS 基于 Web 的集成开发环境（IDE）AWS Cloud 9 提供了更简单、更便宜的替代方案。AWS Cloud 9 需要一个 EC2 实例，AWS CloudShell 会在会话之间免费提供 1 个配备 1 个 vCPU、2GB RAM 和 1GB 持久存储空间的实例。除此之外，它还预安装了各种工具，如 kubectl（Kubernetes 控制平面命令行界面）、Boto3（AWS Python SDK）等，使其非常适合用于运维任务和交互式开发。Docker 与在 AWS CloudShell 上预安装的 AWS CDK 或 AWS CLI 的结合为基础设施开发开辟了两个新途径。</p><p></p><p>首先，利用“DockerImageFunction”和“DockerImageCode” CDK Lambda 资源，现在可以从 AWS CloudShell 中部署执行 Docker 容器的 AWS Lambda 函数。</p><p></p><p><code lang=\"javascript\">…\nconst { DockerImageFunction, DockerImageCode } = require('aws-cdk-lib/aws-lambda');\nconst path = require('path');\n…\nclass DockerTutorialStack extends Stack {\n  constructor(scope, id, props) {\n    super(scope, id, props);\n    // define lambda that uses a Docker container\n    const dockerfileDir = path.join(__dirname);\n    new DockerImageFunction(this, 'DockerTutorialFunction', {\n      code: DockerImageCode.fromImageAsset(dockerfileDir),\n      functionName: 'DockerTutorialFunction',\n    });\n  }\n}\nnew DockerTutorialStack(app, 'DockerTutorialStack');\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c2/c28546f934dec691f1e03acc3f789ac3.png\" /></p><p></p><p>部署引用 Docker 镜像的 CDK 栈（来源：AWS CloudShell 教程)</p><p></p><p>或者，现在可以使用 AWS CLI 在 AWS CloudShell 中构建 Docker 镜像并推送到注册表，以便在 AWS ECS、AWS EKS 或 AWS Lambda 中使用。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/86/86c88a659a0bdeffc141618f0b7ef99d.png\" /></p><p></p><p>将 Docker 镜像推送到 Amazon ECR（来源：AWS CloudShell 教程)</p><p></p><p>随着 Docker Engine 的推出，AWS CloudShell 在功能上与 Azure 和 GCP 等同类产品更加接近。不过，与 GCP 或 Azure 的 5GB 限制相比，AWS CloudShell 的 1GB 持久存储限制意味着只能进行小容器原型设计或构建。用户 @MicheAngeCamhi 在 X 上分享他的经验，他写道:</p><p></p><p></p><blockquote>. . . 本地存储被限制在 1 GB，而如果使用 Docker 镜像可能会很快就会用完！事实上，我的构建大小一直在增长，现在因为‘Docker 空间不足’导致失败</blockquote><p></p><p></p><p>最后，除了加利福尼亚、大阪和斯德哥尔摩，目前默认的 AWS CloudShell 区域都支持 Docker。更多指导信息可在 AWS CloudShell 的用户指南中找到。</p><p></p><p>查看英文原文：</p><p></p><p><a href=\"https://www.infoq.com/news/2024/01/docker-aws-cloudshell/\">https://www.infoq.com/news/2024/01/docker-aws-cloudshell/</a>\"</p><p></p><p>AI 革新时代，InfoQ AIGC 学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的 AI 知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src=\"https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png\" /></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了 AI 行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖 40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ 大模型测评报告 2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC 热潮下的技术百态》：聚焦 AIGC 引发的变革，与 50 多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的 AIGC》：我们深度采访了 LeptonAI、智谱 AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就 AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI 行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解 AI 技术的最新进展和应用案例。产品经理和开发者：探索 AIGC 在产品开发中的创新应用。</p><p></p>",
    "publish_time": "2024-02-23 10:15:58",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2023年JavaScript生态系统发展趋势",
    "url": "https://www.infoq.cn/article/itmVGcHEvphysb9Ad9F7",
    "summary": "<p>最近，Rising Stars 发布了 JavaScript 生态系统趋势发展报告，根据 GitHub Stars 展示了 2023 年的一些杰出项目。总的来说，最受欢迎的项目是 shadcn/ui。这是一个可用于创建自定义组件的 UI 组件集。JavaScript 运行时 Bun 仍然保持着良好的发展势头，成为第二受欢迎的项目。Excalidraw 是一个手绘风格的开源虚拟白板项目，它也变得日益流行。</p><p></p><p>自从 shadcn/ui 在 GitHub 上第一次提交以来，到现在已经有一年了。该项目是一个可重用的组件集，可以复制和粘贴到应用程序中用于构建组件。这样就不用安装库了。根据 shadcn/ui FAQ 页面，其理念是：</p><p></p><p>… 赋予开发人员对代码的所有权和控制权，允许他们决定如何构建组件以及采用什么样式。Shadcn/ui 可以与支持 React 的框架一起使用，比如 Next js、Astro、Remix 和 Gatsby。</p><p></p><p>Bun 在最受欢迎的项目中排名第二。它是一个 JavaScript 运行时、包管理器、测试运行器和打包器，因其速度、效率和全面的工具包而备受关注。Bun 是用 Zig 编程语言开发的，旨在成为 Node.js 的替代品。</p><p></p><p>在前端框架列表中，React 继续保有其在 JavaScript 生态系统中的领先地位。其次，作为一个 JavaScript 库，Htmx 使开发人员能够仅仅使用 HTML 来创建交互式 Web 应用程序。它使用新属性扩展了 HTML，它们可以触发 HTTP 请求和处理响应数据，从而使开发人员不需要编写的大量 JavaScript 代码就可以实现现代 Web 应用程序。</p><p></p><p>在前端框架中排名第三的是 Svelte。Svelte 是一个基于编译器的前端框架，利用声明式语法和反应性来构建高性能、可维护的 Web 应用程序。备受期待的 Svelte 5 有望引入重大改进和诸多新特性，进一步增强开发体验和应用程序性能。</p><p></p><p>在 Vue 生态系统中，Vue 2 衰落，在努力升级到 Vue 3 后又获得了 Nuxt、Vuetify 和 PrimeVue 等框架的支持。Nuxt 被评为最受欢迎的 Vue 框架。</p><p></p><p>Next.js 在后端 / 全栈类别中依然占据主导地位。Next.js 14 于 2023 年发布，最显著的变化是 Turbopack Optimizations 缩短了页面初始加载时间，改进了性能，减少了代码。Server Actions Stability 现在已经稳定，Partial Prerendering（一种预渲染部分应用程序的技术）作为预览特性引入。Astro 凭借其创新性的静态网站生成和动态页面生成能力攀升至榜单前列。</p><p></p><p>在移动领域，Expo、Tamagui 和 Nativewind 致力于统一 Web 和本地开发体验，最大化代码重用，使其更方便 Web 开发人员使用。React Native 保持了它的主导地位，但其愈加独树一帜的解决方案表明了移动开发范式的演变。</p><p></p><p>原文链接：</p><p></p><p><a href=\"https://www.infoq.com/news/2024/01/javascript-rising-stars/\">https://www.infoq.com/news/2024/01/javascript-rising-stars/</a>\"</p><p></p><p>欢迎加入 InfoQ 读者技术交流群，与志同道合的朋友一起探讨知识，交流经验。</p><p><img src=\"https://static001.infoq.cn/resource/image/71/c1/71ac76d61c2afdf231d9490ebd5b80c1.png\" /></p><p></p><p></p><p></p>",
    "publish_time": "2024-02-23 10:23:59",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Java近期新闻：LibericaJDK支持RISC-V、Payara Platform、Gradle 8.6、LangChainj 0.26、Spring Cloud",
    "url": "https://www.infoq.cn/article/E0WtdDdix6b6UghzxW94",
    "summary": "<p></p><h4>OpenJDK</h4><p></p><p><a href=\"https://www.linkedin.com/in/briangoetz?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Oracle Java 语言架构师 Brian Goetz</a>\" 提交了 JEP Draft 8324965（<a href=\"https://openjdk.org/jeps/8324965?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">类文件 API（第二次预览）</a>\"）进行第二轮预览，以获取对前一轮预览的反馈：在JDK 22中交付的JEP 457（<a href=\"https://openjdk.org/jeps/457?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">类文件 API（预览）</a>\"）。这个 JEP 提议提供一个 API 来解析、生成和转换 Java 类文件。这最初将作为 JDK 中 <a href=\"https://asm.ow2.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">ASM</a>\"（Java 字节码操作和分析框架）的内部替代品，并计划将其作为公共 API 开放。Goetz 将 ASM 描述为 \"一个古老的代码库，带有大量的遗留问题\"，并提供了 <a href=\"https://mail.openjdk.org/pipermail/discuss/2022-June/006131.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">背景信息</a>\"，说明这个草案将如何发展并最终取代 ASM。</p><p></p><h4>JDK 23</h4><p></p><p>JDK 23 <a href=\"https://jdk.java.net/23/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">早期访问版本</a>\" 的 <a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-23%2B8?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Build 8</a>\" 已发布，包含了针对 Build 7 的 <a href=\"https://github.com/openjdk/jdk/compare/jdk-23%2B7...jdk-23%2B8?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">更新</a>\"，其中包括对各种 <a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2023%20and%20%22resolved%20in%20build%22%20%3D%20b08%20order%20by%20component%2C%20subcomponent&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">问题</a>\" 的修复。关于这个版本的更多详细信息可以在 <a href=\"https://jdk.java.net/23/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p></p><h4>JDK 22</h4><p></p><p>JDK 22 <a href=\"https://jdk.java.net/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">早期访问版本</a>\"的 <a href=\"https://github.com/openjdk/jdk/releases/tag/jdk-22%2B34?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Build 34</a>\" 已发布，包含了针对 Build 33 的 <a href=\"https://github.com/openjdk/jdk/compare/jdk-22%2B33...jdk-22%2B34?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">更新</a>\"，其中包括对各种 <a href=\"https://bugs.openjdk.org/issues/?jql=project%20%3D%20JDK%20AND%20fixversion%20%3D%2022%20and%20%22resolved%20in%20build%22%20%3D%20b34%20order%20by%20component%2C%20subcomponent&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">问题</a>\" 的修复。关于这个版本的更多详细信息可以在 <a href=\"https://jdk.java.net/22/release-notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p>对于 <a href=\"https://openjdk.org/projects/jdk/23/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">JDK 23</a>\" 和 <a href=\"https://openjdk.org/projects/jdk/22/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">JDK 22</a>\"，开发者可以通过 <a href=\"https://bugreport.java.com/bugreport/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Java Bug Database</a>\" 报告 bug。</p><p></p><h4>GlassFish</h4><p></p><p><a href=\"https://glassfish.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">GlassFish</a>\" 7.0.12（<a href=\"https://twitter.com/OmniFishEE/status/1752432012953031010?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">第十二个维护版本</a>\"）主要集中在查找和修复以往出现的几个“奇怪”的 WebSocket 相关 bug 的根本原因上。新特性包括：对 servlet 缓存过滤器的优化，消除在高请求速率下可能多次加载相同资源；在 AdminGUI 中新增了一个新的传输层安全 (TLS) 复选框；向 start-cluster 命令添加了一个新的 --debug 选项，类似于 start-domain 和 start-instance 命令，可以在调试模式下启动所有实例。关于这个版本的更多详细信息可以在 <a href=\"https://github.com/eclipse-ee4j/glassfish/releases/tag/7.0.12?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p></p><h4>GraalVM</h4><p></p><p>Oracle Labs 发布了 <a href=\"https://github.com/graalvm/native-build-tools/releases/tag/0.10.0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">0.10.0版本</a>\" 的 <a href=\"https://github.com/graalvm/native-build-tools/blob/master/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Native Build Tools</a>\"，这是一个 GraalVM 项目，包含了与GraalVM原生镜像互操作的插件。这个最新版本提供了：文档的改进；依赖项升级；支持工作流矩阵中测试数组的并发性；以及减少每次测试执行所需的时间。关于这个版本的更多详细信息可以在 <a href=\"https://github.com/graalvm/native-build-tools/compare/0.9.28...0.10.0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">变更日志</a>\" 中找到。</p><p></p><h4>Spring Framework</h4><p></p><p><a href=\"https://spring.io/projects/spring-cloud?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Spring Cloud</a>\" 2022.0.5（代号 Kilburn）已经 <a href=\"https://spring.io/blog/2024/01/30/spring-cloud-2022-0-5-aka-kilburn-is-now-availavle?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发布</a>\"，其中包括对子项目的更新，例如：Spring Cloud Vault 4.0.2、Spring Cloud Kubernetes 3.0.5、Spring Cloud OpenFeign 4.0.6 和 Spring Cloud Config 4.0.5。其中有一些重大变更，包括：由于在 Spring Framework 6 中移除了 AsyncRestTemplate 类，因此移除了 <a href=\"https://docs.spring.io/spring-cloud-commons/reference/spring-cloud-commons/loadbalancer.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Spring Cloud LoadBalancer</a>\" 的自动配置；移除了 spring.cloud.kubernetes.enabled属性，采用 Spring Boot 的 <a href=\"https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnCloudPlatform.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">@ConditionalOnCloudPlatform</a>\" 注解；迁移到 <a href=\"https://docs.spring.io/spring-security/reference/servlet/oauth2/index.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Spring Security OAuth2</a>\" 客户端，支持 OAuth2。关于这个版本的更多详细信息可以在 <a href=\"https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2022.0-Release-Notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><h4>Payara</h4><p></p><p>Payara 发布了 <a href=\"https://www.payara.fish/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Payara Platform</a>\" 的2024年1月份版本，其中包括社区版 6.2024.1 和企业版 6.10.0。两个版本都包含了 bug 修复、组件升级以及对 ARM 架构的 Payara Micro 和 Payara Server Docker 镜像的支持。此外，还对 <a href=\"https://square.github.io/okio/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Okio</a>\" 3.4.0 和 <a href=\"https://square.github.io/okhttp/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">OkHttp</a>\" 4.9.2 进行了依赖升级，解决了 <a href=\"https://access.redhat.com/security/cve/cve-2023-3635?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CVE-2023-3635</a>\" 这个漏洞，该漏洞由 Okio 中的一个缺陷引起，<a href=\"https://javadoc.io/doc/com.squareup.okio/okio/1.17.6/okio/GzipSource.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">GzipSource</a>\" 类在解析格式错误的 gzip 缓冲区时无法处理处理异常。攻击者可以处理格式错误的文件，从而导致拒绝服务。关于这些版本的更多详细信息可以在 <a href=\"https://docs.payara.fish/community/docs/Release%20Notes/Release%20Notes%206.2024.1.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">社区版 6.2024.1</a>\" 和 <a href=\"https://docs.payara.fish/enterprise/docs/Release%20Notes/Release%20Notes%206.10.0.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">企业版 6.10.0</a>\" 的发行说明中找到。</p><p></p><h4>Open Liberty</h4><p></p><p>IBM 发布了 <a href=\"https://openliberty.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Open Liberty</a>\" 的 24.0.0.1 版本，其中包括：扩展了对规范和实用工具的即时支持，例如 <a href=\"https://jakarta.ee/specifications/xml-web-services/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Jakarta XML Web Services</a>\"、<a href=\"https://jakarta.ee/specifications/mail/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Jakarta Mail</a>\"、<a href=\"https://openliberty.io/docs/latest/reference/feature/passwordUtilities-1.0.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">密码实用工具</a>\"、<a href=\"https://openliberty.io/docs/latest/reference/feature/jdbc-4.1.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Java 数据库连接</a>\" 和 <a href=\"https://openliberty.io/docs/latest/reference/feature/appSecurity-1.0.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">应用程序安全</a>\"；以及验证 Open Liberty 公钥真实性的能力，可以检查签名、验证包是否由 Open Liberty 发布并且自发布以来没有被修改过。</p><p></p><p>IBM 还发布了基于 Eclipse OpenJ9 0.42 和 OpenJDK jdk-21.0.1+12 的 <a href=\"https://developer.ibm.com/languages/java/semeru-runtimes/downloads/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">IBM Semeru Runtime</a>\" 的开放和认证版本21.0.1.0，并包含了来自 Oracle <a href=\"https://www.oracle.com/security-alerts/cpuoct2023.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">关键补丁更新</a>\" 的最新 CPU 和安全补丁。</p><p></p><h4>Quarkus</h4><p></p><p>Red Hat 发布了 <a href=\"https://quarkus.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Quarkus</a>\" 的 3.7 版本，该版本提供了 bug 修复、依赖项升级和新功能，例如：将 JDK 17 作为基线；支持 Micrometer 的 <a href=\"https://github.com/micrometer-metrics/micrometer/blob/main/micrometer-core/src/main/java/io/micrometer/core/aop/MeterTag.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">@MeterTag</a>\" 注解；以及使用内联证书链进行令牌验证。此版本还解决了两个问题：<a href=\"https://access.redhat.com/security/cve/CVE-2023-5675?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CVE-2023-5675</a>\"，在 Quarkus RestEasy Reactive 和 Classic 应用程序中使用端点的授权缺陷，由使用注解处理器自定义的 Quarkus 扩展引起； <a href=\"https://access.redhat.com/security/cve/CVE-2023-6267?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CVE-2023-6267</a>\"，一个基于注解的安全漏洞，即资源可能使用 JSON 消息体在评估和应用安全约束之前被处理，即反序列化。关于此版本的更多详细信息可以在 <a href=\"https://github.com/quarkusio/quarkus/releases/tag/3.7.1?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">变更日志</a>\" 中找到。</p><p></p><p></p><h4>BellSoft</h4><p></p><p>BellSoft <a href=\"https://bell-sw.com/blog/bellsoft-releases-liberica-jdk-21-for-risc-v-with-support/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发布了 Liberica JDK 21，支持 RISC-V 架构，因为该架构在嵌入式系统中的普及程度越来越高。BellSoft 列</a>\"出了选择 Java 作为 RISC-V 语言的主要原因：</p><p></p><p>高性能、内存占用小，特别是在<a href=\"https://bell-sw.com/libericajdk-for-embedded/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">嵌入式系统使用他们的 Liberica JDK</a>\" 时。Java 具有良好的可移植性，采用 一次编写，到处运行 的模型，在生产环境中引入新架构时无需重写应用程序。有众多标准库可以用于处理任务，开发人员不必为特定用例编写自己的实现。方便的内存管理，避免内存分配错误。</p><p></p><p>关于 BellSoft 对 RISC-V 快速扩展和 Java 的评估的更多细节可以在这篇 <a href=\"https://bell-sw.com/announcements/2022/05/18/what-is-risc-v-and-when-is-the-java-port-coming/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">文章</a>\" 中找到。</p><p></p><h4>Hibernate</h4><p></p><p><a href=\"https://hibernate.org/orm/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Hibernate ORM</a>\" 6.4.3.Final 发布，提供了 bug 修复和一个新特性，该特性可以支持使用 <a href=\"https://atlasgo.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Atlas</a>\" （一个管理数据库 schema 的工具）进行构建的项目中的 Oracle GraalVM。关于此版本的更多详细信息可以在 <a href=\"https://hibernate.atlassian.net/browse/HHH-17699?jql=project%20%3D%20HHH%20AND%20fixVersion%20%3D%206.4.3&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p></p><h4>Infinispan</h4><p></p><p><a href=\"https://infinispan.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Infinispan</a>\" 15.0.0.Dev08 发布，包括大量的依赖项升级和一些值得注意的变化，例如：将 Square 的 <a href=\"https://square.github.io/okhttp/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">OkHttp</a>\" 替换为 Java 的 <a href=\"https://download.java.net/java/early_access/jdk22/docs/api/java.net.http/java/net/http/HttpClient.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">HttpClient</a>\"；将 <a href=\"https://github.com/infinispan/infinispan/blob/main/commons/all/src/main/java/org/infinispan/commons/TimeoutException.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TimeoutException</a>\" 类移动到 org.infinispan.commons 包中，与 <a href=\"https://github.com/infinispan/infinispan/blob/main/commons/all/src/main/java/org/infinispan/commons/CacheException.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CacheException</a>\" 类位于同一个包中；更新 <a href=\"https://github.com/infinispan/infinispan/blob/main/core/src/main/java/org/infinispan/remoting/transport/jgroups/JGroupsTransport.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">JGroupsTransport</a>\" 类，实现了 <a href=\"http://www.jgroups.org/javadoc4/org/jgroups/stack/AddressGenerator.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">AddressGenerator</a>\" 接口（对现有 <a href=\"https://github.com/infinispan/infinispan/blob/main/core/src/main/java/org/infinispan/remoting/transport/Transport.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Transport</a>\" 和 <a href=\"http://www.jgroups.org/javadoc4/org/jgroups/ChannelListener.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">ChannelListener</a>\" 接口的补充）。关于此版本的更多详细信息可以在 <a href=\"https://github.com/infinispan/infinispan/releases/tag/15.0.0.Dev08?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p>类似的，Infinispan 14.0.23 也包含了大量依赖项升级和一些值得注意的变化，例如：添加了配置 JGroups bundler 的选项，可以将 transfer-queue 定义为默认的 bundler 类型，并禁用了 TCP <a href=\"https://www.ibm.com/docs/en/cics-tg-zos/9.0?topic=settings-so-linger-setting&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">SO_LINGER</a>\" 设置；解决了一个问题，即在 <a href=\"https://github.com/infinispan/infinispan/blob/main/core/src/test/java/org/infinispan/persistence/sifs/SoftIndexFileStoreRestartTest.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">SoftIndexFileStoreRestartTest</a>\" 中定义的 testStatsUponRestart() 方法会意外复活被替换的值；解决了 <a href=\"https://github.com/infinispan/infinispan/blob/main/server/hotrod/src/test/java/org/infinispan/server/hotrod/tx/TopologyChangeFunctionalTest.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TopologyChangeFunctionalTest</a>\" 类中随机测试失败的问题，原因是更新函数不能正确处理状态传输的重试。关于此版本的更多详细信息可以在 <a href=\"https://github.com/infinispan/infinispan/releases/tag/14.0.23.Final?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><h4>Grails</h4><p></p><p>Grails 6.1.2 发布，包含了依赖项升级和一些改进，例如：解耦了 <a href=\"https://www.sonatype.com/products/sonatype-nexus-repository?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Sonatype Nexus Repository</a>\" 发布和发布作业的配置；与 Groovy 3.0.20 兼容；将任务分解为多个作业，改进了发布工作流程。关于此版本的更多详细信息可以在 <a href=\"https://github.com/grails/grails-core/releases/tag/v6.1.2?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><h4>TornadoVM</h4><p></p><p><a href=\"https://www.tornadovm.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TornadoVM</a>\" 1.0.1（<a href=\"https://twitter.com/tornadovm/status/1752315730065010750?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">第一个维护版本</a>\"）包含了 bug 修复和一些改进，例如：初步支持 <a href=\"https://www.mathworks.com/help/coder/ug/what-is-half-precision.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">half-precision 数据类型</a>\"；支持 Java <a href=\"https://download.java.net/java/early_access/jdk22/docs/api/java.base/java/lang/Math.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Math</a>\" 类中定义的 ceil() 方法，并在 <a href=\"https://github.com/beehive-lab/TornadoVM/blob/master/tornado-api/src/main/java/uk/ac/manchester/tornado/api/math/TornadoMath.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TornadoMath</a>\" 类中为所有后端添加了 ceil() 方法；在设备选择中启用多任务多设备行为作为 <a href=\"https://github.com/beehive-lab/TornadoVM/blob/master/tornado-api/src/main/java/uk/ac/manchester/tornado/api/TaskGraph.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TaskGraph</a>\" API 的一部分。关于此版本的更多详细信息可以在 <a href=\"https://github.com/beehive-lab/TornadoVM/releases/tag/v1.0.1?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><h4>Eclipse Vert.x</h4><p></p><p>Eclipse <a href=\"https://vertx.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Vert.x</a>\" 4.5.2 发布，带来了一些值得注意的变化，例如：改进 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/net/HostAndPort.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">HostAndPort</a>\" API，特别是在处理 URI 权限方面；解决了 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/http/WebSocket.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">WebSocket</a>\" 接口异常处理策略，其中 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/net/impl/ConnectionBase.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">ConnectionBase</a>\" 异常处理程序未在 exceptionHandler() 方法中正确设置；弃用在 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/json/jackson/DatabindCodec.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">DatabindCodec</a>\" 类中定义的 prettyMapper() 方法，因为它不再被需要。关于此版本的更多详细信息可以在 <a href=\"https://github.com/vert-x3/wiki/wiki/4.5.2-Release-Notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 和 <a href=\"https://github.com/vert-x3/wiki/wiki/4.5.2-Deprecations-and-breaking-changes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">弃用和重大变更</a>\" 中找到。</p><p></p><p>类似的，Eclipse <a href=\"https://vertx.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Vert.x</a>\" 4.4.7 版本也带来了一些值得注意的变化，例如：一个新的 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/Timer.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Timer</a>\" 接口，它扩展了 Vert.x 的 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/Future.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Future</a>\" 接口，可以用作未来链中的起始点，也可以在未来的组合中使用；确保<a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/net/impl/pool/Task.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Task</a>\" 类的实例在被 Java <a href=\"https://download.java.net/java/early_access/jdk22/docs/api/java.base/java/util/concurrent/Executor.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Executor</a>\" 拒绝时不在 <a href=\"https://github.com/eclipse-vertx/vert.x/blob/master/src/main/java/io/vertx/core/impl/TaskQueue.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">TaskQueue</a>\" 中。关于此版本的更多详细信息可以在 <a href=\"https://github.com/vert-x3/wiki/wiki/4.4.7-Release-Notes?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p>这两个版本都解决了 <a href=\"https://access.redhat.com/security/cve/cve-2024-1023?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CVE-2024-1023</a>\"漏洞，这是 Eclipse Vert.x 工具包中的一个漏洞，由于使用 Netty <a href=\"https://netty.io/4.1/api/io/netty/util/concurrent/FastThreadLocal.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">FastThreadLocal</a>\" 类提供的数据结构而导致内存泄漏，特别是当 Vert.x HTTP 客户端与不同主机建立连接时。</p><p></p><h4>Graal Cloud Native</h4><p></p><p><a href=\"https://graal.cloud/gcn/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Graal Cloud Native</a>\" (GCN) 4.2.1 （Oracle 的 Micronaut Framework 构建版本）已发布，其中包括：新的 Google Cloud 指南；支持 JDK 21 和 GraalVM Native Image；一个带有 Micronaut Framework 4.2.1 的新材料清单；对 <a href=\"https://graal.cloud/gcn/launcher/?advanced=true&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">GCN Launcher</a>\" 和 <a href=\"https://graal.cloud/gcn/get-started/installing-gcn-cli/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">GCN CLI</a>\" 进行了更新；更新的 VS Code 工具。InfoQ 将跟进更详细的新闻报道。</p><p></p><h4>OpenXava</h4><p></p><p><a href=\"https://openxava.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">OpenXava</a>\" 7.2.3 发布，带来了 bug 修复、依赖项升级和改进，例如：当在 <a href=\"https://github.com/openxava/openxava/blob/master/openxava/src/main/java/org/openxava/annotations/Condition.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">@Condition</a>\" 中使用 <a href=\"https://jakarta.ee/specifications/persistence/3.1/apidocs/jakarta.persistence/jakarta/persistence/manytomany?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">@ManyToMany</a>\" 注释时，如果 failOnAnnotationMisuse 属性设置为 true，则记录警告消息或抛出异常；当使用旧版本的 OpenXava 时记录警告消息；可能在应用中使用的新通用标签。关于此版本的更多详细信息可以在 <a href=\"https://github.com/openxava/openxava/releases/tag/7.2.3?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发行说明</a>\" 中找到。</p><p></p><p></p><h4>JetBrains Ktor</h4><p></p><p>JetBrains 发布 <a href=\"https://ktor.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Ktor</a>\" 2.3.8，这是一个用于创建微服务和 Web 应用程序的异步框架，包含了一些改进和问题修复，例如：当 <a href=\"https://github.com/ktorio/ktor/blob/main/ktor-http/common/src/io/ktor/http/CacheControl.kt?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">CacheControl</a>\" 类中定义的 max-age 属性的值大于 Int.MAX_VALUE 时抛出 NumberFormatException；在自定义 JavaScript 引擎中使用 <a href=\"https://github.com/ktorio/ktor/blob/main/ktor-http/common/src/io/ktor/http/URLBuilder.kt?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">URLBuilder</a>\" 时，由于自身属性导致的 ReferenceError；在 <a href=\"https://github.com/ktorio/ktor/blob/main/ktor-http/common/src/io/ktor/http/RequestConnectionPoint.kt?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">RequestConnectionPoint</a>\" 接口中实现了 toString() 方法，改进了日志记录。关于此版本的更多详细信息可以在 <a href=\"https://ktor.io/changelog/2.3/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">变更日志</a>\" 中找到。</p><p></p><h4>Keycloak</h4><p></p><p><a href=\"https://www.keycloak.org/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Keycloak</a>\" 23.0.5 发布，包含了 bug 修复和新特性/增强，例如：在文档中将 Red Hat Data Grid 的引用改为 Infinispan；解决了使用细粒度权限时角色映射选项卡不可见的问题；更新了 <a href=\"https://aws.amazon.com/route53/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">AWS Route 53</a>\" 指南，兼容 <a href=\"https://aws.amazon.com/rosa/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Red Hat OpenShift Service on AWS</a>\" (ROSA) 和 Openshift 4.14.x。</p><p></p><h4>LangChain for Java</h4><p></p><p><a href=\"https://github.com/langchain4j/langchain4j/blob/main/README.md?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">LangChain for Java</a>\" (LangChain4j) 0.26.0 带来了许多 bug 修复、新的集成和特性：高级检索增强生成 (RAG) 基础，灵感来自于这篇<a href=\"https://blog.langchain.dev/deconstructing-rag/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">文章</a>\" 和这份<a href=\"https://arxiv.org/abs/2312.10997?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">白皮书</a>\"；通过在 LangChain4j Chat API 中实现图像输入并集成 OpenAI 和 Gemini 来支持多模态；在 <a href=\"https://github.com/langchain4j/langchain4j/blob/main/langchain4j/src/main/java/dev/langchain4j/chain/ConversationalRetrievalChain.java?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">ConversationalRetrievalChain</a>\" 类的 execute() 方法中添加了元数据，允许用户在追加检索到的文档信息时添加额外信息。关于此版本的更多详细信息可以在 <a href=\"https://github.com/langchain4j/langchain4j/releases/tag/0.26.1?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发布说明</a>\" 中找到。</p><p></p><h4>Gradle</h4><p></p><p>Gradle 8.6 <a href=\"https://github.com/gradle/gradle/releases/tag/v8.6.0?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发布</a>\"，带来了这些特性：支持通过GRADLE_ENCRYPTION_KEY环境变量配置缓存中的自定义加密密钥；改进了错误和警告报告；改进了<a href=\"https://docs.gradle.org/8.6-rc-1/userguide/build_init_plugin.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">Build Init Plugin</a>\"，支持各种类型的项目；增强了插件作者和构建工程师开发自定义构建逻辑的功能。有关此版本的更多详细信息，请参阅<a href=\"https://docs.gradle.org/8.6/release-notes.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDg2NTY2NjQsImZpbGVHVUlEIjoiOTAzMEpOS1p4ZEM1UE9rdyIsImlhdCI6MTcwODY1NjM2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.PxZty_xoho9HnLqXoEgkLbJCD1N7ITEuoez71ip3IaM\">发布说明</a>\"。</p><p></p><p></p><p>原文链接：</p><p><a href=\"https://www.infoq.com/news/2024/02/java-news-roundup-jan29-2024/\">https://www.infoq.com/news/2024/02/java-news-roundup-jan29-2024/</a>\"</p><p></p><p>欢迎加入 InfoQ 读者技术交流群，与志同道合的朋友一起探讨知识，交流经验。</p><p><img src=\"https://static001.infoq.cn/resource/image/7a/67/7ab2278f940601c21a1a37bde501b467.png\" /></p><p></p>",
    "publish_time": "2024-02-23 10:50:01",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！",
    "url": "https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U",
    "summary": "<p>Stability AI 发布了 Stable Diffusion 3.0，这款图像生成 AI 模型再次刷新了人们的认知。</p><p>&nbsp;</p><p>这款由 Stability AI 倾力打造的文本变图模型，可是迄今为止最强大的“黑科技”！ 无论你想生成多主题的奇幻场景，还是高精度的风景写真，统统不在话下！</p><p>&nbsp;</p><p>Stability AI强调了该版本的几个亮点，其中首要的就是文字渲染能力，他们在其官网上一连给了三幅含有文字的图片，不仅文字清晰而且也没有任何拼写错误。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/68/680eecb0d5342430e6217ccd673edf68.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque也在X（Twitter）上狂炫带有文字的图片：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cd/cdf6e5ffdc31f0518f2b1b447ba81fc0.png\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f83f92c52eeef7c6da36aa530ec2c297.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stable Diffusion 3.0 中改进的排版是 Stability AI 在新模型中构建的几个改进的结果。</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque 说：“这归功于 Transformer 架构和额外的文本编码器。现在可以实现完整的句子和一致的风格。”</p><p>&nbsp;</p><p>另一个亮点是“多主题生成”：用一句话，就能描绘出用户脑中的万千世界！</p><p>&nbsp;</p><p>Stability AI举了一些例子，让SD3根据一句含有多个元素的Prompt画一幅画：</p><p>&nbsp;</p><p>“一幅画作，描绘了一位宇航员骑着一头穿着芭蕾舞裙的猪，手里还撑着一把粉色雨伞。在猪旁边，一只戴着高顶礼帽的知更鸟静静伫立。画面一角，写着‘Stable Diffusion’。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/526a3315b60a03668714442fec7de4b8.png\" /></p><p></p><p>&nbsp;</p><p>“一张照片，画面中有一个红色的球体放在一个蓝色的立方体上面。它们的后面有一个绿色的三角形，右边有一只狗，左边有一只猫。”</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9e/9ece589c0d15dc858fca4b85a62e3ae0.png\" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>其中一个主题元素变化还能不影响其他元素：</p><p>&nbsp;</p><p></p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一个亮点就是“超高画质”，这简直是细节控的福音，每一张图片都堪称艺术品！例如下面这张变色龙特写照片：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6afad7d73a6dbf86982dc55763e8d1b7.png\" /></p><p></p><p>&nbsp;</p><p>而且生成的漫画和素描，质感也比之前的版本进步了一个台阶：</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/ccdeffebc2ee3f538730c4743340edcf.png\" /></p><p></p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6c/6c6417031da3747bc14f296c53b0891f.png\" /></p><p></p><p>&nbsp;</p><p>虽然 Stable Diffusion 3.0 最初被展示为文本转图像生成 AI 技术，但它将成为更广泛应用的基础。Stability AI 近几个月也在开发 3D 图像生成和视频生成功能。</p><p>&nbsp;</p><p>Mostaque 说：“我们制作可以随时随地使用并适应任何需求的开放模型。这是一个跨尺寸的模型系列，将支持我们下一代视觉模型的发展，包括视频、3D 等。”</p><p>&nbsp;</p><p>Mostaque也在X（Twitter）给出了一个SD3D的视频：</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/79/79680675b18abdd482941023979e2987.gif\" /></p><p></p><p>&nbsp;</p><p>而且，Stable Video也正式开放公测了，支持图生视频和文生视频。尽管人们都在关注Sora，但有人估计至少Sora还需要三个月才能开始内测。需要强调的是，这是内测，不同于像Stable Video这样的公开测试。</p><p>&nbsp;</p><p>从官网放出的例子来看，生成视频在画面稳定性、运动幅度、画面细节丢失上，效果跟Sora不相上下。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/d6/d60eea5c00b19921a2adccb70fffd69c.gif\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f7/f7a63f8409c5ab4a53272d8431593605.gif\" /></p><p></p><p></p><p>而一些试玩了Stable Video的网友，还是觉得跟Sora有所差距，并对此评论：“越来越期待Sora了”。该网友表示，“用自己的照片试用了一下Stable Video，发现只有没有脸的图才能有比较好的生成结果，有脸的都崩了。”其他网友补充称，有脸的图调低motion值也可以得到相对正常的结果，但会很卡顿。</p><p>&nbsp;</p><p></p><h2>架构变革：采用类似Sora模型架构</h2><p></p><p>&nbsp;</p><p>在过去的一年中，Stability AI 一直在稳步迭代和发布多个图像模型，每个模型都显示出越来越高的复杂性和质量。7 月份发布的 SDXL 大幅改进了 Stable Diffusion 基础模型，现在该公司正寻求更进一步的发展。</p><p>&nbsp;</p><p>新的 Stable Diffusion 3.0 模型旨在提供改进的图像质量和更好的性能，以从多主题提示生成图像。它还将提供比以前的 Stable Diffusion 模型更出色的排版，从而在生成的图像中实现更准确和一致的拼写。过去，排版一直是 Stable Diffusion 的一个弱点，包括 DALL-E 3、Ideogram 和 Midjourney 在最近的版本中也一直在努力解决这个问题。Stability AI 正在构建各种模型大小的 Stable Diffusion 3.0，模型可选择的参数范围在800M 到 8B 。</p><p>&nbsp;</p><p>Stable Diffusion 3.0 不仅仅是 Stability AI 已经发布的模型的新版本，它实际上基于一种全新的架构。</p><p>&nbsp;</p><p>Emad Mostaque 表示，Stable Diffusion 3 是原始 Stable Diffusion 的正统续作。它采用了类似于 OpenAI 近期发布的 Sora 模型的 Diffusion Transformer 新架构，代表了该领域的最新技术突破。</p><p>&nbsp;</p><p>“Diffusion Transformer”技术在 2022 年首次提出，并在 2023 年进行了改进，现在已经实现了可扩展性。 此外，Stable Diffusion 3.0 还采用了“流匹配”技术，这也是另一项改进质量且不会增加太多额外负担的新技术。</p><p>&nbsp;</p><p>Stability AI 一直在尝试多种图像生成方法。本月早些时候，该公司发布了 Stable Cascade 的预览版，它使用 Würstchen 架构来提高性能和准确性。Stable Diffusion 3.0 采取了不同的方法，使用了 Diffusion Transformer。</p><p>&nbsp;</p><p>Mostaque 强调说：“Stable Diffusion 以前没有 Transformer。”</p><p>&nbsp;</p><p>Transformer 是许多生成 AI 革命的基础，被广泛用作文本生成模型的基础。图像生成主要在 Diffusion 模型领域。详细介绍 Diffusion Transformer (DiT) 的研究论文解释说，它是一种新的 Diffusion 模型架构，它用操作潜在图像块的 Transformer 取代了常用的 U-Net 主干。DiT 方法可以更有效地利用计算资源，并且可以超越其他形式的 Diffusion 图像生成。</p><p>&nbsp;</p><p>Stable Diffusion 的另一个重大创新是流匹配 (flow matching)。 流匹配的研究论文解释了它是一种训练 Continuous Normalizing Flows (CNFs) 以模拟复杂数据分布的新方法。根据研究人员的说法，使用Conditional Flow Matching (CFM) 和optimal transport paths（最佳传输路径），与diffusion paths相比，可以实现更快的training、更有效的采样和更好的性能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/\">https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/</a>\"</p><p><a href=\"https://twitter.com/EMostaque\">https://twitter.com/EMostaque</a>\"</p><p><a href=\"https://stability.ai/news/stable-diffusion-3\">https://stability.ai/news/stable-diffusion-3</a>\"</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2024-02-23 13:35:23",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "jQuery 4.0.0现已发布beta版：全球7800万网站该面临升级了？",
    "url": "https://www.infoq.cn/article/ZZRcTXfErLIftQNwwSZg",
    "summary": "<p>2月6日，jQuery核心团队负责人Timmy Willison宣布，jQuery 4.0.0现已发布beta版。</p><p></p><blockquote>jQuery 4.0.0已经开发了很长时间，如今终于准备好推出beta版本！新版本有不少内容值得介绍，我们也很高兴迎接它的到来。除了bug修复和性能改进之外，4.0.0还做出了一系列重大调整。我们裁剪掉遗留代码，删除了部分已被弃用的API，还去掉了不少从未对外公开、仅供内部使用的公共函数参数，同时不再支持某些过于复杂的“神奇”操作。</blockquote><p></p><p>&nbsp;</p><p>本文将向大家简单介绍这些变更。先从最重要的入手：放弃对IE10及更早版本的支持。jQuery团队原本计划在微软于2022年结束支持后放弃IE11，但最终又决定将计划延后至v5，以避免v4版本出现更多问题。</p><p>&nbsp;</p><p>即将发布的新版本将使用ES模块，并将打包方案从RequireJS切换至Rollup。新版本还删除了13项已被弃用的函数，这些函数“要么长期仅对内部开放，要么已经在所有受支持浏览器上均已有等效替代选项”。</p><p>&nbsp;</p><p></p><h2>jQuery：全球7800万网站的共同选择</h2><p></p><p>&nbsp;</p><p>此次公告的一大重要主题，就是全面遵循各种现代浏览器行为与规范。事实上，自2006年1月jQuery诞生以来（当时IE还占全球九成市场份额&nbsp;），网络浏览器已经取得了长足的进步，前端开发也掀起一波旷日持久的竞争。</p><p>&nbsp;</p><p>现如今，99.84%的浏览器均已支持ES6、提供大量效果良好的Web API还迎来了CSS的强大升级（允许我们使用WebAssembly在浏览器中运行成熟WordPress实例）——至少不再需要依赖1.25 MB的DOM操作库了。</p><p>&nbsp;</p><p>或者用一位Reddit用户的话说：</p><p></p><blockquote>看看，jQuery简直是不可思议。它以难以置信的方式改变了JS，给JS开发者带来了前所未有的改变。它如此创意满满，JS社区和TC39实现了很多jQ以往根本做不到的事。jQ的最大目标就是制定标准和改进JS语言，它做到了，而现在也是时候退出历史舞台了。</blockquote><p></p><p>&nbsp;</p><p>从在线统计数据来看，这种说法显然很有道理。jQuery可能已经成了前端领域最不招人疼的孩子，但可观的市场份额却足以让其他时髦框架相形见绌。</p><p>&nbsp;</p><p>从NPM看，jQuery 3.7.1发布于2023年8月，每周下载量超过900万次，相应依赖包更是超过20k。</p><p>&nbsp;</p><p>BuiltWith指出目前全球超7800万网站在使用jQuery，而W3Techs报告称“据我们所知，全部JavaScript库网站中有94.4%使用jQuery，在所有网站中占比77.1%。”</p><p>&nbsp;</p><p></p><h2>源远流长</h2><p></p><p>jQuery之所以能够长期流行，主要原因之一就是它对生态系统的卓越贡献。具体来讲，它被捆绑在WordPress Core当中，成为了众多主题与插件的固定组成部分。</p><p>&nbsp;</p><p>WordPress采用基于React的Gutenberg，降低了对jQuery的依赖。在Willison做出题为《JavaScript之于现代WordPress开发》（<a href=\"https://wordpress.tv/2024/02/13/developer-hours-javascript-for-modern-wordpress-development/\">https://wordpress.tv/2024/02/13/developer-hours-javascript-for-modern-wordpress-development/</a>\"）演讲一周后的Developers Hours开发者会议上，Automattic开发倡导者Ryan Welcher和Nick Diego花了一个多小时深入讨论JS工具和技术如何构建块和编辑器扩展，但却一次都没有提到过jQuery。</p><p>&nbsp;</p><p>在2021年10月在Make Themes博客上发表的文章中，核心贡献者Felix Arntz甚至敦促开发者们放弃jQuery以提高性能。</p><p>&nbsp;</p><p>尽管如此，在Willison宣布jQuery新版本的当天，TRAC还是率先报道了这一消息，并提问“WordPress核心团队期待这次更新吗？”Automattic首席开发者Andrew Ozz立马回复，“当然：）”</p><p>&nbsp;</p><p>作为在CMS市场上占比高达43%的巨头，WordPress的肯定无疑是给jQuery续命的万能灵药。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b6/b6f26f679333c710436fba5df08eb541.png\" /></p><p></p><p>&nbsp;</p><p>WordPress Tavern上次介绍jQuery还是在2020年，当时jQuery Migarte 1.4.1被从WordPress 5.5中删除，并引发不少主题和插件失效。</p><p>&nbsp;</p><p>WordPress核心团队的Enable jQuery Migrate Helper插件专为解决这次问题而推出，时至今日仍在继续维护，并拥有10万活跃安装量。用户们普遍反响不错，表示这东西确实有效。可这也不禁让我们要问，现在已经是2024年了，为什么构建WordPress网站还需要借助这样一个“作为临时解决方案的插件，为的就是让插件和主题作者们能继续拖着不更新和测试自己的代码？”</p><p>&nbsp;</p><p></p><h2>推动Web向前发展的开拓者</h2><p></p><p>&nbsp;</p><p>也许答案就在W3Techs上一条令人震惊的评论当中。目前，使用jQuery的网站中仍有三分之一运行着3.x甚至更早（3.0.0发布于2016年6月）版本。</p><p>&nbsp;</p><p>这样的结果与OpenJS基金会及IDC于2023年11月开展的一项小范围研究也对得上。在509名调查受访者中，有89%确认自己在使用jQuery，其中56%表示部署的是旧版本，其中有些版本甚至不再维护。</p><p>&nbsp;</p><p>开源与标准化专家Tobie Langel在W3C的Secure the Web Forward研讨会上发表讲话，认为“jQuery巨大的影响力和长久的生命力”使其处于独特的市场地位：如果捍卫jQuery就是捍卫Web，那么jQuery也许会再一次迸发出新的生机，以开拓者的姿态继续推动Web向前发展。</p><p>人们已经在为此而努力：2022年10月，开源安全基金会（OpenSSF）的Alpha-Omega项目向jQuery授予了35万美元的资助，旨在“帮助其用户并推动代码现代化，从而缓解jQuery的潜在安全问题。”</p><p>&nbsp;</p><p>而且在Linux基金会、微软、谷歌、亚马逊等行业巨头的支持下，以及由GoDaddy、IBM、Joyent和Sovereign Tech Fund支持的OpenJS基金会的推动下，jQuery似乎已经呈现出复苏的迹象。</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://wptavern.com/look-whos-back-jquery-4-0-0-is-now-in-beta\">https://wptavern.com/look-whos-back-jquery-4-0-0-is-now-in-beta</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-02-23 13:49:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "2024年，这些AI引擎和软件开发安全问题亟需解决",
    "url": "https://www.infoq.cn/article/GKoIPxyS1deGv2jK7OP6",
    "summary": "<p></p><p></p><blockquote>作者：&nbsp;JFrog大中华区总经理 董任远</blockquote><p></p><p>&nbsp;</p><p>随着AI应用的规模不断扩大以及大语言模型（LLM）的商品化，开发者越来越多地承担起将人工智能（AI）和机器学习（ML）模型与软件更新或新软件一起打包的任务。虽然AI/ML在创新方面大有可为，但同时也加剧了人们的担忧，因为许多开发人员没有足够的带宽来安全地管理其开发。</p><p>&nbsp;</p><p>安全漏洞可能无意中将恶意代码引入AI/ML模型，从而使威胁行为者有了可乘之机，引诱开发者使用开放源码软件模型变种，渗透企业网络并对组织造成进一步损害。甚至还有开发者越来越多地使用生成式AI来创建代码，却不知道自己生成的代码是否受到威胁的情况，这同样会导致安全威胁长期存在。因此，必须自一开始就对代码进行适当的审查，以主动降低软件供应链受到损害的威胁。</p><p>&nbsp;</p><p>由于威胁行为者会想方设法利用AI/ML模型，威胁将持续困扰着安全团队。随着安全威胁的数量不断增加，规模不断扩大，在2024年开发者将更加重视安全性，并部署必要的保障措施，以确保其企业的弹性。</p><p>&nbsp;</p><p></p><h2>开发者的角色演变</h2><p></p><p>&nbsp;</p><p>对于开发者来说，在软件生命周期初始阶段就考虑到安全性是一种相对较新的做法。通常情况下，二进制级别的安全性被认为只是“锦上添花”的存在。而威胁行为者会利用这种疏忽，寻找将ML模型武器化以对抗组织的途径，找出将恶意逻辑注入最终二进制文件的方法。</p><p>&nbsp;</p><p>同样，许多开发者由于没有接受过必要的培训，无法在开发的初始阶段就将安全性嵌入到代码中。由此造成的主要影响在于，由AI生成并在开源存储库上训练的代码通常没有经过适当的漏洞审查，且缺乏整体安全控制来保护用户及其组织免受利用。尽管这可能会节省工作职能中的时间和其他资源，但开发者却在不知不觉中将其组织暴露在众多风险之下。一旦这些代码在AI/ML模型中实现，这些漏洞利用就会造成更严重的影响，而且有可能不会被发现。</p><p>&nbsp;</p><p>随着AI的广泛应用，传统的开发者角色已不足以应对不断变化的安全环境。步入2024年，开发者也必须成为安全专业人员，从而巩固DevOps和DevSecOps不能再被视为独立工作职能的理念。通过从一开始就构建安全解决方案，开发者不仅能确保关键工作流的最高效率，还能增强对组织安全性的信心。</p><p></p><h2>通过“左移”，把安装保障措施放在最开始</h2><p></p><p>&nbsp;</p><p>如果安全团队要在新的一年里对威胁保持警惕，那么ML模型的安全性就必须持续发展演进。然而，随着AI的大规模应用，团队不能在软件生命周期的后期才确定必要的安全措施，因为到那时，可能就真的为时已晚了。</p><p>&nbsp;</p><p>组织内部负责安全方面的高层必须以“左移”的方式进行软件开发。通过坚持此方法，即能够自一开始就确保软件开发生命周期中所有组成部分的安全，并从整体上改善组织的安全情况。当应用到AI/ML时，左移不仅能确认外部AI/ML系统中开发的代码是否安全，还能确保正在开发的AI/ML模型不含恶意代码，且符合许可要求。</p><p>&nbsp;</p><p>展望2024年及以后，围绕AI和ML模型的威胁将持续存在。如果团队要持续抵御来自威胁行为者的攻击并保护组织及其客户，确保自软件生命周期之始就考虑到安全性将是至关重要的。</p>",
    "publish_time": "2024-02-23 14:20:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "性能媲美8卡H100，但运行三年，推理成本比H100高30多倍！Groq CEO：它正在接近免费",
    "url": "https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA",
    "summary": "<p>在人工智能的世界里，正在发生一场翻天覆地的变化，随着ChatGPT、Sora的横空出世，我们正在从深度学习时代转向生成式人工智能时代，而在这场巨变中，芯片成为了科技巨头们的必争之地。</p><p>&nbsp;</p><p>近日，硅谷一家初创企业以一款独特的芯片产品攻占各大科技媒体板块头条。该公司正以一种与过往不同的方式推动这场人工智能革命。该公司名为<a href=\"https://groq.com/\">Groq</a>\"，是一家人工智能解决方案公司。</p><p>&nbsp;</p><p>据多家外媒报道，Groq 刚刚推出了 alpha 预览版的推理引擎，该引擎使用其定制的语言处理单元 (LPU) 芯片架构。这款推理引擎主打一个“快”字，每秒能输出500个token。相比之下，Chat GPT-3.5每秒生成速度为40个token。</p><p>&nbsp;</p><p>“Groq那疾如闪电的演示开始疯传，让人们第一次意识到当前版本的ChatGPT、Gemini甚至是Grok看起来是多么笨拙和迟缓。”有网友感叹道。</p><p>&nbsp;</p><p>“你必须尝试的疯狂技术！” HyperWriteAI CEO&nbsp;Matt Shumer在X上极力称赞Groq：“以 500 tok/s 的速度运行 Mixtral 8x7B-32k，答案几乎是即时的。开辟新的用例，并彻底改变现有用例的用户体验可能性。”</p><p>&nbsp;</p><p>根据Shumer发布在X上的演示，Groq能够瞬间给出包含数百个单词的事实性答案，并提供逻辑链上的消息来源。</p><p>&nbsp;</p><p>在另一段演示中，Groq 公司创始人兼CEO Jonathon Ross还邀请CNN主持人以实时对话的方式，跟跨越半个地球的AI聊天机器人来了场电视直播交流。虽然之前的ChatGPT、Gemini等其他聊天机器人也都带来令人印象深刻的表现，但Groq单凭速度一项就倾倒了众生。正所谓“天下武功，唯快不破”，速度往往是决定技术成果能否实际应用的关键。</p><p>&nbsp;</p><p>在Groq的第一个公开基准测试中，Meta AI 的 Llama 2 70B 在 Groq LPU™ 推理引擎上运行，其输出令牌吞吐量快了 18 倍，优于所有其他基于云的推理提供商。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c0f9610cb66d008a050d5818cf18abe.png\" /></p><p></p><p>此外，根据Artificial Analysis上周公布的第三方测试结果，Groq每秒能够生成247个token，远远高于微软的18个token。也就是说如果将ChatGPT运行在Groq芯片之上，其速度将可提高13倍有余。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/b6/b687e5aead1cea0e24c5369a699149b6.png\" /></p><p></p><h2>成本推算屡受质疑</h2><p></p><p>&nbsp;</p><p>在传统CPU和GPU领域，更快的推理速度往往意味着要付出更高的成本。但从成立之初，Groq就在强调公司的使命是将计算成本降至零。</p><p>&nbsp;</p><p>在面对成本问题时，Ross曾在两年前接受《福布斯》采访时表示：“Groq 决定做一些完全不同的事情，进行与传统半导体行业智慧相反的创新。我们的使命是将计算成本降至零。我知道每个人都讨厌高昂的计算成本。但是，如果你回顾一下计算的历史就会发现计算成本避无可避。因此，当我们说‘将计算成本降至零’时，我们仍然以具有竞争力的行业价格点来销售我们的解决方案。也就是说，当我们提供数量级的性能改进（200 倍、600 倍、1000 倍）时，我们每美元所提供的性能是 200、600、1000 倍。所以，它正在接近免费。”</p><p>&nbsp;</p><p>Groq 在官网上称“保证击败同等上市模型的已发布提供商所发布的每百万token的价格。”</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/be/be9065b8c356d94ed5e6635933052721.png\" /></p><p></p><p>但一些业内人士以及开发者群体对于Groq卡的高昂价格和CEO主张的的“价格正在接近免费”的说辞提出了质疑。原Facebook人工智能科学家、原阿里巴巴技术副总裁贾扬清就给Grop算了一笔账，Groq的成本到底如何，且看大佬的分析。</p><p>&nbsp;</p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a8ba14ccbf2c99ca77893006f4425ff.jpeg\" /></p><p></p><p>（图片来自网络）</p><p>&nbsp;</p><p>此外，也有Groq前员工在Hacker News上表示Groq理论上的推理成本是不切合实际的。</p><p>&nbsp;</p><p></p><blockquote>Groq 曾在发文中指出，他们使用了 576 个芯片来实现以 500 T/s 的速度运行 Mixtral 8x7B-32k 这样的结果。但不得不注意的是，每个单独的用户都需要一个单独的 KV 缓存，每个用户将增加更多千兆字节。&nbsp;我曾在Groq工作两年，我预计他们实现这些性能数字的总费用将超过数百万美元，他们发布的理论价格应该比实际使用价格更低，因此这个结果是不切实际的。从每美元实际性能的角度来看，它们似乎不可行，但如果你将成本问题抛到九霄云外，那么它们确实挺酷的。</blockquote><p></p><p></p><h2>Groq 背后的秘密：架构和编译器</h2><p></p><p>&nbsp;</p><p>那么，Groq又是如何做到如此之快呢？据悉，Groq能做到如此之快背后的秘诀是架构和编译器的创新。</p><p></p><h3>从零开始设计架构</h3><p></p><p>&nbsp;</p><p>在一次公开技术分享中，Groq CEO Ross透露， Groq芯片的架构从头开始设计的，其中包含数千个并行处理推理查询的多线程处理器。每个芯片周围都有一个独特的、确定性的数据流架构，可最大限度地提高吞吐量，同时最大限度地减少延迟和功耗。</p><p>&nbsp;</p><p>Groq 的 TSP 处理器绕过了造成时序不可预测性的缓存和控制逻辑。相反，结果按照软件定义的序列直接从一个执行单元流向下一个执行单元，从输入到输出仅花费几微秒。</p><p>&nbsp;</p><p>对于大规模部署，GroqNode 服务器提供机架就绪的可扩展计算系统。GroqNode 是八个 GroqCard 加速器组，在 4U 服务器机箱中具有集成芯片到芯片连接以及双服务器级 CPU 和高达 1 TB 的 DRAM。GroqNode 旨在实现大型深度学习模型的高性能和低延迟部署。</p><p>&nbsp;</p><p>最后，对于数据中心部署，GroqRacks 提供了可扩展的加速器网络。GroqRack 结合了 8 个 GroqNode 集的功能，具有多达 64 个互连芯片。其结果是一个确定性网络，单个机架的端到端延迟仅为 1.6 微秒，非常适合海量工作负载，并且旨在扩展到整个数据中心。</p><p>&nbsp;</p><p>在面对面的基准测试中，与基于 GPU 的大型语言模型推理系统相比，Groq 系统的延迟时间提高了 100 倍，而成本仅为 1/5。当 GPU 性能受到批处理要求和内存层次结构的影响时，Groq 的架构是从头开始构建的，以最大限度地减少单个查询的延迟。</p><p>&nbsp;</p><p>通过消除昂贵的数据移动，GroqChips 仅消耗几瓦的功率，而不是像 GPU 那样消耗数百瓦的功率。这使得能源效率提高了 10 倍，这对于控制爆炸式增长的 AI 计算成本至关重要。</p><p>&nbsp;</p><p>值得注意的是，Groq自称“第一个语言处理单元 (LPU™) 的创建者”。它的核心壁垒在于其独特的 LPU 推理引擎，LPU 代表语言处理单元，这是一种新型的端到端处理单元系统，可为具有顺序组件的计算密集型应用程序提供最快的推理，例如人工智能大语言模型。</p><p>&nbsp;</p><p>Groq 一直在强调，LPU解决了大语言模型的两个瓶颈：计算密度和内存带宽。就大语言模型而言，LPU 比 GPU 和 CPU 具有更大的计算能力。这减少了每个单词的计算时间，从而可以更快地生成文本序列。此外，消除外部内存瓶颈使 LPU 推理引擎能够在大语言模型上提供比 GPU 好几个数量级的性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ec/ec7c200508e19acf6d0c3a70f5b177b6.png\" /></p><p></p><p>&nbsp;</p><p>根据推特上与Groq关系密切的投资人k_zeroS分享，LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。</p><p>&nbsp;</p><p>与传统GPU、GPU、TPU相比，Groq的LPU也有其自身优势。</p><p>&nbsp;</p><p>一直以来，使用现有架构并连接许多 CPU 解决了训练挑战。人工智能推理要困难得多，因为它是实时的、对延迟敏感的，并且需要高性能和高效率。</p><p>&nbsp;</p><p>随着时间的推移，CPU 变得越来越大、越来越复杂，具有多个内核、多个线程、片上网络和控制电路。负责加速软件性能和输出的开发人员必须处理复杂的编程模型、安全问题以及由于处理抽象层而导致编译器控制可见性的丧失。简而言之，标准计算架构具有不提供推理性能优势的硬件功能和元素。</p><p>&nbsp;</p><p>GPU 架构专为 DRAM 带宽而设计，并构建在多数据或多任务固定结构处理引擎上。GPU 执行大规模并行处理任务，但存在内存访问延迟，而 ML 已经突破了外部内存带宽的限制。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/23/2371ffa3c81a58e8cb20587451430763.png\" /></p><p></p><p>不同于英伟达 GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。</p><p>&nbsp;</p><p>鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于英伟达的GPU。</p><p>&nbsp;</p><p>如果在AI处理场景中采用Groq的LPU，可能就无需为英伟达 GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。</p><p></p><h3>编译器是重要基石</h3><p></p><p>&nbsp;</p><p>在编译器部分，Groq也做了大量创新。Jonathan Ross 坚持将编译器作为公司技术能力的基石，因此设计团队在做芯片的前六个月的时间里专注于设计和构建编译器。只有在团队对编译器感到满意后，才开始研究芯片架构。</p><p>&nbsp;</p><p>与传统编译器不同，Groq 不依赖内核或手动干预。通过编译器和硬件的软件优先协同设计方法，Groq 构建了编译器，自动将模型直接映射到底层架构。自动编译过程允许编译器优化硬件上的模型执行，而无需手动开发或调整内核。</p><p>&nbsp;</p><p>该编译器还可以轻松添加资源和扩展。到目前为止，Groq 已经使用刚刚描述的自动化流程编译了 500 多个用于实验目的的 AI 模型。</p><p>&nbsp;</p><p>当 Groq 将客户的工作负载从 GPU 移植到 Groq LPU 时，第一步是删除针对 GPU 的不可移植的供应商特定内核，然后删除任何手动并行或内存语义。当所有非必要的内容都被剥离后，剩下的代码会变得更加简单和优雅。</p><p>&nbsp;</p><p>目前，在Groq网站上，用户可以随意测试不同的聊天机器人，并查看它们在Groq LPU上的运行速度。感兴趣的朋友可以点击尝试：<a href=\"https://groq.com/\">https://groq.com/</a>\"</p><p></p><h2>Groq为何备受关注？</h2><p></p><p>&nbsp;</p><p>Groq/Grok这个词来自Robert Heinlein于1961年创作的科幻小说《异乡异客》（Stranger in a Strange Land），本身的意思是“深刻而直观地理解”。也许正是为了达成这样的效果，众多AI厂商才争相用它来形容自己的AI产品。</p><p>&nbsp;</p><p>那么，Groq为何能在短期内获得如此大的关注？</p><p>&nbsp;</p><p>有分析认为，之所以备受关注，原因主要有三点：其一，是Groq在架构和编译器上的创新（上文已经详解，不再赘述）；其二，是谷歌芯片大佬光环加持；其三，是Groq LPU的出现有望使客户摆脱硬件的锁定。</p><p>&nbsp;</p><p>2016年底，Jonathon Ross从谷歌离职创办了Groq，希望能为AI和HPC工作负载提供毫不妥协的低延迟和高性能。Ross此前发明了驱动谷歌机器学习（ML）软件的张量处理单元（TPU），这两项技术为当时红极一时的AlphaGo提供了重要的技术支撑。​当时，谷歌的这支工程团队在大约 14 个月内就完成了第一代 TPU，因此被外界认为是一支技术实力超群的技术团队。</p><p>&nbsp;</p><p>就在那一年，这支技术实力超强的谷歌TPU 团队中的前 10 名成员中有 8 名成员跟随Ross离开了谷歌。</p><p>&nbsp;</p><p>2017年，这家初创公司从风险投资家 Chamath Palihapitiya 那里获得了 1030 万美元的资金，公司最近还聘请了Xilinx 销售副总裁 Krishna Rangasayee 担任首席运营官。</p><p>&nbsp;</p><p>这个神秘的团队在成立后的三年时间里几乎从社交媒体中“隐身”，没有过多关于公司的消息爆出。直到2019年10月，Groq发布了一篇名为《世界，认识Groq》的博客，向世界宣告了自己的存在。</p><p>&nbsp;</p><p>此后的时间里，Groq 打造出了名为语言处理单元（LPU）的AI芯片，并向外界放出消息称其速度已经超越了英伟达的图形处理单元（GPU）。换句话说，从早期结果来看，LPU的确有希望击败已经在AI模型领域成为行业标准的英伟达GPU。</p><p>&nbsp;</p><p>迄今为止，Groq 已从顶级风险投资公司获得了约 3.62 亿美元的资金。</p><p>&nbsp;</p><p>据Ross介绍，Groq 的软件定义架构提供了更大的灵活性，有望帮助客户摆脱传统硬件解决方案中将用户锁定在特定于供应商的框架（例如CUDA和英伟达生态系统）中的处境。</p><p>&nbsp;</p><p>正如Ross所描述的，“我们的编译器会自动执行此操作。因此，您可以在其中放入一行groq.it，然后将模型放在括号中，就这样了。”&nbsp;这种便携式方法允许使用 PyTorch 等标准框架训练的模型无需修改即可在 Groq 系统上高效运行。</p><p>&nbsp;</p><p>通过避免专有接口，Groq 能够与最新出现的机器学习创新兼容，而不需要模型转换。因此，Groq的平台设计旨在防止当今困扰许多 GPU 部署的硬件锁定问题。对于平衡新兴需求与遗留约束的开发团队来说，Groq 的灵活性提供了一条前进的道路。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/77/778e1e89bcb6a5d0c00b0371c92aa589.png\" /></p><p></p><p>乔纳森·罗斯 (Jonathan Ross)，Groq 的首席执行官兼创始人。</p><p>&nbsp;</p><p>尽管Groq赢得了一波广泛关注，但其AI芯片是否真能与英伟达GPU或者谷歌TPU在计算性能和可扩展性上正面对抗仍然有待观察。</p><p></p><h2>英伟达的霸主地位，短期内谁都撼动不了</h2><p></p><p>&nbsp;</p><p>在近期Groq攻占各大科技媒体头条板块之时，老牌AI芯片霸主英伟达刚刚公布了去年第四季度财报。</p><p>&nbsp;</p><p>据英伟达最新财报显示，截至 2024 年 1 月 28 日，2024 财年第四季度收入达到 221 亿美元，环比增长22%，同比增长 265%，净利润为 122.85 亿美元，同比增长 769%。值得一提的是，英伟达单季度收入甚至已高于2021年全年。这一增长主要得益于人工智能技术的快速发展，特别是在加速计算和生成式 AI 领域。</p><p>&nbsp;</p><p>受此影响，该公司股价在美股盘后一度大涨10%。英伟达CEO黄仁勋表示，加速计算和生成式人工智能已经达到了引爆点，全球各个公司、行业和国家的需求都在飙升。</p><p>&nbsp;</p><p>多年来，通过巧妙的收购、内部硬件/软件开发和战略联盟，以及利用ChatGPT 发布所引发的生成式 AI热潮，英伟达以压倒性优势牢牢占领了芯片霸主地位。无论是全行业的芯片短缺，还是其拟斥资 400 亿美元收购芯片竞争对手 Arm的失败，都没有对英伟达的惊人增长产生任何明显影响。</p><p>&nbsp;</p><p>“一个新的计算时代已经开始。世界各地的公司正在从通用计算向加速计算和生成式人工智能转型。”英伟达创始人兼首席执行官黄仁勋在公司财报中表示。</p><p>&nbsp;</p><p>每家芯片公司都把英伟达列为了一个巨大的目标，如今，Groq似乎距离赶超英伟达这一目标更近了些。</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871\">https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871</a>\"</p><p><a href=\"https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx\">https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx</a>\"</p><p><a href=\"https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083\">https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083</a>\"</p><p>&nbsp;</p>",
    "publish_time": "2024-02-23 14:29:37",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果开源一个可提升Apache Spark向量处理速度的插件",
    "url": "https://www.infoq.cn/article/zzFbvk1jFPg0H5sM695E",
    "summary": "<p>本文最初发布于THENEWSTACK。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/71e520f7e05bb3287f35a2e3590f6296.png\" /></p><p></p><p>&nbsp;</p><p>消费电子巨头苹果公司发布了一个开源插件，可以帮助<a href=\"https://thenewstack.io/spark-continuous-processing-turn-integration-discussion-ear/\">Apache Spark</a>\"更有效地执行向量搜索，使开源数据处理平台在<a href=\"https://thenewstack.io/vector-databases-where-geometry-meets-machine-learning/\">大规模机器学习数据处理</a>\"方面变得更有吸引力。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ee/ee22c7dc14a78bfb928994f83a3222ae.png\" /></p><p></p><p><a href=\"https://cdn.thenewstack.io/media/2024/02/2a5890f3-datafusion-logo-background-white-300x150.png\">&nbsp;（点击查看大图）</a>\"</p><p>&nbsp;</p><p>这个<a href=\"https://thenewstack.io/google-spends-1-million-to-make-rust-c-interoperable/\">基于Rust</a>\"的插件名为<a href=\"https://github.com/apache/arrow-datafusion-comet/tree/comet-upstream\">Apache Spark DataFusion Comet</a>\"。苹果工程师已经将其<a href=\"https://incubator.apache.org/ip-clearance/\">提交</a>\"给了<a href=\"https://incubator.apache.org/ip-clearance/\">Apache软件基金会</a>\"，使其成为<a href=\"https://thenewstack.io/introduction-to-apache-arrow/\">Apache Arrow</a>\"项目下的一个子项目。该插件是以可扩展的<a href=\"https://arrow.apache.org/datafusion/\">Apache DataFusion</a>\"查询引擎（<a href=\"https://thenewstack.io/where-does-the-time-go-rusts-problem-with-slow-compiles/\">也是用Rust编写的</a>\"）和<a href=\"https://thenewstack.io/how-apache-arrow-is-changing-the-big-data-ecosystem/\">Arrow列式数据格式</a>\"为基础构建的。</p><p>&nbsp;</p><p>“我们的目标是通过将Spark的物理计划执行委托给DataFusion的高度模块化执行框架来加速Spark查询执行，同时在Spark用户看来语义不变，”苹果软件工程师<a href=\"https://twitter.com/sunchao\">Chao Sun</a>\"在<a href=\"https://lists.apache.org/thread/0q1rb11jtpopc7vt1ffdzro0omblsh0s\">Apache邮件列表</a>\"中解释道。</p><p>&nbsp;</p><p>Sun指出，该项目的功能尚未全部开发完成，但部分功能已经应用于生产环境。</p><p>&nbsp;</p><p><a href=\"https://arrow.apache.org/\">Apache Arrow</a>\"项目管理委员会主席Andy Grove在<a href=\"https://twitter.com/criccomini/status/1755012003503251890\">X</a>\"上指出：“对于最近每个人都在谈论的可组合数据系统概念，这就是一个很好的例子。利用Spark非常成熟的计划和调度，并将其委托给DataFusion进行本地执行。”</p><p>&nbsp;</p><p></p><h2>Apache Arrow DataFusion Comet是什么？</h2><p></p><p>利用Apache Arrow DataFusion运行时，Comet可以使用Apache Arrow列式格式查询数据。这种方法旨在通过本机向量化执行来改进查询效率和查询运行时。</p><p>&nbsp;</p><p>Apache Spark<a href=\"https://thenewstack.io/the-good-bad-and-ugly-apache-spark-for-data-science-work/\">创建</a>\"于2010年，用于处理各种格式化和非格式化结构（“<a href=\"https://thenewstack.io/the-next-wave-of-big-data-companies-in-the-age-of-chatgpt/\">大数据</a>\"”）中的<a href=\"https://thenewstack.io/context-apache-spark-for-artificial-intelligence-and-ai-2-0/\">大量分布式数据</a>\"。</p><p>&nbsp;</p><p>向量处理已经成为<a href=\"https://thenewstack.io/the-transformative-fusion-of-probability-and-vector-search/\">机器学习社区</a>\"中<a href=\"https://thenewstack.io/the-building-blocks-of-llms-vectors-tokens-and-embeddings/\">最受欢迎的技术</a>\"，因为它可以缩短<a href=\"https://thenewstack.io/what-you-can-do-with-vector-search/\">分析大量数据</a>\"的时间。</p><p>&nbsp;</p><p>Fivetran高级产品布道师<a href=\"https://www.linkedin.com/in/charles-wang-81ab5525/\">Charles Wang</a>\"在<a href=\"https://www.fivetran.com/blog/a-tale-of-three-data-platforms\">上个月的一篇分析文章</a>\"中写道，“向量化查询可以操作批量数据并并行处理多个数据元素，改善了分析查询的性能、效率、可扩展性和内存占用。它与<a href=\"https://www.fivetran.com/learn/a-guide-to-columnar-database\">列式数据库架构</a>\"有着千丝万缕的联系，因为它允许将整个列加载到CPU寄存器中进行处理。”</p><p>&nbsp;</p><p>按照设计，Comet的特性会与Spark保持对等（目前支持Spark 3.2到3.4版本）。也就是说，无论是否使用Comet扩展，用户都可以运行同样的查询。</p><p>&nbsp;</p><p>Spark内置的表达式和操作符（Filter/Project/Aggregation/Join/Exchange）可以在Comet中使用，<a href=\"https://thenewstack.io/an-introduction-to-apache-parquet/\">Apache Parquet</a>\"列式存储格式也可以，无论是读模式还是写模式。</p><p>&nbsp;</p><p>Comet可以在Linux或Mac OS上运行，需要JDK 8及以上版本和GLIBC 2.17。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/44/4449b13eea6c530c83f3b989516929ee.png\" /></p><p></p><p><a href=\"https://cdn.thenewstack.io/media/2024/02/a727ad75-comet-overview-1024x800.png\">&nbsp;（点击查看大图）</a>\"</p><p>&nbsp;</p><p></p><h2>其他可加速向量处理的Spark插件</h2><p></p><p>软件工程师Chris Riccomini<a href=\"https://twitter.com/criccomini/status/1755012003503251890\">指出</a>\"，苹果公司并不是<a href=\"https://thenewstack.io/more-data-engineers-crave-faang-jobs/\">FAANG俱乐部</a>\"中唯一对向量处理感兴趣的成员。去年，Meta也发布了自己的Spark向量处理项目：<a href=\"https://facebookincubator.github.io/velox/spark_functions.html\">Velox</a>\"。</p><p>&nbsp;</p><p>类似的项目还包括英特尔的<a href=\"https://github.com/oap-project/gluten\">Gluten</a>\"（最近被接收进入<a href=\"https://incubator.apache.org/projects/gluten.html\">ASF孵化</a>\"）、<a href=\"https://thenewstack.io/nvidia-gpu-dominance-at-a-crossroads/\">英伟达</a>\"的<a href=\"https://github.com/NVIDIA/spark-rapids\">GPU RAPIDS Spark加速器</a>\"、<a href=\"https://github.com/blaze-init/blaze\">Blaze</a>\"（也可与<a href=\"https://thenewstack.io/apache-arrow-designed-accelerate-hadoop-spark-columnar-layouts-data/\">Apache Arrow DataFusion</a>\"搭配使用），以及<a href=\"https://github.com/apache/arrow-ballista\">Ballista</a>\"分布式SQL查询引擎。</p><p>&nbsp;</p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark\">https://thenewstack.io/apple-comet-brings-fast-vector-processing-to-apache-spark</a>\"</p>",
    "publish_time": "2024-02-23 14:46:15",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "元宵有奖 | 人脑与AI的较量！大模型出的灯谜你能全猜对吗？",
    "url": "https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG",
    "summary": "<p>汤圆甜甜你也甜，元宵佳节趣无边！各位亲爱的朋友们，是不是已经闻到了浓浓的节日味道？是不是已经迫不及待想要融入这欢乐的海洋？</p><p></p><p>值此元宵佳节，AI 前线精心策划了一场趣味盎然的猜谜活动。</p><p></p><p></p><blockquote>猜谜活动福利：腾讯祥龙Q毛绒公仔5只福利获取方式：下方共9道题目，各位粉丝朋友可以在公众号「AI 前线」评论区写下自己的答案。答对题目数量前5名用户将获得本次福利礼物。如遇并列情况将按照用户评论时间排序，先答对者将获得礼物。活动参与截止时间：2 月 27&nbsp;日（下周二） 中午12:00正确答案公布时间：2 月 27&nbsp;日（下周二）&nbsp;中午12:01于公众号「AI 前线」评论区置顶答案本活动图片均由腾讯混元助手生成</blockquote><p></p><p></p><p>快来参与吧！让我们一起点亮智慧的火花，共享团圆的喜悦！</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/0d/0dcb569e1ae23120a9dc9d43b3a4170c.jpeg\" /></p><p></p><p></p><h2>猜谜大挑战&nbsp;——“花”落谁家</h2><p></p><p></p><p>元宵花会最早可追溯到北宋时期。当时，元宵节被称为“上元节”，人们在这一天放灯、祭拜神灵，庆祝新春的到来。</p><p></p><p>随着时间的推移，元宵节逐渐演变成为元宵花会这一盛大的庆典活动，并在明清达到鼎盛，成为了民间艺术的盛宴，也引起了许多文人墨客的赞赏和描写。</p><p></p><p>先来两个简单的谜语练练手吧！</p><p></p><p></p><h5>请选择生成下图花卉的正确谜面~</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/58/58d5cc4a93548c43dfa719c41bd8dd4a.jpeg\" /></p><p></p><p>A&nbsp;园林三月风兼雨，桃李飘零扫地空。唯有此花偏耐久，绿枝又放数枝红。</p><p></p><p>B&nbsp;红花万点傲雪绽，半树初盛半树含。清香四溢迷人醉，伸手欲折心又怜。</p><p></p><p>C&nbsp;得天独厚艳而香，国色天香美名扬。不爱攀附献媚色，何惧飘落到他乡。&nbsp;</p><p></p><p>答案：C</p><p></p><p></p><h5>再来看看下面这张图片，它是由谜面 “一个小姑娘，生在水中央，身穿粉红衫，坐在绿船上” 生成的图片，这是哪种花卉呢？</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/36/36fecc360cd19d2f0ad9a8245040411f.png\" /></p><p></p><p>A&nbsp;昙花</p><p></p><p>B&nbsp;荷花</p><p></p><p>C&nbsp;水仙花&nbsp;&nbsp;</p><p></p><p>答案：B</p><p></p><p></p><h2>猜谜大挑战 ——“果”然是你</h2><p></p><p></p><p>下面开始正式答题啦，你准备好了吗？</p><p></p><p>除了传统的汤圆、元宵等食品外，水果也是不可或缺的一部分。水果不仅能够为节日增添色彩，还因其寓意吉祥而受到人们的喜爱。元宵节期间，人们会选择一些特定寓意的水果来食用或摆放。</p><p></p><p></p><h5>第一题：下图是由谜面 “小小红坛子，装满红饺子，吃掉红饺子，吐出白珠子&nbsp;” 生成的图片，快来猜猜这是什么水果吧~</h5><p></p><p></p><p>（注：这道题看似简单，却暗藏玄机哦~ 大家要谨慎选择，可在公众号后台回复“元宵快乐”获取提示）&nbsp;&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6a/6a0b19f4c87d2db4a1608fdb6d7e2e58.jpeg\" /></p><p>A&nbsp;桔子</p><p></p><p>B&nbsp;杨梅</p><p></p><p>C&nbsp;石榴&nbsp;&nbsp;</p><p></p><p></p><h5>第二题：下图是由谜面 “头戴青色帽，身穿紫色衣，遇着铁将军，劈开白身体&nbsp;” 生成的图片，这又是什么水果呢？</h5><p></p><p></p><p>（注：这道题也是暗藏玄机哦~ 大家可在公众号后台回复“元宵快乐”获取提示）</p><p><img src=\"https://static001.geekbang.org/infoq/3e/3e695b76015a3af4d05929c47ad6b256.png\" /></p><p></p><p>A&nbsp;山竹</p><p></p><p>B&nbsp;紫葡萄</p><p></p><p>C&nbsp;甘蔗&nbsp;&nbsp;</p><p></p><p></p><h2>猜谜大挑战 —— 碳水大爆炸</h2><p></p><p></p><p>上面 2 道题是不是稍微具有一点迷惑性呢~</p><p></p><p>接下来， 到了大家最爱的 “碳水大爆炸” 环节！两大主食闪亮登场！</p><p></p><p>元宵节这一天，家家户户张灯结彩，热闹非凡。而在我们的餐桌上，也总少不了那些美味的佳肴，除了人人熟知的元宵、汤圆，在一些地区，人们也会制作其他美味的主食。</p><p></p><p></p><h5>第三题：下图是由谜面 “白纸包葱姜，抛在海中央&nbsp;” 生成的图片，快来猜猜这是什么主食吧~（2字谜底）</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8deee3611ee150a3f15bb752a548a177.png\" /></p><p></p><h5>第四题：下图是由谜面 “金衣包裹绿意浓，油炸之后更香浓&nbsp;” 生成的图片，这又是什么主食呢？（2字谜底）</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2b/2b4e4a151c7f77f2ff497db49ebb11a9.jpeg\" /></p><p></p><p></p><h2>猜谜大挑战 —— “圆”满成功</h2><p></p><p></p><p>正月十五是一年中最浪漫的日子之一，抬头观月圆，低头品汤圆，甜甜蜜蜜聚团圆，和和美美幸福圆。</p><p>“圆” 虽短短一字，却含义无比深重。</p><p></p><p>祝你家庭幸福团圆，事业红得溜圆，爱情花好月圆，一生春色满园，一世幸福美圆！</p><p></p><p>下面 2 张图是由 2 个含有 “圆” 字的四字成语生成的，快来猜猜分别是什么成语吧~</p><p></p><p></p><h5>&nbsp;第五题</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6b/6bec4623d2ba5e87172d34559c6a94a6.jpeg\" /></p><p></p><p></p><h5>第六题</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c8/c8c5a10606345b7d714ea45f1e65821d.jpeg\" /></p><p></p><p></p><h2>猜谜大挑战 —— 龙年大吉</h2><p></p><p></p><p>元宵节，作为中国传统节日中的一颗璀璨明珠，承载着丰富的文化内涵和独特的魅力。</p><p></p><p>在这一天，人们会沉浸在一系列精彩纷呈的传统习俗活动中，共同庆祝这个充满喜庆和团圆的节日。</p><p>以下是由不同的元宵节习俗生成的图片，快来猜猜都是什么习俗吧~</p><p></p><p></p><h5>&nbsp;第七题（4字谜底）</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/1b/1b4fc7aca46c504a7866c050efeaae43.jpeg\" /></p><p></p><p></p><h5>第八题（3字谜底）</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b5/b5fb1964885e80042d1b15ce351f9825.jpeg\" /></p><p></p><p></p><h5>&nbsp;第九题（3字谜底）</h5><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/fa/fa1d12ed71ef8167f9ca4288ad5c4854.jpeg\" /></p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>用人工智能来创造谜语的图像，是不是一种有趣并富有创意的尝试呢？你是否已经挑战了以上充满趣味的谜语，并成功猜出了几个呢？</p><p></p><p>AI 不仅能够帮助我们解答谜题，还能将文字转化为生动的图像，让传统的猜谜活动变得更加生动形象和引人注目。</p><p></p><p>在这个特别的日子里，我们一起享受了科技与优秀传统文化的巧妙结合，让元宵节的庆祝更加精彩纷呈。</p><p></p><p>在此，AI 前线 再次向大家送上最温馨的祝福：愿这个元宵节为你的生活带来光明和喜悦，愿你的每一天都如同这节日的灯笼，照亮前行的道路，充满希望和快乐。祝大家元宵节快乐，团圆美满，幸福安康！</p><p></p><p>下图均由腾讯混元助手根据文字 “AI 前线祝你元宵节快乐&nbsp;” 生成</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8a/8a498cde35d5bb3e866d3ff5dac0ef75.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/51b2a9ab12d709a920fde78cf5ddb1a4.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/31/31e193644751e7dafc0cd547a0d94002.jpeg\" /></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/22/22bf5937397003e78639c07b8e83b6b4.jpeg\" /></p><p></p><p></p><p></p><h4>扫码阅读文章，在评论区留言即可参与活动</h4><p></p><p><img src=\"https://static001.geekbang.org/infoq/49/491631591e98b82ca6683ebabc300ce5.jpeg\" /></p><p></p>",
    "publish_time": "2024-02-23 14:55:13",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "苹果扼杀 PWA ？iOS 上的 PWA 体验难达标，原生应用才是王道",
    "url": "https://www.infoq.cn/article/R9AZAYSQ3vhWuc4sj9Cg",
    "summary": "<p>上个月，在大批 Campsite 用户向我们提出想要一个移动应用后，我们为 Campsite 提供了 PWA 支持。现在 Campsite 可以安装在手机主屏幕上，也能接收到推送通知了，于是我们立刻意识到这项工作物有所值，我们的用户也很高兴。</p><p><img src=\"https://static001.geekbang.org/infoq/83/8380387ce4885a19d0830507c114a933.jpeg\" /></p><p>我们确实想要给 Campsite 做一个原生应用，但考虑到我们只是一个小团队，还在市场中寻找自己的立足点，所以增加更多的平台开销会拖累我们的发展速度。</p><p>&nbsp;</p><p>与此同时，我们发现在 iOS 上支持 PWA 需要大量时间——无论我们如何努力，都会有太多的错误和缺失的特性，让我们感觉很难满足自己设定的工艺和质量标准。</p><p></p><h2>网络推送：好处</h2><p></p><p>苹果在 iOS 16.4 中向 PWA 添加了 Safari Web Push。这个 API 非常易用——你甚至不需要开发者帐户。</p><p>&nbsp;</p><p>Campsite 是一个带有 NextJS 前端的 Rails API。为了让网络推送正常工作，我们需要做的就是：</p><p>&nbsp;</p><p>通过 window.matchMedia('(display-mode:standalone)') 检测我们是否运行在 PWA 环境中，并提示用户启用推送。我们请求推送权限并注册一个服务 worker。Pushpad 的服务 worker 帮我们搞定了这块。这个 worker 将注册的推送端点以及 p256dh 和身份验证令牌发送到我们的 API。发生一个可推送事件时，我们在队列里添加一个 Sidekiq 作业，以使用 Pushpad 的分叉 web-push gem 发送一个推送。如果苹果返回一个 410 响应，我们就会销毁这个推送订阅。</p><p>&nbsp;</p><p>这样，我们就可以在 Campsite 中发送高信号通知和聊天的推送了。</p><p><img src=\"https://static001.geekbang.org/infoq/00/007d4ee76de0746467ce3ac3e3e34a6e.jpeg\" /></p><p></p><h2>网络推送：坏处</h2><p></p><p>如果你一直习惯的是构建原生推送通知，那么你会发现 Safari Web Push 缺少很多特性，还会造出很多陷阱。</p><p>&nbsp;</p><p>我们发现的情况中最令人惊讶的是，你在收到通知时必须总是在设备上显示通知。这是在 Service Worker 中完成的，因此从技术上讲你可以跳过它的显示。但如果你这样做，苹果将撤销你的推送端点。来自官方文档：</p><p></p><blockquote>Service Worker 收到推送通知后立即向用户呈现推送通知。如果你不这样做，Safari 会撤销你站点的推送通知权限。</blockquote><p></p><p>Reddit 上的用户发现，第三次未显示通知后权限就被撤销了。</p><p>&nbsp;</p><p>这意味着，如果你正在 PWA 上查看一段聊天内容并收到了新消息，你是没办法屏蔽新消息的推送的，这对用户来说非常烦人。</p><p>&nbsp;</p><p>为了解决这个问题，我们会延迟 10 秒发送，这样你在查看聊天内容时就能把刚收到的信息标记为已读。相比之下，原生应用可以控制是否显示推送通知。</p><p>&nbsp;</p><p>以下是我们在 iOS 上使用 Safari Web Push 时遇到的一些其他问题：</p><p>&nbsp;</p><p>没有静默推送，因此我们只能使用显示的推送来更新应用图标的小红点。理想情况下，如果你在其他地方清除通知，我们会自动删除你的手机上的应用图标小红点记录，但这对于 PWA 的推送机制来说是不可能做到的。除非你点击通知，否则无法从通知中心删除通知。你可以获取通知，但调用 notification.close() 不会执行任何操作。用户必须手动清除 Campsite 的推送。你无法删除“from Campsite”这条注释。没有通知分组或通讯通知。</p><p></p><h2>错误和缺失的特性</h2><p></p><p>我们在 Campsite 中提供了由 next-thems 驱动的动态明暗模式支持，简单说就是：</p><p><code lang=\"null\">window.matchMedia('(prefers-color-scheme: dark)')</code></p><p>虽然你的 PWA 将以浅色或深色模式呈现，但在应用程序被终止之前它不会来回切换。</p><p><img src=\"https://static001.geekbang.org/infoq/a9/a99f4c7aba8954227627129adb537884.jpeg\" /></p><p>随着 iOS 17 的发布，这个功能失效了。撰写本文时功能已经失效了 6 个多月，而且在 17.4 Beta 版中它似乎还是这个样子。开发人员在过去一段时间来一直在报告问题。</p><p>&nbsp;</p><p>我们经常遇到一些更烦人的错误：</p><p>&nbsp;</p><p>我们使用 CSS sticky 将元素固定在视口的顶部/底部（导航栏、聊天输入等）。一段时间后，sticky 元素会破裂并在页面上自由滚动。这只能通过终止应用来解决。键盘也变化无常得厉害。它将 sticky 元素推离屏幕，有时它在 PWA 中干脆显示不出来了，唯一的解决方法是重新启动手机。没有用于触觉、PIP 或联系人同步的 API。（感谢 Jacob 指出这些问题）</p><p></p><h2>我们接下来该怎么做？</h2><p></p><p>我非常赞成我们构建 PWA 的决定。我们发现应用程序图标红点和推送通知可以帮助我们同用户保持更紧密的联系。我们的用户也同意这一点——有些人现在使用 Campsite 一半的时间都是在用手机应用！</p><p>&nbsp;</p><p>不幸的是，iOS 上的 PWA 不符合 Campsite 的工艺和质量标准，而且苹果限制 PWA 在欧洲使用的最新消息也令人担忧。一旦我们锁定了 Campsite 的核心功能，我们就打算从头构建一个原生应用。</p><p>&nbsp;</p><p>如果你的用户需要原生应用，构建基本的 PWA 支持可以帮助你快速入门，只是不要指望你的 PWA 能够接近原生体验。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://app.campsite.co/campsite/p/notes/rengvq2txami\">https://app.campsite.co/campsite/p/notes/rengvq2txami</a>\"</p>",
    "publish_time": "2024-02-23 14:55:24",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "OpenAI Sora 的关键成分：时空补丁解析",
    "url": "https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD",
    "summary": "<p></p><p><img src=\"https://static001.geekbang.org/infoq/12/127a40330d24d0b9fbf93201b3ef2ad7.webp\" /></p><p></p><p>人工智能工具如何将一张静态图像转化为一段动态、逼真的视频？OpenAI 的 Sora 通过时空补丁的创新使用给出了答案。</p><p>&nbsp;</p><p>在快速发展的生成式 AI 模型领域，OpenAI 的 Sora 已经成为了一座重要的里程碑，有望重塑我们对视频生成的理解和能力。我们揭示了 Sora 背后的技术及其激发新一代图像、视频和 3D 内容创建模型的潜力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/52/52e05a8224ce4629238d85402c5e7c19.jpeg\" /></p><p></p><p></p><p>这个演示是由 OpenAI 使用以下文本提示生成的：</p><p></p><blockquote>一只猫叫醒熟睡的主人，要求吃早餐。主人试图忽视这只猫，但猫尝试了新的策略，最后主人从枕头下拿出秘密藏匿的零食，让猫再呆一会儿。</blockquote><p></p><p></p><p>随着 Sora 的诞生，我们在视频内容生成方面已经迈入了与现实几乎无法区分的境界。由于该模型正在测试，它尚未向公众完整发布。</p><p></p><h2>Sora 的独特方法如何改变视频生成技术</h2><p></p><p>在生成式模型的世界中，我们业已看到了从 GAN 到自回归和扩散模型的许多方法，它们都有自己的优点和局限性。Sora 现在引入了一种范式转变，采用了新的建模技术并提升了灵活性，可以处理更长的持续时间、更多的宽高比和分辨率参数。</p><p>&nbsp;</p><p>Sora 将 Diffusion 和 Transformer 架构结合在一起创建了一个 Diffusion Transformer 模型，并能够提供以下功能：</p><p>&nbsp;</p><p>文本到视频：正如我们所见图像到视频：为静态图像带来生命视频到视频：将视频转换为其他风格实时延长视频：向前和向后创建无缝循环：让循环视频看起来永无止境图像生成：静止图像是浓缩在一帧中的影片（最大2048 x 2048）生成任何格式的视频：从 1920 x 1080 到 1080 x 1920 以及之间的所有格式模拟虚拟世界：如《我的世界》和其他视频游戏创建一段视频：长度不超过 1 分钟，包含多个短片</p><p>&nbsp;</p><p>想象一个厨房场景。传统的视频生成模型（例如 Pika 和 RunwayML 中的模型）就像严格遵循菜谱做菜的厨师。他们可以制作出精美的菜肴（视频），但受到他们所知道的食谱（算法）的限制。厨师可能专注于使用特定成分（数据格式）和技术（模型架构）烘焙蛋糕（短片）或烹饪面食（特定类型的视频）。</p><p>&nbsp;</p><p>相比之下，Sora 是一位了解风味基础知识的新型厨师。这位厨师不仅可以按已有的菜谱做菜，还能发明新的菜谱。Sora 的原料（数据）和技术（模型架构）的灵活性使它能够制作各种高质量的视频，就像多才多艺的大厨的烹饪作品一样。</p><p></p><h2>Sora 秘方的核心：探索时空补丁</h2><p></p><p>时空补丁是 Sora 创新的核心，建立在 Google DeepMind 对 NaViT 和 ViT（视觉 Transformer）的早期研究基础上，该研究基于 2021 年的论文《An Image is Worth 16x16 Words》。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79846a0dcbd0bf586be8784dc1b01ce7.webp\" /></p><p></p><p>“Vanilla”视觉 Transformer 架构 — 来源：Dosovitskiy et al., 2021</p><p>&nbsp;</p><p>传统上，对于视觉 Transformer，我们使用一系列图像“补丁”（而不是用于语言 Transformer 的单词）来训练用于图像识别的 Transformer 模型。这些补丁使我们能够摆脱卷积神经网络来处理图像。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/51/5169a9411b1a1a76647f51002e0a8eba.webp\" /></p><p></p><p>帧/图像如何“补丁化” — 来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>然而，视觉 Transformer 受到了大小和长宽比固定的图像训练数据的限制，从而限制了质量水平并且需要大量的图像预处理工作。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3f/3f9f869b429a600f4ca226bb3339672e.gif\" /></p><p></p><p>视频时态数据切片的可视化 — 来源：kitasenjudesign</p><p>&nbsp;</p><p>Sora 将视频视为很多补丁序列，这样就保持了原始的宽高比和分辨率，和 NaViT 对图像的处理机制很像。这种保存方法非常重要，使模型能够捕捉视觉数据的真正本质，从更准确的世界表示中学习，从而赋予 Sora 近乎神奇的准确性。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f1/f1ccab4cab3ad412c2e250406ecbd82d.webp\" /></p><p></p><p>时空补丁（处理）的可视化 — 来源：OpenAI（Sora）</p><p>&nbsp;</p><p>该方法使 Sora 能够有效地处理各种视觉数据，而无需调整大小或填充等预处理步骤。这种灵活性确保每条数据都能够帮助模型加深理解，就像厨师使用各种原料来提升菜肴的风味一样。</p><p>&nbsp;</p><p>通过时空补丁对视频数据进行详细而灵活的处理，为精确的物理模拟和 3D 一致性等复杂功能奠定了基础。有了这些至关重要的功能后，我们就可以创建不仅看起来逼真，而且符合世界物理规则的视频，让我们一睹人工智能创建复杂、动态视觉内容的潜力。</p><p></p><h2>喂养 Sora：多样化数据在训练中的作用</h2><p></p><p>训练数据的质量和多样性对于生成模型的性能而言是非常重要的。现有的视频模型传统上是基于更严格的数据集、更短的长度和更窄的目标来训练的。</p><p>&nbsp;</p><p>Sora 使用的是庞大且多样化的数据集，其中包括了不同时长、分辨率和宽高比的视频和图像。它能够重建像《我的世界》这样的数字世界，它的训练集中可能还包括来自虚幻或 Unity 等系统的游戏玩法和模拟世界画面，以便捕捉所有角度和各种风格的视频内容。这样 Sora 就迈入了“通用”模型的境界，就像文本领域的 GPT-4 一样。</p><p>&nbsp;</p><p>这种涉猎广泛的训练方法使 Sora 能够理解复杂的动态并生成多样化且高质量的内容。该方法模仿大型语言模型在不同文本数据上的训练方式，将类似的原理应用于视觉内容以实现通用能力。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cf/cf358d3dea5cbcc282b892be948e55c6.webp\" /></p><p></p><p>可变“补丁”，NaVit 与传统视觉 Transformers 的对比，来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>正如 NaViT 模型将不同图像的多个补丁打包到单个序列中的方法展示了显著的训练效率和性能增益一样，Sora 利用时空补丁在视频生成中实现了类似的效率。这种方法可以更有效地从海量数据集中学习，提高模型生成高保真视频的能力，同时其所需的计算量与现有建模架构相比也减少了。</p><p></p><h2>将物理世界带入生活：Sora 对 3D 和连续性的把握</h2><p></p><p>3D 空间和物体持久性是 Sora 演示中的关键亮点之一。通过对各种视频数据进行训练，无需调整或预处理视频，Sora 学会了以令人印象深刻的精度对物理世界建模，因为它能够使用原始形式的训练数据。</p><p>&nbsp;</p><p>它可以生成数字世界和视频，其中对象和角色在三维空间中令人信服地移动和交互，即使它们被遮挡或离开镜头也能保持连贯性。</p><p></p><h2>展望未来：Sora 的未来影响</h2><p></p><p>Sora 为生成式模型的潜能设立了新的标准。这种方法很可能会激发开源社区尝试和推进视觉模式的能力，推动新一代生成式模型的发展，突破创造力和现实主义的界限。</p><p>&nbsp;</p><p>Sora 的旅程才刚刚开始，正如 OpenAI 所说，“扩展视频生成模型是构建物理世界通用模拟器的一条有希望的道路”。</p><p>&nbsp;</p><p>Sora 的方法将最新的人工智能研究与实际应用相结合，预示着生成式模型的光明未来。随着这些技术的不断发展，它们有望重新定义我们与数字内容的交互方式，使高保真、动态视频的创建变得更加容易和多样化。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b\">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b</a>\"</p>",
    "publish_time": "2024-02-23 15:20:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "平安业研一体 BizDevOps——降本增效与业务价值最大化实践",
    "url": "https://www.infoq.cn/article/lljfjjZRrkyhTcEVEleF",
    "summary": "<p>在企业数字化转型的背景下，各家公司都在积极深化数字化、精细化管理。为更全面、更高效地利用数字技术赋能业务数字化，在高效交付数字化产品的同时，助力业务成功，提升IT 价值，最终实现降本增效与业务价值最大化并举。本次演讲将结合实际案例，探讨业研一体化的建设背景和理念、落地难点、解题思路及关键实践。</p>\n<p>听众受益点：</p>\n<p>了解业研一体的建设背景和理念<br />\n了解业研一体落地的难点和解题思路<br />\n通过具体案例的剖析，了解业研一体的关键实践</p>",
    "publish_time": "2024-02-23 15:24:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "WebNN，Web 端侧推理的未来",
    "url": "https://www.infoq.cn/article/LXliFqOfOrj2wNvslzZ0",
    "summary": "<p>本次演讲将会给大家分享 WebNN API 的 W3C 标准进度，对 CNN，Transformer 以及更广泛的生成式 AI (Generative AI) 模型的支持情况和计划，以及在 Chrome，Edge 等浏览器的实现进展。作为 JavaScript ML 框架的后端，WebNN 将会在几乎不更改前端代码的前提下，为 Web 开发者及他们的产品带来相较于 Wasm，WebGL 更为优异的性能体验。</p>\n<p>听众收益点：</p>\n<p>了解 Web 平台对异构处理器的支持<br />\n了解基于 Web 的机器学习模型硬件加速<br />\n了解 Chromium 实现内部细节</p>",
    "publish_time": "2024-02-23 15:25:02",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "我的领导离职了，公司损失了一个“知识库”？",
    "url": "https://www.infoq.cn/article/Fwh4UrToAlWwO1wa5YrE",
    "summary": "<p>写这篇文章的想法是在一次会议上冒出来的，那次会议上我们知道了我们的主管要离开公司去寻找新机会了。一位同事对此感叹，我们最怀念的就是随着这位领导一同离去的那些知识。</p><p>&nbsp;</p><p>不幸的是，事情就是这样：我们不仅失去了一位同事，而且还失去了很多宝贵的知识和经验。然而，这样的故事并不只是发生在我的主管身上，也发生在了我的导师身上。</p><p>&nbsp;</p><p>所有在各自领域中成为专家的人们都在重复这样的故事。他们熟谙通向成功的路径，也知道如何避开那些通向灾难性失败的方向。当他们离开我们的身边，会带走很多我们在任何书籍、笔记或 Jira 票证中都找不到的知识。</p><p>&nbsp;</p><p>这就引出了一个根本性的问题：如何才能避免这种知识“黑洞”？我们如何确保知识不会随着它们的拥有者一起消失？这篇文章讨论的就是这样一个主题。</p><p>&nbsp;</p><p></p><h2>有些人作出了业务决策……但并没有告诉我们理由</h2><p></p><p>我专门为本文创建了一个术语，名为“生物数据存储（Biological Data Storage）”或简称“BDS”。公司中的几乎每一位员工都适用于这条术语。我知道没有人希望自己被视为一种单纯的资源，当然也不想被视为“生物数据存储”的一部分。然而，从公司资源的视角来看，员工可以比作某种技术数据的存储库，但除了技术数据外还有着价值很高的上下文。</p><p>&nbsp;</p><p>我想从工程师的角度从更大的层面上来研究这个问题。我们经常听到有人提到康威定律：</p><p>&nbsp;</p><p></p><blockquote>任何组织在设计一个系统（广义定义）时所做出来的设计结构，都是组织内部沟通结构的副本。</blockquote><p></p><p>&nbsp;</p><p>我认为知识的流失其实是沟通不畅的结果，这最终会导致组织所创建的系统出现缺陷。</p><p>&nbsp;</p><p>工程方法的特点就是我们致力于衡量各种事件的影响，并使用特定指标评估事件的真正意义。在应对员工离职的挑战时，请考虑以下指标来评估组织的有效性：</p><p>&nbsp;</p><p>解决问题的时间：</p><p>衡量解决问题或挑战的速度，并帮助确定问题解决过程的效率。</p><p>知识转移率：</p><p>衡量新员工开始独立产生价值所需的时间，并表明知识转移和新人培训的效果。</p><p>&nbsp;</p><p>我认为这些指标为组织效率及其无缝整合新的团队成员的能力提供了宝贵的见解。在康威定律的背景下，知识的流失成为了不仅影响组织内部沟通效率，而且影响公司内部系统设计的关键因素。</p><p>&nbsp;</p><p>考虑一下：当拥有丰富知识和专业知识的团队成员离开时，他们带走的不仅是事实和数据，还有他们独特的见解、解决问题的方法以及对组织复杂性的理解。缺乏此类知识可能会扰乱团队内部和跨部门的信息流动管道。结果，组织的沟通结构可能会因此动摇，影响组织有效应对挑战的能力。</p><p>&nbsp;</p><p>此外，系统的设计也会受到深远的影响。掌握宝贵知识的工程师和开发人员可能会基于他们的专业知识做出设计选择。这些决策可能没有被其他人记录下来或清楚地理解到位，当它们的作者离开时，决策本身就可能会变得不透明。这可能会导致维护和开发这些系统出现困难，可能导致效率低下和漏洞丛生。</p><p>&nbsp;</p><p>现在，当我们将知识转移率指标引入这种背景时，很明显，衡量新员工开始独立产生价值所需的时间是至关重要的。这个时间越长，知识漏洞就会越明显，进而影响组织沟通和系统设计。组织必须认识到知识不仅仅涉及数据，还关系到对数据的理解和数据的上下文，它的流失会严重阻碍团队的顺利运作和系统的发展。</p><p></p><h2>组织没有记忆</h2><p></p><p>你可能会问，“失去这些知识对公司又能有什么影响？”业务流程是不是会因为流失的知识而像沙土堆一样崩溃呢？创新也会失去翅膀？公司的运转效率会像秋风冷雨中的落叶一样直线下降？在 98% 的情况下，上述问题的答案当然是否定的，因为我们可以管理此类风险。公司有很多应对这些问题的方法，但他们真的成竹在胸吗？</p><p>&nbsp;</p><p>Trevor Kletz 的著作《灾难的教训》中引用了《组织没有记忆》中的一句话，该书强调了组织记忆这一概念，以及由于组织内缺乏从过去的错误中有效学习的能力，而导致事件和事故再次发生。Kletz 教授强调，组织无法从事故中吸取教训，即使是在公司内部发生的事故也是如此。有时我觉得当知识离开我们的公司时也会出现类似的模式。也许是因为它不能轻易地用金钱来衡量，所以它常常被低估。</p><p>&nbsp;</p><p>虽然 Kletz 的著作讲的是化学工程的领域，但我从中看到了一些适用于任何情况和行业的普遍真理。例如，另一句话“你没有的东西，是不能泄漏的”与“你没有的代码是免维护的，并且不会有错误”的想法非常相似。我们的领域可能存在类似的原则。</p><p>&nbsp;</p><p>然而，即使在这个阶段，知识获取的过程也可以加速。有多种方法可以做到这一点，例如创建过程、图示、表格和文档。</p><p>&nbsp;</p><p>文档就像是业务世界中的藏宝图。创建文档是一回事，但在组织内（无论其规模如何）保持文档内容不落伍则是一项挑战。鼓励团队定期更新文档也是一个挑战。即使准备得最好的文档也常常缺乏许多细节，例如特定业务决策背后的基本原理、为什么选择特定数据库或框架，或者为什么我们使用技术 Y 而不是在整个公司内更流行的 X 技术。</p><p>&nbsp;</p><p>因此，虽然文档就像公司的藏宝图，但有关公司内部流程、系统和实践的记录、组织和结构化信息更多属于架构决策记录（ADR）的范畴。ADR 就像我们业务的飞行黑匣子。它们包含了系统设计期间做出的关键决策或重大技术选择的记录。</p><p>&nbsp;</p><p>为什么这很重要？在创造新事物时，我们会做出许多决定，如果日后没有正确的背景信息供查阅，这些决定可能会显得很不合理。ADR 就像打开了一个盒子，解释了为什么当时我们要做出这些决定。这是了解公司历史和演变的关键。在我们的 BDS 背景下，ADR 就像是专家在做出关键决策时的想法记录。当这些专家离开后，这些记录就成为了知识的宝库，帮助我们避免重蹈覆辙。</p><p>&nbsp;</p><p>一个常见的情况是：负责解决问题的团队必须投入宝贵的时间来重新发现那些本来被探索过的解决方案、尝试潜在的修复方法，甚至进行反复试验。这不仅会延长解决问题的过程，还会导致解决方案不够理想、增加挫败感并对整体生产力产生负面影响。借助文档和 ADR，我们可以显著缩短这一过程。</p><p></p><h2>冗长文档的替代方案？</h2><p></p><p></p><blockquote>没有人读文档。如果有人读了，他也看不懂。如果他理解了，也立刻就会忘记。</blockquote><p></p><p>&nbsp;</p><p>不幸的是，正如上面引用的 Stanisław Lem 的描述一样，文档、程序和 ADR 的问题在于人们需要熟悉它们。我想即使在 SpaceX 中，这些内容是否会被认为是最激动人心的阅读材料也要打一个大大的问号，或者也许我只是不了解他们。无论如何，即使有人设法阅读文档，他们也只会保留他们理解的那些内容。我们从文档中看到了其他人的工作，以及他们强加的思维和决策方式。经常出现的情况是，当下出现的问题没有人知道答案，而知道答案的人也不再在公司工作了。</p><p>&nbsp;</p><p>由于我们现在很清楚自己的心理存在局限，因此我们可以使用事件风暴（EventStorming）方法，而不是强迫人们筛选成堆的文档。这种方法有助于我们理解业务流程、识别事件和活动，并以可理解的方式将知识归纳总结在一起。我们关注行为、变化的内容以及原因。我们一起开发解决方案并了解各种流程，因为我们是从头到尾走过这些流程的。通过事件风暴方法理解流程比阅读文档更快、更容易。在事件风暴会议期间，大多数问题都能找到答案，而且知识可以同时传达给许多人，无论他们是否是技术人员。此类会议最重要的成果是，你可以讨论为什么流程看起来是这样的，为什么要选择特定的顺序，而不是另一个——这本质上是文档、ADR 和对话交流的合体。我再次强调，对流程的理解是集体层面的——每个人都感觉自己是解决方案的一部分。就我们的 BDS 而言，事件风暴可以让我们在做出关键决策时捕捉到那些专家的想法。</p><p></p><h2>现实生活中的例子</h2><p></p><p>在 Allegro，我们最近遇到了一种情况，负责某项关键服务的整个开发团队被转移到了另一个项目。继承该服务的新团队有机会与调职的团队合作一段时间。然而，在这种背景下，我们也进行了事件风暴会议。为了提供更多细节，这些会议持续了整整两天，每次持续 8 小时。之前团队过去五年来积累的知识并不只是浓缩在了两张绘图纸大小、每张 6 米长的纸上，更是基本无缝地融入了每一位会议参与者的头脑中。我相信这一过程有助于新团队在接管该领域时获得更大的信心。</p><p>&nbsp;</p><p>有趣的是，你不需要在事件风暴上花费大量时间来发现足够的业务知识。在前面提到的案例中，会议持续了两天，但这是整个团队层面的。对于个人来说，两个小时的研讨会足以了解我们流程的整体情况。尽管事件风暴使我们能够相对轻松地吸收一些知识，以了解流程中发生了什么事情，以及为什么发生种种变化，但细节决定成败。要真正了解这个过程是如何变化的，最好的入门方法是在有经验的人的指导下完成一些小的任务。</p><p></p><h2>正在寻找类似 UML 的替代方案？</h2><p></p><p>不幸的是，事件风暴并不能解决所有与知识流失相关的问题。虽然我不怀疑这个工具的出色效果，但通过它获得的知识只会留在参与者的脑海中。如果不以某种方式以文档或 ADR 的形式保存下来，这些知识依旧可能会像离职员工一样转瞬即逝。关于这一问题我们还能做些什么？我们最初的想法可能会推动我们创建某种形式的描述或文档，正如我们所知，这一过程中会遇到很多关于文档准备的挑战，还会让试图吸收新知识的人们出现认知超载。</p><p>&nbsp;</p><p>看来，在处理知识流失及其有效转移问题时，值得一提的是像 BPMN（业务流程模型和表示法）这样的工具。BPMN 提供业务流程的标准化图形表示。通过使用 BPMN 图，我们可以直观地映射工作流程和过程。这种方法不仅简化了对复杂流程的理解，而且有助于全面记录。当与其他知识共享技术（例如事件风暴）结合使用时，BPMN 可以成为保存和传输关键业务知识的强大资产。</p><p>&nbsp;</p><p>然而，BPMN 有一套复杂的符号和符号规则，这可能会让某些人创建和解释图表的过程变得颇为复杂。创建高级 BPMN 图并充分利用符号的潜力需要专业的知识和经验。不熟悉 BPMN 的人们可能很难有效地使用它。尽管存在这些不便，BPMN 仍然是许多组织中建模和记录业务流程的宝贵工具。我相信它是对前文提到的技术的完美补充。</p><p>&nbsp;</p><p>只需记住，你应该在你的武器库中准备正确的工具，更重要的是根据具体情况选择合适的工具，同时充分衡量其优点和缺点。</p><p></p><h2>还有一件事……</h2><p></p><p>解决问题的时间指标是组织应对挑战时的效率的一项明确指标。解决问题的时间较短意味着问题得到迅速解决，最大限度地减少干扰并确保组织平稳运行。知识转移率指标是一种量化和解决知识损失的方法，揭示了其对组织内沟通结构和系统设计的影响。</p><p>&nbsp;</p><p>这两个指标都直接受到文档、ADR、事件风暴或 BPMN 等工具的合理使用的影响。我也在前文尝试揭示了它们在知识转移方面的优点和缺点。</p><p>&nbsp;</p><p>然而还有另一项挑战——改变公司文化。员工必须知道他们拥有哪些工具，并认可分享知识是成功关键这一观念。领导力在这里起着至关重要的作用，因为领导者需要积极促进和参与知识共享和开放沟通过程。如果公司领导积极认可并参与知识共享，其他员工就更有可能效仿他们。然而，改变组织文化是一个耗时的过程。在新的行为和信念战胜旧的行为和信念之前，耐心和毅力至关重要。</p><p></p><h2>世上无难事</h2><p></p><p>作为组织中的工程师，无论规模大小，你都可以采取一些积极主动的步骤来促进知识转移。首先也是最重要的，我们应该积极与同事进行开放的沟通。我们应该鼓励讨论和信息共享，尤其是在你的专业领域内，以确保大家共享的是有价值的见解。其次，指导可以是一个强大的工具。我们可以主动指导初级团队成员或向更有经验的同事寻求指导。此外，我们可以参与公司内部的知识共享活动，例如棕包会议、研讨会或跨职能项目。最后，我们应当考虑创建内部文档和存储库或对其作出贡献。这些资源可以作为你的同事和未来团队成员的宝贵参考，确保知识保留在组织内。通过积极参与这些实践，你可以在组织内保存和传播关键知识方面发挥关键作用。</p><p></p><h2>小结</h2><p></p><p>在本文中，我讨论了从工程师的角度来看，公司中的知识流失是如何出现的，以及为什么它会构成威胁。生物数据存储这个术语可能听起来很不传统，但它强调了每个团队成员在保存和转移知识方面所发挥的关键作用。重点在于，我们要记住员工不仅仅是资源，更是宝贵的信息、经验和专业知识的活宝库。在 BDS 的世界中，每个成员都为集体知识体系做出贡献，塑造组织的沟通结构。当我们告别离职的同事时，让我们也一同告别知识应该局限于个人头脑的观念。相反，让我们采用开放沟通、积极知识共享和正确工具（例如事件风暴和 BPMN）的文化，在整个组织内捕获、保存和共享关键知识。</p><p>&nbsp;</p><p>原文链接：<a href=\"https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html\">https://blog.allegro.tech/2023/10/battle-against-knowledge-loss.html</a>\"</p>",
    "publish_time": "2024-02-23 15:31:36",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于时间序列数据预测模型的智能量化交易系统性能优化实践",
    "url": "https://www.infoq.cn/article/OwyKd5uz3ONYymSvxfN0",
    "summary": "<p>这次分享，将带来我们对系统全链路从数据采集-数据计算-模型预测-交易下单，全流程进行优化的实践分享，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响，怎么高效部署调用低延迟、多模型、多版本的 AI 模型预测服务，系统故障的数据断点快速恢复等。</p>\n<p>听众收益点：</p>\n<p>构建高性能、低延迟的智能量化交易系统<br />\n多语言开发的复杂系统的全链路性能分析和优化<br />\nAI 模型在智能量化交易系统的实践</p>",
    "publish_time": "2024-02-23 16:24:39",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "成立10年，融资超4亿元，又一家云原生容器独角兽倒下了",
    "url": "https://www.infoq.cn/article/KGTY8odAOOBRRB4244Ey",
    "summary": "<p></p><blockquote>Weaveworks联合创始人兼CEO Alexis Richardson在LinkedIn上遗憾公布公司即将关停的消息。</blockquote><p></p><p></p><h2>Weaveworks CEO发帖宣布关停公司，开源软件仍将继续服务</h2><p></p><p></p><p>近日，Weaveworks公司CEO在LinkedIn上突然发帖，宣布公司即将与大家告别。曾经的云原生容器管理领域创新灯塔Weaveworks，如今已宣布将停止运营，成为又一家没能挺过大环境动荡的科技初创企业。</p><p>&nbsp;</p><p>以下为Alexis Richardson的告别信全文：</p><p>&nbsp;</p><p></p><blockquote>我非常遗憾地正式宣布，Weaveworks即将告别大家并停止一切商业运营。我们后续将很快公布财务受托方名单，继续为客户及合作伙伴提供服务。&nbsp;我公司的收入曾经突破千万美元，旗下新产品数量也在2023年内实现倍增。然而，由于销售增幅波动导致我们的现金流受到冲击。我们需要一位合作伙伴或投资方协助维持长期增长。尽管努力争取，但我们与某家大型企业长达11个小时的并购流程谈判最终失败，因此决定关停业务。&nbsp;对于这个突如其来的消息，我向大家诚挚道歉。这样的情况并不该发生，但近期市场不确定性已经令众多企业难以为继，包括其他体量更大的公司。Weaveworks拥有一支特别的团队，曾经历过漫长且艰难的发展旅程。我们每个人都在积极为客户、开源社区乃至参与成员竭力服务。感谢各位的付出，相信共同的记忆将被深深铭记在彼此的人生当中。&nbsp;一路走来，Weaveworks的故事令人振奋——从容器技术诞生之初，我们就在为其贡献力量。无论是第一次在Azure上运行起Kubernetes的那个瞬间，CNCF云原生计算基金会的启动，我们不慎清空了自己的系统，新冠疫情初期的需求大爆发，乃至我们通过不懈投入为众多企业客户提供GitOps方案等，都让人永生难忘。那些鸿飞泥沼，种种高潮落寞，都是Weaveworks带给我们每个人、带给整个世界的精彩过往。&nbsp;但我们的故事不会终结——Weaveworks的开源软件仍无处不在。我们正与多家大型组织合作，确保CNCF Flux保持健康运行。很快将有更多消息向大家公布，也希望大家能继续关注我们的未来动向。&nbsp;我们不会停止探索的脚步，哪怕踏遍青山，却又回到原点，我们也将收拾行囊再出发。</blockquote><p></p><p>&nbsp;</p><p>Weaveworks的故事，就是初创公司与宏观市场和资本打压斗智斗勇的经典历程。如CEO在信中所述，尽管在2023年实现了两位数增长，但该公司仍面临着销售额“不稳定”且市场空间持续缩小的窘境。收购谈判失败则成为压垮骆驼的最后一根稻草——可以说Weaveworks就代表着一众初创公司最害怕、但却难以绕过的悲惨命运。</p><p>&nbsp;</p><p>Weaveworks成立于2014年，当时的“云原生”还只是个新兴词汇，远没有转化成真正的商业实现。Weaveworks立场通过新的GitOps理念为云基础设施管理塑造未来形态。尽管他们极具开拓精神并早早迈入市场，但财务可持续性的阴云却始终笼罩在其头顶。</p><p>&nbsp;</p><p>Weave GitOps是一套开源软件包，旨在简化Kubernetes集群上通过Git repo部署应用程序和更新的整个持续交付（CD）流程。该公司原本以为这将是其开疆拓土、安身立命的根基，却没想到崩溃来得如此之快。</p><p>&nbsp;</p><p>该公司还留下了FIux项目，这是一个 Kubernetes GitOps 运营商，最初是为自己的部署管道构建的，后来捐赠给了云原生计算基金会 (CNCF) 。2019年，Flux 被接收为沙盒项目。它于2022 年毕业，最新版本2.2于 2023 年12月全面发布 。</p><p>&nbsp;</p><p>近年来，云原生领域的竞争不断加剧，CircleCI和Harness Labs等竞争对手分走了不少市场关注和投资份额。Weaveworks与这些大资本支持下的对手们的抗争之路，也凸显出初创企业单凭创新并不能保证成功的严酷现实。</p><p>&nbsp;</p><p>Weaveworks在其生命周期之内共筹集到超6100万美元，而且2020年最后一轮融资也已高达3600万美元。虽然态势不错，但四年间隔期对于风险投资世界而言已经太久太久。随着2022年经济衰退的来临，Weaveworks与许多其他公司一样，突然发现自己再也拉不到更多投资，并最终倒在了寻求并购失败后的一个清冷冬季。</p><p></p><h2>这是一场残酷的游戏</h2><p></p><p>Richardson的声明不只是一场告别，更让人们意识到科技企业身处怎样一个残酷的竞争环境。他对Weaveworks的命运感到遗憾，但也指出整个行业目前都面临着更广泛的挑战。相信很多创业者都能感受到这股寒流，哪怕是曾经最具前景的公司也可能在金融波动和市场饱和之下瞬间崩塌。</p><p>&nbsp;</p><p>但Weaveworks留下的遗产仍将永存。该公司为开源社区做出的贡献，特别是CNCF Flux，支撑着其致力于推进云原生技术发展的承诺。Richardson希望Flux能够继续运行下去。</p><p>&nbsp;</p><p>他在信中写道，“我们的故事不会终结——Weaveworks的开源软件仍无处不在。我们正与多家大型组织合作，确保CNCF Flux保持健康运行。”</p><p>&nbsp;</p><p>回顾Weaveworks的发展历程，我们会意识到科技生态圈既是一片充满机遇的土地，也是一方争斗不休的战场。该公司令人惊醒的故事也提醒我们，尽管行业随时面临着滚滚向前的变革浪潮与极端严酷的生存挑战，创业者的精神仍在推动其不断迈进。</p><p>&nbsp;</p><p>下面想用一张简单的时间表，回顾Weaveworks那辉煌而短暂的一生：</p><p></p><p>Weaveworks为Docker容器发布检测、映射与监控工具Weave Scope（2015年6月）；Weaveworks将软件定义网络引入容器生态（2015年12月）；Weaveworks向Kubernetes引入网络多播（2016年4月）；Weaveworks将网络、Prometheus监控功能集成至云原生服务和Weave Cloud（2016年11月）；GitOps：将一切纳入“Git Push”（2018年5月）；Weave GitOps Core将Git与Kubernetes融为一体（2021年7月）；Weaveworks添加策略即代码以保护Kubernetes用例（2022年2月）；Weaveworks&nbsp;WKSctl为Kubernetes引入基于GitOps的队列管理功能（2022年2月）。</p><p></p><h2>公司倒闭背后的真实原因是什么？</h2><p></p><p>&nbsp;</p><p>Weaveworks的关停是一个令人悲伤的故事，此事也在Hacker News上引发了诸多讨论，而讨论最多话题的就是公司走到如今地步的真实原因以及对公司运营情况的质疑。有人认为，公司走到如此境地，是人员过于冗余导致，Hacker News上一名用户发表评论称：</p><p>&nbsp;</p><p></p><blockquote>以年收入1000万计算，他们可以维持 50名员工，每名员工的全部用人成本为 20万 美元。然而，根据 Linkedin 的数据，他们的员工人数最多时达到了近 200 名。&nbsp;除此之外，他们三年前似乎筹集了 3600 万美元，换句话说，不知何故，他们连续三年每月损失约 150 万美元，直到今天“突然”耗尽了最后一点“余粮”。&nbsp;公司根据首席执行官在 LinkedIn 上发布的帖子，他们基本上是在努力保持自己是一家 200 人的公司的形象，直到某个更大的傻瓜将他们收购，但这似乎失败了。&nbsp;作为这样一家公司的董事会成员或首席执行官，你怎么会不考虑早点削减开支呢？成为一家不断发展、盈利、拥有 50 名员工的公司比成为烧钱的波将金独角兽公司要好得多。</blockquote><p></p><p>&nbsp;</p><p>也有人认为，像很多初创企业一样，把自己包装得很完美，以求在被收购时将自己卖个好价。ID名为KaiserPro的用户评论称：</p><p>&nbsp;</p><p></p><blockquote>许多初创公司都是如此，几乎80%“成功”的初创公司都遵循这种模式。如果你不冒巨大的风险，那么你就不会得到回报。听起来他们即将被买断或被聘用，但在最后一刻分崩离析（这并不罕见）。</blockquote><p></p><p>&nbsp;</p><p>从Weaveworks的倒闭之路不难看出，对于很多初创企业来说，要么成功，要么破产，没有其他选择。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href=\"https://thenewstack.io/end-of-an-era-weaveworks-closes-shop-amid-cloud-native-turbulence/\">https://thenewstack.io/end-of-an-era-weaveworks-closes-shop-amid-cloud-native-turbulence/</a>\"</p><p><a href=\"https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67/\">https://www.linkedin.com/posts/richardsonalexis_hi-everyone-i-am-very-sad-to-announce-activity-7160295096825860096-ZS67/</a>\"</p>",
    "publish_time": "2024-02-23 16:51:04",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "蚂蚁、智源、百川、讯飞专家齐聚，大模型开发与应用探索，AICon 2024邀您共鉴",
    "url": "https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT",
    "summary": "<p>经过一年的深入发展，大型人工智能模型在对话生成、图像创作、视频制作等多个领域取得了显著进步。</p><p></p><p>近日，Twitter上的网友们分享了一张精彩的图鉴，生动展示了大模型在文本处理、视频编辑、音频分析以及设计和沟通交流等方面的强大应用能力。随着这些工具的不断成熟，大模型技术正越来越多地被企业所采纳。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/75/75e86529f2cf245768383ea0e954d9ff.jpeg\" /></p><p></p><p></p><p>在图中，你可以看到ChatGPT&nbsp;、Bard、Claude.ai、Pika、GitHub&nbsp;Copilot、ElevenLabs、Midjourney等等知名应用。然而，除了这些直接可用的工具外，企业应该如何将大模型落地到生产实践中也是不少人关注的事宜。</p><p></p><p>适逢这一机会，InfoQ&nbsp;即将于5月17日-18日落地&nbsp;AICon全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展。此次盛会专门为工程师、产品经理、数据分析师等专业人士量身打造，旨在深度探索大模型训练与推理、AI代理、检索与生成（RAG）、多模态大模型等领域的最新进展。</p><p></p><p>在大会的筹备过程中，我们与许多行业专家及潜在听众进行了广泛而深入的交流。通过这些对话，我们发现各个群体对大模型持有的兴趣点和关注焦点存在显著差异：</p><p></p><p>技术与管理层（如CEO、CTO、研发管理负责人）：关注大模型的整体战略和商业价值，以及其在企业内应用的潜力和对企业战略的影响；技术专业人员（如工程师、架构师、数据分析师）：关注大模型的架构、算法等技术细节，以及在特定技术领域的应用；业务负责人和产品经理：探索大模型如何为业务创新提供价值，以及其在特定业务场景下的应用可能性。市场和营销专业人员：研究大模型在市场营销中的作用，以及其对品牌形象和消费者行为的影响。创新驱动者和独立开发者：对成本控制、资源优化和独特的大模型应用案例特别感兴趣。</p><p></p><p>为了满足不同参与者的需求和兴趣，大会内容将覆盖从大模型开发到应用的的多个层面，确保每位到场的专业人士都能从中获得价值。以下是大会已经确认的专题：</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/64/644fe5243809b42c0b6dc58e2c002398.jpeg\" /></p><p></p><p></p><p>截至今日，我们非常荣幸地宣布，已有多位业界顶尖专家确认将参与本次大会，他们将对会议内容进行严格的把关，确保每位参会者都能获得最前沿的知识和最深刻的洞察。</p><p></p><p>已确认联席主席包括：</p><p>林咏华，北京智源人工智能研究院副院长兼总工程师，其深厚的学术背景和丰富的行业经验，在人工智能研究与应用方面有着卓越的成就。贾扬清，Lepton&nbsp;AI联合创始人兼CEO，以其在深度学习和人工智能领域的创新贡献而闻名。谢剑，百川智能技术联合创始人，他在AI技术创新和实际应用转化方面具有丰富的经验和卓越的成绩。余锋（褚霸），蚂蚁集团蚂蚁超级计算部负责人，其在大规模计算和大模型优化方面的深入研究，为行业带来了诸多创新。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f0/f0a057f8859babb5a71492537d67c23a.png\" /></p><p></p><p>此外，大会还邀请到了多位专题出品人，包括但不限于：</p><p>张佶，阿里巴巴通义实验室NLP资深算法专家杨萍，字节跳动Code&nbsp;AI团队技术负责人李鑫&nbsp;博士，科大讯飞AI研究院副院长、科研部部长郭瑞杰，阿里巴巴总监，以及其他多位在AI领陈祖龙，阿里巴巴&nbsp;企业智能算法负责人杨浩，博士&nbsp;华为&nbsp;文本机器翻译实验室主任孟二利，小米AI&nbsp;实验室机器学习团队技术主管张科，蚂蚁集团&nbsp;AI&nbsp;Infra&nbsp;负责人</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d3/d332ca0b5e03173d5d7230bc7b0dcae8.png\" /></p><p></p><p></p><p>此外，我们还特别推荐以下几位业界领袖的精彩演讲：</p><p></p><p>精彩演讲推荐一</p><p>在【大模型基础设施】专题，我们邀请了崔慧敏中科加禾&nbsp;创始人&nbsp;&amp;&nbsp;CEO，现任中科院计算技术研究所研究员，处理器芯片全国重点实验室副主任，是中科院计算所编程与编译方向的学术带头人。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b7/b7c511a7a29569d51bd066fed691680d.jpeg\" /></p><p></p><p></p><p>崔慧敏提到，目前以通用大模型为代表的AI技术高速发展，带来了对高性能智算算力需求的爆发式增长；而各厂商围绕自身硬件特性构建相对独立且排他的工具链系统，适配集成各类&nbsp;AI&nbsp;框架形成分支版本，构成“中间件/框架+工具链+硬件”紧密协同的长链条式智算生态，并且厂商间互不兼容，致使上层智算应用与特定系统的锁定，难以在多个竖井生态系统间迁移部署，无法形成系统的整体运用效能。</p><p></p><p>她将以《构建兼容多元加速卡的大模型基础设施》为主题，在大会上进行分享。通过崔老师的分享，你可以了解针对大模型应用的跨硬件基础设施研究进展和应用方向。</p><p></p><p>精彩演讲推荐二</p><p>在【大模型+行业应用】专题论坛，我们邀请到了陈鸿蚂蚁集团资深算法专家，他是蚂蚁金融大模型算法负责人。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e6/e6927bad93cead4573abdc5ebede0d96.jpeg\" /></p><p></p><p></p><p>在他的演讲中，他提到“金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。”陈鸿老师将以《金融场景中的多智能体应用探索》来分享在实际业务中打磨过的多智能体协同方案。</p><p>通过陈鸿老师的分享，你将了解蚂蚁集团在多智能体领域的技术探索，对大模型驱动的智能体/多智能体系统的未来有所思考</p><p></p><p>精彩演讲推荐三</p><p></p><p>在【大模型+行业创新应用】专题论坛，我们有幸邀请到了陶万杰，马上消费金融的算法总监，目前在马上消费金融人工智能研究院担任要职，负责推进企业数字化及办公智能化相关的AI大模型技术研发。陶万杰老师的背景在金融领域的智能文档和OA流程自动化方面特别丰富，他在智能营销决策算法、运筹学和商业化算法等领域带领团队取得了卓越的成就。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/04/040b8872d002a562424f37fac2bd6d8f.jpeg\" /></p><p></p><p></p><p>陶万杰老师将在本次论坛上分享的主题是《大模型在金融领域办公智能化场景的应用》。他将探讨在数字化时代背景下，RPA技术（机器化流程自动化）和AI大模型如何结合，实现智能自动化，提高工作效率，缩短业务流程处理时间，降低企业成本。特别是在金融领域，如何在确保监管政策合规的前提下，推动企业办公数智化的进程。</p><p></p><p>精彩演讲推荐四</p><p>在【AI前沿探索】专题论坛中，我们荣幸邀请到季超，科大讯飞的人形机器人总负责人。季超博士是科大讯飞与中国科学技术大学联合培养的博士生，拥有丰富的机器人科研及产业经验，在人机交互、具身智能、机器人强化学习运动控制等领域有着深入的研究。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9189a775a1429d244cce1b75be91480.jpeg\" /></p><p></p><p></p><p>季超将分享的主题是《大模型在具身智能通用机器人领域的创新探索》。他将探讨模型技术如何推动具身智能发展到新的高度，并与人形机器人结合，打造出集成高级认知与执行能力的通用机器人。演讲内容将涵盖以下几个关键点：</p><p>智能机器人行业的发展趋势，以及当前产业面临的主要痛点。大模型、具身智能、机器人技术在通用机器人领域的关键技术和系统集成方法。强化学习在运动控制中的应用和前沿技术探索。科大讯飞在大模型、具身智能和机器人全技术栈方面的进展和成就。针对AGI+Robot生态构建的倡议和展望。</p><p>听众通过季超的分享，将能深入了解大模型在具身智能机器人领域内的创新应用及重大机遇，认识到企业在这一浪潮中能扮演的角色和做出的贡献，同时了解科大讯飞在这一领域的最新进展和成果。</p><p></p><p></p><p>精彩演讲推荐五</p><p></p><p>在【多模态大模型技术与应用】专题论坛，我们邀请到小米的语音技术负责人王育军。王育军拥有20年声学语音领域经验，曾在清华、伯明翰大学学习，且在NEC、鲁汶大学、百度等机构工作。作为小米声学语音团队负责人，王育军带领团队涵盖语音识别、声音分析还原、语音合成等多个子领域，取得了国际认可的成就。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/32/32c47d4a2e75f9a7b981c817099d1295.jpeg\" /></p><p></p><p></p><p>王育军的演讲主题为《声音基础模型如何推动声音理解和生成》，将探讨大模型时代编解码范式如何深化声音的理解与生成。内容聚焦于小米声音基础模型的技术演进，以及这些模型如何精准助力声音理解与生成两侧，提升语音识别准确性、优化语音合成自然度以及改善声音还原和降噪效果。</p><p>听众将深入了解声音基础模型在声音理解与生成中的核心作用，及小米在该领域的最新进展和未来方向，为关注语音技术和多模态交互的专业人士提供宝贵的学习交流机会。</p><p></p><p>精彩演讲推荐六</p><p></p><p>在【Copilot应用构建实践】专题论坛，我们邀请到了腾讯的资深产品经理汪晟杰。汪晟杰曾任职于阿里、Autodesk等公司，拥有近20年在软件架构、产品管理、团队效率提升等方面的经验。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e84b74788a0704fc15f239332c77d48f.jpeg\" /></p><p></p><p></p><p>汪晟杰的演讲主题为《代码大模型对于工程理解的探索研究》，重点介绍GitHub&nbsp;Copilot在提升工程理解和Agent协作方面的进展。他将探讨如何通过RAG和CoT实验，加强对项目多文件的理解，并通过微调训练语料增强工程理解下的代码补全能力，特别是针对有内部代码依赖库和业务封装组件的企业产品。</p><p></p><p>演讲将涵盖GitHub&nbsp;Copilot的工程理解增强、多文件理解实现、微调训练探索，以及AISE在国内企业开发中的应用挑战和进展。汪晟杰还将演示如何在编辑器内强化理解工程并唤起内联对话，展示AI时代编程的新模式。</p><p></p><p>听众将获得关于GitHub&nbsp;Copilot如何助力工程理解增强、RAG和CoT技术探索的深入了解，为关注代码大模型和AI辅助软件开发的专业人士提供宝贵的洞见。</p><p></p><p>【活动推荐】</p><p>AICon&nbsp;全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击「阅读原文」查看更多详情。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ad/ad61af065d4ee62c5fcd2068f63d683a.jpeg\" /></p><p></p><p>目前会议&nbsp;8&nbsp;折优惠购票，火热进行中，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>",
    "publish_time": "2024-02-23 17:43:57",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "LLM 和多 Agent 在运维领域的落地经验｜QCon",
    "url": "https://www.infoq.cn/article/WZlok9GppT3KWswvQKk3",
    "summary": "<p>在数字化时代，企业和组织的&nbsp;IT&nbsp;系统变得越来越复杂，运维工作也变得越来越繁琐和困难。为了解决这些问题，AIOps智能运维技术应运而生，而大模型的出现，为AIOps更强大的计算、决策与自学能力，极大地提升了IT运营的自动化和效率。在大模型的加持下，新时代的智能运维方案具有以下优点：</p><p>学习与适应：大模型能从数据中学习并适应环境变化，及时识别并调整模型以应对IT运营数据中的微妙变动。预测性分析：通过对历史数据的深度分析，大模型能够预测未来IT运营趋势，提前预警潜在系统故障。自然语言处理：大模型能够理解人类语言，实现自然高效的互动，如解读用户对系统性能问题的反馈，并推测可能原因。自动决策：面对复杂的IT问题时，大模型能够综合考量多个变量，计算最佳解决方案并实时执行，实现问题自动解决。端到端自动化：大模型可实现从问题发现到解决方案确定再到实施的全流程自动化，从而提升生产力并减少人工干预需求。异常检测：通过深入分析历史趋势和性能指标，大模型能敏锐捕捉到不易被人类察觉的异常现象。</p><p></p><p>华为在&nbsp;LLM&nbsp;和&nbsp;Multi-agent&nbsp;在运维领域的实验探索有了不错的经验，即将与4月11-13日举办的QCon&nbsp;全球软件开发大会暨智能软件开发生态展邀请到华为集团&nbsp;IT&nbsp;平台服务部算法科学家张曦博士前来分享。她是犹他州立大学统计学博士，研究方向为&nbsp;AI&nbsp;for&nbsp;Data、AI&nbsp;for&nbsp;BI、AIOps，时间序列分析等；具有丰富的人工智能在企业场景落地应用的成功经验，应用场景覆盖营、销、服、供、采、制、研发等多领域，支撑华为集团&nbsp;600+&nbsp;业务应用&nbsp;+AI，带领团队成功攻克&nbsp;5+&nbsp;企业技术难题，并主导发布多个&nbsp;AI&nbsp;服务。</p><p></p><p>她将从智能运维面临的挑战和痛点出发，介绍在企业运维领域应用&nbsp;AIGC&nbsp;的实践案例，提出以&nbsp;LLM&nbsp;为中心，基于多&nbsp;Agent&nbsp;协同的运维方案，并提出在大模型时代下，对下一代智能运维的思考。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/ea9acb601540703b415421444edd5b66.jpeg\" /></p><p></p><p></p><p>该方案亮点突出，可实现多&nbsp;Agent协同完成运维主流程，异常检测-&gt;根因定位-&gt;故障分析-&gt;修复建议，且框架与算法不依赖具体特定应用场景，结合大模型实现较强的泛化能力</p><p></p><p>并且，如果你也对运维领域如何有效抑制大模型幻觉，提升问题处理的准确率，如何将传统运维积累和沉淀的海量知识快速激活，结合大模型相关能力有效解决运维问题等相关话题感兴趣，欢迎听取张曦博士的分享。</p><p></p><p>围绕着“效能”，本届大会策划了多个相关分论坛，邀请了多位业界知名大咖前来交流。</p><p></p><p>柯旻，「智能运维大模型」分论坛出品人，字节跳动基础架构&nbsp;SRE&nbsp;负责人，负责整体字节跳动基础架构全球相关基础组件产品的稳定性、成本优化、运维产品开发、智能运维等相关工作。</p><p></p><p>王宁，「智能运维大模型」分论坛演讲嘉宾，北京大学统计硕士，字节跳动基础架构&nbsp;SRE&nbsp;数据化方向技术专家，关注稳定性，成本与效率。在智能运维&nbsp;aiops&nbsp;和机器学习领域有多年工作经验，包括异常检测，根因定位，大语言模型等。在去年的&nbsp;Aiops&nbsp;智能运维挑战赛&nbsp;2023&nbsp;上，以“SRE－Copliot：基于大语言模型的智能运维架构”方案获得冠军，在本次会议中，他将介绍最新的实践经验。</p><p></p><p>陈鑫（神秀），「下一代生产力工具」分论坛出品人&amp;演讲嘉宾，阿里云云效、通义灵码产品技术负责人，致力于企业研发效率、产品质量、DevOps&nbsp;方向研究和探索。2011&nbsp;年加入阿里，带领过大数据测试团队、测试工具研发团队、研发平台团队。对研发协同、测试、交付、运维领域都有很深的见解。目前正在带领团队向云原生、极致效率、智能化等领域进行持续演进。</p><p></p><p>吴玮琦，「下一代生产力工具」分论坛演讲嘉宾，百度工程效能部高级研发工程师&nbsp;负责智能代码助手&nbsp;Comate&nbsp;客户端、云开发平台&nbsp;iCoding&nbsp;等代码服务研发工作，参与文心一言代码相关能力数据建设。他将分享的题目是《智能研发经验及&nbsp;Comate&nbsp;开放平台》。</p><p></p><p>茹炳晟，「效能工程新时代」分论坛出品人，腾讯&nbsp;Tech&nbsp;Lead，腾讯研究院特约研究员，中国计算机学会&nbsp;(CCF)TF&nbsp;研发效能&nbsp;SIG&nbsp;主席，中国通信标准化协会&nbsp;TC608&nbsp;云计算标准和开源推进委员会云上软件工程工作组副组长，“软件研发效能度量规范“标准核心编写专家，中国商业联合会互联网应用技术委员会智库专家，多本技术畅销书作者，著作有《测试工程师全栈技术进阶与实践》《软件研发效能提升之美》《多模态大模型技术原理与实战》《高效自动化测试平台:&nbsp;设计与开发实战》《软件研发效能提升实践》和《软件研发效能权威指南》等，译作有《持续架构实践》和《现代软件工程》等。公众号“茹炳晟聊软件研发”主理人。</p><p></p><p>张宇辰，「效能工程新时代」分论坛演讲嘉宾，毕业于上海交通大学，毕业后一直在互联网研发领域工作。曾经在网易有道任职，自&nbsp;2012&nbsp;年开始在猿辅导，担任过前端工程师、服务端工程师、业务研发经理、基础架构负责人等多种不同职能角色。对于前后端软件开发、技术管理有着丰富经验。他将分享《If&nbsp;It&nbsp;Hurts,&nbsp;Do&nbsp;It&nbsp;More&nbsp;Often&nbsp;——Motiff&nbsp;的主干开发实践》。</p><p></p><p>唐辉，「效能工程新时代」分论坛演讲嘉宾，百度资深工程师，2017&nbsp;年加入百度，2019&nbsp;年带领&nbsp;10+&nbsp;同学从&nbsp;0&nbsp;到&nbsp;1&nbsp;建设云上百度，完成统一账户权限、统一&nbsp;Console、预算管理、透明账单等混合云能力建设，达成公司三年上云的战略目标。2023&nbsp;年随着大模型的发展，开始负责&nbsp;DevOps&nbsp;产品的智能化建设，目前百度内周渗透用户超过&nbsp;60%。此外，在微前端、性能优化、体验优化、To&nbsp;B&nbsp;多版本管理等方向有深入探索和落地。他将分享《大模型赋能&nbsp;DevOps，研发全环节提速》。</p><p></p><p>朱宏宝，「效能工程新时代」分论坛演讲嘉宾，字节跳动客户端测试技术专家，十余年软件测试与技术管理工作经验，有服务端、移动端业务测试，近几年主要从事效能平台工具开发，负责过多个公司级效能平台从&nbsp;0-1&nbsp;建设。曾就职于贝壳找房、滴滴出行、京东等公司。目前就职于字节跳动，负责移动端智能化测试建设。他将分享《字节移动端智能化测试实践》。</p><p></p><p>【活动推荐】</p><p>&nbsp;为了提供更丰富多元的交流平台，QCon全球软件开发大会将不再局限于传统的分享与研讨模式，而是全面整合为集技术分享、深度研讨和前沿展览于一体的综合性会展活动，并正式更名为【QCon全球软件开发大会暨智能软件开发生态展】。</p><p>同时，会议正式改期为：2024年4月11-13日，地点：北京·国测国际会议会展中心。</p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6da62c2c243c3a62ad38efb35aa65e5.jpeg\" /></p><p></p><p>会议现已进入&nbsp;8&nbsp;折早鸟购票阶段，错失7折特惠的朋友们，可以联系票务经理&nbsp;17310043226&nbsp;。<a href=\"https://qcon.infoq.cn/2024/beijing/track?utm_source=wechat&amp;utm_medium=qconart-0223\">点击此处</a>\"了解大会更多详情，期待与各位开发者现场交流。</p>",
    "publish_time": "2024-02-23 17:55:56",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "从 Elasticsearch 到 Apache Doris，统一日志检索与报表分析，360 企业安全浏览器的数据架构升级实践",
    "url": "https://www.infoq.cn/article/OK8aTSSeA0YXpTP53AS5",
    "summary": "<p></p><blockquote>随着 360 企业安全浏览器用户规模的不断扩张，浏览器短时间内会产生大量的日志数据。为提供更好的日志数据服务，360 企业安全浏览器设计了统一运维管理平台，并引入 Apache Doris 替代了&nbsp;Elasticsearch，实现日志检索与报表分析架构的统一，同时依赖 Doris 优异性能，聚合分析效率呈数量级提升、存储成本下降了 60%....为日志数据的可视化和价值发挥提供了坚实的基础。</blockquote><p></p><p></p><p>作者｜360 企业安全浏览器&nbsp;刘子健</p><p></p><p>近年来，随着网络攻击和数据泄露事件的增加，使得浏览器安全问题变得更加紧迫和严峻。漏洞一旦被利用，一个简单的链接就能达到数据渗透的目的，而传统浏览器在安全性和隐私保护方面存在一些限制，无法满足政企领域对于安全浏览的需求。在此背景下，360企业安全浏览器成为政企客户的首选，以提供统一管理、降本增效、安全可控的解决方案。</p><p></p><p>在 360 企业安全浏览器强大安全防护能力的背后，对海量安全日志进行深入分析和挖掘是及时发现潜在风险的重要手段。为了提供更好的日志数据服务，360 企业安全浏览器设计了统一运维管理平台，引入 Apache Doris 作为日志分析架构的核心组件，实现数据导入、计算和存储的统一，保障了数据的准确性和一致性，实现了低成本、高效的实时查询能力与同步能力，为日志数据的可视化和价值发挥提供了坚实的基础。</p><p></p><h2>业务需求</h2><p></p><p>随着 360 企业安全浏览器用户规模的不断扩张，浏览器短时间内会产生大量的日志数据，这些数据具有格式多样化、信息维度丰富、时效要求高、数据体量大和隐私安全性高等特点。如果能够对这些数据进行有效分析，可及时发现潜在威胁并提升网站使用体验，因此我们设计了统一运维管理平台。该平台旨在对终端层、应用层和安全层进行监控和分析，并进行多维度分析和可视化展示。</p><p></p><p>在应用层，提供应用总览、访问分析、性能分析、体验分析以及异常分析等功能，可全面了解应用的运行状况，及时发现并解决应用中存在的问题。在终端层，提供终端导览和终端活跃分析功能，及时掌握终端设备状况，从而更好地管理和优化终端性能。在安全层，提供策略预警和策略建议等功能，可及时发现和预防安全风险，提高系统的安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e8/e89809394cb518470702aa486ebde5ca.png\" /></p><p></p><p>对于政企相关单位而言，浏览器受到攻击可能导致大量隐私数据泄露，给单位和个人带来难以预料的后果。因此，为保障客户信息的安全，统一运维管理平台应具备以下几个能力：</p><p></p><p>实时告警：部分客户对查询性能有较高的要求。比如：实时统计服务异常或系统崩溃的次数，并第一时间反馈给相关负责人解决。导入性能：在业务运行过程中，生成的日志数据会被保存在服务器上。在高并发的情况下，日志数据量非常庞大，因此对导入性能有较高的要求。数据一致性： 数据一致性对任何行业来说都是关键考虑因素，只有在数据一致的基础上进行指标计算，才能确保统计结果的准确性。部署简单：因 360 企业安全浏览器主要为政企提供服务，通常采用私有化部署的方式，这意味着服务和客户端将完全集成在客户本地环境中。这就要求架构要足够精简，在确保在实现功能的同时，尽可能降低部署的复杂度。</p><p></p><h2>架构 1.0 ：基于 Elasticsearch 的简洁日志处理架构</h2><p></p><p>为满足统一运维管理平台的要求，我们首先设计了一个简洁的日志处理架构。在该架构中，浏览器客户端发起请求后，经过业务层的服务 API 处理，日志数据在服务应用层进行处理，并最终存储于 MySQL、Elasticsearch 和 Redis 等数据存储系统中。</p><p></p><p>MySQL 主要存储业务相关数据以及少量计算完成的统计数据，用于管理平台中随查随用，Elasticsearch 主要用于存储日志类数据，以支持数据实时分析和检索需求。Redis 主要用于存储热数据和管理平台的配置信息，以提高接口性能。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/71/711fd1484b0dfae2b126807f69baf377.png\" /></p><p></p><p>在架构 1.0 使用过程中，我们发现几个痛点问题：</p><p></p><p>Elasticsearch 索引不支持变更：Elasticsearch 一旦创建索引，不再支持更改，分词参数和字段类型也无法修改。当提出新的业务需求时，就需要创建新的索引，并需要编写脚本将历史数据迁移至新索引中，这就带来较高的操作和开发成本。Elasticsearch 聚合性能差：当执行复杂的聚合查询或存在大量聚合任务时，Elasticsearch 需要为聚合操作分配大量的内存，如果计算资源不足，会造成聚合操作执行时间过长，从而影响查询效率。</p><p></p><h2>架构 1.1：引入 Apache Doris 1.0 版本</h2><p></p><p>据前文可知，Elasticsearch 聚合性能较差，而在实际的使用场景中存在大量需深度聚合的数据表，因此我们决定对架构进行升级改进。在正式升级之前，我们对多个数据分析组件进行调研，并发现 Apache Doris 具备许多特性符合我们的需求，有望解决当前存在的问题。以下列举我们较为关注的特点：</p><p></p><p>支持多种数据模型：支持 Aggregate、Unique、Duplicate 三种数据类型，其中 Aggregate Key 模型能够在快速且准确的写入数据的同时进行数据聚合，即通过提前聚合大幅提升查询性能。采用列式存储：Doris 按列进行数据编码压缩和读取，从而实现极高压缩比，该存储方式也减少了大量非相关数据的扫描，提高 IO 和 CPU 资源的利用率。支持物化视图：既能对原始明细数据进行任意维度的分析，也能快速对固定维度进行分析查询，对于查询性能的提升有显著的效果。</p><p></p><p>基于这些优势，我们在架构 1.0 的基础上先引入了 Apache Doris 1.0 版本，并将其作为数据存储层。Apache Doris 在架构中主要替代 Elasticsearch 进行实时计算，并将相关统计报表的计算和存储都迁移到 Doris 中来进行，由 Doris 提供统一数据服务。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/19/1916939c99237fcb39fd007847f66f89.png\" /></p><p></p><p>不仅如此，Apache Doris 的引入也带来了许多性能和效率提升：</p><p></p><p>开发效率提升：相比之前需要编写复杂的 Elasticsearch 聚合代码，现在只需要创建聚合 Key，Doris Aggregate 模型即可完成聚合计算，极大提升了数据开发的效率。数据一致性保证：Doris 提供了统一的数仓服务，数据的导入、计算和存储均可在 Doris 中实现，简化了数据处理的链路和复杂度，对数据一致性的保障起关键作用。查询性能提升：当面对 4000 万条数据的聚合查询时，Elasticsearch 需要 6-7 秒才能返回查询结果，而 Doris 在 1 秒内就能完成查询并返回结果，查询性能显著提升。</p><p></p><p>除此之外，Apache Doris 在语法结构上也有明显的优势，这为客户在排查问题时提供了极大的便利、缩短了排查时间。为更直观体现其便捷性，我们对 Elasticsearch 和 Apache Doris 的语法结构进行对比。</p><p></p><p>在 Elasticsearch 中，聚合需要多层 group by，由于其语法与标准 MySQL 协议存在差异，因此语法结构相对复杂。</p><p></p><p><code lang=\"sql\">  \"aggregations\": {\n    \"group_day_time\": {\n      \"aggregations\": {\n        \"group_urltitle\": {\n          \"aggregations\": {\n            \"group_app_id\": {\n              \"aggregations\": {\n                \"group_url_host\": {\n                  \"aggregations\": {\n                    \"group_org_id\": {\n                      \"terms\": {\n                        \"field\": \"org_id\",\n                        \"size\": 200000\n                      }\n                    }\n                  },\n                  \"terms\": {\n                    \"field\": \"url_host\",\n                    \"size\": 200000\n                  }\n                }\n              },\n              \"terms\": {\n                \"field\": \"app_id\",\n                \"size\": 10000\n              }\n            }\n          },\n          \"terms\": {\n            \"field\": \"urltitle\",\n            \"size\": 100000\n          }\n        }\n      },\n      \"date_histogram\": {\n        \"calendar_interval\": \"day\",\n        \"field\": \"day_time\"\n      }\n    }\n  }\n</code></p><p></p><p>当用户遇到问题时，我们需要向客户发送大量的 Curl 命令来排查问题。然而，对于没有 Elasticsearch 使用经验的用户来说，语法调试难度非常高。</p><p></p><p><code lang=\"sql\">curl -u elastic:elastic 'http://127.0.0.1:9200/user_log*/_search?ignore_unavailable=true&amp;pretty=true' -H 'Content-Type: application/json' -d '{\"aggregations\":{\"group_day_time\":{\"aggregations\":{\"group_sysname\":{\"aggregations\":{\"group_app_id\":{\"aggregations\":{\"group_url_host\":{\"aggregations\":{\"group_org_id\":{\"terms\":{\"field\":\"org_id\",\"size\":200000}}},\"terms\":{\"field\":\"url_host\",\"size\":200000}}},\"terms\":{\"field\":\"app_id\",\"size\":10000}}},\"terms\":{\"field\":\"sysname\",\"size\":100000}}},\"date_histogram\":{\"calendar_interval\":\"day\",\"field\":\"day_time\"}}},\"query\":{\"bool\":{\"filter\":[{\"range\":{\"day_time\":{\"from\":\"2022-06-02T00:00:00+08:00\",\"include_lower\":true,\"include_upper\":true,\"to\":null}}},{\"range\":{\"day_time\":{\"from\":null,\"include_lower\":true,\"include_upper\":false,\"to\":\"2022-06-03T00:00:00+08:00\"}}}]}}}'\n</code></p><p></p><p>**引入 Apache Doris 后，**在创建表时可以使用 Aggregate Key 模型来定义聚合条件。且 Apache Doris 支持标准 MySQL ，不仅语法更加简洁、查询也更加方便，如出现问题，只要熟悉 MySQL 的基本语法，便可以快速进行问题排查。</p><p></p><p><code lang=\"sql\">CREATE TABLE user_log \n(\n    day_time datetime    DEFAULT NULL COMMENT ‘时间',\n    org_id   int(10) DEFAULT ‘0’ COMMENT ‘组织id',\n    app_id   int(10) DEFAULT ‘0’ COMMENT ‘应用id',\n    url_host varchar(255) DEFAULT NULL COMMENT 'url地址‘,\n    urltitle varchar(255) DEFAULT '' COMMENT 'title',\n    pv_count    BIGINT SUM DEFAULT \"0\" COMMENT \"总数\"\n) Aggregate KEY(day_time,org_id,app_id, url_host, urltitle)\nPARTITION BY RANGE (day_time) ()\nDISTRIBUTED BY HASH(day_time) BUCKETS 10\n\n\nSELECT day_time,org_id，app_id，url_host，urltitle，sum(pv_count)  as pv \nFROM user_log \nWHERE day_time &gt;= \"2022-06-02\" and day_time &lt;= \"2022-06-03\" \nGROUP BY day_time,org_id，app_id，url_host，urltitle  \nORDER BY uv desc;\n</code></p><p></p><p>而在架构 1.1 版本中，我们仍然面临一些挑战和问题：</p><p></p><p>Bitmap 问题：在处理大规模数据时，对于字符串类型基数很高的数据，如果直接使用 Bitmap ，计算性能无法很好满足。数据准确性问题：当对 75 万基础数据测试时，Bitmap 哈希冲突可能导致数据准确性问题。存储空间：由于 Elasticsearch 还未被 Apache Doris 全部替换，目前系统仍存在存储资源消耗较大的问题。</p><p></p><h2>架构 2.0 ：引入 Apache Doris 2.0，全面替代 Elasticsearch</h2><p></p><p>针对上述问题，我们积极寻找下一步的解决方案。在与 Apache Doris 社区技术同学沟通过程中，我们得知 Apache Doris 2.0 版本在日志分析场景上有了全面加强：</p><p></p><p>支持 JOSN 格式：Apache Doris 2.0 支持 JSON 格式，在我们的数据中有大量采用 JSON 格式的数据，该能力使我们能够更方便地进行数据存储。支持部分列更新：2.0 版本支持了部分列更新功能，无需对整个数据集进行更新，这种精确的更新方式大大降低了计算资源的消耗，提高了数据更新效率。支持<a href=\"https://www.selectdb.com/blog/158\">倒排索引</a>\"：2.0 版本支持倒排索引，可以满足字符串类型的全文检索和普通数值/日期等类型的等值、范围检索，更加符合日志数据分析的场景的查询需求。</p><p></p><p>基于此，我们引入了 Apache Doris 2.0 版本，实现了从架构 1.1 到架构 2.0 的升级。在架构 2.0 中，我们对整体架构进行了调整， 以区分日志服务、基础服务与其他服务，这也使得系统更加清晰和易于管理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d6/d69b365f20ac66b51eaf2202f473a6ce.png\" /></p><p></p><p>在新架构中，我们使用 Apache Doris 完全替代了 Elasticsearch ，由 Apache Doris 统一提供日志检索和实时报表服务。此外，我们还对报表导入方式进行了改进，早期的做法是通过 Insert Into 拼接 MySQL 的方式进行导入，而新架构中引入了 FileBeat 工具，使报表数据的导入和导出更加高效便捷。</p><p></p><p>具体数据导入流程为：当用户在浏览器中访问应用网址时，需要采集的信息会被记录在本地，当采集时间或数量达到设定阈值时，这些信息将通过接口上报给日志服务。日志服务的主要任务是对数据进行清洗和填充，以补充浏览器空缺数据，并生成一条 JSON 存到服务器的日志文件。当轮询脚本触发时，将对日志文件进行读取，数据通过 Stream Load 将数据同步到 Doris 中。</p><p></p><h3>01 简单易用，提升开发效率</h3><p></p><p>Apache Doris 学习成本低、轻松上手。Apache Doris 兼容 MySQL 协议，支持使用标准 SQL 语言进行数据查询和操作，使得开发人员可以方便地进行复杂的数据查询和聚合操作。相比之下，Elasticsearch 的 DSL 是一种基于 JSON 的查询语言，对于不熟悉 DSL 开发人员来说，完全掌握该语法需要一定的学习曲线，具有较高的学习和使用门槛。</p><p></p><p>我们通过以下示例代码来展示使用 GOM 实现 Doris 查询功能的代码实现。从代码示例可知，对于熟悉代码管理、代码规范、代码质量和后期维护等方面的人来说，这种写法非常方便。对于新加入的同事来说，进行代码审查也变得非常容易，相较于以前的 Elasticsearch ，使用 Apache Doris 可以节省大量的开发时间。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4c/4cf8e379bc687d182e144d994e8ac404.png\" /></p><p></p><h3>02 合理进行表设计，满足查询秒级响应</h3><p></p><p>在表设计中，我们主要使用了 Aggregate Key 聚合模型和 Duplicate Key 明细模型。 聚合模型用于统计浏览器相关指标，如用户 PV（页面访问量）和 UV（独立访客数）以及应用访问 PV 和 UV 等数据；明细模型主要用于存储日志数据，以便进行用户或设备的留存分析。</p><p></p><p>在实际的应用中，大部分报表选择聚合模型进行实时计算，SUM 和 BITMAP 为常用的聚合计算，其中，SUM 约有 100+ 个聚合维度，BITMAP 约有 20-30 个维度，因涉及维度较多，我们将它们分布在不同的表中。小部分报表采用明细模型，我们也在明细模型上建了 Rollup 来提高查询速度。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/72/7213791ecaa9e1e3b531f8cde49f02e6.png\" /></p><p></p><p>具体字段设置为：</p><p></p><p>UV 采用 BITMAP 聚合模型，聚合函数 BITMAP_UNIONPV 采用 BIGINT 类型，聚合函数 SUM留存：BITMAP_INTERSECT众数：TOPN</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/82/822542eb3c590d6574a96ada24609e5c.png\" /></p><p></p><h4>SUM 性能评估</h4><p></p><p>如上所述，我们在表创建过程中广泛使用了 Bitmap 和 SUM 函数。为了评估 SUM 函数的性能，我们对一张约有 54 亿行数据的表进行测试，并在创建 Rollup 后进行查询，**结果显示查询耗时为 0.32 秒，**这表明 SUM 函数在处理大规模数据里表现出良好的性能，满足我们对查询时延的要求。</p><p></p><p><code lang=\"sql\">select count(*) from testorg; # 5400179000 \n\nselect org_id,sum(app_pv_count) from org_stats where os_type=\"windows\" and day_time &gt; \"2023-07-01\"  and org_id &gt;0  group by org_id;  # 0.32s \n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2d/2d5f4734bcf83a1a4d3413597d51cae3.png\" /></p><p></p><h4>Bitmap 性能评估</h4><p></p><p>对于 Bitmap 而言，Bitmap 的长度相对于数据行数更为重要。随着 Bitmap 数据量的增大，Bitmap Union Count 的执行速度可能变慢。</p><p></p><p>为验证其性能，我们对一张包含 9 万行数据的表进行 IP 测试，IP 数量始终保持在 75 万以上，即每个 Bitmap 的长度大于等于 75 万。在这个 9 万*75 万的数据集上，我们进行 Bitmap Union Count 计算，将 IP 转换为整数类型，查询时间约为 0.5 秒，总体而言查询性能较好，符合性能要求。</p><p></p><p><code lang=\"sql\">select count(*) from testlog; # 90000 \n\nselect app_id,day_time,bitmap_union_count(ip_pv_count) from test group by app_id,day_time  ;  #0.5s\n</code></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/d4/d4b1157a85fc4795d463bc403c1050e6.png\" /></p><p></p><h3>03 相较 Elasticseach，存储成本降低 60%</h3><p></p><p>在引入 Apache Doris 之后，我们对 Doris 和 Elasticseach 的存储空间占用进行了对比。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10d1572bd6b8543fd6485e6ee872803b.png\" /></p><p></p><p>我们以一天数据量为例进行测试，大约 606 GB 的 JSON 日志数据。当我们将这些数据存储到 Doris 中时，其所占用存储空间仅为 170 GB，压缩比达到 1:3.6。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3a/3a0de9ce7c363132549c6e91d7d21971.png\" /></p><p></p><p>与此相比，相同规模的数据存储到 Elasticsearch 中则需要 391 GB 的存储空间，远超过 Apache Doris 所需的空间，升级后存储成本降低 60%。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c9/c9cdd21c84c1149207d50c4255e05ec8.png\" /></p><p></p><h2>收益总结</h2><p></p><p>我们将系统架构从 Elasticsearch 升级为 Apache Doris 之后，具体取得的收益如下：</p><p></p><p>将日志检索和报表分析统一到一个系统中，Doris 2.0 版本在增加倒排索引后，能同时满足这两个场景，从而缩短了数据处理的链路和复杂度，显著提高了数据处理的效率。聚合分析性能得到数量级的提升，之前在 Elasticseach 中需要近 10 秒才能完成聚合查询，而在 Doris 中不到 1 秒就能完成，聚合分析效率至少提升 100%。Doris 提供了高效的数据压缩效率，相较于 Elasticseach，同一份数据的存储资源成本降低了 60%。Doris SQL 相比 Elasticseach DSL 更加简单易用，能够大幅提升开发效率和问题排查的效率。</p><p></p><p>不仅如此，Apache Doris 的引入帮助我们实现了运营可视化管理，提供了浏览器多种指标的实时监控，以指导业务部门下一步动作：</p><p></p><p>在安全方面，当崩溃次数达到设定阈值时，系统会通过邮件通知相关人员，以便排查浏览器崩溃的原因。还可对登录次数进行统计，有效监测是否存在外部人员试图攻击接口。在绩效统计方面，可对应用访问数据进行统计，以帮助我们评估工作情况，从而更好地安排工作。优化流量损耗和磁盘占用：通过对页面中 JS、CSS、Image 等资源的统计，可有效地发现访问流量和资源大小并进行优化，以减少流量损耗和磁盘空间使用，从而实现降本提效。提供业务系统健康报告：可准确监测应用 Web 页面所引用的资源、资源加载时长以及异常情况等关键信息，并根据这些信息生成应用健康报告，基于报告能够帮助企业完成业务系统的优化。</p><p></p><h2>未来规划</h2><p></p><p>未来，我们着重关注并探索以下方向，以更好地满足客户的需求。</p><p></p><p>冷热数据分离：冷热数据分离能够在降低成本的同时提高效率，未来我们计划将客户的冷数据存储到 S3 等存储介质，将热数据存储在相应的数据磁盘，以提高存储空间的利用率。<a href=\"https://www.selectdb.com/blog/102\">Doris Manager</a>\" 部署集成：未来我们计划集成 Doris Manager ，以便客户能够直观便捷地排查和发现问题，监控集群的使用情况。</p>",
    "publish_time": "2024-02-23 18:06:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]