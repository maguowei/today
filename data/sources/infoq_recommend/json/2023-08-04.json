[
  {
    "title": "SoFlu 自定义函数开发实践：单函数、多函数",
    "url": "https://www.infoq.cn/article/E77tQaav5o3T0m5KXDi2",
    "summary": "<p>在现代企业开发中，初级开发者难以掌握开发企业级 Java 应用，中高级开发者则被繁琐任务所占据。为了让大家能快速上手可以解决这个难题的“SoFlu 软件机器人”，前蚂蚁金服技术专家杨彪设计了《2 小时学会 10 个组件“取代”传统 Java 开发》课程，本节为该系列课程的第五讲。</p>\n<p>在实际项目开发中经常需要对接第三方的平台，比如对接微信和支付宝，SoFlu 能实现吗？答案是肯定的！本节便将介绍 SoFlu 中如何开发自定义函数，展示函数的灵活高可扩展性能力，并使用自定义函数的方式来实现第三方平台 API 的集成功能。</p>\n<p>大家在课后可以登录 Gitee 下载 SoFlu 软件机器人客户端进行实践：<a href=\"http://suo.im/8wROo\">点击下载</a></p>\n<p>大家可以扫码添加小助手，进学习群与专家一对一交流：<br />\n<img alt=\"\" src=\"https://static001.infoq.cn/resource/image/e8/c9/e8833a01ba0bc705acab14a572b57cc9.png\" /></p>",
    "publish_time": "2023-08-04 09:00:00",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "一大批AIGC应用在App Store国区下架",
    "url": "https://www.infoq.cn/article/gEg6LzWKUUNY5Dhu4vVr",
    "summary": "<p>近日，热门科技博主 @foxshuo 在推特上表示，“一大波AI应用被国区App Store下架，应该是苹果应合规要求做了批量操作。”foxshuo 发布的<a href=\"https://twitter.com/foxshuo/status/1686189604158988288\">截图</a>\"显示，目前已经有 100 多个人工智能应用程序从国区App Store下架。经过证实，其中一些应用程序确实无法在中国应用商店中找到。</p><p><img src=\"https://static001.geekbang.org/infoq/9c/9c00dca9683dbfb5cb2d5db1f6ea16a0.png\" /></p><p></p><p>据悉，此举是在中国开发者收到苹果公司通知他们的应用程序被删除之后做出的。苹果在给ChatGPT 原生客户端<a href=\"https://apps.apple.com/app/opencat/id6445999201\">OpenCat的</a>\"<a href=\"https://twitter.com/waylybaye\">信</a>\"中表示，下架该应用的理由是“内容在中国非法”。</p><p>&nbsp;</p><p>7 月中旬，七部门发布了<a href=\"https://www.infoq.cn/article/l9d6WALH3ufAvBIDCKJr\">《生成式人工智能服务管理暂行办法》</a>\"，要求在中国运营的人工智能应用程序必须获得行政许可，这在苹果的下架通知中得到了体现。</p><p>&nbsp;</p><p>“如您所知，政府一直在加强与深度合成技术（DST）和生成人工智能服务（包括 ChatGPT）相关的法规。苹果公司向 OpenCat 表示，DST 必须满足在中国运营的许可要求，包括获得工业和信息化部 (MIIT) 的许可。“根据我们的审查，您的应用程序与 ChatGPT 相关联，而 ChatGPT 没有在中国运营所需的许可证。”</p><p>&nbsp;</p><p></p><p>参考链接：</p><p>https://techcrunch.com/2023/08/01/generative-ai-services-pulled-from-apple-app-store-in-china-ahead-of-new-regulations/</p>",
    "publish_time": "2023-08-04 10:17:27",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "软件交付优化：数据洞察下的智慧决策",
    "url": "https://www.infoq.cn/article/QIRCUl6MJWzZ88myFydo",
    "summary": "<p>“<a href=\"https://www.infoq.com/articles/data-driven-decision-making-article-series/\">数据驱动的决策制定</a>\"”系列文章概述了数据驱动的决策制定是如何为软件交付中的三个主要活动——产品管理、开发和运营提供支持的。</p><p>&nbsp;</p><p></p><h1>背景介绍</h1><p></p><p>&nbsp;</p><p>在软件行业中，优化软件交付组织并不是一个简单的标准化过程。因为可度量的指标太多，将产生大量的度量数据。要让组织分析这些数据并基于其采取行动是一项困难的任务，而这却是整个优化过程最重要的一步。如果组织中的人不基于度量数据采取行动，那么基于数据驱动的组织优化也就不会发生。</p><p>&nbsp;</p><p>为了进一步推动这一领域的发展，2020年以来的“<a href=\"https://www.infoq.com/articles/data-driven-decision-making-article-series/\">数据驱动的决策制定</a>\"”系列文章提供了一个框架，指明如何通过数据驱动决策制定来支持软件交付中的三个主要活动——产品管理、开发和运营。从那时起，有很多团队在使用这个框架来实现组织优化方面获得了数年的经验。在本文中，我们将介绍一个优化软件交付组织的社会技术框架是如何被建立起来以及如何进行常规应用的。</p><p>&nbsp;</p><p></p><h1>选择度量维度</h1><p></p><p>&nbsp;</p><p>在软件交付组织中，有太多可度量的东西，可以是容易计数的纯数学度量，例如一段时间内的缺陷数量，也可以是难以量化的社会技术过程度量，例如中断持续时间（发生中断的开始和停止时间）。</p><p>&nbsp;</p><p>无论度量的是什么，只有当人们基于它们采取行动时，它们才是有效的。如果不定期采取措施来分析度量数据，并根据分析结果在组织中做出改变，那么度量过程就成了可避免的浪费。</p><p>&nbsp;</p><p>在一个给定的组织中，人们可能很难就优化软件交付的度量维度达成一致。一个可能的指导原则是只度量组织可能愿意基于其采取行动的东西。可采取的行动包括确定优先级、过程变更、组织变更、工具变更和资本投入。</p><p>&nbsp;</p><p>近年来，一些度量方法变得流行起来。例如，使用<a href=\"https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture\">DORA</a>\"指标来度量软件交付过程的稳定性和速度，因为它是以对软件交付性能驱动因素的多年科学研究为基础，因此很受欢迎。</p><p>&nbsp;</p><p>另一个例子是度量可靠性。在这方面，越来越多运行大规模服务的组织在采用<a href=\"https://www.infoq.com/articles/data-driven-decision-product-operations\">SRE</a>\"，它基于SLI、SLO和相应的错误预算消耗跟踪来度量可靠性。</p><p>&nbsp;</p><p>在度量价值方面，软件行业中已经出现了一些可为团队提供行动见解的指标。这与收益价值流里的价值指标不同。一些组织为此使用了<a href=\"https://barryoreilly.com/explore/blog/how-to-implement-hypothesis-driven-development/\">假设驱动开发</a>\"或<a href=\"https://amplitude.com/north-star\">North Star</a>\"（北极星）框架。到目前为止，还没有出现能够在这一领域占据主导地位的框架。</p><p>&nbsp;</p><p>正如2020年的文章“<a href=\"https://www.infoq.com/articles/data-driven-decision-optimize-delivery/\">数据驱动的决策制定——优化产品交付组织</a>\"”所描述的，我们决定对价值、速度、稳定性和可靠性进行度量。到了2022年，我们增加了另一个衡量维度：云成本。为什么我们决定测量这些维度，而不是其他维度？答案如下表所示。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>到目前为止，我们没有打算度量其他维度，这有几个方面的原因。</p><p>&nbsp;</p><p>我们已经可以使用当前的五个度量维度来优化组织，并给客户和业务带来积极的影响：优化订阅价值，让订阅给客户带来更多价值。特性的优先级更多的是由价值进行驱动的。优化云成本让我们的业务案例变得更加强大。团队在设计软件架构时将云成本考虑在内。优化部署速度有助于快速找到适合市场的特性。团队可以适当地进行特性分解、设计松散耦合的架构、进行测试自动化、部署自动化等。优化部署稳定性有助于在频繁更新的同时提供良好的用户体验。团队努力实现零停机部署、API向后兼容性等。优化可靠性有助于在整个订阅期间始终保持良好的用户体验。团队努力实现有效的监控和事故处理。我们已经看到，优化当前的这些度量维度隐式地推动了组织其他方面的改进，例如：团队努力实现松散耦合、测试自动化和部署自动化。更重要的是，他们不断寻找方法来优化这些领域的部署管道，这在软件交付组织中有组织提供了一系列用于自动化创建合规性文档的工具，提升持续合规性遵循能力。这些工具会在每次部署管道运行时自动运行。助于形成一种非常健康的工程文化。团队定期更新第三方框架和库依赖项。除了需要更频繁地进行安全渗透测试，我们还没有看到这些度量对安全和数据隐私实践造成什么影响。</p><p>&nbsp;</p><p>总而言之，虽然我们也可以引入其他度量维度，但当前的这些度量维度似乎足以用来驱动一个合理的整体持续改进。</p><p>&nbsp;</p><p></p><h1>建立度量系统</h1><p></p><p>&nbsp;</p><p>我们建立的度量系统涉及数据驱动决策的三个主要层次：团队、中层管理和高层管理。</p><p>&nbsp;</p><p>对于上述的每一个度量维度，我们设置了三个指标粒度：团队级指标、产品级指标和产品线级指标，如下图所示。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/73/73daca32bccf828d29f9a8e48bd889f3.png\" /></p><p></p><p>&nbsp;</p><p>每一个度量维度生成的数据可以被视为一种三轴立方体。</p><p>&nbsp;</p><p>X轴：指标粒度团队级指标；产品级指标；产品线级指标。Y轴：度量维度价值；云成本；稳定性；速度；可靠性。Z轴：组织级别团队；中层管理（产品经理、开发经理、运营经理）；高层管理（“主管”角色）。</p><p>&nbsp;</p><p>这使得整个产品交付组织能够按照适合手头需要解决的问题的粒度来处理数据。数据集的示意图如下所示。</p><p>&nbsp;</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/27/27e0fc6ee3ca244e1eb2e051d4ef6ac3.png\" /></p><p></p><p>&nbsp;</p><p>例如，分析交付速度的产品经理（上图中的蓝色立方体）可以基于产品级指标来查看所有相关产品的交付速度数据。他们也可以更进一步，基于产品线级指标来查看总体的速度数据。如果产品经理有技术背景，他们还可以基于团队级指标来更详细地查看速度数据。分析的结果可能会导致技术特性的优先发生变化，从而加快产品的交付，而更快的交付速度意味着可以找到更适合产品市场的产品。</p><p>&nbsp;</p><p>同样，分析可靠性的团队架构师（上图中的红色立方体）可以基于团队级可靠性指标来查看其团队所拥有的所有服务的可靠性。然后，他们也可以查看他们所依赖的其他团队的服务的可靠性（也是基于团队级可靠性指标）。在考虑使用新产品时，他们可以先查看过去汇总的产品级可靠性数据（产品级可靠性指标）。如果产品级可靠性是合理的，他们就可以深入了解组成产品的单个服务的可靠性（团队级可靠性指标）。根据分析结果，可能需要与产品所有者进行数据驱动的对话，调整可靠性特性和面向客户的特性之间的优先级。</p><p>&nbsp;</p><p>同样，由产品主管、开发主管和运营主管组成的领导团队可能会分析云成本数据。他们可以从查看产品线的成本数据开始，分析成本趋势，并将它们与相应的价值趋势联系起来。对于成本趋势与价值趋势反向相关的产品线，领导团队可以深入了解产品级成本和价值数据。根据分析结果，可能需要与各自的产品经理就新产品的预计盈亏平衡点和成熟产品的收入趋势进行对话。</p><p>&nbsp;</p><p></p><h1>建立行动过程</h1><p></p><p>&nbsp;</p><p>要基于上述跨组织孤岛和级别的度量数据采取行动，需要建立专门的过程。对于团队、中层管理人员（产品经理、开发经理、运营经理）和高层管理人员（“负责人”角色）来说，这个过程是不一样的。我们发现下面的这些方法在我们的组织中很有用。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>关于团队级数据分析周期的说明：尽管许多团队选择每3个月查看一次指标数据，但有些团队更频繁地查看某些指标。具体来说，有时每天都要查看云成本数据，特别是当团队在通过优化架构或设计来降低云成本时。此外，当团队在大型重构后进行稳定性工作时，有时候每周都会查看构建和部署稳定性数据。</p><p>&nbsp;</p><p></p><h1>优化组织</h1><p></p><p>&nbsp;</p><p>在本小节中，我们将提供一个示例来说明我们如何利用在不同组织级别发生的数据驱动决策来优化组织的交付速度。</p><p>&nbsp;</p><p>交付速度是一个非常重要的度量维度，因为每个人都希望能够更快地交付特性。在开始时，我们所有的团队都非常渴望加快交付速度。在某个时刻，我们引入了速度指标并趋于成熟，这在整个组织层面形成了如下所述的数据驱动工作流：</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h1>总结</h1><p></p><p>&nbsp;</p><p>从整体上优化软件交付组织是一项复杂的工作，可以通过三种粒度的度量指标——团队级、产品级和产品线级指标来为其提供很好的支持。这为团队、组织的中层管理人员和高层管理人员提供了数据驱动的决策制定。建立专门的流程来分析数据，并在这三个层面采取行动，有助于组织进行整体的持续改进。</p><p>&nbsp;</p><p>作者简介：</p><p>Vladyslav Ukis博士毕业于德国埃尔兰根-纽伦堡大学（计算机科学专业）和英国曼彻斯特大学。毕业后，他加入Siemens Healthineers，从事软件架构、企业架构、创新管理、私有云和公有云计算、团队管理、工程管理、投资组合管理、合作伙伴管理和数字化转型等方面的工作。他目前担任Siemens Healthineers团队数字健康平台的研发主管。他在2022年出版的“Establishing SRE Foundations”（Addison Wesley出版社）一书中分享了他的DevOps知识：<a href=\"https://www.informit.com/store/establishing-sre-foundations-a-step-by-step-guide-to-9780137424658\">https://www.informit.com/store/establishing-sre-foundations-a-step-by-step-guide-to-9780137424658</a>\"</p><p>&nbsp;</p><p>原文链接：</p><p><a href=\"https://www.infoq.com/articles/software-delivery-performance-indicators/\">https://www.infoq.com/articles/software-delivery-performance-indicators/</a>\"</p><p></p><p>相关阅读：</p><p><a href=\"https://www.infoq.cn/article/k0Lr2oVo3EdPqVR6CLo0\">范珂：数字化时代下，数据驱动决策组织文化的打造</a>\"</p><p><a href=\"https://www.infoq.cn/article/Y5qzSjI0YRxhp31Sf5JE\">首席数据官：数据驱动时代的大势所趋</a>\"</p><p></p>",
    "publish_time": "2023-08-04 10:24:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "腾讯音乐娱乐集团数据智能高级总监李深远，确认担任QCon北京数据科学为产品赋能（PCon）专题出品人",
    "url": "https://www.infoq.cn/article/ike5erbcKBghJR752IM9",
    "summary": "<p>9 月 3 日 - 5 日，在 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=0804&amp;utm_content=lishenyuan\">QCon 全球软件开发大会（北京站）</a>\"，腾讯音乐娱乐集团数据智能高级总监李深远将担任「数据科学为产品赋能（PCon）」的专题出品人。在此次专题中，你将了解到如何用数据科学来洞察市场与客户。</p><p></p><p>李深远，腾讯音乐娱乐集团数据智能高级总监，数据科学专家。负责 TME 集团数据中台及 QQ 音乐业务线数据科学研发。</p><p></p><p>相信李深远的到来，可以帮助提升此专题的质量，让你学习到利用数据科学来洞察市场与客户，可以帮助产品团队在产品设计时做出更好的决策，或是在优化产品时发现和解决其中的问题，并提供解决方案，为产品有关方面的工作提供了新的视角。</p><p></p><p>除上述专题外，QCon 北京还将围绕<a href=\"https://qcon.infoq.cn/202309/beijing/track/1553?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">异构计算</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1554?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">向量数据库</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1556?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">FinOps&nbsp;落地</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1558?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">业务安全技术</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1557?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;BI&nbsp;到&nbsp;BI+AI，新计算范式下的大数据平台</a>\"、<a href=\"https://qcon.infoq.cn/202309/beijing/track/1559?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9\">从&nbsp;MLOps&nbsp;到&nbsp;LLMOps</a>\" 等进行分享。</p><p></p><p>近 100 名讲师、近 30 个精彩专题、8 种交流活动，QCon 北京 2023，相约 9 月！现在购票，享 9 折特惠，立省 ¥880！咨询购票请联系 18514549229（微信同手机号）。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/33/33cbbbf20baa8b2a18db4f0681f159aa.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-04 14:14:54",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "易点天下发布AIGC数字营销创作平台，AIGC如何助推内容生产力革新？",
    "url": "https://www.infoq.cn/article/hssxLXJmigGzRrPha2j2",
    "summary": "<p>近日，易点天下发布了首个AIGC数字营销创作平台KreadoAI面向全球创作者正式发布。以“AI数字人、AI模特、AI工具、AI创意资产”4大解决方案为依托，KreadoAI将为营销领域全链路的降本提质增效，注入新的活力与动能。</p><p>&nbsp;</p><p>2010年前后，移动互联网和云计算的兴起带来了营销数据的爆炸式增长，易点天下成立，并推出了Yeahmobi等平台产品，并不断发展成长，逐步打造出完整的营销产品体系，提供数据挖掘、分析可视化报告、ROI实时监测在内的丰富功能。</p><p>&nbsp;</p><p>随着大模型时代的到来，易点天下在国内首批接入AI大模型，推动多场景应用不断落地，实现以AI技术赋能企业管理，实现降本增效。如利用文生图加速设计环节的增效，或提供营销文案生成工具以提供16倍的创新效率提升。</p><p>&nbsp;</p><p>据易点天下介绍，目前，KreadoAI平台的核心产品服务包括四大模块：AI数字人、AI模特、AI工具、AI创意资产。其中，AI数字人解决方案，共有AI数字人口播视频、1:1真人数字人分身克隆、语音声纹克隆三大功能，已应用在商旅推荐、电商购物、应用下载、教育培训、企业服务等领域，为创作者们提供了极大便利。</p><p>&nbsp;</p><p>而AI模特解决方案，则已支持为包括假发、服装、眼镜等细分行业的电商客户，生成不同地域国家、肤色、年龄、表情等媲美棚拍精度的AI产品展示图，被产品测试阶段的重度用户们称为“出海电商福音”。</p><p>&nbsp;</p><p>除此之外，AI工具解决方案所提供的AI生成营销文案、AI文本配音、AI智能抠图功能，也成为了极受出海卖家们欢迎的“效率助手”。</p><p>&nbsp;</p><p>AI创意资产服务模块，包括AIGC生成、模板素材、创意资料管理等功能。基于Google、Facebook、TikTok、抖音等海外及国内主流媒体，以创意素材为维度，KreadoAI的AI创意资产解决方案则可以针对营销投放前、中、后的创意趋势洞察、素材营销效果数据分析和爆款内容分析进行数字化营销管理。</p><p>&nbsp;</p><p>亚马逊云科技如何在AIGC领域赋能易点天下</p><p>&nbsp;</p><p>据易点天下介绍，该款KreadoAI平台的发布，背后离不开亚马逊云科技在技术上的支持。</p><p>&nbsp;</p><p>易点天下早在2014年就开始采用亚马逊云科技遍布全球的云基础设施为智能营销业务提供支持，并在每个季度获得亚马逊云科技提供的新技术培训，获取应用构建过程中问题的指导，消除 AIGC 应用构建过程中的障碍。此外随着其和亚马逊云科技合作深入，易点天下加入亚马逊云科技合作伙伴网络，获得了更多的技术和市场资源，让 KreadoAI 在构建与商业化上得到了更多的专业支持。</p><p>&nbsp;</p><p>在构建&nbsp;KreadoAI 模特解决方案的过程中，易点天下选择了使用 Amazon Elastic Compute Cloud（Amazon EC2）和 Amazon Elastic Kubernetes Service（EKS）进行站点的托管与预处理服务，在后端由 Amazon SageMaker 运行模型的训练任务与异步推理，并将相关素材与结果统一存储在 Amazon Simple Storage Service（Amazon S3）中，用户可以通过 Amazon Route 53、Amazon CloudFront 获得低延迟的访问体验。</p><p>&nbsp;</p><p>在&nbsp;KreadoAI 数字人视频融合解决方案中，易点天下采用了配备有 Auto Scaling 组的 Amazon EC2 G4dn 实例提供 GPU 运算支持，并针对多语言覆盖在服务中集成了具备快速合成能力、自然语音与可调整风格的 Amazon Polly 服务为跨境电商客户的多语种用户提供自定义 AI 数字虚拟人的生成能力。</p><p>&nbsp;</p><p>易点天下技术中心总经理秦鹏在接受媒体采访时表示，“我们大多数的电商客户以前在通过海外模特进行棚拍，单张照片的成本就需要百元左右，现在采用亚马逊云科技驱动的生成式人工智能自动输出，使电商素材生产的成本降低50%。来自某客户的数据显示 CTR 点击率提升35%，单次点击成本降低45%，客户能够直观地感受到 AI 应用所带来的收益。”</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>",
    "publish_time": "2023-08-04 14:54:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "性能提升5倍！翼支付基于多租户的降本增效实践",
    "url": "https://www.infoq.cn/article/DvIHvNPRMxPpFuAU418i",
    "summary": "<p></p><blockquote>作者：王硕&nbsp;中国电信翼支付 DBA</blockquote><p></p><p></p><p>翼支付是天翼电子商务有限公司旗下第三方服务平台，面向 7000 万月活用户，提供民生缴费、消费购物、金融理财等服务内容，依托云计算、大数据、人工智能等技术，联合合作伙伴，赋能超 1000 万家线下商户门店及 170 余家线上知名电商。</p><p></p><p>作为拥有千万月活用户的服务平台，翼支付与生活息息相关，其业务不仅种类繁多且复杂，与此同时需要对相关数据进行存储和处理，当前的数据库方案出现存储空间吃紧、分析实时性差、成本难以掌控、运维难度增大等问题，亟需选型和替换架构以保证业务长期的稳定运行。</p><p></p><p>在此大背景下，翼支付深入调研分析了市面已有的分布式数据库方案，最终将 OceanBase 作为首选方案。</p><p></p><p>该方案在真实场景测试和验证后，性能方面较旧方案提升 5 倍，硬件成本下降 57%，存储空间节省 10%，机器成本与运维成本极大降低。于是决定将消息中心、账单中心等业务由某国产数据库替换成 OceanBase ，同时将已有的 MySQL 业务逐渐迁移至新方案。</p><p></p><h2>挑战：实际使用面临多个难题</h2><p></p><p></p><p>在早期的数据库方案中，某国产数据库主要应用于账单中心、征信及反洗钱等业务场景并发挥了重要作用。随着月活用户量的不断增加，相关联的业务也在不断增长，在实际使用中遇到以下 3 个主要问题。</p><p></p><p>一、租户不隔离</p><p></p><p>由于我们在某国产数据库集群中放置了很多库，因此多个库之间共享集群资源，在某些库对应的业务流量高峰期时，业务之间互相影响，严重影响使用体验。</p><p></p><p>二、硬件成本高</p><p></p><p>在运维过程中，为了保障业务的稳定性，避免不同业务之间互相影响，通常对业务进行物理隔离，即不同的业务使用不同的数据库环境，因此多套业务对应多套数据库环境。也就是说，为了保证业务的稳定性，一个业务一套集群且集群的每个角色都配备一台机器，以账单中心和消息中心为例，原有的方案需要分别部署数据库环境且一套数据库环境即需要消耗7台机器，共需要 14 台机器。虽然业务之间做到了隔离，但是成本昂贵，性价比不高。</p><p></p><p>三、稳定性不够好</p><p></p><p>以消息中心业务为例，测试中发现某些在某国产数据库中查询较慢且出现秒级别尖刺，业务不定期出现抖动现象。</p><p></p><p>考虑到公司业务大多已采用两地三中心部署方案，业务层面也应用了双活架构，对比市面上的分布式数据库，OceanBase 正好提供两地三中心部署，并且每个中心都可以提供业务访问，完美契合了当前公司的业务架构。</p><p></p><h2>选型：敲定OceanBase</h2><p></p><p></p><p>此外，作为国内典型的分布式方案，OceanBase 具有原生分布式架构，支持金融级高可用、透明水平扩展、分布式事务、多租户和语法兼容等企业级特性。此外，从性能、成本、稳定性等方面来看都能满足公司需求。</p><p></p><p>性能上：每个节点都具备计算和存储能力，当业务计算要求增加或者数据量快速增长时，通过增加节点来扩展计算和存储能力，同时一体化架构使得分布式集群组件之间和组件内部 RPC（Remote procedure call）消耗更少，业务访问尽可能本地完成，减少不必要的 RPC 交互，性能更好。在实际测试中，我们发现通过增加硬件资源，集群的性能线性增长，符合预期。</p><p></p><p>成本上：在业务使用中，使用租户隔离特性非常便捷地将多个业务放在一套或极少数量的环境进行运维，加上官方配套的运维管控平台 OCP 、数据迁移工具 OMS &nbsp;等等生态工具，使得运维复杂度极大地降低。在实际测试中，我们发现在硬件层面，相比其他数据库方案，OceanBase &nbsp;资源消耗更少。综合评估下来，使用 OceanBase &nbsp;成本更低。</p><p></p><p>稳定性上：业务表对应的数据在底层以多个数据分片形式存在，在分布式架构下，单表的数据可以均衡分布在不同的节点，不需要复杂的分库分表方案；同时在底层数据存储时，数据存储多份（默认三副本）同时引入多数派 paxos 选举协议，在集群少数节点或者副本故障、异常时，确保上层业务不会受到影响，同时业务数据不丢失。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/6e/6efa25d43dfb07e676ffa5cbf1ca5785.png\" /></p><p>图1 OceanBase&nbsp; 典型三副本架构</p><p></p><p>这三个特性是当前业务最需要、最看重的能力，因此，OceanBase 数据库成为了解决我们业务问题的首选方案。</p><p></p><h2>业务双写验证测试结果超预期</h2><p></p><p></p><p>在确定选型方案后，我们对 OceanBase &nbsp;3.1.4 版本与某国产数据库进行各方面的对比。在实际环境中，对业务进行了简单改造，采用业务双写的方式验证对比某国产数据库与 OceanBase 方案。测试结果超出我们的预期：</p><p></p><p>第一，硬件成本下降 57%，同时资源消耗显著降低。OceanBase 的多租户特性具备资源隔离的能力，因此我们将账单中心和消息中心业务迁移至 OceanBase 环境，并使用多租户能力分别创建业务租户，机器资源从原来的 14 台机器变为 6 台，硬件成本降低 57%，同时多套业务集中在一套环境运维，日常管理更加方便。</p><p></p><p>在 CPU &nbsp;使用率方面，账单中心和消息中心在某国产数据库环境中，CPU 平均使用率 20%-25%，在 OceanBase 环境中， CPU 使用率为 5% 左右；在存储空间上，某国产数据库需要占用 19TB &nbsp;的空间，OceanBase 的存储空间占用为 17TB ，节省空间约 10%。同等业务量下，OceanBase &nbsp;方案资源消耗更少。</p><p></p><p>第二，性能提升 5 倍，单表分析能力提升 10%-20%。在消息中心业务中，某国产数据库消息状态更新接口耗时平均在 10ms ，同等条件下 OceanBase 使用分区键的响应 latency 持续稳定在 2ms ，响应时间更短且稳定。另外，线上的账单业务有一个 200 亿大表，在hash 分区策略下，OceanBase 单表分析能力较某国产数据库提升了 10%-20%，</p><p></p><p>第三，极大减少运维成本。在数据库集群管理方面，借助 OceanBase 提供的 OCP 白屏管理工具，OceanBase 集群能够实现统一管理，我们的 DBA 可以直接登录 OCP 平台对所有集群进行日常操作与维护，管理界面如图 2 所示，减少了大量的管理成本。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c6/c6c300a8f4f2911375632bcab22fef96.png\" /></p><p>图2 OCP集群管理界面</p><p></p><p>除日常运维管理能力外，OCP 也提供了对集群的监控和告警服务，如图 3 所示，我们可以直接从 OCP 页面看到各个集群的运行状态，在出现异常的时候发出报警。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8d/8dee65b3b8d6f03d79810413cd64c169.png\" /></p><p>图3 OCP监控界面</p><p></p><p>当前我们的业务环境中OceanBase 已经支持了消息中心、账单中心等业务服务。结算中心、反洗钱业务后续会全部迁移至OceanBase 。</p><p></p><h2>经验总结</h2><p></p><p></p><p>对于此次的数据库技术方案选型以及实际使用效果反馈，总体来说让我们有些出乎意料。我们将此次选型成功的重要因素和经验总结为以下 3 点，供大家参考。</p><p></p><p>第一、业务平滑迁移</p><p></p><p>通常在数据库迁移过程中，我们最关心的问题就是如何保证\"服务不停、数据不丢\"的同时最大化降低数据迁移的时间和成本。我们使用 OMS 平滑、准确、高效地解决了 MySQL 环境迁移数据的问题，降低了业务迁移成本，同时兼容性方面做到应用不需要修改即可完成迁移。比如，在某国产数据库迁移中，我们选择使用某国产数据库的 Binlog &nbsp;工具来完成某国产数据库到 OceanBase 的数据平滑迁移。</p><p></p><p>第二、统一平台管理，提升运维效率</p><p></p><p>OceanBase 环境使用一套 OCP 环境管理，不需要单独对每一套环境进行运维和管理，帮助运维人员便捷地进行环境管理和运维工作，同时其自带的监控和告警系统大大提高了问题发现的实效性，使问题能够更加高效、快捷的被解决。</p><p></p><p>第三、多租户能力及资源隔离优势明显</p><p></p><p>在实际使用中如商城业务会分很多库，为了避免这些库之间资源发生争抢从而导致其他库无法正常运行，将库按租户进行分离，利用租户的资源隔离能力，限制每个库的使用资源额度。并且，租户资源可以灵活调整，所以，每个库的资源也可以动态调整，从而保证业务的稳定性和灵活性。</p><p></p><p>以上就是翼支付的数据库技术方案选型过程及感受，希望能对正在考虑数据库选型的朋友一些提供参考价值。</p>",
    "publish_time": "2023-08-04 15:03:14",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "马斯克拿下极品域名AI.com：曾被OpenAI斥资千万美元买下，不到一年就易主了？",
    "url": "https://www.infoq.cn/article/OOFTxLA9wy38QyJ9rl6X",
    "summary": "<p>据外媒报道，极品域名AI.com已被马斯克买下，目前访问AI.com，将直接跳转到马斯克名下xAI公司的官网。并且跳转后，网页域名会自动变成x.ai。</p><p>&nbsp;</p><p><a href=\"https://www.infoq.cn/article/BjJt1kkDd6e0EczzbRpJ\">xAI</a>\"是马斯克在今年刚刚宣布成立的人工智能公司。当地时间 7 月 13 日，马斯克在推特上正式宣布成立 xAI 公司“去了解现实”。马斯克称，该公司的目标是“理解宇宙的真实本质”，简单来说，就是“xAI 公司的理念是打造‘能够畅所欲言，不受社会理念限制‘的 AI 系统”。</p><p>&nbsp;</p><p>在官网有限的信息中，xAI 主要列出了自己的创始团队名单，并大概介绍了这些人之前的贡献：</p><p>&nbsp;</p><p></p><blockquote>我们的团队由特斯拉和 SpaceX 的 CEO 埃隆·马斯克领导。我们曾在 DeepMind、OpenAI、谷歌研究、微软研究、特斯拉以及多伦多大学工作过。我们共同贡献了该领域中最广泛使用的一些技术方法，特别是Adam 优化器、批量归一化、层归一化和对抗性样本的发现。我们还引入了创新技术和分析，如Transformer-XL、Autoformalization、Memorizing Transformer,、Batch Size Scaling和μTransfer。我们曾参与并领导了该领域的一些重大突破发展，包括AlphaStar、AlphaCode、Inception、Minerva、GPT-3.5和GPT-4。</blockquote><p></p><p>&nbsp;</p><p>有观点认为，马斯克购买AI.com域名是为了在AI领域进行影响，让自己的公司成为这一领域的中心，从而与OpenAI 、微软、谷歌等公司竞争。目前，财大气粗马斯克已成功集齐ai.com、x.ai、x.com三大顶级域名。</p><p>&nbsp;</p><p>值得一提的是，极品域名AI.com在跳转到xAI 官网以前，是跳转到ChatGPT的。今年2月，OpenAI曾以至少1100万美元（约合人民币7535万元）的高价，拿下了域名AI.com。如今不到一年，AI.com便易主。</p><p>&nbsp;</p><p>据新网查询，AI.com注册于1993年5月，距今已有30年的历史。在此之前，AI.com也曾多次易主。2021年，域名投资公司（Top Notch Domains, LLC）的总裁Elliot Silver发布推特表示：极品两字母域名AI.com已经确认交易。由于whois信息隐藏暂时并不知道买家是谁，但来自Saw.com 的Jeff Gabriel透露：“AI.com是卖给了NFT领域的某个人”。</p>",
    "publish_time": "2023-08-04 15:15:33",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "聊聊 Docker 和 Dockerfile",
    "url": "https://www.infoq.cn/article/62eff2487120b583999f5cc6a",
    "summary": "<p>对于开发人员来说，会Docker而不知道Dockerfile等于不会Docker，上一篇文章带大家学习了Docker的基本使用方法：《一文带你学会Docker》，今天了不起带大家学习一下Dockerfile，帮助你快速上手并创建高效的 Docker 镜像。</p><p></p><h3>一、了解Dockerfile</h3><p></p><p></p><p>Dockerfile 是一个文本文件，用于定义 Docker 镜像的构建过程。它以指令的形式描述了如何构建镜像，从基础镜像开始逐步添加配置、文件和依赖，最终形成我们所需要的镜像。为我们提供了一种简单且可重复的方式来定义镜像构建过程。</p><p></p><h3>二、Dockerfile 指令</h3><p></p><p></p><p>FROM 指令：&nbsp;FROM 指令是 Dockerfile 的第一条指令，用于指定基础镜像。选择合适的基础镜像非常重要，因为它将直接影响镜像的大小和性能。我们还可以利用多阶段构建来减小镜像大小。RUN 指令：&nbsp;RUN 指令用于在镜像构建过程中执行命令。通过 RUN，我们可以安装软件包、运行脚本以及配置环境。COPY 和 ADD 指令：&nbsp;这两个指令用于将本地文件复制到镜像中。区别在于 ADD 指令支持自动解压缩和远程 URL，但推荐使用 COPY 指令，因为它更明确和可预测。CMD 和 ENTRYPOINT 指令：&nbsp;这两个指令用于定义容器启动时要执行的命令。CMD 定义的命令可以被 docker run 命令行参数所覆盖，而 ENTRYPOINT 定义的命令会一直执行。</p><p></p><p>以下是一个简单的Dockerfile 示例：</p><p><code lang=\"null\"># 使用 openjdk 镜像作为基础镜像\nFROM openjdk:latest\n\n# 设置工作目录\nWORKDIR /app\n\n# 复制 Java 项目的 JAR 文件到镜像中\nCOPY target/myapp.jar /app/\n\n# 定义容器启动时执行的命令\nCMD [\"java\", \"-jar\", \"myapp.jar\"]</code></p><p></p><p>在上面的示例中，我们使用&nbsp;openjdk:latest&nbsp;作为基础镜像，并将 Java 项目的 JAR 文件复制到镜像中。然后，通过 CMD 指令定义了容器启动时执行的命令，即运行&nbsp;java -jar myapp.jar&nbsp;启动 Java 应用程序。</p><p></p><h3>三、多阶段构建</h3><p></p><p></p><p>多阶段构建是一种优化 Docker 镜像大小的技巧，特别适用于构建 Java 项目等编译型语言的应用。在多阶段构建中，我们可以在一个 Dockerfile 中定义多个 FROM 指令，每个指令表示一个构建阶段。最终镜像只保留最后一个 FROM 指令所定义的阶段，其他中间产物都不会包含在最终镜像中，从而减小镜像的体积。</p><p></p><p>Dockerfile 示例：</p><p><code lang=\"null\"># 第一阶段：构建 Java 项目\nFROM maven:latest AS builder\n\nWORKDIR /app\n\nCOPY pom.xml .\nRUN mvn dependency:go-offline\n\nCOPY src/ /app/src/\nRUN mvn package\n\n# 第二阶段：运行 Java 项目\nFROM openjdk:latest\n\nWORKDIR /app\n\nCOPY --from=builder /app/target/myapp.jar /app/\n\nCMD [\"java\", \"-jar\", \"myapp.jar\"]</code></p><p></p><p>在上面的示例中，我们使用了两个 FROM 指令：</p><p></p><blockquote>FROM maven:latest AS builder&nbsp;表示第一阶段构建 Java 项目，使用 Maven 镜像进行依赖安装和项目构建；FROM openjdk:latest&nbsp;表示第二阶段，使用 OpenJDK 镜像来运行 Java 项目。通过 COPY --from 指令，我们从第一阶段的镜像中复制构建好的 JAR 文件到第二阶段，从而减小了最终镜像的大小。</blockquote><p></p><p></p><h3>四、Dockerfile 高级用法</h3><p></p><p></p><p>使用 ARG 和 ENV：&nbsp;ARG 指令用于在构建过程中传递参数，而 ENV 指令用于设置环境变量。利用这些指令，我们可以更灵活地定制镜像的构建过程。使用 WORKDIR：&nbsp;WORKDIR 指令用于设置工作目录，即在容器内运行命令的默认目录。这样可以使 Dockerfile 更易读和维护。使用 VOLUME：&nbsp;VOLUME 指令用于在容器中创建挂载点，使得容器中的数据可以持久化保存在宿主机上。</p><p></p><p>Dockerfile 示例：</p><p><code lang=\"null\"># 第一阶段：构建 Java 项目\nFROM maven:latest AS builder\n\n# 使用 ARG 指令传递构建参数\nARG APP_VERSION=1.0.0\nARG BUILD_ENV=production\n\n# 设置工作目录\nWORKDIR /app\n\n# 复制 pom.xml 并安装项目依赖\nCOPY pom.xml .\nRUN mvn dependency:go-offline\n\n# 复制源代码并构建项目\nCOPY src/ /app/src/\nRUN mvn package -DskipTests\n\n# 第二阶段：运行 Java 项目\nFROM openjdk:latest\n\n# 使用 ENV 指令设置环境变量\nENV APP_PORT=8080\nENV BUILD_ENV=${BUILD_ENV}\n\n# 使用 VOLUME 指令创建挂载点\nVOLUME /app/logs\n\n# 设置工作目录\nWORKDIR /app\n\n# 复制构建好的 JAR 文件到镜像中\nCOPY --from=builder /app/target/myapp-${APP_VERSION}.jar /app/\n\n# 定义容器启动时执行的命令\nCMD [\"java\", \"-jar\", \"myapp-${APP_VERSION}.jar\", \"--port=${APP_PORT}\", \"--env=${BUILD_ENV}\"]</code></p><p></p><p>在上面的示例中，我们首先使用&nbsp;ARG&nbsp;指令来定义构建参数&nbsp;APP_VERSION&nbsp;和&nbsp;BUILD_ENV，并在&nbsp;FROM maven:latest AS builder&nbsp;阶段中使用&nbsp;ARG&nbsp;指令传递构建参数。</p><p></p><p>这样，在构建时可以通过&nbsp;--build-arg&nbsp;参数来传递具体的值，例如：</p><p><code lang=\"null\">cssCopy code\ndocker build --build-arg APP_VERSION=2.0.0 --build-arg BUILD_ENV=staging -t my-java-app .</code></p><p></p><p>这样可以构建不同版本和不同环境的镜像。</p><p>同时，我们使用&nbsp;VOLUME&nbsp;指令创建了挂载点&nbsp;/app/logs，使得容器中的日志文件可以持久化保存在宿主机上。</p><p></p><h3>五、小结</h3><p></p><p></p><p>Dockerfile 是构建 Docker 镜像的核心工具，它使得镜像构建过程变得简单、可重复和高效。通过本文的介绍，你已经了解了 Dockerfile 的基本语法和常用指令，以及一些最佳实践。随着你的实践和深入学习，相信你将能够创建出更加优秀的 Docker 镜像，并更好地应用 Docker 在软件开发和部署中。</p>",
    "publish_time": "2023-08-04 09:55:19",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "Spring Cloud实战案例 │ Apollo和Zuul的整合开发",
    "url": "https://www.infoq.cn/article/8ff076affb55b6e5a75feab6b",
    "summary": "<p>Apollo是携程研发的开源配置管理中心，能够集中管理应用于不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性。</p><p>本案例结合一个案例介绍Apollo和Zuul的整合开发。整个应用分为4个微服务项目，分别是Eureka服务器项目mweathereurekaserver、服务提供者项目apolloconfig、服务提供者项目apollouser、服务消费者(即zuul路由服务)项目zuulapollo。</p><p></p><h1>1、Apollo配置中心的准备和启动</h1><p></p><p></p><h2>1●Apollo配置中心的准备</h2><p></p><p>为了让大家更快地了解Apollo配置中心(或称为服务器)，Apollo研发者准备了一个Quick Start项目，通过该项目能够在几分钟内部署和启动Apollo配置中心。先从Quick Start的代码库(https://github.com/nobodyiam/apollo-build-scripts)中下载该项目的代码压缩包并进行解压缩。解压缩后的目录和文件如图1所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/25/257c456b4af59afae52998c897e6c2d3.png\" /></p><p>■&nbsp;图1 解压缩后apollo-builds-scripts-master文件夹内的文件和目录</p><p>使用Apollo时先要确保安装的Java版本在1.8以上，安装的MySQL版本在5.6.5以上。由于Quick Start需要用到Git Bash环境，需要安装Git Bash(或者直接使用IDE的Git Bash环境)。</p><p>Apollo服务端需要两个数据库：ApolloPortalDB和ApolloConfigDB。通过Navicat for MySQL或MySQL原生客户端，导入解压缩包里sql目录下的文件apolloportaldb.sql和文件apolloconfigdb.sql。</p><p>Apollo服务端需要知道如何连接到前面创建的两个数据库，所以需要修改文件demo.sh中数据库连接信息。将root的用户名和密码改为您自己的MySQL的root用户名和密码。</p><p></p><h2>2●Apollo配置中心的启动</h2><p></p><p>在目录apollo-builds-scripts-master下启动Git Bash，执行如例E-1所示的命令启动Apollo配置中心。</p><p>【例1】启动Apollo配置中心的命令示例。</p><p><code lang=\"null\">./demo.sh&nbsp;start</code></p><p>启动Apollo配置中心的命令、过程和结果如图2所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e9/e9fdf1ea1cf72d774f6a5417894b77bf.png\" /></p><p></p><p>■&nbsp;图2 Apollo配置中心的启动命令、过程和结果</p><p>在浏览器中输入localhost:8070，结果如图3所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/54/544d9d0ff8a05d93bfd8f9bc243f1d82.png\" /></p><p></p><p>■&nbsp;图3 在浏览器中输入localhost:8070的结果</p><p>在图3中输入正确的Username(初始值为apollo)和Password(初始值为admin)后，结果如图4所示，显示已有一个项目默认SampleApp。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/2c/2c4171a8e1c9cf6b45274d310509749e.png\" /></p><p></p><p>■&nbsp;图4在图3中输入正确Username和Password后的结果</p><p>SampleApp项目的基本信息如图5所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/06/0608e761d801bfa08f443c44767ef8c0.png\" /></p><p></p><p>■&nbsp;图5 默认项目SampleApp的基本信息</p><p></p><p></p><h1>2、本案例的结构说明和Apollo配置中心的内容设置</h1><p></p><p></p><p></p><h2>1●本案例的结构说明</h2><p></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本案例的微服务之间的关系，如图6所示。zuul项目(zuulapollo)、Apollo配置中心(或称为配置中心)以及服务提供者项目apolloconfig和apollouser都要用到Eureka服务器。服务提供者项目apolloconfig、apollouser和zuul项目都要用到Apollo配置中心上的配置信息。用户访问微服务时，根据用户的不同由zuul项目将微服务apolloconfig或微服务apollouser分配给用户。本案例中用户除了可以访问zuul项目之外还可以直接访问项目apolloconfig或apollouser(正式情况下一般不能直接访问微服务)。为了对比，项目apolloconfig或apollouser均提供了返回文本内容和返回视图两类接口。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/4b/4bbfab44396074ebe51cc43c59c5394f.png\" /></p><p></p><p>■&nbsp;图6 本案例的微服务之间的关系</p><p></p><p></p><h2>2●Apollo配置中心的内容设置</h2><p></p><p>在 Apollo配置中心默认项目SampleApp中，增加如表1所示的配置内容。增加1条配置信息(以admin为例)的方法是单击项目SampleApp后，再单击“新增配置”按钮，弹出“添加配置项”对话框，如图7所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/f8/f8c912b258fe330617a5e31370159d3c.png\" /></p><p></p><p>■&nbsp;图7 “添加配置项”对话框</p><p>依次在Key文本框和Value文本框填写admin、admin，单击“提交”按钮。</p><p>表1要在 Apollo配置中心的默认项目SampleApp中增加的配置内容</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/10/10934de93c7de91f3186e86f90d37e70.png\" /></p><p></p><p>按照同样方法设置表1中其他配置信息，单击“发布”按钮，结果如图8所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/90/9036c53582fac5a71698887fe5ee2916.png\" /></p><p></p><p>■&nbsp;图8 向项目SampleApp增加配置内容并进行发布之后的结果</p><p></p><h1>3、实现服务提供者项目apolloconfig</h1><p></p><p></p><p></p><h2>1●新建项目并添加依赖</h2><p></p><p>新建项目apolloconfig，确保在文件pom.xml的和之间添加了Eureka Client、Web、Thymeleaf、Apollo Client依赖。</p><p></p><p></p><h2>2●创建类、文件和修改配置文件</h2><p></p><p>创建类AppConfig、ACController，并修改这些类的代码。</p><p>在目录src/main/resources/templates下创建文件admin.html，并修改其代码。</p><p>修改在目录src/main/resources下的配置文件application.properties。</p><p></p><p></p><h1>4、实现服务提供者项目apollouser</h1><p></p><p></p><p></p><h2>1●新建项目并添加依赖</h2><p></p><p>新建项目apollouser，确保在文件pom.xml的和之间添加了Eureka Client、Web、Thymeleaf、Apollo Client依赖。</p><p></p><p></p><h2>2●创建类、文件和修改配置文件</h2><p></p><p>创建类AppConfig、ACController，并修改这些类的代码。</p><p>在目录src/main/resources/templates下创建文件guest.html，并修改其代码。</p><p>修改在目录src/main/resources下的配置文件application.properties。</p><p></p><p></p><h1>5、实现zuul项目zuulapollo</h1><p></p><p></p><p></p><h2>1●新建项目并添加依赖</h2><p></p><p>新建项目zuulapollo，确保在文件pom.xml的和之间添加了Eureka Client、Web、Zuul、Apollo Client依赖。</p><p></p><p></p><h2>2●创建类、修改入口类和配置文件</h2><p></p><p>在包com.bookcode中创建类ZuulPropertiesRefresher，并修改其代码。</p><p>修改入口类，增加注解@EnableApolloConfig和注解@EnableZuulProxy。</p><p>修改在目录src/main/resources下的配置文件application.properties。</p><p></p><p></p><h1>6、程序运行结果</h1><p></p><p>依次运行项目mweathereurekaserver(端口为8761)、apolloconfig(服务名称为apolloconfig，端口为8765)、apollouser(服务名称为apollouser，端口为8760)、zuulapollo(服务名称为zuulapollo，端口为8665)。</p><p></p><p></p><h2>1●apolloconfig服务运行结果</h2><p></p><p>在浏览器中输入localhost:8765/userinfo，结果如图9所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/c3/c3a69662ab4fd3f46876b8857945e175.png\" /></p><p></p><p>■&nbsp;图9 在浏览器中输入localhost:8765/userinfo的结果</p><p>在浏览器中输入localhost:8765/admin/userinfo，结果如图10所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/5f/5f9036a9ecc885c76ce694b8159db9df.png\" /></p><p></p><p>■&nbsp;图10 在浏览器中输入localhost:8765/admin/userinfo的结果</p><p></p><p></p><h2>2●apollouser服务运行结果</h2><p></p><p>在浏览器中输入localhost:8760/userinfo，结果如图11所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee0fcde1b6197275a72cd7b5ba746bb.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee0fcde1b6197275a72cd7b5ba746bb.png\" /></p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/8e/8ee0fcde1b6197275a72cd7b5ba746bb.png\" /></p><p></p><p></p><p>■&nbsp;图11 在浏览器中输入localhost:8760/userinfo的结果</p><p>在浏览器中输入localhost:8760/guest/userinfo，结果如图12所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/18/18d5c573148b94936783563fef73ec05.png\" /></p><p></p><p>■&nbsp;图12 在浏览器中输入localhost:8760/guest/userinfo的结果</p><p></p><p></p><h2>3●zuulapollo服务运行结果</h2><p></p><p>在浏览器中输入localhost:8665/admin/userinfo，结果如图13所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/cc/cc593edc3d93a46f81bb670cd33f8d46.png\" /></p><p></p><p>■&nbsp;图13 在浏览器中输入localhost:8665/admin/userinfo的结果</p><p>在浏览器中输入localhost:8665/admin/admin/userinfo，结果如图14所示。对比图9和图13(或图10和图14)，可以发现它们结果相同，即zuul路由项目zuulapollo对URL进行了转换处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/ea/eaa0d63581bf40874fa4212cf93b1999.png\" /></p><p></p><p>■&nbsp;图14 在浏览器中输入localhost:8665/admin/admin/userinfo的结果</p><p>在浏览器中输入localhost:8665/guest/userinfo，结果如图15所示。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/e3/e3a6cad5521963b99610f010f7ad0113.png\" /></p><p></p><p>■&nbsp;图15 在浏览器中输入localhost:8665/guest/userinfo的结果</p><p>在浏览器中输入localhost:8665/guest/guest/userinfo，结果如图16所示。对比图11和图15(或图12和图16)，可以发现它们结果相同，即项目zuulapollo对URL进行了转换处理。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/b2/b271e34daffea6cc25cc6d27afef48da.png\" /></p><p></p><p>■&nbsp;图16 在浏览器中输入localhost:8665/guest/guest/userinfo的结果</p><p>对比图13和图15(或图14和图16)，可以发现项目zuulapollo对URL进行了解析并调用不同的服务(apolloconfig或者apollouser)为用户提供服务。</p>",
    "publish_time": "2023-08-04 10:30:20",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "基于Web3D+GIS智慧森林防火监测预警系统",
    "url": "https://www.infoq.cn/article/41e6ed0cd7c26e8df681360f3",
    "summary": "<p>森林火灾是森林最危险的敌人，也是林业最可怕的灾害，它会给森林带来毁灭性的后果。</p><p></p><h1>建设背景</h1><p></p><p>森林火灾，重在预防。随着现代技术的快速发展，数字化森林监控已成为及早发觉，排除森林火灾隐情的必要手段。充分利用现代科技手段，提高森林防火行业的科技含量，才能更好地实现森林火灾的综合防御和控制能力。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/70/707cf15ec0a4351855cb18bd1ce838a2.jpeg\" /></p><p></p><p></p><h1>系统概述</h1><p></p><p>“智慧森林防火系统”通过AI智能算法、云计算、大数据、GIS地图等信息技术，实现森林防火智能化监测告警和管理。通过实时监测和告警功能，及时掌控林区内早期火情动态，大幅提高预防监测能力，在森林早期火情监测、告警以及火灾扑救过程中发挥作用。</p><p></p><h1>开发平台</h1><p></p><p>智慧森林防火监测预警系统基于数维图Sovit3D可视化平台开发，融合物联网、大数据、云计算等技术，通过在线编辑器拖拉拽组件图表的方式，搭建了一个基于Web端3DGIS高清卫星电子地图的可视化大屏驾驶舱，以资源“一张图”方式提供森林资源监管、地表火监测、智能视频监控、森林防火管理、森林网格巡护管理等防火业务应用，构建以人防、技防、物防、和先期火情处理能力的“三防一能力”为核心的森林防火综合监管体系结合GIS系统。适用于森林、草原、景区、湿地公园、自然保护区等野外环境地表火险监测与预警。</p><p></p><h1>系统功能</h1><p></p><p>大数据驾驶舱</p><p>依托数维图Sovit3D可视化大屏设计平台，以当前区域地图为背景，对整个区域空间中的有关地理分布森林数据进行显示和描述，再利用无人机结合森林摄像机进行森林火灾监测。利用现代摄影测量技术进行火灾自动识别，实现对森林火灾信息进行全面、细致、准确地监测。将当前森林数据及环境数据显示在大屏两侧。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a0/a009570e689656bb1e9d8462180f6c14.png\" /></p><p></p><p></p><p>监测站点管理</p><p>系统配有GIS地图，可显示当前所有监测站点的分布位置，如发生报警事件，可第一时间定位站点位置。以及通过大屏幕电视墙在指挥中心展示，在平台上实现远程操作和控制前端基站的重型数字云台等设备进行大范围、大视野的监控，实现网络与上、下级单位联网实现统一的联网智能管理。</p><p></p><p>实时在线监测</p><p>多维度构建全天候、高频次、大范围的森林防火立体监测网络。基于热成像和AI技术的地面智能巡查网，可及时发现火情，实现火情早发现。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/a9/a9370752852fb6bc00e5b7588f738139.jpeg\" /></p><p></p><p></p><p>环境监测系统</p><p>在选择具体区域时，显示具体区域的实时温度、湿度、风级和烟雾浓度等环境信息，展示全局气象状况。提供当前积温、累积降水、温度等历史多年对比分析数据。</p><p></p><p>视频监控系统</p><p>可对监控区域进行24小时全天候远程实时监控，运用智能视频分析技术，建立林区安全预警系统，对视频采集的可见光、红外图像进行分析，实现宏观到微观，动态安全预警提醒，打造林区安全防御体系。</p><p></p><p></p><p><img src=\"https://static001.geekbang.org/infoq/3d/3d29f382d6cb15a7ba40cde28269e1c9.jpeg\" /></p><p></p><p></p><p>智能巡护系统</p><p>护林员对林场进行日常巡护，实时掌握林场的现场视频信息和巡护人员的位置，巡护轨迹等，用于指挥中心指挥巡护工作，协助巡护人员提高工作效率。</p><p></p><p>应急预警系统</p><p>建立预警触发机制，当出现突发情况时，可以自动、半自动报警，并立即通过声光等方式提示相关人员，自动联动现场监控信息进行复核，根据事件情况自动启动应急预案，详实清晰的记录所有的事件经过，以便日后查对、取证和经验积累。</p><p></p><p>指挥调度系统</p><p>主要用于森林防火应急预案管理、应急资源管理、应急指挥调度、应急辅助决策，推动林区落实日常应急管理及与各级政府间的应急联动，为事故应急提供技术支持，辅助林区进行快速、精准、科学应急响应。</p><p>……</p><p></p><h1>系统价值</h1><p></p><p>智慧森林防火监测预警系统以可见光烟雾识别、林火报警为辅，实现夜视监控、无人值守、远程监控、逐圈扫描等功能，落实“早发现、早出动、早扑灭”的森林防火“三早”战略思想。结合大数据、可视化、AI等先进技术，实现数字化智能预警提醒，达到森林防火系统的“数字化、高清化、智能化”，以前端视频监控、烟雾识别、卫星遥感为基础，以火灾自动预警为条件，以数字化通讯为手段，实现林业防火管理的数字化。</p><p></p><h1>总结</h1><p></p><p>通过应用物联感知、人工智能等技术，构建包含卫星遥测、无人机、热成像视频和人工巡护等多手段融合的全天候、高频次、大范围立体化智能监测网络，构建具备火灾监测预警、火情研判、扑火指挥、态势分析、灾损评估、火灾督查等功能的智慧森林防火监测预警可视化平台。有效增强森林火灾综合防控能力，提高森林管护成效。</p><p></p><p>本文主要介绍了Sovit2D、Sovit3D可视化编辑器在森林防火智慧化场景开发中的实践应用，数维图科技只提供前端可视化开发编辑器产品，不提供行业解决方案。</p><p></p><p></p><p>​E N D</p><p>​长沙数维图信息科技有限公司&nbsp;</p><p>​Web组态/3D物联网可视化PaaS平台&nbsp;</p><p>​数见视界，维新以图&nbsp;</p><p>​▼&nbsp;</p>",
    "publish_time": "2023-08-04 11:19:34",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "MaaS突破“临界点”，全栈Serverless化再升级，阿里云如何重塑云计算技术体系？",
    "url": "https://www.infoq.cn/article/jms5AvaZd6Bg9iJ9etye",
    "summary": "<p>2009 年，飞天的第一行代码敲在了阿里云最早的办公室里，也敲在了国内<a href=\"https://xie.infoq.cn/article/2162a06d9f7f675606040d0b6\">云计算</a>\"的里程碑上。十几年后的今天，我们仍然能够看到这股创新力量在阿里云不断汇聚，等待某一刻的爆发，而这一刻似乎已经到来。早在今年 4 月的阿里云峰会上，阿里巴巴集团董事会主席兼首席执行官、阿里云智能集团 CEO 张勇表示，目前阿里云已形成了全栈的技术服务，搭建了模型即服务（MaaS）、平台即服务（PaaS）、基础设施即服务（IaaS）三层架构。在此之后，阿里云推出了“飞天发布时刻”这一产品技术发布平台，并开始以这一平台高频地对外发布在智能时代云计算创新体系下的一系列新技术和新产品。在刚刚过去的 7 月 31 日，飞天发布时刻再次带来了一系列新产品，并引发了业内对智能时代云计算技术体系相关理念的关注。</p><p></p><p>一直以来，业界对于 <a href=\"https://xie.infoq.cn/article/1637fc1e818f084a5ccd8f5ad\">MaaS </a>\"存在诸多讨论。那么，MaaS 理念之下是否实现了业务场景的适配与落地？被热议的全栈 Serverless 化做到了哪一步？对企业和开发者又有何价值？云厂商如何才能真正做到“普惠”？什么样的云计算体系架构适合智能时代？本文将针对上述问题进行探讨并寻找答案。</p><p></p><p></p><h3>MaaS 理念下如何实现大模型能力产品化？</h3><p></p><p></p><p>AI 浪潮下，作为大模型底层基石的云计算发生了新的变化。当前阶段，云厂商已经基本达成共识：AI 与云计算互生互融成为必然趋势，应用将大规模建立在大模型上。与此同时，业界在讨论大模型时普遍提到了一个关键词：MaaS。</p><p></p><p>MaaS 是什么？去年 11 月，阿里云在云栖大会上首次提出了 MaaS（Model-as-a-service ，模型即服务）概念。阿里云 CTO 周靖人曾对 MaaS 做了如下表述“MaaS 最底层的含义是要把模型作为重要的生产元素，围绕模型的生命周期设计产品和技术，从模型的开发入手，包括数据处理、特征工程、模型的训练和调优、模型的服务等，提供各种各样的产品和技术。”可以明确的一点是，MaaS 并非一个技术层，而是一种理念。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/9b/9b92c6a10339fd2b81cceeb88ffdd31a.jpeg\" /></p><p></p><p>随着“百模大战”日趋白热化，MaaS 理念成为越来越多大厂选择的商业路径。MaaS 是否能重塑云计算改变云计算的游戏规则，目前定论还尚早。但可以肯定的是，以往的 PaaS 和 SaaS 架构都将被置于大模型的底层能力之上，大模型将成为生产要素，在各行业释放力量。</p><p></p><p>尽管大模型对未来的颠覆性影响已成为共识，但是我们仍然需要面对的现实是，国内对大模型的探索处在早期阶段，多数企业对于大模型仍然持有观望态度，原因在于其在业务场景适配与落地上存在较大难题。当各大厂正在跟随 MaaS 理念纷纷研发自己的大模型或者寻找大模型落地场景时，阿里云已经实现了大模型能力的产品化。</p><p></p><p>今年的 WAIC 大会上，阿里云通义大模型家族揭开了最新成员的面纱，基于自研的组合式生成模型 Composer 的 AI 绘画创作大模型——通义万相。其实，在这之前阿里云已先后发布了超大规模的语言模型——“通义千问”和专攻音视频生产力的 AI 产品“通义听悟”。至此，阿里云在 AI 的三大主要方向全部打通。</p><p></p><p>“面向 AI 时代，所有产品都值得用大模型重新升级。”是阿里云对大模型产业落地的判断。当所有聚光灯都打在两个月内迅速诞生的通义千问和通义万相两个大模型上时，阿里云已经同步实现了诸多产品的智能升级，通义听悟、钉钉都是其中的先行者。</p><p></p><p>通义听悟是一款面向工作和学习的 AI 助手，通义听悟强大的理解能力背后除了以自研的通义千问大模型为基座，更重要的是内置了阿里云新一代工业级语音识别模型 Paraformer，这是业界首个应用落地的非自回归端到端语音识别模型，在推理效率上最高可较传统模型提升 10 倍。最新数据显示，通义听悟在发布首月累计访问用户数 49.1w。</p><p></p><p>除此之外，通义大模型能力也足以赋能其他企业级产品。在钉钉宣布全面接入通义千问大模型的 3 个月之后，我们看到了大模型对企业级产品智能化升级的真正实力。知识库、Teambition、白板等加入 AI 能力，钉钉 12 条产品线、40 多项场景接入大模型。用户通过斜杠“/”输入自然语言，即可生成 PPT、思维导图、数据分析图表、项目看板等。在智能化升级中，钉钉将大模型深度融入到工作流程的各个环节，用户可以在钉钉上完成从沟通到协作、从创意到实现、从管理到决策的全流程并能充分感受到大模型交互与理解能力所带来的新功能、新体验。</p><p></p><p>在开发者生态层面，为进一步降低大模型使用门槛，阿里云推出国内首款大模型调用工具魔搭 GPT（ModelScopeGPT），它能接收用户指令，通过“中枢模型”一键调用魔搭社区其他的 AI 模型，大小模型协同完成复杂任务。魔搭 GPT 现已能够调用魔搭社区十多个核心 AI 模型的 API，未来随着更多模型 API 的加入，魔搭 GPT 的能力也将不断增强。构建这一模型调用工具的数据集和训练方案将会对外开放，供开发者自行使用，开发者可以根据需要对不同的大模型和小模型进行组合。值得一提的是，就在昨天，阿里云通义千问开源。AI 模型社区魔搭 ModelScope 上架两款开源模型 Qwen-7B 和 Qwen-7B-Chat，阿里云确认其为通义千问 70 亿参数通用模型和对话模型，两款模型均开源、免费、可商用。在多个权威测评中，通义千问 7B 模型取得了远超国内外同等尺寸模型的效果，成为当下业界最强的中英文 7B 开源模型。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/03/03194d472cbe998b19d2cb35528deafe.png\" /></p><p></p><p>从通义听悟到钉钉再到魔搭 GPT，我们看到阿里云在用户层面、企业层面、开发者层面实现了大模型产品化的全面布局。这也意味着，阿里云最先实现了在 MaaS 理念之下大模型与业务场景的创新落地。然而，大厂的理念再先进、产品落地再好，普通企业和开发者要想玩转 AI，尤其是在云上玩转 AI，依旧难度不小，降低 AI 开发甚至应用开发的门槛，是开发者们提出的诉求，也是云厂商最重要的功课之一。</p><p></p><p></p><h3>降低 AI 开发门槛，全栈 Serverless 化，做高质量的 PaaS 层</h3><p></p><p></p><p>大模型浪潮，率先将算力推至风口浪尖。据 OpenAI 测算，全球 AI 训练所用的计算量呈现指数级增长，平均每 3.43 个月便会增长一倍，目前计算量已扩大 30 万倍，远超算力增长速度。国家信息中心发布的《智能计算中心创新发展指南》显示，当前我国超过 30 个城市正在建设或提出建设智算中心，但仍然无法满足相关需求。</p><p></p><p>打造一个 AI 大模型究竟需要多少算力？据公开数据显示，ChatGPT 初始所需的算力就是 1 万块英伟达 A100，价格超过 7 亿元。后续的调优训练每天消耗算力大概是 3640PFLOPS，需要 7 至 8 个算力达 500PFLOPS 的数据中心支持，建设成本约为三、四十亿元。</p><p></p><p>然而，提供算力的所有 GPU 不能只是简单堆砌，更需要让所有算力联合起来为模型训练服务。大模型的训练和推理过程需要海量数据资源，相比于传统中央处理器 CPU，GPU 拥有上千个小型处理核心，能够同时处理大规模数据的并行计算任务，运算速度更快。凭借这些优势成为了智能计算的理想选择。但是，算力的构成并不仅仅只是 GPU 加速芯片，还需要构建包括网络互联、操作系统、深度学习框架以及相应 SDK、算法与应用程序等，形成一个完整的计算生态系统，通过体系化的技术支撑汇聚 AI 算力。</p><p></p><p>而智算服务 PAI-灵骏恰恰就能将这一体系整合。智算服务 PAI-灵骏包含的基础设施层的 RDMA 网络和融合算力集群、智算工程平台和智算资产管理以及强大的 <a href=\"https://xie.infoq.cn/article/c27caa29721819fe26dd92ea0\">Serverless </a>\"化的调度能力和运维管控能力等，都助力开发者摆脱堆砌算力的老路。</p><p></p><p>同时，智算服务 PAI-灵骏面向大规模深度学习及融合计算场景，一站式地提供覆盖 Al 开发全流程的工程平台和深度优化的融合算力，支撑了 10 万亿参数规模的大型模型训练。基于 PAI-灵骏智算服务，单训练任务可达万卡级别规模，训练性能可提高近 10 倍，千卡规模的线性扩展效率达 92%，极大降低 AI 开发门槛。</p><p></p><p>智算服务 PAI-灵骏本质上是一个 Serverless 化的产品，为 AI 开发新范式提供了 Serverless 化的平台支持。而在 AI 开发之外，Serverless 也已经是大家普遍认同的应用开发的范式。根据 Gartner 预测，到 2025 年将会有 50% 以上的全球企业采用 Serverless 化架构。为什么越来越多企业会使用 Serverless ？</p><p></p><p>Serverless 的核心目的是在云计算的基础上，彻底“包揽”所有的环境工作，直接提供计算服务。在 Serverless 架构下，开发者只需编写代码并上传，云平台就会自动准备好相应的计算资源，完成运算并输出结果，从而大幅简化开发运维过程。随着企业数字化进程加快，Serverless 的全托管服务、自适性弹性、按实际用量计费等特点越来越满足企业的业务需求。</p><p></p><p>Serverless 的价值不言自明，但是要想让用户用好 Serverless，单纯在应用运行时层面进行 Serverless 化是远远不够的，应用依赖的下游数据库等系统，如果没有良好的弹性，就会成为系统整体的“短板”。</p><p></p><p>全面实现 Serverless 化取决于整个研发链路上有多少云产品提供了这样的形态。阿里云是国内对Serverless 探索最早的厂商之一，其于 2017 年推出了函数计算产品 FC，2018 年推出了 Serverless 应用引擎 SAE 和 Serverless 容器服务 ASK，2020 年开源了 Serverless Devs，2021 年阿里云 Serverless 产品能力在 Forrester 评测中拿下国内第一 &nbsp;，2022 年 Serverless 应用中心发布……在去年的云栖大会上，阿里云宣布全栈 Serverless 化之后，业内都在期待相关成果。</p><p></p><p>“让云计算从资源真正变成一种能力”，阿里云一直坚定地推进全栈 Serverless 化并通过多年的 Serverless 产品创新积淀等待新的突破。</p><p></p><p>在本周一的飞天发布时刻上，阿里云陆续带来了 Serverless 领域的最新进展：函数计算 FC 与 AIGC 的创新融合、容器服务 Serverless 版（ACK Serverless）以及 Serverless 应用引擎 SAE2.0。这意味着，阿里云在全栈 Serverless 化又前进了一步。</p><p></p><p>在权威咨询机构 Forrester 发布的最新全球 FaaS 能力报告中，阿里云函数计算凭借产品能力在 40 个严苛的评分项目中拿下 24 个最高分，综合稳居领导者象限，成为国内唯一两度进入该象限的科技公司。函数计算的产品实力加速了与 AIGC 的创新落地。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/79/79edcc513536dc8566e47fa3a2803939.png\" /></p><p></p><p>面对应用开发的高门槛，阿里云函数计算整合了 AIGC 应用开发，集结经典的 AIGC 模版，5 分钟就可以完成 AIGC 应用部署，使模型托管的难度降低、效率提高。</p><p></p><p>阿里云的容器服务 Serverless 版，则是将 ACK 和 ASK 两款产品融合，在弹性能力和调度能力上实现了更大提升。例如，升级了智能弹性预测 AHPA，相比人工配置，弹性准确率提升 80%；基于库存感知调度和可用区打散调度，提高了弹性的确定性以及应用的高可用性。</p><p></p><p>全托管、免运维、高弹性是 SAE 的主要特点，本次升级的 SAE2.0 将研发运维提效 50%、应用成本下降 40% 以上并实现百毫秒级弹性伸缩，应用冷启动提效，支持缩容到 0，这对于新兴业务以及一些创新创业的公司更加友好。</p><p></p><p>我们看到，从智算服务 PAI-灵骏到全栈 Serverless 化的最新进展，都是在降低 AI 开发门槛和应用开发门槛，背后的本质是云计算技术的不断创新与发展，而云计算技术创新和发展的终极目标则是降低算力成本，让每个企业甚至每个人都能用得起、用得好算力，让计算真正成为公共服务。</p><p></p><p></p><h3>创新与规模效应加持下，将“普惠”进行到底&nbsp;&nbsp;</h3><p></p><p></p><p>目前，国内大部分算力掌握在少数厂商手里，而云厂商占了很大比重。算力，在很多情况下成为了想法落地的最关键一环，是很多机构和企业迈不过去的坎。</p><p></p><p>普惠在任何行业都是具有巨大价值的事情，算力普惠更是如此。但做这件事情是有门槛的，首先就是技术创新。阿里云掌握着国内云计算核心技术体系，拥有自研软硬件一体研发系统，例如，自研 CPU 倚天 710、云数据中心处理器 CIPU 以及飞天操作系统，构建了从芯片、板卡、服务器、操作系统和上层云原生应用软件、数据库等核心云基础设施。阿里云对软硬件一体技术整合的持续大力投入所推动的算力提升、资源调度能力增强、以及细颗粒度的运营，是阿里云能够降本让利的底气所在。</p><p></p><p>让更多企业和开发者享受到云计算的红利，是阿里云的初心。</p><p></p><p>降低开发者的获取门槛是阿里云“普惠”的重要一步。今年 4 月中旬，阿里云推出了“飞天免费试用计划”，面向 1000 万云上开发者，提供核心云产品的免费试用，最长达三个月，可支持开发者构建包括业务在线、大数据类、AI 等不同类型应用，并且支持 Serverless 的开发模式。</p><p></p><p>目前该计划也推出了国际版，涵盖 50 多款产品，包括 ECS t5 实例的一年期免费试用、PolarDB 数据库永久免费试用，以及指定规格试用期满折扣续费等多种产品优惠。据悉，阿里云还将进一步扩大免费试用范围，针对学生、中小企业的专属免费试用计划也在筹备中。</p><p></p><p>成本是云计算发展的命门，在降低用户成本上，阿里云展现了最大的决心和诚意。今年的 4 月阿里云宣布核心产品价格全线下调 15%-50%，存储产品最高降价 50%。例如，弹性计算 7 代实例和倚天实例降价最高 20%，存储 OSS 深度冷归档降价 50%，网络负载均衡 SLB 降价 15%，数据库 RDS 倚天版降价最高 40%。被外界称为“阿里云有史以来规模最大的降价”。</p><p></p><p>然而，降本并不等于降价也不是价格战，而是通过产品优化和规模效应带来 IT 总成本的降低。</p><p></p><p>作为国际领先的云计算厂商，阿里云在过去的十年里持续降低云计算的“使用门槛”。其提供的算力成本下降了 80%，存储成本下降了近 90%。在不断降价的过程中，阿里云所期待的是联合更多分销商和集成商一起，扩大云的用户基数和规模，推动更多产业进一步从传统 IT 向云计算转移，提高计算资源的利用率，带动算力成本不断下降。利用技术改进、规模效应释放让利空间，价格下降又为技术改进、规模增长带来更多推力的正循环。</p><p></p><p>即便降低用户成本，但是阿里云在安全层面并不打折扣。特别是在降低企业确保业务安全稳定运行的成本上。例如，云安全中心的多云统管能力和办公安全平台的轻量版。尤其是办公安全平台的轻量版，适合中小企业使用的同时，核心功能和标准版基本一致且价格只有标准版的不到 10%。可以看出，阿里云对中小企业的关注与支持印证了其普惠理念。</p><p></p><p></p><h3>写在最后</h3><p></p><p></p><p>从 MaaS 理念下的大模型能力的产品化，到 PaaS 层技术迭代与积淀迸发，再到 IaaS 层创新与规模效应下的成本降低。在这些产品和理念的背后，我们看到阿里云是“一家云计算产品公司”的核心定位，并坚定走向“产品被集成”。大模型时代，企业都在探索新的商业模式和生存之道，对于企业而言，找到靠谱的合作伙伴是未来发展的重要一步，阿里云趟出了一条可能路径并走在了最前面。我们需要给先行者们更多的时间，来共同建立适合智能时代的云计算体系。</p>",
    "publish_time": "2023-08-04 15:30:55",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "移动端性能挖掘：字节跳动iOS与安卓性能归因实践",
    "url": "https://www.infoq.cn/article/twFsuxo4IQi5FIqe3OKA",
    "summary": "<p></p><p>本文整理自字节跳动技术专家刘成清在 ArchSummit 杭州 2022 全球架构师峰会的演讲分享，主题为“字节跳动 APM 线下性能归因实践”。</p><p></p><p>分享主要从四个部分展开：第一部分介绍线下工具的发展史，分析线下工具有哪些共同目标和痛点；第二部分分别以各种常见的性能问题为大家介绍归因这类问题的常见解决思路，同时也会穿插讲解一些字节内部的实际案例；第三部分就 iOS 部分能力为大家介绍实际的工作原理；最后是本次分享的总结。</p><p></p><p>在分享开始前，首先看下本次分享能给大家带来哪些收益？</p><p></p><p>第一，本次分享主要介绍移动端 iOS 与安卓的性能归因手段，从系统层面分析 App 性能。</p><p></p><p>第二，介绍如何使用 iOS 的后门服务，像安卓使用 adb atrace 一样进行性能归因。</p><p></p><p>第三，通过性能归因实战，看如何使用线下工具为卡顿、内存、功耗等问题进行归因提效。</p><p></p><p></p><h2>线下工具的前世今生</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/96/968c0748dc11641e2fa95bdb9b408f70.png\" /></p><p></p><p>性能归因如同 App 健康监测，根据用户群体的不同，可分为线上和线下，线上通过性能 SDK 采集实际用户的真实数据，APM 平台通常的能力有卡顿监控、LPS 监控、OOM 监控等，但由于权限等原因，线上 SDK 往往无法采集部分深度数据，而线下通过 PC 工具，内部 Debug SDK 对线下模拟的用户进行分析，拥有足够大的权限，所以可以采集一些深度的数据用于一些深度的性能归因分析。两者相辅相成，线下是线上分析的补充，线上是线下测试的兜底，如今部分线下能力也在往线上迁移，如字节的 memory graph，既能采集到线上的真实数据，也能使用丰富的分析能力，而业内对于线上已经有大量的 show case 案例。今天的主题还是线下归因分析，看看线下都有哪些被大家忽视的优秀能力，帮助大家将问题的发现前置，避免漏到线上。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b4/b47096dc4a67653eeabe2e92050383b7.png\" /></p><p></p><p>左侧是 ktrace 命令行分析工具，了解 iOS 性能优化的同学都知道，ktrace 的丰富能力如同安卓的 system chains 一样强大，可以采集大量的内核数据，但由于门槛较高，部分研发同学并不能轻松驾驭。右侧是 Apple 提供的 Instruments，可见数据更为直观，并且 Instruments 每年的 WWDC 依旧会更新新的能力，Google 的 Perfetto 亦是如此，从中我们得知，工欲善其事，必先利其器。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/8e/8e816ba3424201a3edbcaca12bf65272.png\" /></p><p></p><p>这是性能归因的三部曲，即生产、采集与消费。而我们引入工具的目的就是为了提升归因的效率，我们希望把效率从天级别降低到分钟级别，而使用门槛也从专家级降到小白级。在命令行时期，工具只能提供采集能力，我们需要手动模拟场景，通过工具采集数据，并且根据经验进行性能分析，但往往性能问题的归因的时效性需要数天，甚至需要立项解决，而到了 GUI 时期，工具虽然提供了采集和图形化相关的一些能力，一定程度上简化了流程，但 Perfetto 与 Instruments 依旧有一定的使用门槛，如果工具能结合数据生产、采集、消费，并且能以部分范式的经验聚类数据，就能让常见的问题做到自动归因，将性能问题的发现与解决前置到业务开发当中，也能降低问题的复工率，同时还能与 CICD 结合，作为准入的一个卡口，提升性能问题的拦截率。目前这两种形式分别以不同的形态落地了字节，服务于 RD、QA，提升了各个产品形态的研发效率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7e/7e94f206ebac9aef45518c71c331e294.png\" /></p><p></p><p>Instruments 和 Perfetto 都提供了相应的能力，那么我们为什么还需要去做一个自己的工具？原因有三，第一 Instruments 和 Perfetto 对包的限制还是比较苛刻的，大部分功能只适用于Debug 包，当 QA 用内测包反馈一些性能问题的时候，我们并没有办法直接使用工具进行归因分析。第二涉及数据的精度，本身采样工具都会有精度的丢失，以 Instruments 为例，假设 T2、T3 时刻丢失了采样，整体会影响到对函数耗时的统计，但这些问题我们都会通过聚类算法进行规避。第三，Instruments 没有一些火焰图的展现形式，并且不支持一些自定义的指标水位，我们要做自动归因的话，也需要对原始数据进行二次分析。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/f4/f4a719cca8b79a2d98cc185b7ea7bb7b.png\" /></p><p></p><p>总结一下我们要做的工具需要达到的几个目标，数据要足够详细，尽可能地图形化数据，尽可能地降低使用门槛。</p><p></p><p></p><h2>性能归因的降本增效</h2><p></p><p></p><p>有了目标，接下来我们看看基于这些目标，在呈现性能问题上的提效手段和落地的效果。</p><p></p><p>首先先来看一下效果。当我们发现性能问题，且上下文信息不足以归因时，我们可能需要切换到可调试的包，或反复埋点分析，这无异于增加了归因的链路，且可能导致问题不再复现，这时我们可以直接分析 Store 上的线上包，大部分能力是无需接入 SDK 的，也无需重启 App，直接保留现场，即插即用，可视化的分析数据几分钟就能定位到大部分问题的具体原因。具体效果如视频所示。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4f/4f0889112c81de216e1e050301590d8b.png\" /></p><p></p><p>上图是字节内部对这个工具的一些反馈情况。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/7b/7b7da3c0c02a7f323f693a9e14437504.png\" /></p><p></p><p>接下来我们看一下如何进行归因提效。最下层的数据生产，大家常用的有自动化测试和人工测试，而字节采用的最有效的提效手段就是 Fastbot，既通过 AI 驱动操作 App，而中间层的数据采集分别使用的是 DXTMsg 与 ADB 进行数据进行数据通信，以及 ktrace、profilo 的能力进行数据采集，其中也包含了一些字节已经开源的 SDK 能力，上层消费侧则是将采集的数据进行清洗与聚类，分别以更直观的方向展现出来，我们将这些能力进行整合，从而减少使用链路，提高效率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4a/4a5fa8b37f5d103ff90c0cd1ba5783de.png\" /></p><p></p><p>接下来我们分别从卡顿、内存、电量这三个问题展开介绍。首先是关注度比较高的卡顿问题，如同人体骨折，无法使人箭步如飞，早期只能凭借老医生的经验判断，当有了 CT 之后，我们只需要拍一张 CT 的片子，就算是没有任何医学经验的普通人也能看懂哪里发生了骨折，以及严重的程度如何，而面对卡顿问题，我们也需要一张这样的 CT 片子，能直观地告诉我们哪里发生了卡顿，以及导致卡顿的原因。通过收集线上快照，线程状态优先级，以及毫秒级的 CPU 使用率，这些信息就能绘制出右侧的时序效果图，往往就能直观地定位到 80% 的卡顿问题，而剩下的 20% 则还需要深度分析。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/04/0425a2a926547ee1d7efa65adb70973b.png\" /></p><p></p><p>接下来我们看看这 80% 的问题是如何定位的，当我们发生卡顿的时候，我们通常的排查手段是通过察看日志，如果日志能直接归因，我们这个问题就结束了，如果无法直接归因，我们就需要通过埋点、重新打包、重新复现、再分析数据进行归因，如果这时能完成归因，当前问题也能直接结束，但如果无法正常归因，我们还需要重复性的进行埋点并重新打包这个链路，而引入工具的目的就是为了能在发生卡顿时，直接使用工具进行问题的归因。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/b4/b40e372507c71077e0082a5ef9a2bc4e.png\" /></p><p></p><p>首先是慢函数，这也是最容易被发现的卡顿问题，也就是一个函数执行耗时过长，这是某 App 私信场景下的一个卡顿 case ，通过火焰图我们能直接定位到卡顿的调用栈，也就是在主线程执行了一些 DB 的操作，而这类问题很容易被发现，为什么还会遗漏到线上？主要原因还是因为其使用场景的隐秘性，在这个场景中，DB 与私信消息是有关的，当私信条目不多时并不会暴露，就算 QA 发现了这类问题，我们也无法直接定位问题，因为可进行函数分析的 Instruments 对非 Debug 包的支持欠佳，往往我们还是需要通过埋点、重新验证等反复操作的方式才能进行问题的验证。</p><p></p><p>为了解决这个问题，我们将工具的使用范围从 Debug 包拓展到所有包，就算是线上包我们也可以通过无侵入的方式直接采集线上快照，从而将问题的归因时效从小时级降到分钟级，而 Lark 和头条先后使用该能力，也解决了线上的一些卡顿问题。虽然慢函数这类问题可以通过线上的 APM 进行采集，但由于本身的采样率、性能损耗和阈值等原因,可能会丢失一些相关数据，这导致用户反馈的问题无法及时排查，而这个工具就能高效的保证排查的效率。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13cce946b4aac41f19878c284cb233df.png\" /></p><p></p><p>以上介绍了使用场景的提效，接下来我们看看功能上的提效。依旧是慢函数，当我们通过函数名无法定位具体原因时，即这个函数确实应该在主线程执行，但为什么执行这么慢？我们可以结合一些辅助信息，比如说线程状态，通过上图可以看到，慢函数期间有 80% 的线程状态都是Blocked，我们通过对应线程 Blocked 的一些信息，以及对应的一个子线程，当前时刻的一个调用栈可以发现，主线程正在等待子线程的 NSLock 的操作，排查到这里，基本上问题的原因也确定了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/9d/9d2cb6303a9aa532b40692615c9e333f.png\" /></p><p></p><p>除了锁等待，还有一种导致慢函数原因的就是资源抢占，而这类问题也是隐匿性最强的慢函数问题，在线程状态中它的体现是 Preempted 的，而这类问题的分析就得 case by case 的处理了，触发的常见原因有软中断、高优先级抢占主线程资源或者优先级反转等，目前本工具已经支持了优先级反转场景的识别。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/13/13963533bf96c7e9e2bc72e3c3903cb4.png\" /></p><p></p><p>以上是直接定位到卡顿慢函数的场景，而导致卡顿的原因是在一个渲染周期内执行时间过长，无法及时渲染，可能不是由于一个函数引起，比如这个卡顿场景通过火焰图无法直接查到卡顿的慢函数，但实际场景确实发生了卡顿，这就是典型的低消耗高频的卡顿场景。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/1d/1d7afe7b3503b11611adf5ab342d606d.png\" /></p><p></p><p>我们通过反转调用栈，并且聚类底层函数可以发现，CALayer.setBorderColor 这个函数调用了 623 次，总计消耗了 2.78 秒，而这个函数本身执行耗时不长，但是是在一个渲染周期内执行次数过多导致的，最后通过调用关系会受到调用这个函数的业务代码发现，这属于业务逻辑处理不当导致过度调用引发的卡顿问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/4d/4d0e9356e9cc57a94a7c6caa3fb62a9a.png\" /></p><p></p><p>以上是函数层面引起的卡顿，导致卡顿的原因还有很多，这是安卓的一个实际案例，在某个 App 下发现当进入某一场景下，会有大量的类加载。大家也知道，当程序需要读取一块未被加载的内存时，会发生页中断，也就是导致这个卡顿的原因，这边通过 JVMTI 监控到当前场景下确实有大量的类加载，而解决这类问题的办法也很简单，就是通过收集这些类信息，生成一个新的 profile 再基于这个 profile 进行预加载，从而规避卡顿的风险。</p><p></p><p>启动是卡顿的一个特殊场景。作为 App 的第一印象，业内早已经把启动作为 P0 的任务处理了，相应的监控和优化方案也层出不穷，当然也有需要改进的一些点，比如横向对比，我们在优化到一定地步之后，更想知道的是自己与竞品之间的差距，看看自己的优势，或者是可优化的空间在哪，但由于各个厂商之间都有自己的一些统计规则，虽然原理大同小异，但依旧无法完全一致，并且我们也无法直接拿到其它产品的统计指标。其次，当这个数据波动了，厂商也意识到 App 起动性能对手机自身体验的影响，所以在系统层面也做了一些缓存优化，比如说 Apple 的 dyld cache，这些对于统计引擎性能也是有数据波动的影响的。</p><p></p><p>最后就是监控的粒度，监控细了本身也会影响启动的性能，监控粗了也无法直接归因到一些具体的原因，而这里通过收集系统内核的一些信息，可将任意 App 在该设备上启动各阶段的耗时进行展现，从而做到横向的对比，分析各个 App 的优劣情况。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/05/05c130ee3f92691f67581935995aeb1f.png\" /></p><p></p><p>介绍完卡顿问题，接下来就是内存问题了，线上 OOM 也是一个比较棘手的问题，我们看看如何线下提前分析这类问题，避免遗漏到线上。当我们去处理内存问题的时候，常常会问到一个问题，就是内存消耗在哪里？而我们的归因手段就是通过收集内存节点和引用关系，在保留基本的引用关系的情况下，尽可能的将多而杂的节点进行聚类，从而将问题进行暴露。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e2/e2e246beda2763ac4d6fd6b63db01371.png\" /></p><p></p><p>这边双方的手段略有不同，安卓分别使用 adb、profile 获取 Java 与 Native 内存信息，而 &nbsp;iOS &nbsp;则是在 MemoryGraph 的基础上进行二次消费数据，从而将数据的粒度最大化。</p><p></p><p>常见的 case 有在某一个场景下内存居高不下，还有就是进入到某个场景之后内存激增，针对这两类场景我们的解决方案分别是：对于内存居高不下的场景进行内存快照的采集，但由于快照之间有上百万个内存节点，我们并没有办法直接归因一些问题，我们会对相应的节点进行聚类以及排序，同时对聚类比较高的节点信息进行补充，从而能通过这些节点信息归因到具体调用的情况，而对于内存激增的情况，我们更多使用对比的方式。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/57/5748a40e740a1a123ee7c7fd7df93693.png\" /></p><p></p><p>以下是这些功能的具体使用情况，如图所示是 iOS 的一个案例，我们通过将 Malloc History 与 LInkMap 的数据进行关联，可以将零散的节点聚类到 Class 或者 Function 的维度，在前期排查问题的时候，就能将问题聚焦到一定范围。通过该图左侧的聚类信息，我们可以得到，是哪个方法申请的内存较大，再结合右侧 Malloc History 的信息我们可以得到它原本的调用栈是怎样的，这些信息都能有效的帮助我们去定位一些内存问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0d/0d4b3c057f7893c0895bf98f9834c67e.png\" /></p><p></p><p>有时我们通过堆栈也无法确定问题的具体原因，如图所示安卓的一个 case ，内存分配中有大量的 Bitmap 的使用，单看这些信息远远不够定位问题，我们这边通过将 Bitmap 的数据进行了还原，问题就比较直观了，最终原因就是地图 Icon 的内存泄漏导致的问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bf/bff01cc0e0c6f783f74f9cfa463ad183.png\" /></p><p></p><p>最后一个手段就是数据对比了，由于对比可以把聚类的范围限制在 diff 内，这样的话，内存的变量就会被放大，从而有利于我们分析内存问题，如图所示，我们进入特定场景之后进行 diff，发现红框内线程的栈内存增量最为显著，这也就是我们归因这个问题的突破口。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/a0/a04a08ea743828a8d4916ba7cc0ec9cb.png\" /></p><p></p><p>第三类问题就是功耗问题了，由于前两类问题各厂早早就开始布局了，大部分问题都通过线上或者线下方式进行了一些修复，已经达到了可预期的水平，而功耗相对来说起步较晚，但它是近期大家比较关注的指标，并且功耗是由共同因素影响的，比如 CPU、WiFi 等，所以精准测量功耗还是有可待提升的空间。同样归因这类问题也需要结合其它模块的归因能力进行原动分析。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/25/25fc0c3873b6804f5da032706242e6c4.png\" /></p><p></p><p>以下是具体的手段，因为 iOS 只有 Apple 一个厂商，只需要从 Smart Battery 以及 &nbsp;sysdiagnosis 里获取数据即可，而安卓的厂商较多，字节这边也是单独开发了一个 SDK，兼容了各个厂商的计算规则，并与厂商之间对齐过电量统计的规则算法，一定程度上保证了功耗指标统计的准确性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/38/3835ec445f8da375c453cc588d8b02e8.png\" /></p><p></p><p>有了指标之后就是归因了，如左侧流程图所表示，我们定时采集功耗指标，当发生异常时便会自动开启 CPU 线程快照及网络数据采集，将这类信息通过时间维度聚类到一起，如右图所示，再结合上文中提及的分析手段，我们就能逐步进行问题的归因，而抖音业务线也使用该工具成功发现和优化了一些功耗相关的异常问题。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d0/d0e92ce911b64bd6d2c67bc17aa7541c.png\" /></p><p></p><p>介绍完采集和消费流程上的降本增效，最后再简单看一下数据生产上的提效，字节这边自研了一套自动化测试服务，既通过 AI 识别视图中的元素，以更接近人类操作的方式驱动 Web Agent 进行自动化测试，相比传统的 Monkey，无论是场景覆盖率，还是代码覆盖率上都有显著的提升，数据如图所示，结合 Fastbot 的数据生产，加上上文提及到的归因手段，我们整体的效率都有了一定的提升。以上为大家介绍了从数据生产、采集、消费全链路上的归因提效手段，虽然这些归因手段目前只是在线下使用，但部分能力也可以逐步迁移到线上，以丰富线上的归因能力。</p><p></p><p></p><h2>原理分析</h2><p></p><p></p><p>介绍完手段和效果之后，大家可能会对其中的一些实现原理有一定的好奇。接下来主要针对线上快照的采集与消费进行原理介绍，看看如何在无侵入的方式下获得线上快照，我们也利用这个方式成功分析过一些竞品 App 的运行逻辑。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e8/e8d093d48607fc1f03ffb18c77f4946a.png\" /></p><p></p><p>以卡顿分析的火焰图为例，我们只需要采集线上快照和符号化两步就能够让 App 的运行流程毫无保留的暴露在我们面前，而采集线上快照，我们常用的方式有 Hook 与插桩，安卓与 iOS 都有各自的一些解决方案，但这两种方式都需要侵入 App，其本质都改变了 App 本身，故无法测试 Store 上的正式包，所以我们采用的是 Ktrace 的采集方案。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/e2/e2b9fb711f62885de48505e26a6edae0.png\" /></p><p></p><p>首先我们看看 KDebug 能力，KDebug 类似于安卓的 systemtrace，用于收集内核事件，通过日志的形式暴露出来，看过 XNU 源码的同学可能都见过它的身影，比如线程调度的源码中，线程的 Block、Unblock 都会通过 KDebug 进行一些日志的记录，并通过唯一的 Event Code 标识各类事件，据不完全统计，目前已经有 2300+ 个 Event Code 正在使用当中。而最新的 iOS16 提供了 Run Loop 的调度监控也是通过 KDebug 补充的新能力。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/0c/0c256403bb47c28e99a866997de51122.png\" /></p><p></p><p>其次就是 KPerform，作为 Ktrace 第二大工程，它有定时采集线程快照的能力，并将快照以日志的形式保留下来，看到这是不是感觉我们平时做得拆装、Hook 相关的一些工作系统早已经在内核层面帮我们预置了，并且由于是在内核层面采集的，这些数据用于 App 的性能分析完全如同降维打击一般，我们几乎无须担心数据的准确性，以及采集工具的性能损耗，我们只需要打开开关，过滤出你所关心的 App 对应的数据，即可进行问题的分析与归因。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/22/2215fb4a224014ae31a78507993741e5.png\" /></p><p></p><p>那么我们如何访问这些数据？有些同学可能会猜测，既然是内核数据，是不是就需要获取越狱权限才行？其实不然，Apple 早已经为我们开启了后门服务，大家先记住这个端口号，62078，这个端口曾经也被黑客当作漏洞一样使用，但它就是达摩克利斯之剑，既是漏洞，也是福利，它主要的能力也类似于 adb，如同 adb 一样，我们在 ESB 建立连接并试用后就可以通过 Socket 通信进行数据访问了，而这个后门服务目前已经在业内的各大开源库中正常使用，如比较有名的 mobiledevice、 Facebook 的 idb，以及阿里的 tidevice 都在使用这个后门进行数据通信。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2c/2c6ac187a8c7e8009bacf5e55b464acd.png\" /></p><p></p><p>接下来我们简单看一下这个后门服务是如何运转的。通信之前，我们首先得建立连接，在 Mac上使用的是 USDMuxd 这个服务进行数据通信，USDMuxd 本质是 USB 协议上的一个多路 TCP 连接，既将 USB 抽象成 TCP 通信，使用它，我们可以通过 Socket 与设备进行连接，连接有了，接下来我们看看消息是发到哪里才能被设备响应的？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/bc/bc5e8896e577698aa3669d24074563d7.png\" /></p><p></p><p>这里首先介绍一下 Lockdownd 这个守护进程，简单理解，你可以把它类比成手机端接收远程消息的一个网关，拦截各种非法消息，在 System 路径下我们可以找到 Lockdownd 这个 Plist 描述文件，可见 Lockdownd 这个守护进程会创建一个端口号为 62078 的 TCP Socket，也就是前文中提及的那个后门的端口号，有了这个 Socket 以及端口号，我们就可以发送消息了，但具体发送什么消息才算合法的？设想一下，如果是你设计这个通信方案，你需要远程执行一些设备端的能力，你的消息体会包含哪些信息？</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/16/1610c4bab1f1891aa12efec1ec0f2f10.png\" /></p><p></p><p>我们需要的是类名、方法名和具体的参数，当然苹果也是这么设计的，这里通过捕获两个手机端的堆栈可以看到，第一个堆栈是 DTXMessage 用来解析 Buffer 消息，而第二个堆栈是 DTXMessage invokeWithTarget，这个 API 是否很像消息转发的 API？通过堆栈可以看到 DTXMessage 最后执行了 Running Processes 这个能力，既获取当前设备的活跃进程信息，我们只要知道这个 DTXMessage 数据格式就能发送对应的消息了，而这个数据格式目前在开源库中都已经提供出来了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/2e/2e15e5bf9cbd76360c968b209eeee106.png\" /></p><p></p><p>有了通道，有了所发消息的格式，最后我们就来看一下消息发送之后，手机端是如何响应的，大家都知道 iPhone 升级系统之后 XCode 需要添加对应设备的 Device Support 才能继续调试，有没有想过这个 Device Support 是干吗的？这边展开来看可以发现里面有大量的私有库，通过名字我们可以大胆的猜测，它就是 Instruments 和 GPU Tools 等工具的一些具体实现，它也就是前文中提及到的后门服务的具体实现，我们通过将这些 Image 挂载到手机上就能访问对应的一些能力了，这个设备重启之后，这些挂载的 Image 就会自动卸载，一定程度上也保障了iPhone 设备的安全性。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/3c/3c0e7e211d5dabf8b8a1f2ed0c07c7dd.png\" /></p><p></p><p>接着我们回顾一下通信的整个流程，首先我们会携带 ServiceID，发送 requestChannel 的消息，获取刚刚看到的各种 Framework 中 Class 与 Channel 的绑定关系，返回一个 Channel &nbsp; Code，这个 Channel Code 就是我们下次访问消息所需要的 Token 信息了，我们通过 Channel Code 再拼接我们刚才所说的 Selector 和 Arguments 的一些参数就能远程调用设备端的一些能力了，而设备那边执行完成之后，也会通过 Channel Code 返回执行的结果，从而完成一次完整的通讯链路，有了这个链路我们就能直接和内核层进行数据通信了。</p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/d9/d900a3f9abffe2b4b765da1859a199b6.png\" /></p><p></p><p>最后我们再回顾一下整体的流程图，当手机连接工具的时候，我们会将 Image 进行判断，并且挂载到手机上，挂载完成之后我们就能访问对应的后门服务了，我们通过这个后门服务能访问大量内核层的数据，将这些数据进行清洗封装之后，我们就能获得各个的指标数据，以及线程快照的一些数据了。</p><p></p><p></p><h2>总结回顾</h2><p></p><p></p><p><img src=\"https://static001.geekbang.org/wechat/images/c4/c43e086c8aebbcae662e9ef6f6dd1e29.png\" /></p><p></p><p>接着我们做一个简单的回顾，本次分享首先介绍了工具的发展史，并确定了工具的目标，然后我们分别从卡顿、内存、功耗三类场景介绍了归因提效的手段，以及如何使用 FastBot 提高数据生产的效率。最后我们通过火焰图的采集消费为例，介绍了使用 iOS 后门和 Ktrace 采集线程快照的基本原理。我们创作这个工具的初衷是让工具变得更简单，使归因不再有门槛。</p><p></p><p>最后感谢字节 AppHealth 以及各个业务方同学的技术方案以及落地实践，同时也感谢主办方以及老师的指导意见，以上所介绍的功能能力都源于字节内部的 Diggo 项目，目前也正在计划将这些能力以 Anytrace 的这个项目逐步提供给大家使用，感兴趣的同学可以关注一下，共同交流，谢谢大家。</p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href=\"https://xie.infoq.cn/article/7a822adfadc59c7101810b4a8\">2023 移动端技术探索</a>\"</p><p><a href=\"https://xie.infoq.cn/article/2ad19f040463045eb33331436\">移动跨端框架发展史及优劣对比</a>\"</p><p><a href=\"https://xie.infoq.cn/article/3a322a0ac1f41e6eff8d3bae2\">移动端动态更新背后的原理及技术原理</a>\"</p><p><a href=\"https://xie.infoq.cn/article/0771c328e638482548c5dee8f\">移动端浏览器性能优化探索</a>\"</p>",
    "publish_time": "2023-08-04 15:41:17",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  },
  {
    "title": "QCon 15 年特别策划：大语言模型如何给前端开发者带来新体验",
    "url": "https://www.infoq.cn/article/UOtFqmDXcoIgU1tmZbHE",
    "summary": "<p>编者按：这篇文章中的大部分内容是借助 AIGC 来完成的，基本的方式是在直播的时候，打开“钉钉闪记”开始音频同步转文字，直播结束后，将文字导出成 Word 文件。打开“文心一言”，选择“ChatFile”功能，将 Word 文件放进去，根据提示词生成直播访谈的摘要。最后，编辑再进行统一整理，加入 <a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=30zhibo&amp;utm_campaign=9&amp;utm_term=0804&amp;utm_content=airuikun\">QCon 北京站</a>\"的基本信息，包括票务信息。既然这是一个 AIGC 的时代，既然这次 QCon 北京站的主题是 AIGC 相关，咱们就从身边开始实践。若有不妥之处，请各位读者随时指出，咱们再修改。</p><p></p><h4>QCon 北京站大会当前进展</h4><p></p><p></p><p>先简单汇报一下目前 QCon 北京站的进展：截止到目前 QCon 全球软件开发大会（北京站）的内容进展已经到 50%，确认了三位联系主席，包括字节跳动基础架构、视频架构部门负责人赵鹏伟，京东集团副总裁、京东零售技术委员会主席尚鑫，以及百度智能云技术委员会主席王耀等。17 位出品人和 37 位讲师，包括最近确认的质谱 AI 的创始人兼 CEO 张鹏、华润雪花数字化转型负责人（CIO）郭华等。</p><p></p><h4>QCon 15 年特别策划缘起</h4><p></p><p></p><p>书归正传，今年是 QCon 进入中国 15 周年，作为 InfoQ 中国的创始人，也是把 QCon 引入到中国的“始作俑者”，霍太稳发起了“QCon 15 年”的这个特别策划。其目的是通过直播连麦的方式，在 9 月 3~5 日举行的<a href=\"https://qcon.infoq.cn/202309/beijing?utm_source=infoqweb&amp;utm_medium=30zhibo&amp;utm_campaign=9&amp;utm_term=0804&amp;utm_content=airuikun\">QCon 北京站</a>\"之前，每期邀请出品人或者讲师围绕一个主题来讨论该技术领域相关的内容，希望吸引更多的研发人员能够参与到这次大会中，持续对科技的发展抱有热情，持续为社会的进步贡献价值。</p><p></p><h4>大语言模型在腾讯新闻中的应用</h4><p></p><p></p><p>首期的直播，特别邀请到来自腾讯新闻的高级前端开发者艾瑞坤，就大语言模型如何给前端开发者带来全新的开发体验展开讨论。艾瑞坤的研究方向是前端，并在 2021 年已经开始研究大模型在前端中的应用。通过研究和学习，他们掌握了如何将图形识别转换为前端代码，并且发现大模型的出现帮助他们解决了许多难题，降低了门槛，让非专业人员也可以直接使用。同时，他们还提到了如何利用大模型实现智能风控、智能审核以及智能容灾等项目的自我完善，让线下线上的项目更加高效和自我完善。大模型的出现极大地降低了成本，让更多人能够快速实现自己的想法，为各个领域的发展带来了新的机遇。</p><p></p><p>在讨论新闻审核领域的应用时，艾瑞坤提到大模型在识别率方面已达到 70%，具有智能图形识别和智能更改等功能。他们正在研究如何更好地利用大模型，收集好的文章研究“提示词”的写法等。通过将好的文章和坏的文章放在一起研究，让机器学习审核方法和策略，最终达到 73% 的准确率，并可能将原来 1000 人的团队减少到 300 人，加上机器审核和 AI 智能审核就足够满足需要，实现了降本增效。同时也提到了可能存在一些特别词库或中文余料不充足等问题。</p><p></p><h4>人工智能一定会改变前端领域，也一定提升工作效能</h4><p></p><p></p><p>当然人工智能也不能解决所有问题，有用户提到人工智能将来会不会完全替代人，艾瑞坤指出审核人员、运营人员和文职人员受到 AI 的影响最大，而设计人员的卡点在于生成的图片无法直接转换成前端设计稿，导致还需要设计人员。霍太稳也提到说，未来可能不是减少技术人员或者设计人员，而是给这些工种的人赋予了更多的能力，让其在同样的时间里提升更多的效能。</p><p></p><p>毫无疑问，在大模型的应用下，前端领域将迎来变革。艾瑞坤表示，大模型将改变现有的开发模式，与可视化平台结合，实现更高级的效果。比如要构建一个网络平台，该平台使用不同原子组件搭建网站，可以让 AI 帮助拼接组件，根据用户需求个性化定制网站。这将对前端工程师的工作产生影响，使开发更加高效和灵活。</p><p></p><h4>QCon 北京站门票优惠信息</h4><p></p><p>在直播的最后，艾瑞坤提到了直播的这些内容，他会在 QCon 北京站的大会上做详细分享，这次因为时间原因，能分享的只是冰山一角，希望和大家能够在 QCon 大会现场做更多的交流。</p><p></p><p>在直播中，霍太稳提到说目前 QCon 北京站已经进入到最后一个月的冲刺阶段，9 月 3~5 日将在北京富力万丽酒店进行，现在购票，可以使用“Kevin-880”的优惠码直接享受目前的折扣之上再减一折的优惠。在报名的时候，可以直接进入<a href=\"https://qcon.infoq.cn/202309/beijing/apply?utm_source=infoqweb&amp;utm_medium=qcon15&amp;utm_campaign=9&amp;utm_term=0804&amp;utm_content=airuikun\">购票网页</a>\"，输入「优惠码」或者和票务经理 18514549229（微信同手机号）沟通。</p><p></p><p>QCon 15 年特别策划持续进行中，欢迎扫描下方二维码，前往「霍太稳」视频号进行直播预约。</p><p></p><p><img src=\"https://static001.geekbang.org/infoq/40/403168e42690ceea73a03e0d9ca994b2.jpeg\" /></p><p></p>",
    "publish_time": "2023-08-04 15:57:31",
    "source": {
      "name": "infoq_recommend",
      "desc": "InfoQ推荐",
      "icon": "https://raw.githubusercontent.com/maguowei/today/master/imgs/icon/infoq.png"
    }
  }
]